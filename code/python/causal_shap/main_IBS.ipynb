{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "from data_processing import DataProcessor\n",
    "from models import ModelTrainer\n",
    "from feature_selection import FeatureSelector\n",
    "from visualization import Visualizer\n",
    "from causal_inference import CausalInference\n",
    "import shap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from evaluation import calculate_metrics, iterative_feature_deletion_scores, iterative_feature_addition_scores, evaluate_global_shap_scores\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ML Pipeline...\n",
      "Base directory set to: ../../../\n",
      "Loading data...\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting ML Pipeline...\")\n",
    "base_dir = '../../../'\n",
    "print(f\"Base directory set to: {base_dir}\")\n",
    "\n",
    "data_path = base_dir + 'dataset/' + 'data_full.xlsx'\n",
    "raw_data_path = base_dir + 'dataset/' + 'result_raw.xlsx'\n",
    "result_dir = base_dir + 'result/'\n",
    "\n",
    "report_file_path = result_dir + 'report.txt'\n",
    "\n",
    "print(\"Loading data...\")\n",
    "data_processor = DataProcessor(data_path=str(data_path))\n",
    "df = data_processor.load_data_metabolites()\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing raw data...\n",
      "Raw data preprocessed successfully.\n",
      "Encoding labels...\n",
      "Labels encoded successfully.\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Model trained successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preprocessing raw data...\")\n",
    "raw_df = data_processor.preprocess_raw_data(raw_data_path=str(raw_data_path))\n",
    "print(\"Raw data preprocessed successfully.\")\n",
    "\n",
    "print(\"Encoding labels...\")\n",
    "df_encoded, label_encoder = data_processor.encode_labels(df, label_column='Group')\n",
    "print(\"Labels encoded successfully.\")\n",
    "\n",
    "X = df_encoded.drop(columns=['Group'])\n",
    "y = df_encoded['Group']\n",
    "\n",
    "print(\"Training Random Forest model...\")\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 7],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "model_trainer = ModelTrainer(X, y)\n",
    "model, best_params = model_trainer.train_random_forest(param_dist)\n",
    "print(\"Model trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "0.8378378378378378\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.54      0.70        26\n",
      "           1       0.80      1.00      0.89        48\n",
      "\n",
      "    accuracy                           0.84        74\n",
      "   macro avg       0.90      0.77      0.79        74\n",
      "weighted avg       0.87      0.84      0.82        74\n",
      "\n",
      "Model evaluation completed.\n",
      "Saving trained model...\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating model...\")\n",
    "accuracy, report = model_trainer.evaluate_model()\n",
    "print(accuracy)\n",
    "print(report)\n",
    "print(\"Model evaluation completed.\")\n",
    "\n",
    "print(\"Saving trained model...\")\n",
    "model_trainer.save_model(str(result_dir + 'best_random_forest_model.pkl'))\n",
    "print(\"Model saved successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities exported successfully to 'predicted_probabilities.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "predicted_probabilities = model.predict_proba(X)\n",
    "\n",
    "prob_df = pd.DataFrame(predicted_probabilities, columns=[f'Prob_Class_{i}' for i in range(predicted_probabilities.shape[1])])\n",
    "\n",
    "result_df = pd.concat([X.reset_index(drop=True), prob_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "result_df.to_excel('data_full_predicted_probabilities.xlsx', index=False)\n",
    "\n",
    "print(\"Predicted probabilities exported successfully to 'predicted_probabilities.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing feature selection using Gini importance...\n",
      "Top 30 features selected based on Gini importance:\n",
      "['xylose', 'xanthosine', 'valylglutamine', 'valine betaine', 'ursodeoxycholate sulfate (1)', 'uracil', 'tyrosine', 'tryptophylglycine', \"trigonelline (N'-methylnicotinate)\", 'tricarballylate', 'thymine', 'threonine', 'thiamin (Vitamin B1)', 'theobromine', 'syringic acid', 'succinimide', 'succinate', 'stearate (18:0)', 'stachydrine', 'sphingosine', 'serotonin', 'serine', 'salicylate', 'saccharin', 'ribulose/xylulose', 'riboflavin (Vitamin B2)', 'ribitol', 'quinolinate', 'quinate', 'pyroglutamine*']\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing feature selection using Gini importance...\")\n",
    "feature_selector = FeatureSelector(model, model_trainer.X_train)\n",
    "selected_features_gini = feature_selector.gini_importance(threshold=0.001)\n",
    "sorted_features = selected_features_gini.sort_values(ascending=False)\n",
    "\n",
    "top_30_features = sorted_features.head(30)\n",
    "\n",
    "print(\"Top 30 features selected based on Gini importance:\")\n",
    "print(top_30_features.to_list())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Predicted Probability for the PC to find Causal Edge that is directed to 'Group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "X = X[[\"xylose\", \"xanthosine\", \"uracil\", \"ribulose/xylulose\", \"valylglutamine\", \"tryptophylglycine\", \"succinate\", \"valine betaine\", \"ursodeoxycholate sulfate (1)\", \"tricarballylate\",\"succinimide\", \"thymine\", \"syringic acid\", \"serotonin\", \"ribitol\" ]]\n",
    "\n",
    "y = df_encoded['Group']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X),columns=X.columns,index=X.index)\n",
    "\n",
    "print(\"Training Random Forest model...\")\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 7],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "model_trainer = ModelTrainer(X, y)\n",
    "model, best_params = model_trainer.train_random_forest(param_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "0.8108108108108109\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.65      0.71        26\n",
      "           1       0.83      0.90      0.86        48\n",
      "\n",
      "    accuracy                           0.81        74\n",
      "   macro avg       0.80      0.77      0.78        74\n",
      "weighted avg       0.81      0.81      0.81        74\n",
      "\n",
      "Model evaluation completed.\n",
      "Saving trained model...\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating model...\")\n",
    "accuracy, report = model_trainer.evaluate_model()\n",
    "print(accuracy)\n",
    "print(report)\n",
    "print(\"Model evaluation completed.\")\n",
    "\n",
    "print(\"Saving trained model...\")\n",
    "model_trainer.save_model(str(result_dir + 'IBS_model.pkl'))\n",
    "print(\"Model saved successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SHAP for explainability...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://matplotlib_inline.backend_inline version unknown.\n",
      "DEBUG:matplotlib.pyplot:Loaded backend module://matplotlib_inline.backend_inline version unknown.\n",
      "DEBUG:matplotlib.font_manager:findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguiemj.ttf', name='Segoe UI Emoji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\timesi.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msjh.ttc', name='Microsoft JhengHei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CENTAUR.TTF', name='Centaur', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\timesbd.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GLECB.TTF', name='Gloucester MT Extra Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCK.TTF', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cambriaz.ttf', name='Cambria', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STSONG.TTF', name='STSong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\himalaya.ttf', name='Microsoft Himalaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\gadugib.ttf', name='Gadugi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2MKPB.TTF', name='HYPMokGak-Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuiz.ttf', name='Segoe UI', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRLNSDB.TTF', name='Berlin Sans FB Demi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\VINERITC.TTF', name='Viner Hand ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SitkaVF-Italic.ttf', name='Sitka', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msmincho.ttc', name='MS Mincho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2GTRM.TTF', name='HYGothic-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbelb.ttf', name='Corbel', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRADMCN.TTF', name='Franklin Gothic Demi Cond', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbel.ttf', name='Corbel', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MTEXTRA.TTF', name='MT Extra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoesc.ttf', name='Segoe Script', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\constani.ttf', name='Constantia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRLNSB.TTF', name='Berlin Sans FB', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_BI.TTF', name='Bodoni MT', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FREESCPT.TTF', name='Freestyle Script', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\WINGDNG2.TTF', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILSANUB.TTF', name='Gill Sans Ultra Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\taileb.ttf', name='Microsoft Tai Le', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FZSTK.TTF', name='FZShuTi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOUDYSTO.TTF', name='Goudy Stout', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\UDDigiKyokashoN-B.ttc', name='UD Digi Kyokasho N-B', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SegUIVar.ttf', name='Segoe UI Variable', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STXINGKA.TTF', name='STXingkai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\taile.ttf', name='Microsoft Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\JOKERMAN.TTF', name='Jokerman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simsunb.ttf', name='SimSun-ExtB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\comici.ttf', name='Comic Sans MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\RAGE.TTF', name='Rage Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\tahomabd.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Nirmala.ttf', name='Nirmala UI', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRADM.TTF', name='Franklin Gothic Demi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MAGNETOB.TTF', name='Magneto', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Deng.ttf', name='DengXian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\YuGothR.ttc', name='Yu Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\courbd.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HATTEN.TTF', name='Haettenschweiler', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\meiryob.ttc', name='Meiryo', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STHUPO.TTF', name='STHupo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segmdl2.ttf', name='Segoe MDL2 Assets', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCKEB.TTF', name='Rockwell Extra Bold', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cambriab.ttf', name='Cambria', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbelz.ttf', name='Corbel', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BIZ-UDMinchoM.ttc', name='BIZ UDMincho', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ANTQUAI.TTF', name='Book Antiqua', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SCHLBKI.TTF', name='Century Schoolbook', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\REFSAN.TTF', name='MS Reference Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOOKOSBI.TTF', name='Bookman Old Style', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LeelawUI.ttf', name='Leelawadee UI', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cambria.ttc', name='Cambria', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MOD20.TTF', name='Modern No. 20', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NIAGENG.TTF', name='Niagara Engraved', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STZHONGS.TTF', name='STZhongsong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BERNHC.TTF', name='Bernard MT Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_CR.TTF', name='Bodoni MT', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mvboli.ttf', name='MV Boli', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\malgun.ttf', name='Malgun Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ariali.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\COPRGTB.TTF', name='Copperplate Gothic Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PLAYBILL.TTF', name='Playbill', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\yumin.ttf', name='Yu Mincho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PALSCRI.TTF', name='Palace Script MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\constanb.ttf', name='Constantia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\georgiaz.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cour.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FTLTLT.TTF', name='Footlight MT Light', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2HDRM.TTF', name='HYHeadLine-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candara.ttf', name='Candara', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NGULIM.TTF', name='New Gulim', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ALGER.TTF', name='Algerian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_CB.TTF', name='Bodoni MT', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MATURASC.TTF', name='Matura MT Script Capitals', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\YuGothL.ttc', name='Yu Gothic', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PRISTINA.TTF', name='Pristina', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BKANT.TTF', name='Book Antiqua', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRITANIC.TTF', name='Britannic Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCB_____.TTF', name='Tw Cen MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\trebucbd.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_CI.TTF', name='Bodoni MT', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LATINWD.TTF', name='Wide Latin', style='normal', variant='normal', weight=400, stretch='expanded', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STENCIL.TTF', name='Stencil', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_CBI.TTF', name='Bodoni MT', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NirmalaS.ttf', name='Nirmala UI', style='normal', variant='normal', weight=350, stretch='normal', size='scalable')) = 10.0975\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MAIAN.TTF', name='Maiandra GD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LFAXD.TTF', name='Lucida Fax', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALISTB.TTF', name='Calisto MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCCEB.TTF', name='Tw Cen MT Condensed Extra Bold', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_PSTC.TTF', name='Bodoni MT', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2GSRB.TTF', name='HYGungSo-Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candarai.ttf', name='Candara', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PARCHM.TTF', name='Parchment', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\consolai.ttf', name='Consolas', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\KUNSTLER.TTF', name='Kunstler Script', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoescb.ttf', name='Segoe Script', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\DUBAI-REGULAR.TTF', name='Dubai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LSANSD.TTF', name='Lucida Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeui.ttf', name='Segoe UI', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRLNSR.TTF', name='Berlin Sans FB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbell.ttf', name='Corbel', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LHANDW.TTF', name='Lucida Handwriting', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BELL.TTF', name='Bell MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HARNGTON.TTF', name='Harrington', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMFMOLD.TTF', name='Yet R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mmrtextb.ttf', name='Myanmar Text', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CURLZ___.TTF', name='Curlz MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LTYPEO.TTF', name='Lucida Sans Typewriter', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\timesbi.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\kaiu.ttf', name='DFKai-SB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\arialbi.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GARABD.TTF', name='Garamond', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SNAP____.TTF', name='Snap ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRABKIT.TTF', name='Franklin Gothic Book', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRSCRIPT.TTF', name='French Script MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\COLONNA.TTF', name='Colonna MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CASTELAR.TTF', name='Castellar', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FORTE.TTF', name='Forte', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\georgiai.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\yumindb.ttf', name='Yu Mincho', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\VIVALDII.TTF', name='Vivaldi', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\trebucbi.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STXINWEI.TTF', name='STXinwei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BIZ-UDGothicB.ttc', name='BIZ UDGothic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Gabriola.ttf', name='Gabriola', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\IMPRISHA.TTF', name='Imprint MT Shadow', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuil.ttf', name='Segoe UI', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuisl.ttf', name='Segoe UI', style='normal', variant='normal', weight=350, stretch='normal', size='scalable')) = 10.0975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11486443  0.00215567 -0.00492032 ...  0.00259128  0.00904321\n",
      "   0.00863349]\n",
      " [ 0.10000743  0.00203317  0.00230973 ... -0.00419223  0.06047792\n",
      "  -0.04543462]\n",
      " [ 0.07868715 -0.00294276  0.00325913 ...  0.00361019  0.00143554\n",
      "  -0.00804236]\n",
      " ...\n",
      " [ 0.10458976 -0.00627233 -0.00065106 ...  0.00192314 -0.01925262\n",
      "   0.01460433]\n",
      " [-0.13420773 -0.01879415 -0.00743571 ... -0.02944572  0.10006502\n",
      "  -0.0198078 ]\n",
      " [-0.16033108  0.00603943  0.0112974  ... -0.00786244 -0.05561119\n",
      "  -0.02222319]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRAMDCN.TTF', name='Franklin Gothic Medium Cond', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ITCKRIST.TTF', name='Kristen ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HTOWERTI.TTF', name='High Tower Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALIFI.TTF', name='Californian FB', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STFANGSO.TTF', name='STFangsong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRUSHSCI.TTF', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\wingding.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILC____.TTF', name='Gill Sans MT Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\sylfaen.ttf', name='Sylfaen', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\verdanab.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GARAIT.TTF', name='Garamond', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\lucon.ttf', name='Lucida Console', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguisym.ttf', name='Segoe UI Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candarab.ttf', name='Candara', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMKMAMI.TTF', name='Ami R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOTHICI.TTF', name='Century Gothic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOTHICB.TTF', name='Century Gothic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMFMPYUN.TTF', name='Pyunji R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msyh.ttc', name='Microsoft YaHei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2SA1M.TTF', name='HYShortSamul-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CascadiaCode.ttf', name='Cascadia Code', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRAHVIT.TTF', name='Franklin Gothic Heavy', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_BLAR.TTF', name='Bodoni MT', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\micross.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BSSYM7.TTF', name='Bookshelf Symbol 7', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRADHITC.TTF', name='Bradley Hand ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARIALN.TTF', name='Arial', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 6.613636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CENTURY.TTF', name='Century', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\comic.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\verdanaz.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BIZ-UDGothicR.ttc', name='BIZ UDGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GARA.TTF', name='Garamond', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LeelaUIb.ttf', name='Leelawadee UI', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GLSNECB.TTF', name='Gill Sans MT Ext Condensed Bold', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCMI____.TTF', name='Tw Cen MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simkai.ttf', name='KaiTi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\framdit.ttf', name='Franklin Gothic Medium', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ANTQUAB.TTF', name='Book Antiqua', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguisb.ttf', name='Segoe UI', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERTILI.TTF', name='Perpetua Titling MT', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\OLDENGL.TTF', name='Old English Text MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ERASBD.TTF', name='Eras Bold ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HARLOWSI.TTF', name='Harlow Solid Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PAPYRUS.TTF', name='Papyrus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2PORL.TTF', name='HYPost-Light', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simfang.ttf', name='FangSong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SegoeIcons.ttf', name='Segoe Fluent Icons', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARLRDBD.TTF', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbeli.ttf', name='Corbel', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRADMIT.TTF', name='Franklin Gothic Demi', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\couri.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BASKVILL.TTF', name='Baskerville Old Face', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LFAXI.TTF', name='Lucida Fax', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\YuGothB.ttc', name='Yu Gothic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\pala.ttf', name='Palatino Linotype', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibrili.ttf', name='Calibri', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LSANSI.TTF', name='Lucida Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ERASMD.TTF', name='Eras Medium ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GIL_____.TTF', name='Gill Sans MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_BLAI.TTF', name='Bodoni MT', style='italic', variant='normal', weight=900, stretch='normal', size='scalable')) = 11.525\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ITCBLKAD.TTF', name='Blackadder ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2GPRM.TTF', name='HYGraphic-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOUDOSB.TTF', name='Goudy Old Style', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALISTBI.TTF', name='Calisto MT', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LSANSDI.TTF', name='Lucida Sans', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguisbi.ttf', name='Segoe UI', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\trebuc.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\VLADIMIR.TTF', name='Vladimir Script', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbelli.ttf', name='Corbel', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRABK.TTF', name='Franklin Gothic Book', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_I.TTF', name='Bodoni MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERTIBD.TTF', name='Perpetua Titling MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\JUICE___.TTF', name='Juice ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mingliub.ttc', name='MingLiU-ExtB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LCALLIG.TTF', name='Lucida Calligraphy', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMKMRHD.TTF', name='Headline R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\WINGDNG3.TTF', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_B.TTF', name='Bodoni MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ariblk.ttf', name='Arial', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 6.888636363636364\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HTOWERT.TTF', name='High Tower Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERI____.TTF', name='Perpetua', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LBRITEDI.TTF', name='Lucida Bright', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\georgiab.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALIST.TTF', name='Calisto MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibril.ttf', name='Calibri', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\yuminl.ttf', name='Yu Mincho', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2MJSM.TTF', name='HYSinMyeongJo-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NirmalaB.ttf', name='Nirmala UI', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\DUBAI-LIGHT.TTF', name='Dubai', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msjhbd.ttc', name='Microsoft JhengHei', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BELLI.TTF', name='Bell MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguili.ttf', name='Segoe UI', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARIALNB.TTF', name='Arial', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 6.8986363636363635\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SIMYOU.TTF', name='YouYuan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARIALNBI.TTF', name='Arial', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 7.8986363636363635\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LBRITED.TTF', name='Lucida Bright', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\OCRAEXT.TTF', name='OCR A Extended', style='normal', variant='normal', weight=400, stretch='expanded', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeprb.ttf', name='Segoe Print', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\arialbd.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOTHIC.TTF', name='Century Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibriz.ttf', name='Calibri', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msyi.ttf', name='Microsoft Yi Baiti', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\holomdl2.ttf', name='HoloLens MDL2 Assets', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\monbaiti.ttf', name='Mongolian Baiti', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\DUBAI-BOLD.TTF', name='Dubai', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\trebucit.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2GTRE.TTF', name='HYGothic-Extra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LBRITE.TTF', name='Lucida Bright', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARIALNI.TTF', name='Arial', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 7.613636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SitkaVF.ttf', name='Sitka', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\palab.ttf', name='Palatino Linotype', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STLITI.TTF', name='STLiti', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\COOPBL.TTF', name='Cooper Black', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCCB___.TTF', name='Rockwell Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOOKOSI.TTF', name='Bookman Old Style', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILI____.TTF', name='Gill Sans MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mmrtext.ttf', name='Myanmar Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STCAIYUN.TTF', name='STCaiyun', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\times.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALIFR.TTF', name='Californian FB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERBI___.TTF', name='Perpetua', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SCHLBKBI.TTF', name='Century Schoolbook', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_R.TTF', name='Bodoni MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BROADW.TTF', name='Broadway', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\OUTLOOK.TTF', name='MS Outlook', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LSANS.TTF', name='Lucida Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCCB____.TTF', name='Tw Cen MT Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GIGI.TTF', name='Gigi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LBRITEI.TTF', name='Lucida Bright', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\framd.ttf', name='Franklin Gothic Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOUDOS.TTF', name='Goudy Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CENSCBK.TTF', name='Century Schoolbook', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ntailu.ttf', name='Microsoft New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\AGENCYB.TTF', name='Agency FB', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ERASDEMI.TTF', name='Eras Demi ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOOKOSB.TTF', name='Bookman Old Style', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LTYPEBO.TTF', name='Lucida Sans Typewriter', style='oblique', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCM_____.TTF', name='Tw Cen MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SCHLBKB.TTF', name='Century Schoolbook', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCC____.TTF', name='Rockwell Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibrii.ttf', name='Calibri', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuib.ttf', name='Segoe UI', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\comicz.ttf', name='Comic Sans MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Dengb.ttf', name='DengXian', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOOKOS.TTF', name='Bookman Old Style', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguibl.ttf', name='Segoe UI', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILBI___.TTF', name='Gill Sans MT', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2PORM.TTF', name='HYPost-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\javatext.ttf', name='Javanese Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMFMMUEX.TTC', name='MoeumT R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCBI____.TTF', name='Tw Cen MT', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\REFSPCL.TTF', name='MS Reference Specialty', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ntailub.ttf', name='Microsoft New Tai Lue', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\palai.ttf', name='Palatino Linotype', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\malgunbd.ttf', name='Malgun Gothic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TEMPSITC.TTF', name='Tempus Sans ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msgothic.ttc', name='MS Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ANTQUABI.TTF', name='Book Antiqua', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\bahnschrift.ttf', name='Bahnschrift', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BAUHS93.TTF', name='Bauhaus 93', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCKB.TTF', name='Rockwell', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOUDOSI.TTF', name='Goudy Old Style', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SCRIPTBL.TTF', name='Script MT Bold', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NIAGSOL.TTF', name='Niagara Solid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LeelUIsl.ttf', name='Leelawadee UI', style='normal', variant='normal', weight=350, stretch='normal', size='scalable')) = 10.0975\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\palabi.ttf', name='Palatino Linotype', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ERASLGHT.TTF', name='Eras Light ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mingliu.ttc', name='MingLiU', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALIFB.TTF', name='Californian FB', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msyhl.ttc', name='Microsoft YaHei', style='normal', variant='normal', weight=290, stretch='normal', size='scalable')) = 10.1545\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\verdanai.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\comicbd.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoepr.ttf', name='Segoe Print', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CHILLER.TTF', name='Chiller', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CascadiaMono.ttf', name='Cascadia Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\meiryo.ttc', name='Meiryo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Dengl.ttf', name='DengXian', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCKI.TTF', name='Rockwell', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ENGR.TTF', name='Engravers MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ebrima.ttf', name='Ebrima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\malgunsl.ttf', name='Malgun Gothic', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SHOWG.TTF', name='Showcard Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candaraz.ttf', name='Candara', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STKAITI.TTF', name='STKaiti', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCKBI.TTF', name='Rockwell', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LTYPE.TTF', name='Lucida Sans Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\AGENCYR.TTF', name='Agency FB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ITCEDSCR.TTF', name='Edwardian Script ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROGFonts-Regular.otf', name='ROG Fonts', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguibli.ttf', name='Segoe UI', style='italic', variant='normal', weight=900, stretch='normal', size='scalable')) = 11.525\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SIMLI.TTF', name='LiSu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\gadugi.ttf', name='Gadugi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibri.ttf', name='Calibri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguisli.ttf', name='Segoe UI', style='italic', variant='normal', weight=350, stretch='normal', size='scalable')) = 11.0975\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCCM____.TTF', name='Tw Cen MT Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguihis.ttf', name='Segoe UI Historic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PER_____.TTF', name='Perpetua', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALISTI.TTF', name='Calisto MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candaral.ttf', name='Candara', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BELLB.TTF', name='Bell MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\POORICH.TTF', name='Poor Richard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\consolaz.ttf', name='Consolas', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2MJRE.TTF', name='HYMyeongJo-Extra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STXIHEI.TTF', name='STXihei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msjhl.ttc', name='Microsoft JhengHei', style='normal', variant='normal', weight=290, stretch='normal', size='scalable')) = 10.1545\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\RAVIE.TTF', name='Ravie', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\YuGothM.ttc', name='Yu Gothic', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\constan.ttf', name='Constantia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERB____.TTF', name='Perpetua', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ebrimabd.ttf', name='Ebrima', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\COPRGTL.TTF', name='Copperplate Gothic Light', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Inkfree.ttf', name='Ink Free', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibrib.ttf', name='Calibri', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ELEPHNTI.TTF', name='Elephant', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\constanz.ttf', name='Constantia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuii.ttf', name='Segoe UI', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simsun.ttc', name='SimSun', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\l_10646.ttf', name='Lucida Sans Unicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LTYPEB.TTF', name='Lucida Sans Typewriter', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\phagspa.ttf', name='Microsoft PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ELEPHNT.TTF', name='Elephant', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FELIXTI.TTF', name='Felix Titling', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOTHICBI.TTF', name='Century Gothic', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\INFROMAN.TTF', name='Informal Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SansSerifCollection.ttf', name='Sans Serif Collection', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILLUBCD.TTF', name='Gill Sans Ultra Bold Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILB____.TTF', name='Gill Sans MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MTCORSVA.TTF', name='Monotype Corsiva', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LFAXDI.TTF', name='Lucida Fax', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MISTRAL.TTF', name='Mistral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\consolab.ttf', name='Consolas', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\consola.ttf', name='Consolas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LFAX.TTF', name='Lucida Fax', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cambriai.ttf', name='Cambria', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRAHV.TTF', name='Franklin Gothic Heavy', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMKMMAG.TTF', name='Magic R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candarali.ttf', name='Candara', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ONYX.TTF', name='Onyx', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\courbi.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\DUBAI-MEDIUM.TTF', name='Dubai', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\phagspab.ttf', name='Microsoft PhagsPa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\UDDigiKyokashoN-R.ttc', name='UD Digi Kyokasho N-R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msyhbd.ttc', name='Microsoft YaHei', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FZYTK.TTF', name='FZYaoTi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simhei.ttf', name='SimHei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans.ttf') with score of 0.050000.\n",
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.FixedLocator object at 0x000001EE47F1BFE0>\n",
      "DEBUG:matplotlib.font_manager:findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=11.0.\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguiemj.ttf', name='Segoe UI Emoji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\timesi.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msjh.ttc', name='Microsoft JhengHei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CENTAUR.TTF', name='Centaur', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\timesbd.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GLECB.TTF', name='Gloucester MT Extra Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCK.TTF', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cambriaz.ttf', name='Cambria', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STSONG.TTF', name='STSong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\himalaya.ttf', name='Microsoft Himalaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\gadugib.ttf', name='Gadugi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2MKPB.TTF', name='HYPMokGak-Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuiz.ttf', name='Segoe UI', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRLNSDB.TTF', name='Berlin Sans FB Demi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\VINERITC.TTF', name='Viner Hand ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SitkaVF-Italic.ttf', name='Sitka', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msmincho.ttc', name='MS Mincho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2GTRM.TTF', name='HYGothic-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbelb.ttf', name='Corbel', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRADMCN.TTF', name='Franklin Gothic Demi Cond', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbel.ttf', name='Corbel', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MTEXTRA.TTF', name='MT Extra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoesc.ttf', name='Segoe Script', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\constani.ttf', name='Constantia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRLNSB.TTF', name='Berlin Sans FB', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_BI.TTF', name='Bodoni MT', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FREESCPT.TTF', name='Freestyle Script', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\WINGDNG2.TTF', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILSANUB.TTF', name='Gill Sans Ultra Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\taileb.ttf', name='Microsoft Tai Le', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FZSTK.TTF', name='FZShuTi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOUDYSTO.TTF', name='Goudy Stout', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\UDDigiKyokashoN-B.ttc', name='UD Digi Kyokasho N-B', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SegUIVar.ttf', name='Segoe UI Variable', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STXINGKA.TTF', name='STXingkai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\taile.ttf', name='Microsoft Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\JOKERMAN.TTF', name='Jokerman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simsunb.ttf', name='SimSun-ExtB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\comici.ttf', name='Comic Sans MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\RAGE.TTF', name='Rage Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\tahomabd.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Nirmala.ttf', name='Nirmala UI', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRADM.TTF', name='Franklin Gothic Demi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MAGNETOB.TTF', name='Magneto', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Deng.ttf', name='DengXian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\YuGothR.ttc', name='Yu Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\courbd.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HATTEN.TTF', name='Haettenschweiler', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\meiryob.ttc', name='Meiryo', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STHUPO.TTF', name='STHupo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segmdl2.ttf', name='Segoe MDL2 Assets', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCKEB.TTF', name='Rockwell Extra Bold', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cambriab.ttf', name='Cambria', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbelz.ttf', name='Corbel', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BIZ-UDMinchoM.ttc', name='BIZ UDMincho', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ANTQUAI.TTF', name='Book Antiqua', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SCHLBKI.TTF', name='Century Schoolbook', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\REFSAN.TTF', name='MS Reference Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOOKOSBI.TTF', name='Bookman Old Style', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LeelawUI.ttf', name='Leelawadee UI', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cambria.ttc', name='Cambria', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MOD20.TTF', name='Modern No. 20', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NIAGENG.TTF', name='Niagara Engraved', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STZHONGS.TTF', name='STZhongsong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BERNHC.TTF', name='Bernard MT Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_CR.TTF', name='Bodoni MT', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mvboli.ttf', name='MV Boli', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\malgun.ttf', name='Malgun Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ariali.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\COPRGTB.TTF', name='Copperplate Gothic Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PLAYBILL.TTF', name='Playbill', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\yumin.ttf', name='Yu Mincho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PALSCRI.TTF', name='Palace Script MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\constanb.ttf', name='Constantia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\georgiaz.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cour.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FTLTLT.TTF', name='Footlight MT Light', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2HDRM.TTF', name='HYHeadLine-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candara.ttf', name='Candara', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NGULIM.TTF', name='New Gulim', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ALGER.TTF', name='Algerian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_CB.TTF', name='Bodoni MT', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MATURASC.TTF', name='Matura MT Script Capitals', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\YuGothL.ttc', name='Yu Gothic', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PRISTINA.TTF', name='Pristina', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BKANT.TTF', name='Book Antiqua', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRITANIC.TTF', name='Britannic Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCB_____.TTF', name='Tw Cen MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\trebucbd.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_CI.TTF', name='Bodoni MT', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LATINWD.TTF', name='Wide Latin', style='normal', variant='normal', weight=400, stretch='expanded', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STENCIL.TTF', name='Stencil', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_CBI.TTF', name='Bodoni MT', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NirmalaS.ttf', name='Nirmala UI', style='normal', variant='normal', weight=350, stretch='normal', size='scalable')) = 10.0975\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MAIAN.TTF', name='Maiandra GD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LFAXD.TTF', name='Lucida Fax', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALISTB.TTF', name='Calisto MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCCEB.TTF', name='Tw Cen MT Condensed Extra Bold', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_PSTC.TTF', name='Bodoni MT', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2GSRB.TTF', name='HYGungSo-Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candarai.ttf', name='Candara', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PARCHM.TTF', name='Parchment', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\consolai.ttf', name='Consolas', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\KUNSTLER.TTF', name='Kunstler Script', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoescb.ttf', name='Segoe Script', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\DUBAI-REGULAR.TTF', name='Dubai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LSANSD.TTF', name='Lucida Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeui.ttf', name='Segoe UI', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRLNSR.TTF', name='Berlin Sans FB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbell.ttf', name='Corbel', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LHANDW.TTF', name='Lucida Handwriting', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BELL.TTF', name='Bell MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HARNGTON.TTF', name='Harrington', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMFMOLD.TTF', name='Yet R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mmrtextb.ttf', name='Myanmar Text', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CURLZ___.TTF', name='Curlz MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LTYPEO.TTF', name='Lucida Sans Typewriter', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\timesbi.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\kaiu.ttf', name='DFKai-SB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\arialbi.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GARABD.TTF', name='Garamond', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SNAP____.TTF', name='Snap ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRABKIT.TTF', name='Franklin Gothic Book', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRSCRIPT.TTF', name='French Script MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\COLONNA.TTF', name='Colonna MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CASTELAR.TTF', name='Castellar', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FORTE.TTF', name='Forte', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\georgiai.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\yumindb.ttf', name='Yu Mincho', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\VIVALDII.TTF', name='Vivaldi', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\trebucbi.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STXINWEI.TTF', name='STXinwei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BIZ-UDGothicB.ttc', name='BIZ UDGothic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Gabriola.ttf', name='Gabriola', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\IMPRISHA.TTF', name='Imprint MT Shadow', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuil.ttf', name='Segoe UI', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuisl.ttf', name='Segoe UI', style='normal', variant='normal', weight=350, stretch='normal', size='scalable')) = 10.0975\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRAMDCN.TTF', name='Franklin Gothic Medium Cond', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ITCKRIST.TTF', name='Kristen ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HTOWERTI.TTF', name='High Tower Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALIFI.TTF', name='Californian FB', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STFANGSO.TTF', name='STFangsong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRUSHSCI.TTF', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\wingding.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILC____.TTF', name='Gill Sans MT Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\sylfaen.ttf', name='Sylfaen', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\verdanab.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GARAIT.TTF', name='Garamond', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\lucon.ttf', name='Lucida Console', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguisym.ttf', name='Segoe UI Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candarab.ttf', name='Candara', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMKMAMI.TTF', name='Ami R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOTHICI.TTF', name='Century Gothic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOTHICB.TTF', name='Century Gothic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMFMPYUN.TTF', name='Pyunji R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msyh.ttc', name='Microsoft YaHei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2SA1M.TTF', name='HYShortSamul-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CascadiaCode.ttf', name='Cascadia Code', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRAHVIT.TTF', name='Franklin Gothic Heavy', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_BLAR.TTF', name='Bodoni MT', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\micross.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BSSYM7.TTF', name='Bookshelf Symbol 7', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRADHITC.TTF', name='Bradley Hand ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARIALN.TTF', name='Arial', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 6.613636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CENTURY.TTF', name='Century', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\comic.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\verdanaz.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BIZ-UDGothicR.ttc', name='BIZ UDGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GARA.TTF', name='Garamond', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LeelaUIb.ttf', name='Leelawadee UI', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GLSNECB.TTF', name='Gill Sans MT Ext Condensed Bold', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCMI____.TTF', name='Tw Cen MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simkai.ttf', name='KaiTi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\framdit.ttf', name='Franklin Gothic Medium', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ANTQUAB.TTF', name='Book Antiqua', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguisb.ttf', name='Segoe UI', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERTILI.TTF', name='Perpetua Titling MT', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\OLDENGL.TTF', name='Old English Text MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ERASBD.TTF', name='Eras Bold ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HARLOWSI.TTF', name='Harlow Solid Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PAPYRUS.TTF', name='Papyrus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2PORL.TTF', name='HYPost-Light', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simfang.ttf', name='FangSong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SegoeIcons.ttf', name='Segoe Fluent Icons', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARLRDBD.TTF', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbeli.ttf', name='Corbel', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRADMIT.TTF', name='Franklin Gothic Demi', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\couri.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BASKVILL.TTF', name='Baskerville Old Face', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LFAXI.TTF', name='Lucida Fax', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\YuGothB.ttc', name='Yu Gothic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\pala.ttf', name='Palatino Linotype', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibrili.ttf', name='Calibri', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LSANSI.TTF', name='Lucida Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ERASMD.TTF', name='Eras Medium ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GIL_____.TTF', name='Gill Sans MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_BLAI.TTF', name='Bodoni MT', style='italic', variant='normal', weight=900, stretch='normal', size='scalable')) = 11.525\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ITCBLKAD.TTF', name='Blackadder ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2GPRM.TTF', name='HYGraphic-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOUDOSB.TTF', name='Goudy Old Style', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALISTBI.TTF', name='Calisto MT', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LSANSDI.TTF', name='Lucida Sans', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguisbi.ttf', name='Segoe UI', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\trebuc.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\VLADIMIR.TTF', name='Vladimir Script', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbelli.ttf', name='Corbel', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRABK.TTF', name='Franklin Gothic Book', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_I.TTF', name='Bodoni MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERTIBD.TTF', name='Perpetua Titling MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\JUICE___.TTF', name='Juice ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mingliub.ttc', name='MingLiU-ExtB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LCALLIG.TTF', name='Lucida Calligraphy', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMKMRHD.TTF', name='Headline R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\WINGDNG3.TTF', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_B.TTF', name='Bodoni MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ariblk.ttf', name='Arial', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 6.888636363636364\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HTOWERT.TTF', name='High Tower Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERI____.TTF', name='Perpetua', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LBRITEDI.TTF', name='Lucida Bright', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\georgiab.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALIST.TTF', name='Calisto MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibril.ttf', name='Calibri', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\yuminl.ttf', name='Yu Mincho', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2MJSM.TTF', name='HYSinMyeongJo-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NirmalaB.ttf', name='Nirmala UI', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\DUBAI-LIGHT.TTF', name='Dubai', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msjhbd.ttc', name='Microsoft JhengHei', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BELLI.TTF', name='Bell MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguili.ttf', name='Segoe UI', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARIALNB.TTF', name='Arial', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 6.8986363636363635\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SIMYOU.TTF', name='YouYuan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARIALNBI.TTF', name='Arial', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 7.8986363636363635\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LBRITED.TTF', name='Lucida Bright', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\OCRAEXT.TTF', name='OCR A Extended', style='normal', variant='normal', weight=400, stretch='expanded', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeprb.ttf', name='Segoe Print', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\arialbd.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOTHIC.TTF', name='Century Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibriz.ttf', name='Calibri', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msyi.ttf', name='Microsoft Yi Baiti', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\holomdl2.ttf', name='HoloLens MDL2 Assets', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\monbaiti.ttf', name='Mongolian Baiti', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\DUBAI-BOLD.TTF', name='Dubai', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\trebucit.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2GTRE.TTF', name='HYGothic-Extra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LBRITE.TTF', name='Lucida Bright', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARIALNI.TTF', name='Arial', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 7.613636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SitkaVF.ttf', name='Sitka', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\palab.ttf', name='Palatino Linotype', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STLITI.TTF', name='STLiti', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\COOPBL.TTF', name='Cooper Black', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCCB___.TTF', name='Rockwell Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOOKOSI.TTF', name='Bookman Old Style', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILI____.TTF', name='Gill Sans MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mmrtext.ttf', name='Myanmar Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STCAIYUN.TTF', name='STCaiyun', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\times.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALIFR.TTF', name='Californian FB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERBI___.TTF', name='Perpetua', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SCHLBKBI.TTF', name='Century Schoolbook', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_R.TTF', name='Bodoni MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BROADW.TTF', name='Broadway', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\OUTLOOK.TTF', name='MS Outlook', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LSANS.TTF', name='Lucida Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCCB____.TTF', name='Tw Cen MT Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GIGI.TTF', name='Gigi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LBRITEI.TTF', name='Lucida Bright', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\framd.ttf', name='Franklin Gothic Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOUDOS.TTF', name='Goudy Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CENSCBK.TTF', name='Century Schoolbook', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ntailu.ttf', name='Microsoft New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\AGENCYB.TTF', name='Agency FB', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ERASDEMI.TTF', name='Eras Demi ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOOKOSB.TTF', name='Bookman Old Style', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LTYPEBO.TTF', name='Lucida Sans Typewriter', style='oblique', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCM_____.TTF', name='Tw Cen MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SCHLBKB.TTF', name='Century Schoolbook', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCC____.TTF', name='Rockwell Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibrii.ttf', name='Calibri', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuib.ttf', name='Segoe UI', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\comicz.ttf', name='Comic Sans MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Dengb.ttf', name='DengXian', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOOKOS.TTF', name='Bookman Old Style', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguibl.ttf', name='Segoe UI', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILBI___.TTF', name='Gill Sans MT', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2PORM.TTF', name='HYPost-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\javatext.ttf', name='Javanese Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMFMMUEX.TTC', name='MoeumT R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCBI____.TTF', name='Tw Cen MT', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\REFSPCL.TTF', name='MS Reference Specialty', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ntailub.ttf', name='Microsoft New Tai Lue', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\palai.ttf', name='Palatino Linotype', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\malgunbd.ttf', name='Malgun Gothic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TEMPSITC.TTF', name='Tempus Sans ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msgothic.ttc', name='MS Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ANTQUABI.TTF', name='Book Antiqua', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\bahnschrift.ttf', name='Bahnschrift', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BAUHS93.TTF', name='Bauhaus 93', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCKB.TTF', name='Rockwell', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOUDOSI.TTF', name='Goudy Old Style', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SCRIPTBL.TTF', name='Script MT Bold', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NIAGSOL.TTF', name='Niagara Solid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LeelUIsl.ttf', name='Leelawadee UI', style='normal', variant='normal', weight=350, stretch='normal', size='scalable')) = 10.0975\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\palabi.ttf', name='Palatino Linotype', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ERASLGHT.TTF', name='Eras Light ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mingliu.ttc', name='MingLiU', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALIFB.TTF', name='Californian FB', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msyhl.ttc', name='Microsoft YaHei', style='normal', variant='normal', weight=290, stretch='normal', size='scalable')) = 10.1545\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\verdanai.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\comicbd.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoepr.ttf', name='Segoe Print', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CHILLER.TTF', name='Chiller', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CascadiaMono.ttf', name='Cascadia Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\meiryo.ttc', name='Meiryo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Dengl.ttf', name='DengXian', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCKI.TTF', name='Rockwell', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ENGR.TTF', name='Engravers MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ebrima.ttf', name='Ebrima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\malgunsl.ttf', name='Malgun Gothic', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SHOWG.TTF', name='Showcard Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candaraz.ttf', name='Candara', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STKAITI.TTF', name='STKaiti', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCKBI.TTF', name='Rockwell', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LTYPE.TTF', name='Lucida Sans Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\AGENCYR.TTF', name='Agency FB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ITCEDSCR.TTF', name='Edwardian Script ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROGFonts-Regular.otf', name='ROG Fonts', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguibli.ttf', name='Segoe UI', style='italic', variant='normal', weight=900, stretch='normal', size='scalable')) = 11.525\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SIMLI.TTF', name='LiSu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\gadugi.ttf', name='Gadugi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibri.ttf', name='Calibri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguisli.ttf', name='Segoe UI', style='italic', variant='normal', weight=350, stretch='normal', size='scalable')) = 11.0975\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCCM____.TTF', name='Tw Cen MT Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguihis.ttf', name='Segoe UI Historic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PER_____.TTF', name='Perpetua', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALISTI.TTF', name='Calisto MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candaral.ttf', name='Candara', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BELLB.TTF', name='Bell MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\POORICH.TTF', name='Poor Richard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\consolaz.ttf', name='Consolas', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2MJRE.TTF', name='HYMyeongJo-Extra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STXIHEI.TTF', name='STXihei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msjhl.ttc', name='Microsoft JhengHei', style='normal', variant='normal', weight=290, stretch='normal', size='scalable')) = 10.1545\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\RAVIE.TTF', name='Ravie', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\YuGothM.ttc', name='Yu Gothic', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\constan.ttf', name='Constantia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERB____.TTF', name='Perpetua', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ebrimabd.ttf', name='Ebrima', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\COPRGTL.TTF', name='Copperplate Gothic Light', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Inkfree.ttf', name='Ink Free', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibrib.ttf', name='Calibri', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ELEPHNTI.TTF', name='Elephant', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\constanz.ttf', name='Constantia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuii.ttf', name='Segoe UI', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simsun.ttc', name='SimSun', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\l_10646.ttf', name='Lucida Sans Unicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LTYPEB.TTF', name='Lucida Sans Typewriter', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\phagspa.ttf', name='Microsoft PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ELEPHNT.TTF', name='Elephant', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FELIXTI.TTF', name='Felix Titling', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOTHICBI.TTF', name='Century Gothic', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\INFROMAN.TTF', name='Informal Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SansSerifCollection.ttf', name='Sans Serif Collection', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILLUBCD.TTF', name='Gill Sans Ultra Bold Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILB____.TTF', name='Gill Sans MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MTCORSVA.TTF', name='Monotype Corsiva', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LFAXDI.TTF', name='Lucida Fax', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MISTRAL.TTF', name='Mistral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\consolab.ttf', name='Consolas', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\consola.ttf', name='Consolas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LFAX.TTF', name='Lucida Fax', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cambriai.ttf', name='Cambria', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRAHV.TTF', name='Franklin Gothic Heavy', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMKMMAG.TTF', name='Magic R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candarali.ttf', name='Candara', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ONYX.TTF', name='Onyx', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\courbi.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\DUBAI-MEDIUM.TTF', name='Dubai', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\phagspab.ttf', name='Microsoft PhagsPa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\UDDigiKyokashoN-R.ttc', name='UD Digi Kyokasho N-R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msyhbd.ttc', name='Microsoft YaHei', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FZYTK.TTF', name='FZYaoTi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simhei.ttf', name='SimHei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=11.0 to DejaVu Sans ('c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans.ttf') with score of 0.050000.\n",
      "DEBUG:matplotlib.font_manager:findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=13.0.\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguiemj.ttf', name='Segoe UI Emoji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\timesi.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msjh.ttc', name='Microsoft JhengHei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CENTAUR.TTF', name='Centaur', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\timesbd.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GLECB.TTF', name='Gloucester MT Extra Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCK.TTF', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cambriaz.ttf', name='Cambria', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STSONG.TTF', name='STSong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\himalaya.ttf', name='Microsoft Himalaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\gadugib.ttf', name='Gadugi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2MKPB.TTF', name='HYPMokGak-Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuiz.ttf', name='Segoe UI', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRLNSDB.TTF', name='Berlin Sans FB Demi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\VINERITC.TTF', name='Viner Hand ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SitkaVF-Italic.ttf', name='Sitka', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msmincho.ttc', name='MS Mincho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2GTRM.TTF', name='HYGothic-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbelb.ttf', name='Corbel', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRADMCN.TTF', name='Franklin Gothic Demi Cond', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbel.ttf', name='Corbel', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MTEXTRA.TTF', name='MT Extra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoesc.ttf', name='Segoe Script', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\constani.ttf', name='Constantia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRLNSB.TTF', name='Berlin Sans FB', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_BI.TTF', name='Bodoni MT', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FREESCPT.TTF', name='Freestyle Script', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\WINGDNG2.TTF', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILSANUB.TTF', name='Gill Sans Ultra Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\taileb.ttf', name='Microsoft Tai Le', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FZSTK.TTF', name='FZShuTi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOUDYSTO.TTF', name='Goudy Stout', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\UDDigiKyokashoN-B.ttc', name='UD Digi Kyokasho N-B', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SegUIVar.ttf', name='Segoe UI Variable', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STXINGKA.TTF', name='STXingkai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\taile.ttf', name='Microsoft Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\JOKERMAN.TTF', name='Jokerman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simsunb.ttf', name='SimSun-ExtB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\comici.ttf', name='Comic Sans MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\RAGE.TTF', name='Rage Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\tahomabd.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Nirmala.ttf', name='Nirmala UI', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRADM.TTF', name='Franklin Gothic Demi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MAGNETOB.TTF', name='Magneto', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Deng.ttf', name='DengXian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\YuGothR.ttc', name='Yu Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\courbd.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HATTEN.TTF', name='Haettenschweiler', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\meiryob.ttc', name='Meiryo', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STHUPO.TTF', name='STHupo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segmdl2.ttf', name='Segoe MDL2 Assets', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCKEB.TTF', name='Rockwell Extra Bold', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cambriab.ttf', name='Cambria', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbelz.ttf', name='Corbel', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BIZ-UDMinchoM.ttc', name='BIZ UDMincho', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ANTQUAI.TTF', name='Book Antiqua', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SCHLBKI.TTF', name='Century Schoolbook', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\REFSAN.TTF', name='MS Reference Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOOKOSBI.TTF', name='Bookman Old Style', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LeelawUI.ttf', name='Leelawadee UI', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cambria.ttc', name='Cambria', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MOD20.TTF', name='Modern No. 20', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NIAGENG.TTF', name='Niagara Engraved', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STZHONGS.TTF', name='STZhongsong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BERNHC.TTF', name='Bernard MT Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_CR.TTF', name='Bodoni MT', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mvboli.ttf', name='MV Boli', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\malgun.ttf', name='Malgun Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ariali.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\COPRGTB.TTF', name='Copperplate Gothic Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PLAYBILL.TTF', name='Playbill', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\yumin.ttf', name='Yu Mincho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PALSCRI.TTF', name='Palace Script MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\constanb.ttf', name='Constantia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\georgiaz.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cour.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FTLTLT.TTF', name='Footlight MT Light', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2HDRM.TTF', name='HYHeadLine-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candara.ttf', name='Candara', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NGULIM.TTF', name='New Gulim', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ALGER.TTF', name='Algerian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_CB.TTF', name='Bodoni MT', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MATURASC.TTF', name='Matura MT Script Capitals', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\YuGothL.ttc', name='Yu Gothic', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PRISTINA.TTF', name='Pristina', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BKANT.TTF', name='Book Antiqua', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRITANIC.TTF', name='Britannic Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCB_____.TTF', name='Tw Cen MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\trebucbd.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_CI.TTF', name='Bodoni MT', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LATINWD.TTF', name='Wide Latin', style='normal', variant='normal', weight=400, stretch='expanded', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STENCIL.TTF', name='Stencil', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_CBI.TTF', name='Bodoni MT', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NirmalaS.ttf', name='Nirmala UI', style='normal', variant='normal', weight=350, stretch='normal', size='scalable')) = 10.0975\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MAIAN.TTF', name='Maiandra GD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LFAXD.TTF', name='Lucida Fax', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALISTB.TTF', name='Calisto MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCCEB.TTF', name='Tw Cen MT Condensed Extra Bold', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_PSTC.TTF', name='Bodoni MT', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2GSRB.TTF', name='HYGungSo-Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candarai.ttf', name='Candara', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PARCHM.TTF', name='Parchment', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\consolai.ttf', name='Consolas', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\KUNSTLER.TTF', name='Kunstler Script', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoescb.ttf', name='Segoe Script', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\DUBAI-REGULAR.TTF', name='Dubai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LSANSD.TTF', name='Lucida Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeui.ttf', name='Segoe UI', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRLNSR.TTF', name='Berlin Sans FB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbell.ttf', name='Corbel', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LHANDW.TTF', name='Lucida Handwriting', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BELL.TTF', name='Bell MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HARNGTON.TTF', name='Harrington', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMFMOLD.TTF', name='Yet R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mmrtextb.ttf', name='Myanmar Text', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CURLZ___.TTF', name='Curlz MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LTYPEO.TTF', name='Lucida Sans Typewriter', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\timesbi.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\kaiu.ttf', name='DFKai-SB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\arialbi.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GARABD.TTF', name='Garamond', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SNAP____.TTF', name='Snap ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRABKIT.TTF', name='Franklin Gothic Book', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRSCRIPT.TTF', name='French Script MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\COLONNA.TTF', name='Colonna MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CASTELAR.TTF', name='Castellar', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FORTE.TTF', name='Forte', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\georgiai.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\yumindb.ttf', name='Yu Mincho', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\VIVALDII.TTF', name='Vivaldi', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\trebucbi.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STXINWEI.TTF', name='STXinwei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BIZ-UDGothicB.ttc', name='BIZ UDGothic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Gabriola.ttf', name='Gabriola', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\IMPRISHA.TTF', name='Imprint MT Shadow', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuil.ttf', name='Segoe UI', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuisl.ttf', name='Segoe UI', style='normal', variant='normal', weight=350, stretch='normal', size='scalable')) = 10.0975\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRAMDCN.TTF', name='Franklin Gothic Medium Cond', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ITCKRIST.TTF', name='Kristen ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HTOWERTI.TTF', name='High Tower Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALIFI.TTF', name='Californian FB', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STFANGSO.TTF', name='STFangsong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRUSHSCI.TTF', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\wingding.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILC____.TTF', name='Gill Sans MT Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\sylfaen.ttf', name='Sylfaen', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\verdanab.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GARAIT.TTF', name='Garamond', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\lucon.ttf', name='Lucida Console', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguisym.ttf', name='Segoe UI Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candarab.ttf', name='Candara', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMKMAMI.TTF', name='Ami R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOTHICI.TTF', name='Century Gothic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOTHICB.TTF', name='Century Gothic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMFMPYUN.TTF', name='Pyunji R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msyh.ttc', name='Microsoft YaHei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2SA1M.TTF', name='HYShortSamul-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CascadiaCode.ttf', name='Cascadia Code', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRAHVIT.TTF', name='Franklin Gothic Heavy', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_BLAR.TTF', name='Bodoni MT', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\micross.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BSSYM7.TTF', name='Bookshelf Symbol 7', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRADHITC.TTF', name='Bradley Hand ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARIALN.TTF', name='Arial', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 6.613636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CENTURY.TTF', name='Century', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\comic.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\verdanaz.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BIZ-UDGothicR.ttc', name='BIZ UDGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GARA.TTF', name='Garamond', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LeelaUIb.ttf', name='Leelawadee UI', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GLSNECB.TTF', name='Gill Sans MT Ext Condensed Bold', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCMI____.TTF', name='Tw Cen MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simkai.ttf', name='KaiTi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\framdit.ttf', name='Franklin Gothic Medium', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ANTQUAB.TTF', name='Book Antiqua', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguisb.ttf', name='Segoe UI', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERTILI.TTF', name='Perpetua Titling MT', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\OLDENGL.TTF', name='Old English Text MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ERASBD.TTF', name='Eras Bold ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HARLOWSI.TTF', name='Harlow Solid Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PAPYRUS.TTF', name='Papyrus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2PORL.TTF', name='HYPost-Light', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simfang.ttf', name='FangSong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SegoeIcons.ttf', name='Segoe Fluent Icons', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARLRDBD.TTF', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbeli.ttf', name='Corbel', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRADMIT.TTF', name='Franklin Gothic Demi', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\couri.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BASKVILL.TTF', name='Baskerville Old Face', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LFAXI.TTF', name='Lucida Fax', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\YuGothB.ttc', name='Yu Gothic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\pala.ttf', name='Palatino Linotype', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibrili.ttf', name='Calibri', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LSANSI.TTF', name='Lucida Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ERASMD.TTF', name='Eras Medium ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GIL_____.TTF', name='Gill Sans MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_BLAI.TTF', name='Bodoni MT', style='italic', variant='normal', weight=900, stretch='normal', size='scalable')) = 11.525\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ITCBLKAD.TTF', name='Blackadder ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2GPRM.TTF', name='HYGraphic-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOUDOSB.TTF', name='Goudy Old Style', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALISTBI.TTF', name='Calisto MT', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LSANSDI.TTF', name='Lucida Sans', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguisbi.ttf', name='Segoe UI', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\trebuc.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\VLADIMIR.TTF', name='Vladimir Script', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbelli.ttf', name='Corbel', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRABK.TTF', name='Franklin Gothic Book', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_I.TTF', name='Bodoni MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERTIBD.TTF', name='Perpetua Titling MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\JUICE___.TTF', name='Juice ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mingliub.ttc', name='MingLiU-ExtB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LCALLIG.TTF', name='Lucida Calligraphy', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMKMRHD.TTF', name='Headline R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\WINGDNG3.TTF', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_B.TTF', name='Bodoni MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ariblk.ttf', name='Arial', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 6.888636363636364\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HTOWERT.TTF', name='High Tower Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERI____.TTF', name='Perpetua', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LBRITEDI.TTF', name='Lucida Bright', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\georgiab.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALIST.TTF', name='Calisto MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibril.ttf', name='Calibri', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\yuminl.ttf', name='Yu Mincho', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2MJSM.TTF', name='HYSinMyeongJo-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NirmalaB.ttf', name='Nirmala UI', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\DUBAI-LIGHT.TTF', name='Dubai', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msjhbd.ttc', name='Microsoft JhengHei', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BELLI.TTF', name='Bell MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguili.ttf', name='Segoe UI', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARIALNB.TTF', name='Arial', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 6.8986363636363635\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SIMYOU.TTF', name='YouYuan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARIALNBI.TTF', name='Arial', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 7.8986363636363635\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LBRITED.TTF', name='Lucida Bright', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\OCRAEXT.TTF', name='OCR A Extended', style='normal', variant='normal', weight=400, stretch='expanded', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeprb.ttf', name='Segoe Print', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\arialbd.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOTHIC.TTF', name='Century Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibriz.ttf', name='Calibri', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msyi.ttf', name='Microsoft Yi Baiti', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\holomdl2.ttf', name='HoloLens MDL2 Assets', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\monbaiti.ttf', name='Mongolian Baiti', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\DUBAI-BOLD.TTF', name='Dubai', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\trebucit.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2GTRE.TTF', name='HYGothic-Extra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LBRITE.TTF', name='Lucida Bright', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARIALNI.TTF', name='Arial', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 7.613636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SitkaVF.ttf', name='Sitka', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\palab.ttf', name='Palatino Linotype', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STLITI.TTF', name='STLiti', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\COOPBL.TTF', name='Cooper Black', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCCB___.TTF', name='Rockwell Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOOKOSI.TTF', name='Bookman Old Style', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILI____.TTF', name='Gill Sans MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mmrtext.ttf', name='Myanmar Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STCAIYUN.TTF', name='STCaiyun', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\times.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALIFR.TTF', name='Californian FB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERBI___.TTF', name='Perpetua', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SCHLBKBI.TTF', name='Century Schoolbook', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_R.TTF', name='Bodoni MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BROADW.TTF', name='Broadway', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\OUTLOOK.TTF', name='MS Outlook', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LSANS.TTF', name='Lucida Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCCB____.TTF', name='Tw Cen MT Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GIGI.TTF', name='Gigi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LBRITEI.TTF', name='Lucida Bright', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\framd.ttf', name='Franklin Gothic Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOUDOS.TTF', name='Goudy Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CENSCBK.TTF', name='Century Schoolbook', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ntailu.ttf', name='Microsoft New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\AGENCYB.TTF', name='Agency FB', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ERASDEMI.TTF', name='Eras Demi ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOOKOSB.TTF', name='Bookman Old Style', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LTYPEBO.TTF', name='Lucida Sans Typewriter', style='oblique', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCM_____.TTF', name='Tw Cen MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SCHLBKB.TTF', name='Century Schoolbook', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCC____.TTF', name='Rockwell Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibrii.ttf', name='Calibri', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuib.ttf', name='Segoe UI', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\comicz.ttf', name='Comic Sans MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Dengb.ttf', name='DengXian', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOOKOS.TTF', name='Bookman Old Style', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguibl.ttf', name='Segoe UI', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILBI___.TTF', name='Gill Sans MT', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2PORM.TTF', name='HYPost-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\javatext.ttf', name='Javanese Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMFMMUEX.TTC', name='MoeumT R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCBI____.TTF', name='Tw Cen MT', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\REFSPCL.TTF', name='MS Reference Specialty', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ntailub.ttf', name='Microsoft New Tai Lue', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\palai.ttf', name='Palatino Linotype', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\malgunbd.ttf', name='Malgun Gothic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TEMPSITC.TTF', name='Tempus Sans ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msgothic.ttc', name='MS Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ANTQUABI.TTF', name='Book Antiqua', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\bahnschrift.ttf', name='Bahnschrift', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BAUHS93.TTF', name='Bauhaus 93', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCKB.TTF', name='Rockwell', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOUDOSI.TTF', name='Goudy Old Style', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SCRIPTBL.TTF', name='Script MT Bold', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NIAGSOL.TTF', name='Niagara Solid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LeelUIsl.ttf', name='Leelawadee UI', style='normal', variant='normal', weight=350, stretch='normal', size='scalable')) = 10.0975\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\palabi.ttf', name='Palatino Linotype', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ERASLGHT.TTF', name='Eras Light ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mingliu.ttc', name='MingLiU', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALIFB.TTF', name='Californian FB', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msyhl.ttc', name='Microsoft YaHei', style='normal', variant='normal', weight=290, stretch='normal', size='scalable')) = 10.1545\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\verdanai.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\comicbd.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoepr.ttf', name='Segoe Print', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CHILLER.TTF', name='Chiller', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CascadiaMono.ttf', name='Cascadia Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\meiryo.ttc', name='Meiryo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Dengl.ttf', name='DengXian', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCKI.TTF', name='Rockwell', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ENGR.TTF', name='Engravers MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ebrima.ttf', name='Ebrima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\malgunsl.ttf', name='Malgun Gothic', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SHOWG.TTF', name='Showcard Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candaraz.ttf', name='Candara', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STKAITI.TTF', name='STKaiti', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCKBI.TTF', name='Rockwell', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LTYPE.TTF', name='Lucida Sans Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\AGENCYR.TTF', name='Agency FB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ITCEDSCR.TTF', name='Edwardian Script ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROGFonts-Regular.otf', name='ROG Fonts', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguibli.ttf', name='Segoe UI', style='italic', variant='normal', weight=900, stretch='normal', size='scalable')) = 11.525\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SIMLI.TTF', name='LiSu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\gadugi.ttf', name='Gadugi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibri.ttf', name='Calibri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguisli.ttf', name='Segoe UI', style='italic', variant='normal', weight=350, stretch='normal', size='scalable')) = 11.0975\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCCM____.TTF', name='Tw Cen MT Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguihis.ttf', name='Segoe UI Historic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PER_____.TTF', name='Perpetua', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALISTI.TTF', name='Calisto MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candaral.ttf', name='Candara', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BELLB.TTF', name='Bell MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\POORICH.TTF', name='Poor Richard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\consolaz.ttf', name='Consolas', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2MJRE.TTF', name='HYMyeongJo-Extra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STXIHEI.TTF', name='STXihei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msjhl.ttc', name='Microsoft JhengHei', style='normal', variant='normal', weight=290, stretch='normal', size='scalable')) = 10.1545\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\RAVIE.TTF', name='Ravie', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\YuGothM.ttc', name='Yu Gothic', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\constan.ttf', name='Constantia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERB____.TTF', name='Perpetua', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ebrimabd.ttf', name='Ebrima', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\COPRGTL.TTF', name='Copperplate Gothic Light', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Inkfree.ttf', name='Ink Free', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibrib.ttf', name='Calibri', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ELEPHNTI.TTF', name='Elephant', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\constanz.ttf', name='Constantia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuii.ttf', name='Segoe UI', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simsun.ttc', name='SimSun', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\l_10646.ttf', name='Lucida Sans Unicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LTYPEB.TTF', name='Lucida Sans Typewriter', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\phagspa.ttf', name='Microsoft PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ELEPHNT.TTF', name='Elephant', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FELIXTI.TTF', name='Felix Titling', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOTHICBI.TTF', name='Century Gothic', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\INFROMAN.TTF', name='Informal Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SansSerifCollection.ttf', name='Sans Serif Collection', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILLUBCD.TTF', name='Gill Sans Ultra Bold Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILB____.TTF', name='Gill Sans MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MTCORSVA.TTF', name='Monotype Corsiva', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LFAXDI.TTF', name='Lucida Fax', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MISTRAL.TTF', name='Mistral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\consolab.ttf', name='Consolas', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\consola.ttf', name='Consolas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LFAX.TTF', name='Lucida Fax', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cambriai.ttf', name='Cambria', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRAHV.TTF', name='Franklin Gothic Heavy', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMKMMAG.TTF', name='Magic R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candarali.ttf', name='Candara', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ONYX.TTF', name='Onyx', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\courbi.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\DUBAI-MEDIUM.TTF', name='Dubai', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\phagspab.ttf', name='Microsoft PhagsPa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\UDDigiKyokashoN-R.ttc', name='UD Digi Kyokasho N-R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msyhbd.ttc', name='Microsoft YaHei', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FZYTK.TTF', name='FZYaoTi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simhei.ttf', name='SimHei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=13.0 to DejaVu Sans ('c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans.ttf') with score of 0.050000.\n",
      "DEBUG:matplotlib.font_manager:findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguiemj.ttf', name='Segoe UI Emoji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\timesi.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msjh.ttc', name='Microsoft JhengHei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CENTAUR.TTF', name='Centaur', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\timesbd.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GLECB.TTF', name='Gloucester MT Extra Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCK.TTF', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cambriaz.ttf', name='Cambria', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STSONG.TTF', name='STSong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\himalaya.ttf', name='Microsoft Himalaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\gadugib.ttf', name='Gadugi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2MKPB.TTF', name='HYPMokGak-Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuiz.ttf', name='Segoe UI', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRLNSDB.TTF', name='Berlin Sans FB Demi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\VINERITC.TTF', name='Viner Hand ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SitkaVF-Italic.ttf', name='Sitka', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msmincho.ttc', name='MS Mincho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2GTRM.TTF', name='HYGothic-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbelb.ttf', name='Corbel', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRADMCN.TTF', name='Franklin Gothic Demi Cond', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbel.ttf', name='Corbel', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MTEXTRA.TTF', name='MT Extra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoesc.ttf', name='Segoe Script', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\constani.ttf', name='Constantia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRLNSB.TTF', name='Berlin Sans FB', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_BI.TTF', name='Bodoni MT', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FREESCPT.TTF', name='Freestyle Script', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\WINGDNG2.TTF', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILSANUB.TTF', name='Gill Sans Ultra Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\taileb.ttf', name='Microsoft Tai Le', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FZSTK.TTF', name='FZShuTi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOUDYSTO.TTF', name='Goudy Stout', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\UDDigiKyokashoN-B.ttc', name='UD Digi Kyokasho N-B', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SegUIVar.ttf', name='Segoe UI Variable', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STXINGKA.TTF', name='STXingkai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\taile.ttf', name='Microsoft Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\JOKERMAN.TTF', name='Jokerman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simsunb.ttf', name='SimSun-ExtB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\comici.ttf', name='Comic Sans MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\RAGE.TTF', name='Rage Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\tahomabd.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Nirmala.ttf', name='Nirmala UI', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRADM.TTF', name='Franklin Gothic Demi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MAGNETOB.TTF', name='Magneto', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Deng.ttf', name='DengXian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\YuGothR.ttc', name='Yu Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\courbd.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HATTEN.TTF', name='Haettenschweiler', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\meiryob.ttc', name='Meiryo', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STHUPO.TTF', name='STHupo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segmdl2.ttf', name='Segoe MDL2 Assets', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCKEB.TTF', name='Rockwell Extra Bold', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cambriab.ttf', name='Cambria', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbelz.ttf', name='Corbel', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BIZ-UDMinchoM.ttc', name='BIZ UDMincho', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ANTQUAI.TTF', name='Book Antiqua', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SCHLBKI.TTF', name='Century Schoolbook', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\REFSAN.TTF', name='MS Reference Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOOKOSBI.TTF', name='Bookman Old Style', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LeelawUI.ttf', name='Leelawadee UI', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cambria.ttc', name='Cambria', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MOD20.TTF', name='Modern No. 20', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NIAGENG.TTF', name='Niagara Engraved', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STZHONGS.TTF', name='STZhongsong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BERNHC.TTF', name='Bernard MT Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_CR.TTF', name='Bodoni MT', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mvboli.ttf', name='MV Boli', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\malgun.ttf', name='Malgun Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ariali.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\COPRGTB.TTF', name='Copperplate Gothic Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PLAYBILL.TTF', name='Playbill', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\yumin.ttf', name='Yu Mincho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PALSCRI.TTF', name='Palace Script MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\constanb.ttf', name='Constantia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\georgiaz.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cour.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FTLTLT.TTF', name='Footlight MT Light', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2HDRM.TTF', name='HYHeadLine-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candara.ttf', name='Candara', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NGULIM.TTF', name='New Gulim', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ALGER.TTF', name='Algerian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_CB.TTF', name='Bodoni MT', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MATURASC.TTF', name='Matura MT Script Capitals', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\YuGothL.ttc', name='Yu Gothic', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PRISTINA.TTF', name='Pristina', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BKANT.TTF', name='Book Antiqua', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRITANIC.TTF', name='Britannic Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCB_____.TTF', name='Tw Cen MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\trebucbd.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_CI.TTF', name='Bodoni MT', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LATINWD.TTF', name='Wide Latin', style='normal', variant='normal', weight=400, stretch='expanded', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STENCIL.TTF', name='Stencil', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_CBI.TTF', name='Bodoni MT', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NirmalaS.ttf', name='Nirmala UI', style='normal', variant='normal', weight=350, stretch='normal', size='scalable')) = 10.0975\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MAIAN.TTF', name='Maiandra GD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LFAXD.TTF', name='Lucida Fax', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALISTB.TTF', name='Calisto MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCCEB.TTF', name='Tw Cen MT Condensed Extra Bold', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_PSTC.TTF', name='Bodoni MT', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2GSRB.TTF', name='HYGungSo-Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candarai.ttf', name='Candara', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PARCHM.TTF', name='Parchment', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\consolai.ttf', name='Consolas', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\KUNSTLER.TTF', name='Kunstler Script', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoescb.ttf', name='Segoe Script', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\DUBAI-REGULAR.TTF', name='Dubai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LSANSD.TTF', name='Lucida Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeui.ttf', name='Segoe UI', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRLNSR.TTF', name='Berlin Sans FB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbell.ttf', name='Corbel', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LHANDW.TTF', name='Lucida Handwriting', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BELL.TTF', name='Bell MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HARNGTON.TTF', name='Harrington', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMFMOLD.TTF', name='Yet R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mmrtextb.ttf', name='Myanmar Text', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CURLZ___.TTF', name='Curlz MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LTYPEO.TTF', name='Lucida Sans Typewriter', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\timesbi.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\kaiu.ttf', name='DFKai-SB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\arialbi.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GARABD.TTF', name='Garamond', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SNAP____.TTF', name='Snap ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRABKIT.TTF', name='Franklin Gothic Book', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRSCRIPT.TTF', name='French Script MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\COLONNA.TTF', name='Colonna MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CASTELAR.TTF', name='Castellar', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FORTE.TTF', name='Forte', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\georgiai.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\yumindb.ttf', name='Yu Mincho', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\VIVALDII.TTF', name='Vivaldi', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\trebucbi.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STXINWEI.TTF', name='STXinwei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BIZ-UDGothicB.ttc', name='BIZ UDGothic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Gabriola.ttf', name='Gabriola', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\IMPRISHA.TTF', name='Imprint MT Shadow', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuil.ttf', name='Segoe UI', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuisl.ttf', name='Segoe UI', style='normal', variant='normal', weight=350, stretch='normal', size='scalable')) = 10.0975\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRAMDCN.TTF', name='Franklin Gothic Medium Cond', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ITCKRIST.TTF', name='Kristen ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HTOWERTI.TTF', name='High Tower Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALIFI.TTF', name='Californian FB', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STFANGSO.TTF', name='STFangsong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRUSHSCI.TTF', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\wingding.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILC____.TTF', name='Gill Sans MT Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\sylfaen.ttf', name='Sylfaen', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\verdanab.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GARAIT.TTF', name='Garamond', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\lucon.ttf', name='Lucida Console', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguisym.ttf', name='Segoe UI Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candarab.ttf', name='Candara', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMKMAMI.TTF', name='Ami R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOTHICI.TTF', name='Century Gothic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOTHICB.TTF', name='Century Gothic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMFMPYUN.TTF', name='Pyunji R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msyh.ttc', name='Microsoft YaHei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2SA1M.TTF', name='HYShortSamul-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CascadiaCode.ttf', name='Cascadia Code', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRAHVIT.TTF', name='Franklin Gothic Heavy', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_BLAR.TTF', name='Bodoni MT', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\micross.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BSSYM7.TTF', name='Bookshelf Symbol 7', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BRADHITC.TTF', name='Bradley Hand ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARIALN.TTF', name='Arial', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 6.613636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CENTURY.TTF', name='Century', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\comic.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\verdanaz.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BIZ-UDGothicR.ttc', name='BIZ UDGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GARA.TTF', name='Garamond', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LeelaUIb.ttf', name='Leelawadee UI', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GLSNECB.TTF', name='Gill Sans MT Ext Condensed Bold', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCMI____.TTF', name='Tw Cen MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simkai.ttf', name='KaiTi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\framdit.ttf', name='Franklin Gothic Medium', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ANTQUAB.TTF', name='Book Antiqua', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguisb.ttf', name='Segoe UI', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERTILI.TTF', name='Perpetua Titling MT', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\OLDENGL.TTF', name='Old English Text MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ERASBD.TTF', name='Eras Bold ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HARLOWSI.TTF', name='Harlow Solid Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PAPYRUS.TTF', name='Papyrus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2PORL.TTF', name='HYPost-Light', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simfang.ttf', name='FangSong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SegoeIcons.ttf', name='Segoe Fluent Icons', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARLRDBD.TTF', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbeli.ttf', name='Corbel', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRADMIT.TTF', name='Franklin Gothic Demi', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\couri.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BASKVILL.TTF', name='Baskerville Old Face', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LFAXI.TTF', name='Lucida Fax', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\YuGothB.ttc', name='Yu Gothic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\pala.ttf', name='Palatino Linotype', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibrili.ttf', name='Calibri', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LSANSI.TTF', name='Lucida Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ERASMD.TTF', name='Eras Medium ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GIL_____.TTF', name='Gill Sans MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_BLAI.TTF', name='Bodoni MT', style='italic', variant='normal', weight=900, stretch='normal', size='scalable')) = 11.525\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ITCBLKAD.TTF', name='Blackadder ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2GPRM.TTF', name='HYGraphic-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOUDOSB.TTF', name='Goudy Old Style', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALISTBI.TTF', name='Calisto MT', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LSANSDI.TTF', name='Lucida Sans', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguisbi.ttf', name='Segoe UI', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\trebuc.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\VLADIMIR.TTF', name='Vladimir Script', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\corbelli.ttf', name='Corbel', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRABK.TTF', name='Franklin Gothic Book', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_I.TTF', name='Bodoni MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERTIBD.TTF', name='Perpetua Titling MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\JUICE___.TTF', name='Juice ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mingliub.ttc', name='MingLiU-ExtB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LCALLIG.TTF', name='Lucida Calligraphy', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMKMRHD.TTF', name='Headline R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\WINGDNG3.TTF', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_B.TTF', name='Bodoni MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ariblk.ttf', name='Arial', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 6.888636363636364\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HTOWERT.TTF', name='High Tower Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERI____.TTF', name='Perpetua', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LBRITEDI.TTF', name='Lucida Bright', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\georgiab.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALIST.TTF', name='Calisto MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibril.ttf', name='Calibri', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\yuminl.ttf', name='Yu Mincho', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2MJSM.TTF', name='HYSinMyeongJo-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NirmalaB.ttf', name='Nirmala UI', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\DUBAI-LIGHT.TTF', name='Dubai', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msjhbd.ttc', name='Microsoft JhengHei', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BELLI.TTF', name='Bell MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguili.ttf', name='Segoe UI', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARIALNB.TTF', name='Arial', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 6.8986363636363635\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SIMYOU.TTF', name='YouYuan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARIALNBI.TTF', name='Arial', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 7.8986363636363635\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LBRITED.TTF', name='Lucida Bright', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\OCRAEXT.TTF', name='OCR A Extended', style='normal', variant='normal', weight=400, stretch='expanded', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeprb.ttf', name='Segoe Print', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\arialbd.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOTHIC.TTF', name='Century Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibriz.ttf', name='Calibri', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msyi.ttf', name='Microsoft Yi Baiti', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\holomdl2.ttf', name='HoloLens MDL2 Assets', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\monbaiti.ttf', name='Mongolian Baiti', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\DUBAI-BOLD.TTF', name='Dubai', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\trebucit.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2GTRE.TTF', name='HYGothic-Extra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LBRITE.TTF', name='Lucida Bright', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ARIALNI.TTF', name='Arial', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 7.613636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SitkaVF.ttf', name='Sitka', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\palab.ttf', name='Palatino Linotype', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STLITI.TTF', name='STLiti', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\COOPBL.TTF', name='Cooper Black', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCCB___.TTF', name='Rockwell Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOOKOSI.TTF', name='Bookman Old Style', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILI____.TTF', name='Gill Sans MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mmrtext.ttf', name='Myanmar Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STCAIYUN.TTF', name='STCaiyun', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\times.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALIFR.TTF', name='Californian FB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERBI___.TTF', name='Perpetua', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SCHLBKBI.TTF', name='Century Schoolbook', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOD_R.TTF', name='Bodoni MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BROADW.TTF', name='Broadway', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\OUTLOOK.TTF', name='MS Outlook', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LSANS.TTF', name='Lucida Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCCB____.TTF', name='Tw Cen MT Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GIGI.TTF', name='Gigi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LBRITEI.TTF', name='Lucida Bright', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\framd.ttf', name='Franklin Gothic Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOUDOS.TTF', name='Goudy Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CENSCBK.TTF', name='Century Schoolbook', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ntailu.ttf', name='Microsoft New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\AGENCYB.TTF', name='Agency FB', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ERASDEMI.TTF', name='Eras Demi ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOOKOSB.TTF', name='Bookman Old Style', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LTYPEBO.TTF', name='Lucida Sans Typewriter', style='oblique', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCM_____.TTF', name='Tw Cen MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SCHLBKB.TTF', name='Century Schoolbook', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCC____.TTF', name='Rockwell Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibrii.ttf', name='Calibri', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuib.ttf', name='Segoe UI', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\comicz.ttf', name='Comic Sans MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Dengb.ttf', name='DengXian', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BOOKOS.TTF', name='Bookman Old Style', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguibl.ttf', name='Segoe UI', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILBI___.TTF', name='Gill Sans MT', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2PORM.TTF', name='HYPost-Medium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\javatext.ttf', name='Javanese Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMFMMUEX.TTC', name='MoeumT R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCBI____.TTF', name='Tw Cen MT', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\REFSPCL.TTF', name='MS Reference Specialty', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ntailub.ttf', name='Microsoft New Tai Lue', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\palai.ttf', name='Palatino Linotype', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\malgunbd.ttf', name='Malgun Gothic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TEMPSITC.TTF', name='Tempus Sans ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msgothic.ttc', name='MS Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ANTQUABI.TTF', name='Book Antiqua', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\bahnschrift.ttf', name='Bahnschrift', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BAUHS93.TTF', name='Bauhaus 93', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCKB.TTF', name='Rockwell', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOUDOSI.TTF', name='Goudy Old Style', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SCRIPTBL.TTF', name='Script MT Bold', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\NIAGSOL.TTF', name='Niagara Solid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LeelUIsl.ttf', name='Leelawadee UI', style='normal', variant='normal', weight=350, stretch='normal', size='scalable')) = 10.0975\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\palabi.ttf', name='Palatino Linotype', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ERASLGHT.TTF', name='Eras Light ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\mingliu.ttc', name='MingLiU', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALIFB.TTF', name='Californian FB', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msyhl.ttc', name='Microsoft YaHei', style='normal', variant='normal', weight=290, stretch='normal', size='scalable')) = 10.1545\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\verdanai.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\comicbd.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoepr.ttf', name='Segoe Print', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CHILLER.TTF', name='Chiller', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CascadiaMono.ttf', name='Cascadia Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\meiryo.ttc', name='Meiryo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Dengl.ttf', name='DengXian', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCKI.TTF', name='Rockwell', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ENGR.TTF', name='Engravers MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ebrima.ttf', name='Ebrima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\malgunsl.ttf', name='Malgun Gothic', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SHOWG.TTF', name='Showcard Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candaraz.ttf', name='Candara', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STKAITI.TTF', name='STKaiti', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROCKBI.TTF', name='Rockwell', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LTYPE.TTF', name='Lucida Sans Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\AGENCYR.TTF', name='Agency FB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ITCEDSCR.TTF', name='Edwardian Script ITC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ROGFonts-Regular.otf', name='ROG Fonts', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguibli.ttf', name='Segoe UI', style='italic', variant='normal', weight=900, stretch='normal', size='scalable')) = 11.525\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SIMLI.TTF', name='LiSu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\gadugi.ttf', name='Gadugi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibri.ttf', name='Calibri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguisli.ttf', name='Segoe UI', style='italic', variant='normal', weight=350, stretch='normal', size='scalable')) = 11.0975\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\TCCM____.TTF', name='Tw Cen MT Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\seguihis.ttf', name='Segoe UI Historic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PER_____.TTF', name='Perpetua', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\CALISTI.TTF', name='Calisto MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candaral.ttf', name='Candara', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\BELLB.TTF', name='Bell MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\POORICH.TTF', name='Poor Richard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\consolaz.ttf', name='Consolas', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\H2MJRE.TTF', name='HYMyeongJo-Extra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\STXIHEI.TTF', name='STXihei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msjhl.ttc', name='Microsoft JhengHei', style='normal', variant='normal', weight=290, stretch='normal', size='scalable')) = 10.1545\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\RAVIE.TTF', name='Ravie', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\YuGothM.ttc', name='Yu Gothic', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\constan.ttf', name='Constantia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\PERB____.TTF', name='Perpetua', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ebrimabd.ttf', name='Ebrima', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\COPRGTL.TTF', name='Copperplate Gothic Light', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Inkfree.ttf', name='Ink Free', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\calibrib.ttf', name='Calibri', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ELEPHNTI.TTF', name='Elephant', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\constanz.ttf', name='Constantia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\segoeuii.ttf', name='Segoe UI', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simsun.ttc', name='SimSun', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\l_10646.ttf', name='Lucida Sans Unicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LTYPEB.TTF', name='Lucida Sans Typewriter', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\phagspa.ttf', name='Microsoft PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ELEPHNT.TTF', name='Elephant', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FELIXTI.TTF', name='Felix Titling', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GOTHICBI.TTF', name='Century Gothic', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\INFROMAN.TTF', name='Informal Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\SansSerifCollection.ttf', name='Sans Serif Collection', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILLUBCD.TTF', name='Gill Sans Ultra Bold Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\GILB____.TTF', name='Gill Sans MT', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MTCORSVA.TTF', name='Monotype Corsiva', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LFAXDI.TTF', name='Lucida Fax', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\MISTRAL.TTF', name='Mistral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\consolab.ttf', name='Consolas', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\consola.ttf', name='Consolas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\LFAX.TTF', name='Lucida Fax', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\cambriai.ttf', name='Cambria', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FRAHV.TTF', name='Franklin Gothic Heavy', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\HMKMMAG.TTF', name='Magic R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\Candarali.ttf', name='Candara', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\ONYX.TTF', name='Onyx', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\courbi.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\DUBAI-MEDIUM.TTF', name='Dubai', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\phagspab.ttf', name='Microsoft PhagsPa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\UDDigiKyokashoN-R.ttc', name='UD Digi Kyokasho N-R', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\msyhbd.ttc', name='Microsoft YaHei', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\FZYTK.TTF', name='FZYaoTi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(FontEntry(fname='C:\\\\Windows\\\\Fonts\\\\simhei.ttf', name='SimHei', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('c:\\\\Users\\\\snorl\\\\Desktop\\\\FYP\\\\venv\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans.ttf') with score of 0.050000.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x750 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Applying SHAP for explainability...\")\n",
    "\n",
    "# Use KMeans background data for SHAP Kernel Explainer\n",
    "explainer = shap.TreeExplainer(model, model_trainer.X_train)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(model_trainer.X_test)\n",
    "\n",
    "# Plot SHAP summary\n",
    "shap_values_class1 = shap_values[:, :, 1]  # Shape: (74, 30)\n",
    "print(shap_values_class1)\n",
    "shap.summary_plot(shap_values[:,:,1], model_trainer.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causal_inference import CausalInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Value: [0.35825431 0.64174569]\n",
      "Model prediction: 0.8782824507867614\n",
      "Sum of SHAP values + expected value: [0.59479107 0.87828245]\n",
      "SHAP sum matches the model prediction.\n"
     ]
    }
   ],
   "source": [
    "i = 0 # Example test instance\n",
    "# SHAP sum and model prediction comparison\n",
    "\n",
    "shap_sum = np.sum(shap_values[:][:][i][:,1]) + explainer.expected_value\n",
    "model_prediction = model.predict_proba(model_trainer.X_test.iloc[i].values.reshape(1, -1))[0][1]\n",
    "\n",
    "print(f\"Expected Value: {explainer.expected_value}\")\n",
    "\n",
    "print(f\"Model prediction: {model_prediction}\")\n",
    "print(f\"Sum of SHAP values + expected value: {shap_sum}\")\n",
    "\n",
    "if np.isclose(shap_sum[1], model_prediction, atol=1e-6):\n",
    "    print(\"SHAP sum matches the model prediction.\")\n",
    "else:\n",
    "    print(\"Discrepancy between SHAP sum and model prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Applying causal SHAP values...\")\n",
    "ci = CausalInference(data=model_trainer.X_train, model=model, target_variable='Prob_Class_1')\n",
    "ci.load_causal_strengths(result_dir + 'Mean_Causal_Effect_IBS.json')\n",
    "print(ci.gamma)\n",
    "X_train_scaled_df = pd.DataFrame(model_trainer.X_train, columns=model_trainer.X_train.columns)\n",
    "X_test_scaled_df = pd.DataFrame(model_trainer.X_test, columns=model_trainer.X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Causal SHAP Values:\n",
      "xylose: 0.13225397406207984\n",
      "xanthosine: -0.0029053634832192075\n",
      "uracil: 0.010855010703359426\n",
      "ribulose/xylulose: 0.12729433964303247\n",
      "valylglutamine: -0.0004056528330309809\n",
      "tryptophylglycine: 0.0010018551608491394\n",
      "succinate: 0.00584595653445039\n",
      "valine betaine: -0.002642197284198119\n",
      "ursodeoxycholate sulfate (1): -0.0001459521197652923\n",
      "tricarballylate: 0.00019075913178059008\n",
      "succinimide: 0.0037575690437436165\n",
      "thymine: 0.005118826204316526\n",
      "syringic acid: 0.000631230148497586\n",
      "serotonin: -0.01461428163472704\n",
      "ribitol: -0.0038996318229844347\n"
     ]
    }
   ],
   "source": [
    "x_instance = pd.Series(X_test_scaled_df.iloc[i], index=X_test_scaled_df.columns)\n",
    "phi_normalized = ci.compute_modified_shap_proba(x_instance)\n",
    "\n",
    "# Print modified SHAP values\n",
    "print(\"Modified Causal SHAP Values:\")\n",
    "for feature, value in phi_normalized.items():\n",
    "    print(f\"{feature}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Causal SHAP Values:\n",
      "xylose: 0.11311892270392937\n",
      "xanthosine: -0.001397362104218143\n",
      "uracil: -0.010857293780255952\n",
      "ribulose/xylulose: 0.1001839486248588\n",
      "valylglutamine: -0.0005100126588998503\n",
      "tryptophylglycine: -0.0007034691256101514\n",
      "succinate: -0.019074634629714073\n",
      "valine betaine: 0.0105829258159314\n",
      "ursodeoxycholate sulfate (1): -8.049816247962688e-05\n",
      "tricarballylate: 0.00025568023672479644\n",
      "succinimide: 0.0007743904165757363\n",
      "thymine: 0.009957546559174616\n",
      "syringic acid: 0.0005421396914991889\n",
      "serotonin: 0.05979818392746521\n",
      "ribitol: 0.0012993817383004785\n"
     ]
    }
   ],
   "source": [
    "i = 30\n",
    "x_instance = pd.Series(X_test_scaled_df.iloc[i], index=X_test_scaled_df.columns)\n",
    "phi_normalized = ci.compute_modified_shap_proba(x_instance)\n",
    "\n",
    "# Print modified SHAP values\n",
    "print(\"Modified Causal SHAP Values:\")\n",
    "for feature, value in phi_normalized.items():\n",
    "    print(f\"{feature}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance: 30\n",
      "Instance Predicted Value: [1]\n",
      "Comparing SHAP and Causal SHAP using feature deletion and addition...\n",
      "Average RMSE (Standard SHAP - Deletion): 0.18007532467532458\n",
      "Average RMSE (Causal SHAP - Deletion): 0.22204404761904759\n",
      "Average RMSE (Standard SHAP - Addition): 0.17516480880230884\n",
      "Average RMSE (Causal SHAP - Addition): 0.19388733766233773\n"
     ]
    }
   ],
   "source": [
    "# Compare standard SHAP and causal SHAP values\n",
    "standard_shap_series = pd.Series(shap_values[i][:,1], index=X_test_scaled_df.columns)\n",
    "causal_shap_series = pd.Series(phi_normalized, index=X_test_scaled_df.columns)\n",
    "y_predicted = model.predict(X_test_scaled_df.iloc[i].values.reshape(1, -1))\n",
    "print(f\"Instance: {i}\")\n",
    "print(f\"Instance Predicted Value: {y_predicted}\")\n",
    "\n",
    "# Apply iterative feature deletion and addition to compare SHAP values\n",
    "print(\"Comparing SHAP and Causal SHAP using feature deletion and addition...\")\n",
    "avg_output_standard_deletion = iterative_feature_deletion_with_rmse(\n",
    "    model=model, input_features=x_instance, attribution_scores=standard_shap_series, y_predicted=y_predicted, top_k=10)\n",
    "\n",
    "avg_output_causal_deletion = iterative_feature_deletion_with_rmse(\n",
    "    model=model, input_features=x_instance, attribution_scores=causal_shap_series, y_predicted=y_predicted, top_k=10)\n",
    "\n",
    "avg_output_standard_addition = iterative_feature_addition_with_rmse(\n",
    "    model=model, input_features=x_instance, attribution_scores=standard_shap_series, y_predicted=y_predicted, top_k=10)\n",
    "\n",
    "avg_output_causal_addition = iterative_feature_addition_with_rmse(\n",
    "    model=model, input_features=x_instance, attribution_scores=causal_shap_series, y_predicted=y_predicted, top_k=10)\n",
    "\n",
    "print(f\"Average RMSE (Standard SHAP - Deletion): {avg_output_standard_deletion}\")\n",
    "print(f\"Average RMSE (Causal SHAP - Deletion): {avg_output_causal_deletion}\")\n",
    "print(f\"Average RMSE (Standard SHAP - Addition): {avg_output_standard_addition}\")\n",
    "print(f\"Average RMSE (Causal SHAP - Addition): {avg_output_causal_addition}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBS Tree SHAP Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8020833333333333,\n",
      "                0.8397435897435898,\n",
      "                0.7131410256410257,\n",
      "                0.6145833333333333,\n",
      "                0.5737179487179487,\n",
      "                0.5817307692307693,\n",
      "                0.6033653846153846,\n",
      "                0.639423076923077,\n",
      "                0.6386217948717948,\n",
      "                0.6810897435897435,\n",
      "                0.6698717948717949,\n",
      "                0.6518429487179487,\n",
      "                0.7471955128205128,\n",
      "                0.6947115384615384,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5333619228350892,\n",
      "                0.5854290017917382,\n",
      "                0.7117184396839162,\n",
      "                0.7458745657755351,\n",
      "                0.7882211683938165,\n",
      "                0.81629281154797,\n",
      "                0.8012005518497218,\n",
      "                0.8247859609755421,\n",
      "                0.8603662885864408,\n",
      "                0.8846268030968748,\n",
      "                0.90505665912008,\n",
      "                0.9438895036052928,\n",
      "                0.9230942930370424,\n",
      "                0.942150054860188,\n",
      "                0.9272027411818561\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17575241929729749,\n",
      "                0.1986929523104957,\n",
      "                0.2597070037610788,\n",
      "                0.27604349501841946,\n",
      "                0.2965766383981693,\n",
      "                0.3094726358791318,\n",
      "                0.30258009664926755,\n",
      "                0.3135342847081855,\n",
      "                0.3291563975002879,\n",
      "                0.3395284163415068,\n",
      "                0.3484802117230528,\n",
      "                0.3641007792104075,\n",
      "                0.3560428205920232,\n",
      "                0.3635532888116729,\n",
      "                0.3581441230715909\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6634081196581196,\n",
      "            \"cross_entropy\": 0.8128847177560736,\n",
      "            \"brier\": 0.30609103755150585\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8565705128205129,\n",
      "                0.8325320512820513,\n",
      "                0.8445512820512819,\n",
      "                0.8878205128205128,\n",
      "                0.8782051282051282,\n",
      "                0.8838141025641025,\n",
      "                0.8814102564102564,\n",
      "                0.8741987179487178,\n",
      "                0.8822115384615383,\n",
      "                0.8766025641025641,\n",
      "                0.8733974358974359,\n",
      "                0.875801282051282,\n",
      "                0.8701923076923077,\n",
      "                0.875801282051282,\n",
      "                0.8782051282051282\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5577995700528187,\n",
      "                0.5201346733885938,\n",
      "                0.4655374628351458,\n",
      "                0.4380237734852441,\n",
      "                0.43838018080987795,\n",
      "                0.4360449867580237,\n",
      "                0.438763731824647,\n",
      "                0.44740492583735564,\n",
      "                0.4363295317869158,\n",
      "                0.4388482578823135,\n",
      "                0.44448749580700625,\n",
      "                0.4479181639936016,\n",
      "                0.4411853843562204,\n",
      "                0.43669113234623613,\n",
      "                0.43130759728033224\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18281475287193621,\n",
      "                0.16834113484809304,\n",
      "                0.145363733060362,\n",
      "                0.13537964233817612,\n",
      "                0.13578212969515902,\n",
      "                0.1345341998682114,\n",
      "                0.1350815524026615,\n",
      "                0.13934149317729566,\n",
      "                0.1352525686591906,\n",
      "                0.13748507467713983,\n",
      "                0.13943411012222015,\n",
      "                0.14046081786348746,\n",
      "                0.13793953188590014,\n",
      "                0.13646746105293178,\n",
      "                0.13441740529050694\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8714209401709403,\n",
      "            \"cross_entropy\": 0.4545904578962888,\n",
      "            \"brier\": 0.14253970718755146\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7875,\n",
      "                0.7458333333333332,\n",
      "                0.6716666666666666,\n",
      "                0.56,\n",
      "                0.5225,\n",
      "                0.495,\n",
      "                0.5275000000000001,\n",
      "                0.5741666666666667,\n",
      "                0.5783333333333334,\n",
      "                0.6258333333333334,\n",
      "                0.5991666666666667,\n",
      "                0.6058333333333333,\n",
      "                0.5204166666666666,\n",
      "                0.5454166666666667,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5893880935369175,\n",
      "                0.6939687843745195,\n",
      "                0.739482983649083,\n",
      "                0.8458936405573276,\n",
      "                0.8495144730423589,\n",
      "                0.887520711575678,\n",
      "                0.9373059843816347,\n",
      "                0.8598579037819417,\n",
      "                0.8939732945679326,\n",
      "                0.8995061653339594,\n",
      "                0.9145578564540002,\n",
      "                0.896320847839611,\n",
      "                0.9219070985617821,\n",
      "                0.9268913809609458,\n",
      "                0.9404186671352546\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.20014143968821002,\n",
      "                0.25060080888344277,\n",
      "                0.27206466693271686,\n",
      "                0.3204676327258146,\n",
      "                0.32196771724375156,\n",
      "                0.33903050572789073,\n",
      "                0.36022320636546296,\n",
      "                0.32889035475869166,\n",
      "                0.3442630343753096,\n",
      "                0.3469030473976222,\n",
      "                0.35334002172356127,\n",
      "                0.34556837299259124,\n",
      "                0.35703636063854377,\n",
      "                0.3591017801705773,\n",
      "                0.3649649438114703\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.5906111111111111,\n",
      "            \"cross_entropy\": 0.8531005257168631,\n",
      "            \"brier\": 0.324304259562377\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7708333333333334,\n",
      "                0.7929166666666666,\n",
      "                0.8283333333333333,\n",
      "                0.8591666666666667,\n",
      "                0.8508333333333333,\n",
      "                0.8458333333333334,\n",
      "                0.8333333333333334,\n",
      "                0.8108333333333333,\n",
      "                0.8108333333333333,\n",
      "                0.8116666666666666,\n",
      "                0.8116666666666666,\n",
      "                0.8116666666666665,\n",
      "                0.8275,\n",
      "                0.8400000000000001,\n",
      "                0.8291666666666667\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.6613720387481131,\n",
      "                0.5813672929279904,\n",
      "                0.5390738351746055,\n",
      "                0.4728810069891966,\n",
      "                0.46698384835870055,\n",
      "                0.4734527853933771,\n",
      "                0.4842780747559211,\n",
      "                0.5228003413035268,\n",
      "                0.5075128233163185,\n",
      "                0.5094612179574532,\n",
      "                0.5042806321029312,\n",
      "                0.5050633476645214,\n",
      "                0.49699225583757406,\n",
      "                0.4902744787977843,\n",
      "                0.4891898601283233\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.22809981569093526,\n",
      "                0.19605940381276157,\n",
      "                0.17778690431151167,\n",
      "                0.15332288574781724,\n",
      "                0.1499510154583705,\n",
      "                0.15291202189486428,\n",
      "                0.15613386367060075,\n",
      "                0.16939742395066504,\n",
      "                0.1646962467012852,\n",
      "                0.1639675945631498,\n",
      "                0.16366221928609567,\n",
      "                0.16480046604569373,\n",
      "                0.16180537509758922,\n",
      "                0.15947555799223034,\n",
      "                0.15935898123209713\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8223055555555557,\n",
      "            \"cross_entropy\": 0.513665589297089,\n",
      "            \"brier\": 0.16809531836371114\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8387096774193548,\n",
      "                0.7741935483870968,\n",
      "                0.7449362340585146,\n",
      "                0.7351837959489873,\n",
      "                0.6781695423855963,\n",
      "                0.6834208552138036,\n",
      "                0.5858964741185296,\n",
      "                0.5596399099774944,\n",
      "                0.5558889722430608,\n",
      "                0.4951237809452363,\n",
      "                0.4028507126781695,\n",
      "                0.46174043510877716,\n",
      "                0.4246061515378845,\n",
      "                0.41747936984246065,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5193068224943925,\n",
      "                0.5884276777641769,\n",
      "                0.6528984636814126,\n",
      "                0.6769923018390795,\n",
      "                0.713251049802941,\n",
      "                0.777170066168812,\n",
      "                0.8097615528760742,\n",
      "                0.8325013104183201,\n",
      "                0.8454462470235794,\n",
      "                0.880687022675766,\n",
      "                0.8618255137513322,\n",
      "                0.8627240321533328,\n",
      "                0.8789419861761316,\n",
      "                0.8881107626199484,\n",
      "                0.8937715432763311\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.16720830628118008,\n",
      "                0.20064877500497325,\n",
      "                0.23147481697693523,\n",
      "                0.24276897776608453,\n",
      "                0.26001066333595496,\n",
      "                0.28937136524704976,\n",
      "                0.3037600035015351,\n",
      "                0.3140788994549396,\n",
      "                0.31916146808575163,\n",
      "                0.334362746881767,\n",
      "                0.3272903945763365,\n",
      "                0.32787975107537387,\n",
      "                0.3345552101040773,\n",
      "                0.33825577726387107,\n",
      "                0.3406323110321205\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.5905226306576644,\n",
      "            \"cross_entropy\": 0.7787877568481087,\n",
      "            \"brier\": 0.28876396443919666\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8945986496624156,\n",
      "                0.8807201800450112,\n",
      "                0.9017254313578394,\n",
      "                0.9167291822955739,\n",
      "                0.9047261815453863,\n",
      "                0.9069767441860466,\n",
      "                0.9182295573893473,\n",
      "                0.9092273068267066,\n",
      "                0.8994748687171792,\n",
      "                0.9024756189047262,\n",
      "                0.9009752438109526,\n",
      "                0.891972993248312,\n",
      "                0.8942235558889722,\n",
      "                0.8987246811702926,\n",
      "                0.8994748687171792\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5339335987660522,\n",
      "                0.4644702556151713,\n",
      "                0.41740777547848185,\n",
      "                0.38370294811830236,\n",
      "                0.38350528284408963,\n",
      "                0.38379002741618,\n",
      "                0.3739531897443354,\n",
      "                0.37935897981210503,\n",
      "                0.38579319122015177,\n",
      "                0.39109098435741246,\n",
      "                0.39038645629215213,\n",
      "                0.4059026829970491,\n",
      "                0.40390593142719505,\n",
      "                0.4041106260777957,\n",
      "                0.40118807518577815\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17395977258876588,\n",
      "                0.14233368561447618,\n",
      "                0.12648882895646923,\n",
      "                0.11529523911652789,\n",
      "                0.1162465477795363,\n",
      "                0.11600668857275998,\n",
      "                0.11253308562957226,\n",
      "                0.11440429261501137,\n",
      "                0.11511658703687726,\n",
      "                0.11738495698531191,\n",
      "                0.11733943412805545,\n",
      "                0.1209865031782178,\n",
      "                0.12115912697505885,\n",
      "                0.12118795043758877,\n",
      "                0.11986653926437998\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.9013503375843961,\n",
      "            \"cross_entropy\": 0.4068333336901501,\n",
      "            \"brier\": 0.12335394925857394\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8286445012787723,\n",
      "                0.7468030690537085,\n",
      "                0.710997442455243,\n",
      "                0.6632566069906224,\n",
      "                0.5524296675191817,\n",
      "                0.6086956521739131,\n",
      "                0.6325660699062234,\n",
      "                0.6982097186700768,\n",
      "                0.711849957374254,\n",
      "                0.6811594202898551,\n",
      "                0.5592497868712702,\n",
      "                0.514919011082694,\n",
      "                0.48763853367433935,\n",
      "                0.550298380221654,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5247611733780392,\n",
      "                0.5992980891784528,\n",
      "                0.6592960329956608,\n",
      "                0.6999423160791688,\n",
      "                0.764792833477202,\n",
      "                0.7780820786677748,\n",
      "                0.7962646706446573,\n",
      "                0.8106359100631979,\n",
      "                0.8076533497670039,\n",
      "                0.8298545949966449,\n",
      "                0.8787514646182164,\n",
      "                0.8905117652941211,\n",
      "                0.8791571272222569,\n",
      "                0.842185806284067,\n",
      "                0.8697720218315294\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17191309223617363,\n",
      "                0.20559231482901733,\n",
      "                0.23306026497931379,\n",
      "                0.25279407750380994,\n",
      "                0.2847126378229196,\n",
      "                0.2913512652958653,\n",
      "                0.3000969222074143,\n",
      "                0.30701958898035975,\n",
      "                0.30565095216923893,\n",
      "                0.3161119218588796,\n",
      "                0.33818781347887356,\n",
      "                0.34332255066556494,\n",
      "                0.33843748071383184,\n",
      "                0.32205690043346263,\n",
      "                0.3348469112139148\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6297811878374538,\n",
      "            \"cross_entropy\": 0.7753972822998664,\n",
      "            \"brier\": 0.2896769796259093\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8047740835464622,\n",
      "                0.8405797101449275,\n",
      "                0.8729752770673486,\n",
      "                0.8635976129582268,\n",
      "                0.8584825234441602,\n",
      "                0.8533674339300937,\n",
      "                0.8337595907928389,\n",
      "                0.8277919863597613,\n",
      "                0.8260869565217391,\n",
      "                0.8337595907928389,\n",
      "                0.8380221653878944,\n",
      "                0.8431372549019608,\n",
      "                0.8533674339300937,\n",
      "                0.8550724637681159,\n",
      "                0.8533674339300937\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.6304875596901828,\n",
      "                0.5231308843317846,\n",
      "                0.4637947978058688,\n",
      "                0.4442152140958895,\n",
      "                0.4401524189059828,\n",
      "                0.44338652637942283,\n",
      "                0.4593776936160279,\n",
      "                0.4696961164785607,\n",
      "                0.4750169900067638,\n",
      "                0.4685488021545115,\n",
      "                0.4605469896397578,\n",
      "                0.46040962483621317,\n",
      "                0.4584951335150209,\n",
      "                0.45552697280724835,\n",
      "                0.45297774690534315\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.21120993032259455,\n",
      "                0.1662162563773505,\n",
      "                0.14575619665769501,\n",
      "                0.13819792658650512,\n",
      "                0.1341011290204091,\n",
      "                0.13534384534591934,\n",
      "                0.14268394260144285,\n",
      "                0.14585743977563176,\n",
      "                0.1484783540859465,\n",
      "                0.14689044987974118,\n",
      "                0.1437225696035937,\n",
      "                0.14330938629004128,\n",
      "                0.14238037453950478,\n",
      "                0.14122245896534602,\n",
      "                0.14064052329750873\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8438761011651038,\n",
      "            \"cross_entropy\": 0.4737175647445719,\n",
      "            \"brier\": 0.14840071888994869\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.77344336084021,\n",
      "                0.7531882970742686,\n",
      "                0.7381845461365341,\n",
      "                0.7464366091522882,\n",
      "                0.6459114778694673,\n",
      "                0.6504126031507876,\n",
      "                0.5746436609152288,\n",
      "                0.5333833458364591,\n",
      "                0.46999249812453114,\n",
      "                0.43435858964741186,\n",
      "                0.32445611402850716,\n",
      "                0.47261815453863465,\n",
      "                0.481245311327832,\n",
      "                0.5048762190547638,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5584202674130104,\n",
      "                0.6152823978620233,\n",
      "                0.659037108740996,\n",
      "                0.6816295750643078,\n",
      "                0.7385189827480575,\n",
      "                0.7741145693503552,\n",
      "                0.8500390166377951,\n",
      "                0.8641993400757866,\n",
      "                0.9009943646743731,\n",
      "                0.9220250930780954,\n",
      "                0.9108920741152599,\n",
      "                0.8813517850454523,\n",
      "                0.8777005361244103,\n",
      "                0.8623889178205392,\n",
      "                0.8770640441784052\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18761853207735799,\n",
      "                0.21349258921102227,\n",
      "                0.2352747003202182,\n",
      "                0.24601078231292514,\n",
      "                0.27172150430532577,\n",
      "                0.2878702796393332,\n",
      "                0.3205881073650181,\n",
      "                0.3263050304054054,\n",
      "                0.3417079947447447,\n",
      "                0.3498104684684685,\n",
      "                0.34633309909909915,\n",
      "                0.3351458415915916,\n",
      "                0.334121,\n",
      "                0.3279449376876877,\n",
      "                0.3339753430930932\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.5735433858464617,\n",
      "            \"cross_entropy\": 0.7982438715285911,\n",
      "            \"brier\": 0.29719468068808613\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7996999249812454,\n",
      "                0.8435858964741185,\n",
      "                0.8522130532633159,\n",
      "                0.8439609902475619,\n",
      "                0.8499624906226556,\n",
      "                0.8529632408102025,\n",
      "                0.8439609902475619,\n",
      "                0.8312078019504877,\n",
      "                0.8477119279819955,\n",
      "                0.8424606151537885,\n",
      "                0.8312078019504876,\n",
      "                0.8375843960990248,\n",
      "                0.8184546136534134,\n",
      "                0.822205551387847,\n",
      "                0.8244561140285072\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5568416944948791,\n",
      "                0.4803972268976447,\n",
      "                0.4913084188236074,\n",
      "                0.48321531022432596,\n",
      "                0.4551934228785443,\n",
      "                0.4634261407490266,\n",
      "                0.4708180234038162,\n",
      "                0.4800239500330183,\n",
      "                0.4797757879311866,\n",
      "                0.48013033431659285,\n",
      "                0.4802807074034457,\n",
      "                0.48575438756350914,\n",
      "                0.5010832771791706,\n",
      "                0.4984998197265036,\n",
      "                0.49914526465592496\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18404619594594598,\n",
      "                0.1502662864114114,\n",
      "                0.15474233671171173,\n",
      "                0.15330450750750751,\n",
      "                0.14288727120679354,\n",
      "                0.14654385604928907,\n",
      "                0.14893739328039773,\n",
      "                0.1514153097325642,\n",
      "                0.15262029286365447,\n",
      "                0.15295567028444262,\n",
      "                0.15194073624517376,\n",
      "                0.15376700067031318,\n",
      "                0.15993943756703133,\n",
      "                0.15819850072202304,\n",
      "                0.15791030935718886\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8361090272568142,\n",
      "            \"cross_entropy\": 0.48705958441874647,\n",
      "            \"brier\": 0.15463167363702987\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 456, 789, 1010]\n",
    "\n",
    "X = X[[\"xylose\", \"xanthosine\", \"uracil\", \"ribulose/xylulose\", \"valylglutamine\", \"tryptophylglycine\", \"succinate\", \"valine betaine\", \"ursodeoxycholate sulfate (1)\", \"tricarballylate\",\"succinimide\", \"thymine\", \"syringic acid\", \"serotonin\", \"ribitol\" ]]\n",
    "\n",
    "y = df_encoded['Group']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X),columns=X.columns,index=X.index)\n",
    "\n",
    "all_scores = {\n",
    "    'deletion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    },\n",
    "    'insertion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    }\n",
    "}\n",
    "\n",
    "for i in seeds:\n",
    "    print(\"Training Random Forest model...\")\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 7],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    model_trainer = ModelTrainer(X, y, random_state=i)\n",
    "    model, best_params = model_trainer.train_random_forest(param_dist)\n",
    "\n",
    "    explainer = shap.TreeExplainer(model, model_trainer.X_train)\n",
    "\n",
    "    shap_values = explainer.shap_values(model_trainer.X_test)\n",
    "\n",
    "    result = evaluate_global_shap_scores(model, model_trainer.X_test, model_trainer.y_test, shap_values)\n",
    "\n",
    "    for method in ['deletion', 'insertion']:\n",
    "        for metric in ['auroc', 'cross_entropy', 'brier']:\n",
    "            all_scores[method][metric].append(result[method][\"average_scores\"][metric])\n",
    "\n",
    "    import json\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.6095732870221622,\n",
      "            \"std\": 0.032641059609739335\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.8036828308299006,\n",
      "            \"std\": 0.028200008983786187\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.30120618437341495,\n",
      "            \"std\": 0.013124072758295892\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.855012392346562,\n",
      "            \"std\": 0.028169263307504012\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.46717330600936935,\n",
      "            \"std\": 0.03577447168804904\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.147404273467363,\n",
      "            \"std\": 0.014720255807790374\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "final_results = {\n",
    "    'deletion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['deletion'].items()\n",
    "    },\n",
    "    'insertion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['insertion'].items()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(json.dumps(final_results, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBS Kernel SHAP Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/74 [00:00<?, ?it/s]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2637457291798042)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.26703247740577474\n",
      "DEBUG:shap:self.fx = 0.12171754921323887\n",
      "DEBUG:shap:self.link(self.fx) = 0.12171754921323887\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.12330795,  0.00196381,  0.0056797 , -0.07048816, -0.00319946,\n",
      "       -0.0290135 , -0.02076631, -0.02581221,  0.00460531,  0.02617228,\n",
      "       -0.0038985 , -0.00912766, -0.00139672, -0.01515636, -0.00328675])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2637457291798043)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.26703247740577485\n",
      "DEBUG:shap:self.fx = 0.8782824507867614\n",
      "DEBUG:shap:self.link(self.fx) = 0.8782824507867614\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.12330795, -0.00196381, -0.0056797 ,  0.07048816,  0.00319946,\n",
      "        0.0290135 ,  0.02076631,  0.02581221, -0.00460531, -0.02617228,\n",
      "        0.0038985 ,  0.00912766,  0.00139672,  0.01515636,  0.00328675])\n",
      "  1%|▏         | 1/74 [00:01<02:12,  1.81s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2728209758913292)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.22211167885566582\n",
      "DEBUG:shap:self.fx = 0.16663834776334777\n",
      "DEBUG:shap:self.link(self.fx) = 0.16663834776334777\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10697033,  0.00121306, -0.00040103, -0.05927242, -0.0005072 ,\n",
      "        0.00882571, -0.00254856, -0.02211066, -0.00487678, -0.00137883,\n",
      "       -0.00681574, -0.01027585,  0.00548295, -0.07318531,  0.0507093 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.272820975891329)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.22211167885566563\n",
      "DEBUG:shap:self.fx = 0.8333616522366522\n",
      "DEBUG:shap:self.link(self.fx) = 0.8333616522366522\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10697033, -0.00121306,  0.00040103,  0.05927242,  0.0005072 ,\n",
      "       -0.00882571,  0.00254856,  0.02211066,  0.00487678,  0.00137883,\n",
      "        0.00681574,  0.01027585, -0.00548295,  0.07318531, -0.0507093 ])\n",
      "  3%|▎         | 2/74 [00:03<02:08,  1.78s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.16778991305406468)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.15599893049291746\n",
      "DEBUG:shap:self.fx = 0.23275109612609612\n",
      "DEBUG:shap:self.link(self.fx) = 0.23275109612609612\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.08814789,  0.00520283, -0.00149165, -0.06089953,  0.00460981,\n",
      "       -0.01112438, -0.05353596,  0.08357873, -0.00035235, -0.01229073,\n",
      "       -0.00017494, -0.02014549, -0.00395014, -0.00906822,  0.01179098])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.16778991305406493)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1559989304929177\n",
      "DEBUG:shap:self.fx = 0.7672489038739042\n",
      "DEBUG:shap:self.link(self.fx) = 0.7672489038739042\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.08814789, -0.00520283,  0.00149165,  0.06089953, -0.00460981,\n",
      "        0.01112438,  0.05353596, -0.08357873,  0.00035235,  0.01229073,\n",
      "        0.00017494,  0.02014549,  0.00395014,  0.00906822, -0.01179098])\n",
      "  4%|▍         | 3/74 [00:05<02:07,  1.79s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4807421175917908)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4682008697068828\n",
      "DEBUG:shap:self.fx = 0.8569508963258964\n",
      "DEBUG:shap:self.link(self.fx) = 0.8569508963258964\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.22929031,  0.01747068,  0.00564811,  0.09402373,  0.01944155,\n",
      "       -0.02034007,  0.023267  , -0.00743094,  0.00581754,  0.00805454,\n",
      "       -0.00278863,  0.00908313,  0.00588957,  0.09331561, -0.01254125])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.480742117591791)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.46820086970688285\n",
      "DEBUG:shap:self.fx = 0.14304910367410367\n",
      "DEBUG:shap:self.link(self.fx) = 0.14304910367410367\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.22929031, -0.01747068, -0.00564811, -0.09402373, -0.01944155,\n",
      "        0.02034007, -0.023267  ,  0.00743094, -0.00581754, -0.00805454,\n",
      "        0.00278863, -0.00908313, -0.00588957, -0.09331561,  0.01254125])\n",
      "  5%|▌         | 4/74 [00:07<02:08,  1.83s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.04180628290728236)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.006401888645875542\n",
      "DEBUG:shap:self.fx = 0.38234813797313805\n",
      "DEBUG:shap:self.link(self.fx) = 0.38234813797313805\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.14556034,  0.00706362, -0.01061465,  0.01612162,  0.01301802,\n",
      "       -0.01129452,  0.00637771, -0.05001509,  0.01193521,  0.00111814,\n",
      "        0.00973679,  0.02797533,  0.00031039,  0.08202149,  0.03540439])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.04180628290728214)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.00640188864587532\n",
      "DEBUG:shap:self.fx = 0.6176518620268618\n",
      "DEBUG:shap:self.link(self.fx) = 0.6176518620268618\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.14556034, -0.00706362,  0.01061465, -0.01612162, -0.01301802,\n",
      "        0.01129452, -0.00637771,  0.05001509, -0.01193521, -0.00111814,\n",
      "       -0.00973679, -0.02797533, -0.00031039, -0.08202149, -0.03540439])\n",
      "  7%|▋         | 5/74 [00:09<02:06,  1.83s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19564155181690873)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.20072882418764781\n",
      "DEBUG:shap:self.fx = 0.18802120243136577\n",
      "DEBUG:shap:self.link(self.fx) = 0.18802120243136577\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.09743486,  0.00254329, -0.01165691, -0.01539004,  0.00086895,\n",
      "       -0.00914559,  0.01044456, -0.04995402, -0.00590425,  0.02180729,\n",
      "       -0.0172643 ,  0.04009412, -0.00342772, -0.06122208, -0.00508727])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19564155181690884)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.20072882418764793\n",
      "DEBUG:shap:self.fx = 0.8119787975686344\n",
      "DEBUG:shap:self.link(self.fx) = 0.8119787975686344\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.09743486, -0.00254329,  0.01165691,  0.01539004, -0.00086895,\n",
      "        0.00914559, -0.01044456,  0.04995402,  0.00590425, -0.02180729,\n",
      "        0.0172643 , -0.04009412,  0.00342772,  0.06122208,  0.00508727])\n",
      "  8%|▊         | 6/74 [00:10<02:03,  1.82s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03152901467019348)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.021347278853291796\n",
      "DEBUG:shap:self.fx = 0.4100973054723054\n",
      "DEBUG:shap:self.link(self.fx) = 0.4100973054723054\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.14018231,  0.00726456, -0.01379454, -0.05497703, -0.00558649,\n",
      "        0.01410677,  0.00858275, -0.02643133, -0.03313154, -0.01037689,\n",
      "       -0.02420011,  0.01990547, -0.00238123,  0.01236632, -0.01018174])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.03152901467019364)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.021347278853292018\n",
      "DEBUG:shap:self.fx = 0.5899026945276945\n",
      "DEBUG:shap:self.link(self.fx) = 0.5899026945276945\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.14018231, -0.00726456,  0.01379454,  0.05497703,  0.00558649,\n",
      "       -0.01410677, -0.00858275,  0.02643133,  0.03313154,  0.01037689,\n",
      "        0.02420011, -0.01990547,  0.00238123, -0.01236632,  0.01018174])\n",
      "  9%|▉         | 7/74 [00:12<02:01,  1.81s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12194298968040529)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12272093297694608\n",
      "DEBUG:shap:self.fx = 0.5114709595959597\n",
      "DEBUG:shap:self.link(self.fx) = 0.5114709595959597\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.13503894,  0.00548627, -0.01225042,  0.06449485, -0.01155903,\n",
      "        0.00045426, -0.07426221,  0.08014534,  0.00457989,  0.00826215,\n",
      "       -0.00066268, -0.03144816,  0.01157084, -0.05790705,  0.00077794])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.12194298968040561)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.12272093297694647\n",
      "DEBUG:shap:self.fx = 0.48852904040404005\n",
      "DEBUG:shap:self.link(self.fx) = 0.48852904040404005\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.13503894, -0.00548627,  0.01225042, -0.06449485,  0.01155903,\n",
      "       -0.00045426,  0.07426221, -0.08014534, -0.00457989, -0.00826215,\n",
      "        0.00066268,  0.03144816, -0.01157084,  0.05790705, -0.00077794])\n",
      " 11%|█         | 8/74 [00:14<01:58,  1.80s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23749012079096127)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.24490209390039122\n",
      "DEBUG:shap:self.fx = 0.14384793271862237\n",
      "DEBUG:shap:self.link(self.fx) = 0.14384793271862237\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.14306165,  0.00448314,  0.00248045, -0.05525936, -0.001144  ,\n",
      "       -0.01103768, -0.06202452,  0.08225354, -0.03032235, -0.0079252 ,\n",
      "       -0.03212844, -0.00301817, -0.00060857,  0.01982271, -0.00741197])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23749012079096096)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24490209390039086\n",
      "DEBUG:shap:self.fx = 0.8561520672813774\n",
      "DEBUG:shap:self.link(self.fx) = 0.8561520672813774\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.14306165, -0.00448314, -0.00248045,  0.05525936,  0.001144  ,\n",
      "        0.01103768,  0.06202452, -0.08225354,  0.03032235,  0.0079252 ,\n",
      "        0.03212844,  0.00301817,  0.00060857, -0.01982271,  0.00741197])\n",
      " 12%|█▏        | 9/74 [00:16<01:55,  1.77s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2641032980210565)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2581053906036879\n",
      "DEBUG:shap:self.fx = 0.13064463601532567\n",
      "DEBUG:shap:self.link(self.fx) = 0.13064463601532567\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10469049,  0.00484354, -0.00175544, -0.02563756,  0.00994959,\n",
      "       -0.00919095, -0.007567  , -0.0243854 , -0.02408057, -0.00927186,\n",
      "       -0.01622822, -0.00442529, -0.00215836, -0.04950527,  0.00599791])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2641032980210565)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.25810539060368787\n",
      "DEBUG:shap:self.fx = 0.8693553639846744\n",
      "DEBUG:shap:self.link(self.fx) = 0.8693553639846744\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10469049, -0.00484354,  0.00175544,  0.02563756, -0.00994959,\n",
      "        0.00919095,  0.007567  ,  0.0243854 ,  0.02408057,  0.00927186,\n",
      "        0.01622822,  0.00442529,  0.00215836,  0.04950527, -0.00599791])\n",
      " 14%|█▎        | 10/74 [00:17<01:52,  1.76s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.13708755595030198)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1199248350481324\n",
      "DEBUG:shap:self.fx = 0.2688251915708812\n",
      "DEBUG:shap:self.link(self.fx) = 0.2688251915708812\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.105059  ,  0.0077476 , -0.00324479, -0.05286815, -0.00237401,\n",
      "       -0.00689694, -0.01387186, -0.01851437,  0.00407279,  0.01006082,\n",
      "       -0.02508573, -0.00905825, -0.00025032,  0.07825465,  0.01716272])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.13708755595030184)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.11992483504813234\n",
      "DEBUG:shap:self.fx = 0.7311748084291189\n",
      "DEBUG:shap:self.link(self.fx) = 0.7311748084291189\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.105059  , -0.0077476 ,  0.00324479,  0.05286815,  0.00237401,\n",
      "        0.00689694,  0.01387186,  0.01851437, -0.00407279, -0.01006082,\n",
      "        0.02508573,  0.00905825,  0.00025032, -0.07825465, -0.01716272])\n",
      " 15%|█▍        | 11/74 [00:19<01:49,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.13831260082139105)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.15768110942509647\n",
      "DEBUG:shap:self.fx = 0.23106891719391712\n",
      "DEBUG:shap:self.link(self.fx) = 0.23106891719391712\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.07044696,  0.01081487, -0.00310681, -0.04036804, -0.00459789,\n",
      "       -0.00765983, -0.05062372, -0.01457498,  0.00700715,  0.00381396,\n",
      "       -0.03306189, -0.00907163,  0.00992557,  0.06363761, -0.01936851])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.13831260082139096)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1576811094250964\n",
      "DEBUG:shap:self.fx = 0.7689310828060829\n",
      "DEBUG:shap:self.link(self.fx) = 0.7689310828060829\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.07044696, -0.01081487,  0.00310681,  0.04036804,  0.00459789,\n",
      "        0.00765983,  0.05062372,  0.01457498, -0.00700715, -0.00381396,\n",
      "        0.03306189,  0.00907163, -0.00992557, -0.06363761,  0.01936851])\n",
      " 16%|█▌        | 12/74 [00:21<01:47,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.31667585070536625)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.306537725031712\n",
      "DEBUG:shap:self.fx = 0.0822123015873016\n",
      "DEBUG:shap:self.link(self.fx) = 0.0822123015873016\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10220411,  0.00867918,  0.00593225, -0.05819336, -0.00022631,\n",
      "       -0.00947777, -0.04529779, -0.03213634, -0.00061107, -0.01120166,\n",
      "       -0.02094831, -0.0050764 ,  0.        , -0.04591415,  0.01013813])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.316675850705366)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.30653772503171195\n",
      "DEBUG:shap:self.fx = 0.9177876984126985\n",
      "DEBUG:shap:self.link(self.fx) = 0.9177876984126985\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10220411, -0.00867918, -0.00593225,  0.05819336,  0.00022631,\n",
      "        0.00947777,  0.04529779,  0.03213634,  0.00061107,  0.01120166,\n",
      "        0.02094831,  0.0050764 ,  0.        ,  0.04591415, -0.01013813])\n",
      " 18%|█▊        | 13/74 [00:22<01:43,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.271526561886385)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.27749620526288493\n",
      "DEBUG:shap:self.fx = 0.11125382135612866\n",
      "DEBUG:shap:self.link(self.fx) = 0.11125382135612866\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.08182575,  0.00138419,  0.00767893, -0.06193777, -0.00144289,\n",
      "       -0.02109713, -0.03857291, -0.026591  ,  0.0008172 , -0.00857664,\n",
      "       -0.00273808,  0.02972245, -0.00580626, -0.06254088, -0.00596964])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.27152656188638513)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.277496205262885\n",
      "DEBUG:shap:self.fx = 0.8887461786438715\n",
      "DEBUG:shap:self.link(self.fx) = 0.8887461786438715\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.08182575, -0.00138419, -0.00767893,  0.06193777,  0.00144289,\n",
      "        0.02109713,  0.03857291,  0.026591  , -0.0008172 ,  0.00857664,\n",
      "        0.00273808, -0.02972245,  0.00580626,  0.06254088,  0.00596964])\n",
      " 19%|█▉        | 14/74 [00:24<01:40,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.08484468216791664)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09170542071143378\n",
      "DEBUG:shap:self.fx = 0.48045544733044737\n",
      "DEBUG:shap:self.link(self.fx) = 0.48045544733044737\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.13762767,  0.01377484,  0.00844597,  0.06009772, -0.00161165,\n",
      "       -0.0018843 , -0.0639815 , -0.04540854, -0.02704133,  0.00628531,\n",
      "       -0.0028482 , -0.01237865,  0.00531416,  0.00845318,  0.00686074])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.08484468216791671)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09170542071143384\n",
      "DEBUG:shap:self.fx = 0.5195445526695527\n",
      "DEBUG:shap:self.link(self.fx) = 0.5195445526695527\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.13762767, -0.01377484, -0.00844597, -0.06009772,  0.00161165,\n",
      "        0.0018843 ,  0.0639815 ,  0.04540854,  0.02704133, -0.00628531,\n",
      "        0.0028482 ,  0.01237865, -0.00531416, -0.00845318, -0.00686074])\n",
      " 20%|██        | 15/74 [00:26<01:38,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.16724736882416258)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1799100055289925\n",
      "DEBUG:shap:self.fx = 0.2088400210900211\n",
      "DEBUG:shap:self.link(self.fx) = 0.2088400210900211\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10817245,  0.00411229,  0.00395391,  0.01714816,  0.00167688,\n",
      "       -0.00725315, -0.05717254,  0.04014642,  0.00447843,  0.02197764,\n",
      "       -0.0024918 , -0.01593294,  0.00037808, -0.0700963 , -0.01266264])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.16724736882416263)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1799100055289925\n",
      "DEBUG:shap:self.fx = 0.791159978909979\n",
      "DEBUG:shap:self.link(self.fx) = 0.791159978909979\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10817245, -0.00411229, -0.00395391, -0.01714816, -0.00167688,\n",
      "        0.00725315,  0.05717254, -0.04014642, -0.00447843, -0.02197764,\n",
      "        0.0024918 ,  0.01593294, -0.00037808,  0.0700963 ,  0.01266264])\n",
      " 22%|██▏       | 16/74 [00:27<01:35,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2976892204187032)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.29105558217456917\n",
      "DEBUG:shap:self.fx = 0.09769444444444444\n",
      "DEBUG:shap:self.link(self.fx) = 0.09769444444444444\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.1167986 , -0.02117069,  0.00252851, -0.04384457,  0.00377414,\n",
      "       -0.01506081, -0.00284476, -0.02784615,  0.00517342, -0.01824984,\n",
      "        0.0028627 , -0.00163919,  0.00125248, -0.06582587,  0.00663364])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2976892204187034)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2910555821745693\n",
      "DEBUG:shap:self.fx = 0.9023055555555558\n",
      "DEBUG:shap:self.link(self.fx) = 0.9023055555555558\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.1167986 ,  0.02117069, -0.00252851,  0.04384457, -0.00377414,\n",
      "        0.01506081,  0.00284476,  0.02784615, -0.00517342,  0.01824984,\n",
      "       -0.0028627 ,  0.00163919, -0.00125248,  0.06582587, -0.00663364])\n",
      " 23%|██▎       | 17/74 [00:29<01:32,  1.63s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.08530038665175388)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1263704778764908\n",
      "DEBUG:shap:self.fx = 0.5151205044955044\n",
      "DEBUG:shap:self.link(self.fx) = 0.5151205044955044\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.01329228, -0.01577941, -0.01193771, -0.0566394 ,  0.00570324,\n",
      "        0.        ,  0.01101319,  0.09771714,  0.00451989, -0.00387032,\n",
      "       -0.01255256, -0.00041868,  0.00482809,  0.04942464,  0.04107009])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.08530038665175396)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.12637047787649086\n",
      "DEBUG:shap:self.fx = 0.48487949550449566\n",
      "DEBUG:shap:self.link(self.fx) = 0.48487949550449566\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.01329228,  0.01577941,  0.01193771,  0.0566394 , -0.00570324,\n",
      "        0.        , -0.01101319, -0.09771714, -0.00451989,  0.00387032,\n",
      "        0.01255256,  0.00041868, -0.00482809, -0.04942464, -0.04107009])\n",
      " 24%|██▍       | 18/74 [00:31<01:30,  1.62s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.49924894013211013)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5346467987778117\n",
      "DEBUG:shap:self.fx = 0.9233968253968253\n",
      "DEBUG:shap:self.link(self.fx) = 0.9233968253968253\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.21309567,  0.01490925,  0.00969499,  0.07833029,  0.01124376,\n",
      "        0.01560578,  0.02783408, -0.00104599,  0.0124522 , -0.00379666,\n",
      "        0.        ,  0.01030538,  0.00747323,  0.10314695,  0.03539786])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.49924894013211035)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.534646798777812\n",
      "DEBUG:shap:self.fx = 0.0766031746031746\n",
      "DEBUG:shap:self.link(self.fx) = 0.0766031746031746\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.21309567, -0.01490925, -0.00969499, -0.07833029, -0.01124376,\n",
      "       -0.01560578, -0.02783408,  0.00104599, -0.0124522 ,  0.00379666,\n",
      "        0.        , -0.01030538, -0.00747323, -0.10314695, -0.03539786])\n",
      " 26%|██▌       | 19/74 [00:32<01:29,  1.63s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2717846976213506)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.28169499831398526\n",
      "DEBUG:shap:self.fx = 0.10705502830502833\n",
      "DEBUG:shap:self.link(self.fx) = 0.10705502830502833\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.09532356,  0.0088725 ,  0.0052219 , -0.0400911 , -0.00749862,\n",
      "       -0.01228132, -0.05505386, -0.01391302, -0.01985682,  0.00912237,\n",
      "        0.01550762, -0.00959334, -0.00223856, -0.05465888, -0.0099103 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2717846976213505)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.28169499831398526\n",
      "DEBUG:shap:self.fx = 0.8929449716949718\n",
      "DEBUG:shap:self.link(self.fx) = 0.8929449716949718\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.09532356, -0.0088725 , -0.0052219 ,  0.0400911 ,  0.00749862,\n",
      "        0.01228132,  0.05505386,  0.01391302,  0.01985682, -0.00912237,\n",
      "       -0.01550762,  0.00959334,  0.00223856,  0.05465888,  0.0099103 ])\n",
      " 27%|██▋       | 20/74 [00:34<01:28,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.030117826639082787)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.032052696171683104\n",
      "DEBUG:shap:self.fx = 0.3566973304473305\n",
      "DEBUG:shap:self.link(self.fx) = 0.3566973304473305\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.12449658,  0.00149759,  0.00838488, -0.0519001 , -0.00064431,\n",
      "       -0.01160944,  0.01665887,  0.0511129 , -0.00426231,  0.03207657,\n",
      "       -0.0199011 ,  0.00029169,  0.        ,  0.07267351, -0.00193487])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03011782663908262)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.03205269617168294\n",
      "DEBUG:shap:self.fx = 0.6433026695526695\n",
      "DEBUG:shap:self.link(self.fx) = 0.6433026695526695\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.12449658, -0.00149759, -0.00838488,  0.0519001 ,  0.00064431,\n",
      "        0.01160944, -0.01665887, -0.0511129 ,  0.00426231, -0.03207657,\n",
      "        0.0199011 , -0.00029169,  0.        , -0.07267351,  0.00193487])\n",
      " 28%|██▊       | 21/74 [00:35<01:26,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4718833699428553)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.48327775115876415\n",
      "DEBUG:shap:self.fx = 0.8720277777777777\n",
      "DEBUG:shap:self.link(self.fx) = 0.8720277777777777\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.18136656,  0.01444113,  0.00641926,  0.09086644,  0.01550966,\n",
      "        0.0060979 ,  0.01905645,  0.06540943,  0.00729378, -0.00248805,\n",
      "       -0.00238925,  0.02749928,  0.00772494,  0.03507584,  0.01139438])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4718833699428556)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.48327775115876437\n",
      "DEBUG:shap:self.fx = 0.12797222222222218\n",
      "DEBUG:shap:self.link(self.fx) = 0.12797222222222218\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.18136656, -0.01444113, -0.00641926, -0.09086644, -0.01550966,\n",
      "       -0.0060979 , -0.01905645, -0.06540943, -0.00729378,  0.00248805,\n",
      "        0.00238925, -0.02749928, -0.00772494, -0.03507584, -0.01139438])\n",
      " 30%|██▉       | 22/74 [00:37<01:25,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1588407588307916)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.13826546483397795\n",
      "DEBUG:shap:self.fx = 0.5270154914529915\n",
      "DEBUG:shap:self.link(self.fx) = 0.5270154914529915\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.14189341,  0.0074628 , -0.00766114, -0.05948578,  0.00117984,\n",
      "        0.01637244,  0.01398432, -0.01782963, -0.00199479, -0.0070891 ,\n",
      "       -0.01467948,  0.01017487,  0.00315396,  0.07335905, -0.02057529])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.15884075883079157)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.138265464833978\n",
      "DEBUG:shap:self.fx = 0.4729845085470085\n",
      "DEBUG:shap:self.link(self.fx) = 0.4729845085470085\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.14189341, -0.0074628 ,  0.00766114,  0.05948578, -0.00117984,\n",
      "       -0.01637244, -0.01398432,  0.01782963,  0.00199479,  0.0070891 ,\n",
      "        0.01467948, -0.01017487, -0.00315396, -0.07335905,  0.02057529])\n",
      " 31%|███       | 23/74 [00:39<01:24,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20006564895901716)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1979755065988039\n",
      "DEBUG:shap:self.fx = 0.1907745200202097\n",
      "DEBUG:shap:self.link(self.fx) = 0.1907745200202097\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.09942676, -0.00976198, -0.0041535 , -0.01719847,  0.00087662,\n",
      "        0.01046638, -0.00755219, -0.02584641, -0.02416957,  0.01239357,\n",
      "        0.00913933, -0.00340316,  0.00329992, -0.04472942,  0.00209014])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20006564895901685)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.19797550659880359\n",
      "DEBUG:shap:self.fx = 0.8092254799797901\n",
      "DEBUG:shap:self.link(self.fx) = 0.8092254799797901\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.09942676,  0.00976198,  0.0041535 ,  0.01719847, -0.00087662,\n",
      "       -0.01046638,  0.00755219,  0.02584641,  0.02416957, -0.01239357,\n",
      "       -0.00913933,  0.00340316, -0.00329992,  0.04472942, -0.00209014])\n",
      " 32%|███▏      | 24/74 [00:40<01:22,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20323880529045218)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2056077785666022\n",
      "DEBUG:shap:self.fx = 0.1831422480524114\n",
      "DEBUG:shap:self.link(self.fx) = 0.1831422480524114\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.09964568,  0.0124274 ,  0.00222142, -0.06174005,  0.01234426,\n",
      "        0.01759071, -0.00991885, -0.01941816,  0.00303491,  0.01813068,\n",
      "       -0.01672641, -0.00680546, -0.00062699, -0.05410658, -0.00236897])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20323880529045193)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.20560777856660195\n",
      "DEBUG:shap:self.fx = 0.8168577519475885\n",
      "DEBUG:shap:self.link(self.fx) = 0.8168577519475885\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.09964568, -0.0124274 , -0.00222142,  0.06174005, -0.01234426,\n",
      "       -0.01759071,  0.00991885,  0.01941816, -0.00303491, -0.01813068,\n",
      "        0.01672641,  0.00680546,  0.00062699,  0.05410658,  0.00236897])\n",
      " 34%|███▍      | 25/74 [00:42<01:20,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.125415882933995)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.11653425854027166\n",
      "DEBUG:shap:self.fx = 0.5052842851592853\n",
      "DEBUG:shap:self.link(self.fx) = 0.5052842851592853\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.12205098, -0.00445392,  0.00944457,  0.0498467 ,  0.01440207,\n",
      "        0.01113213,  0.01487552,  0.06993755, -0.04984152,  0.01261105,\n",
      "       -0.02738143,  0.0029803 ,  0.00398947, -0.10417759, -0.00888162])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.125415882933995)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.11653425854027183\n",
      "DEBUG:shap:self.fx = 0.4947157148407147\n",
      "DEBUG:shap:self.link(self.fx) = 0.4947157148407147\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.12205098,  0.00445392, -0.00944457, -0.0498467 , -0.01440207,\n",
      "       -0.01113213, -0.01487552, -0.06993755,  0.04984152, -0.01261105,\n",
      "        0.02738143, -0.0029803 , -0.00398947,  0.10417759,  0.00888162])\n",
      " 35%|███▌      | 26/74 [00:44<01:19,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.15304787848444562)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.13653072734924043\n",
      "DEBUG:shap:self.fx = 0.525280753968254\n",
      "DEBUG:shap:self.link(self.fx) = 0.525280753968254\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.20068739, -0.00466354,  0.00973008, -0.08220493,  0.        ,\n",
      "       -0.03669955,  0.00904248, -0.02283163,  0.0054477 , -0.0092597 ,\n",
      "       -0.00121755,  0.00116064,  0.00030233,  0.08355417, -0.01651715])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.15304787848444582)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13653072734924054\n",
      "DEBUG:shap:self.fx = 0.474719246031746\n",
      "DEBUG:shap:self.link(self.fx) = 0.474719246031746\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.20068739,  0.00466354, -0.00973008,  0.08220493,  0.        ,\n",
      "        0.03669955, -0.00904248,  0.02283163, -0.0054477 ,  0.0092597 ,\n",
      "        0.00121755, -0.00116064, -0.00030233, -0.08355417,  0.01651715])\n",
      " 36%|███▋      | 27/74 [00:45<01:17,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.018547141282233517)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.04369583307684605\n",
      "DEBUG:shap:self.fx = 0.43244585969585964\n",
      "DEBUG:shap:self.link(self.fx) = 0.43244585969585964\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.00493276,  0.01241877, -0.01103459,  0.06665176,  0.00687175,\n",
      "       -0.0063796 ,  0.00289381, -0.02521164,  0.01285342, -0.00882434,\n",
      "        0.0215113 ,  0.03460413, -0.00246606, -0.08040881,  0.02514869])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.01854714128223367)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.04369583307684621\n",
      "DEBUG:shap:self.fx = 0.5675541403041403\n",
      "DEBUG:shap:self.link(self.fx) = 0.5675541403041403\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.00493276, -0.01241877,  0.01103459, -0.06665176, -0.00687175,\n",
      "        0.0063796 , -0.00289381,  0.02521164, -0.01285342,  0.00882434,\n",
      "       -0.0215113 , -0.03460413,  0.00246606,  0.08040881, -0.02514869])\n",
      " 38%|███▊      | 28/74 [00:47<01:16,  1.67s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.464343991823964)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.48581743369844677\n",
      "DEBUG:shap:self.fx = 0.8745674603174604\n",
      "DEBUG:shap:self.link(self.fx) = 0.8745674603174604\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.2082698 ,  0.01577309,  0.00072919,  0.08047325,  0.00910085,\n",
      "       -0.01233529,  0.0246883 ,  0.03364933, -0.0012951 , -0.00659749,\n",
      "       -0.02133753,  0.01625089,  0.00788505,  0.10908967,  0.02147344])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.46434399182396396)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4858174336984468\n",
      "DEBUG:shap:self.fx = 0.1254325396825397\n",
      "DEBUG:shap:self.link(self.fx) = 0.1254325396825397\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.2082698 , -0.01577309, -0.00072919, -0.08047325, -0.00910085,\n",
      "        0.01233529, -0.0246883 , -0.03364933,  0.0012951 ,  0.00659749,\n",
      "        0.02133753, -0.01625089, -0.00788505, -0.10908967, -0.02147344])\n",
      " 39%|███▉      | 29/74 [00:49<01:13,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.32600379790977774)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3489012665322794\n",
      "DEBUG:shap:self.fx = 0.737651293151293\n",
      "DEBUG:shap:self.link(self.fx) = 0.737651293151293\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.18834253,  0.01362859,  0.        ,  0.02147212,  0.00218846,\n",
      "        0.00368584,  0.01391644, -0.0014945 , -0.00500204, -0.00617837,\n",
      "       -0.01763375,  0.00520138,  0.0038006 ,  0.1040765 ,  0.02289747])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.32600379790977796)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3489012665322796\n",
      "DEBUG:shap:self.fx = 0.2623487068487069\n",
      "DEBUG:shap:self.link(self.fx) = 0.2623487068487069\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.18834253, -0.01362859,  0.        , -0.02147212, -0.00218846,\n",
      "       -0.00368584, -0.01391644,  0.0014945 ,  0.00500204,  0.00617837,\n",
      "        0.01763375, -0.00520138, -0.0038006 , -0.1040765 , -0.02289747])\n",
      " 41%|████      | 30/74 [00:50<01:11,  1.63s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3058315760878354)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2685858852048722\n",
      "DEBUG:shap:self.fx = 0.1201641414141414\n",
      "DEBUG:shap:self.link(self.fx) = 0.1201641414141414\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10559649, -0.00133273, -0.00194437, -0.05385   ,  0.00328324,\n",
      "        0.00533784,  0.00814814, -0.03271186,  0.0026944 , -0.0184745 ,\n",
      "       -0.01686175, -0.00830114, -0.00460884, -0.08161352,  0.03724569])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3058315760878354)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.26858588520487214\n",
      "DEBUG:shap:self.fx = 0.8798358585858587\n",
      "DEBUG:shap:self.link(self.fx) = 0.8798358585858587\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10559649,  0.00133273,  0.00194437,  0.05385   , -0.00328324,\n",
      "       -0.00533784, -0.00814814,  0.03271186, -0.0026944 ,  0.0184745 ,\n",
      "        0.01686175,  0.00830114,  0.00460884,  0.08161352, -0.03724569])\n",
      " 42%|████▏     | 31/74 [00:52<01:09,  1.62s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.15163710063113597)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13903123152521846\n",
      "DEBUG:shap:self.fx = 0.24971879509379513\n",
      "DEBUG:shap:self.link(self.fx) = 0.24971879509379513\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10068443,  0.01564488,  0.00649733, -0.04023807, -0.00234913,\n",
      "       -0.01319011,  0.01197547, -0.03767918,  0.0077762 ,  0.0379439 ,\n",
      "       -0.02053137, -0.00057773, -0.00357389, -0.01265098,  0.01260587])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.15163710063113578)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.13903123152521824\n",
      "DEBUG:shap:self.fx = 0.7502812049062048\n",
      "DEBUG:shap:self.link(self.fx) = 0.7502812049062048\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10068443, -0.01564488, -0.00649733,  0.04023807,  0.00234913,\n",
      "        0.01319011, -0.01197547,  0.03767918, -0.0077762 , -0.0379439 ,\n",
      "        0.02053137,  0.00057773,  0.00357389,  0.01265098, -0.01260587])\n",
      " 43%|████▎     | 32/74 [00:54<01:08,  1.63s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1841877485490173)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.19200269755918453\n",
      "DEBUG:shap:self.fx = 0.19674732905982906\n",
      "DEBUG:shap:self.link(self.fx) = 0.19674732905982906\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.01804745,  0.00043553,  0.00698077, -0.0740162 , -0.00167366,\n",
      "       -0.00826985, -0.02000251, -0.04238881,  0.00435342, -0.00427351,\n",
      "       -0.02946714,  0.00125304, -0.00112165,  0.00205027, -0.00781495])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.18418774854901715)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.19200269755918442\n",
      "DEBUG:shap:self.fx = 0.8032526709401709\n",
      "DEBUG:shap:self.link(self.fx) = 0.8032526709401709\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.01804745, -0.00043553, -0.00698077,  0.0740162 ,  0.00167366,\n",
      "        0.00826985,  0.02000251,  0.04238881, -0.00435342,  0.00427351,\n",
      "        0.02946714, -0.00125304,  0.00112165, -0.00205027,  0.00781495])\n",
      " 45%|████▍     | 33/74 [00:55<01:06,  1.62s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12524998530051346)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.13105370437221753\n",
      "DEBUG:shap:self.fx = 0.5198037309912311\n",
      "DEBUG:shap:self.link(self.fx) = 0.5198037309912311\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 1.62398122e-01,  9.00924708e-03, -1.03792948e-02, -5.01200213e-02,\n",
      "       -7.98966959e-03,  8.61408269e-03,  1.70030560e-02, -2.57426897e-02,\n",
      "        3.50284983e-04,  1.39538518e-04, -5.62078142e-03, -1.15032258e-02,\n",
      "        5.79266801e-03,  3.32986689e-02,  5.80371907e-03])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1252499853005135)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13105370437221753\n",
      "DEBUG:shap:self.fx = 0.480196269008769\n",
      "DEBUG:shap:self.link(self.fx) = 0.480196269008769\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-1.62398122e-01, -9.00924708e-03,  1.03792948e-02,  5.01200213e-02,\n",
      "        7.98966959e-03, -8.61408269e-03, -1.70030560e-02,  2.57426897e-02,\n",
      "       -3.50284983e-04, -1.39538518e-04,  5.62078142e-03,  1.15032258e-02,\n",
      "       -5.79266801e-03, -3.32986689e-02, -5.80371907e-03])\n",
      " 46%|████▌     | 34/74 [00:57<01:06,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.001768868984087374)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.007655204774191626\n",
      "DEBUG:shap:self.fx = 0.38109482184482196\n",
      "DEBUG:shap:self.link(self.fx) = 0.38109482184482196\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.14552644, -0.00119743,  0.00358114,  0.03981466, -0.01544995,\n",
      "       -0.01008066,  0.00981518, -0.03428235, -0.03335888, -0.00888172,\n",
      "        0.00094394,  0.00492463,  0.0074235 , -0.11054738, -0.00588634])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0017688689840870964)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.007655204774191349\n",
      "DEBUG:shap:self.fx = 0.6189051781551779\n",
      "DEBUG:shap:self.link(self.fx) = 0.6189051781551779\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.14552644,  0.00119743, -0.00358114, -0.03981466,  0.01544995,\n",
      "        0.01008066, -0.00981518,  0.03428235,  0.03335888,  0.00888172,\n",
      "       -0.00094394, -0.00492463, -0.0074235 ,  0.11054738,  0.00588634])\n",
      " 47%|████▋     | 35/74 [00:59<01:05,  1.67s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.36653585170214326)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3856843168153299\n",
      "DEBUG:shap:self.fx = 0.7744343434343435\n",
      "DEBUG:shap:self.link(self.fx) = 0.7744343434343435\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.20403171, -0.02754724, -0.0098195 ,  0.09071421,  0.02213438,\n",
      "       -0.02157049,  0.01353976, -0.0066885 ,  0.01217943, -0.0025801 ,\n",
      "       -0.00115608,  0.00781782,  0.00280061,  0.08267983,  0.01914847])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3665358517021431)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3856843168153299\n",
      "DEBUG:shap:self.fx = 0.22556565656565664\n",
      "DEBUG:shap:self.link(self.fx) = 0.22556565656565664\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.20403171,  0.02754724,  0.0098195 , -0.09071421, -0.02213438,\n",
      "        0.02157049, -0.01353976,  0.0066885 , -0.01217943,  0.0025801 ,\n",
      "        0.00115608, -0.00781782, -0.00280061, -0.08267983, -0.01914847])\n",
      " 49%|████▊     | 36/74 [01:00<01:03,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0069416379030128594)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.015894814650827815\n",
      "DEBUG:shap:self.fx = 0.4046448412698414\n",
      "DEBUG:shap:self.link(self.fx) = 0.4046448412698414\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.13710667,  0.0237323 ,  0.0026235 ,  0.04692296,  0.01215019,\n",
      "       -0.00770722,  0.00616621, -0.05170577, -0.0443738 ,  0.02843336,\n",
      "       -0.00476578,  0.00279288, -0.03358987, -0.11084398,  0.00895318])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.006941637903012665)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.01589481465082776\n",
      "DEBUG:shap:self.fx = 0.5953551587301588\n",
      "DEBUG:shap:self.link(self.fx) = 0.5953551587301588\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.13710667, -0.0237323 , -0.0026235 , -0.04692296, -0.01215019,\n",
      "        0.00770722, -0.00616621,  0.05170577,  0.0443738 , -0.02843336,\n",
      "        0.00476578, -0.00279288,  0.03358987,  0.11084398, -0.00895318])\n",
      " 50%|█████     | 37/74 [01:02<01:01,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09460205537339562)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08007758794657499\n",
      "DEBUG:shap:self.fx = 0.3086724386724386\n",
      "DEBUG:shap:self.link(self.fx) = 0.3086724386724386\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.05603658,  0.02661347,  0.00041835, -0.0255528 , -0.01476541,\n",
      "       -0.0229776 , -0.04849035, -0.01992819,  0.01090797,  0.00776038,\n",
      "        0.00196637, -0.00375426,  0.00518923,  0.04404737,  0.01452447])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.09460205537339537)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08007758794657471\n",
      "DEBUG:shap:self.fx = 0.6913275613275612\n",
      "DEBUG:shap:self.link(self.fx) = 0.6913275613275612\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.05603658, -0.02661347, -0.00041835,  0.0255528 ,  0.01476541,\n",
      "        0.0229776 ,  0.04849035,  0.01992819, -0.01090797, -0.00776038,\n",
      "       -0.00196637,  0.00375426, -0.00518923, -0.04404737, -0.01452447])\n",
      " 51%|█████▏    | 38/74 [01:03<00:59,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4140536573386449)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3822624192684323\n",
      "DEBUG:shap:self.fx = 0.7710124458874459\n",
      "DEBUG:shap:self.link(self.fx) = 0.7710124458874459\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.19886133,  0.01248072,  0.00606078,  0.06400711,  0.0137025 ,\n",
      "       -0.01024469,  0.01632862,  0.02041206, -0.01433588,  0.01363712,\n",
      "       -0.00104644,  0.00771776,  0.00031346,  0.08615921, -0.03179124])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4140536573386449)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3822624192684324\n",
      "DEBUG:shap:self.fx = 0.2289875541125541\n",
      "DEBUG:shap:self.link(self.fx) = 0.2289875541125541\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.19886133, -0.01248072, -0.00606078, -0.06400711, -0.0137025 ,\n",
      "        0.01024469, -0.01632862, -0.02041206,  0.01433588, -0.01363712,\n",
      "        0.00104644, -0.00771776, -0.00031346, -0.08615921,  0.03179124])\n",
      " 53%|█████▎    | 39/74 [01:05<00:58,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.16534302942904086)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.12834400208798907\n",
      "DEBUG:shap:self.fx = 0.2604060245310245\n",
      "DEBUG:shap:self.link(self.fx) = 0.2604060245310245\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.11814006, -0.02285252, -0.00697099, -0.04151352,  0.01872748,\n",
      "       -0.02674708,  0.01034315, -0.03982123, -0.01464178, -0.00801776,\n",
      "       -0.00414412,  0.02256282, -0.00096971,  0.06684229,  0.03699903])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.16534302942904067)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12834400208798902\n",
      "DEBUG:shap:self.fx = 0.7395939754689755\n",
      "DEBUG:shap:self.link(self.fx) = 0.7395939754689755\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.11814006,  0.02285252,  0.00697099,  0.04151352, -0.01872748,\n",
      "        0.02674708, -0.01034315,  0.03982123,  0.01464178,  0.00801776,\n",
      "        0.00414412, -0.02256282,  0.00096971, -0.06684229, -0.03699903])\n",
      " 54%|█████▍    | 40/74 [01:07<00:55,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.18441068465872373)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.185941585060572\n",
      "DEBUG:shap:self.fx = 0.20280844155844158\n",
      "DEBUG:shap:self.link(self.fx) = 0.20280844155844158\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.11281822,  0.        ,  0.00475813, -0.06901795, -0.00243855,\n",
      "       -0.01771107,  0.00205189,  0.05664664, -0.00699321,  0.03009249,\n",
      "       -0.01660462,  0.        ,  0.00129807, -0.05367428, -0.0015309 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.18441068465872384)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.18594158506057212\n",
      "DEBUG:shap:self.fx = 0.7971915584415586\n",
      "DEBUG:shap:self.link(self.fx) = 0.7971915584415586\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.11281822,  0.        , -0.00475813,  0.06901795,  0.00243855,\n",
      "        0.01771107, -0.00205189, -0.05664664,  0.00699321, -0.03009249,\n",
      "        0.01660462,  0.        , -0.00129807,  0.05367428,  0.0015309 ])\n",
      " 55%|█████▌    | 41/74 [01:08<00:54,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.11657497378097217)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1157672192217325\n",
      "DEBUG:shap:self.fx = 0.2729828073972811\n",
      "DEBUG:shap:self.link(self.fx) = 0.2729828073972811\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.00316133,  0.00510392, -0.00208396, -0.06002053,  0.00224211,\n",
      "       -0.01078361, -0.00673497,  0.06776299,  0.00481985, -0.00983692,\n",
      "       -0.00804539, -0.00574737, -0.00374733, -0.08634244,  0.00080775])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.11657497378097206)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.11576721922173239\n",
      "DEBUG:shap:self.fx = 0.7270171926027189\n",
      "DEBUG:shap:self.link(self.fx) = 0.7270171926027189\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.00316133, -0.00510392,  0.00208396,  0.06002053, -0.00224211,\n",
      "        0.01078361,  0.00673497, -0.06776299, -0.00481985,  0.00983692,\n",
      "        0.00804539,  0.00574737,  0.00374733,  0.08634244, -0.00080775])\n",
      " 57%|█████▋    | 42/74 [01:10<00:52,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.27819158712987885)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2922225957165827\n",
      "DEBUG:shap:self.fx = 0.0965274309024309\n",
      "DEBUG:shap:self.link(self.fx) = 0.0965274309024309\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.07581323,  0.01301799, -0.00803611, -0.04291417, -0.00211953,\n",
      "        0.00786023, -0.05282657, -0.00970026, -0.0226608 , -0.02341902,\n",
      "        0.00106896, -0.01576809,  0.00679041, -0.05367138, -0.01403101])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.27819158712987874)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2922225957165827\n",
      "DEBUG:shap:self.fx = 0.9034725690975692\n",
      "DEBUG:shap:self.link(self.fx) = 0.9034725690975692\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.07581323, -0.01301799,  0.00803611,  0.04291417,  0.00211953,\n",
      "       -0.00786023,  0.05282657,  0.00970026,  0.0226608 ,  0.02341902,\n",
      "       -0.00106896,  0.01576809, -0.00679041,  0.05367138,  0.01403101])\n",
      " 58%|█████▊    | 43/74 [01:12<00:50,  1.63s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.10383664212165106)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.11631911031309727\n",
      "DEBUG:shap:self.fx = 0.2724309163059163\n",
      "DEBUG:shap:self.link(self.fx) = 0.2724309163059163\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.01810926,  0.00741408,  0.00403995,  0.04619308, -0.00486368,\n",
      "        0.0145797 ,  0.00536603, -0.02146199, -0.04734225, -0.01347223,\n",
      "        0.00761104,  0.00101452,  0.0018097 , -0.08661534, -0.01248247])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.103836642121651)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.11631911031309716\n",
      "DEBUG:shap:self.fx = 0.7275690836940837\n",
      "DEBUG:shap:self.link(self.fx) = 0.7275690836940837\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.01810926, -0.00741408, -0.00403995, -0.04619308,  0.00486368,\n",
      "       -0.0145797 , -0.00536603,  0.02146199,  0.04734225,  0.01347223,\n",
      "       -0.00761104, -0.00101452, -0.0018097 ,  0.08661534,  0.01248247])\n",
      " 59%|█████▉    | 44/74 [01:13<00:48,  1.63s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3389207674267126)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3364702647142517\n",
      "DEBUG:shap:self.fx = 0.05227976190476191\n",
      "DEBUG:shap:self.link(self.fx) = 0.05227976190476191\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.08038266, -0.00095471,  0.0046806 , -0.06664474,  0.00185713,\n",
      "       -0.01709293, -0.04515513, -0.02836179, -0.02046694, -0.01223783,\n",
      "       -0.01718811, -0.00149422, -0.00017734, -0.05530206,  0.0024505 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.33892076742671245)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.33647026471425145\n",
      "DEBUG:shap:self.fx = 0.947720238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.947720238095238\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.08038266,  0.00095471, -0.0046806 ,  0.06664474, -0.00185713,\n",
      "        0.01709293,  0.04515513,  0.02836179,  0.02046694,  0.01223783,\n",
      "        0.01718811,  0.00149422,  0.00017734,  0.05530206, -0.0024505 ])\n",
      " 61%|██████    | 45/74 [01:15<00:48,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4471841575432154)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4373185159495292\n",
      "DEBUG:shap:self.fx = 0.8260685425685428\n",
      "DEBUG:shap:self.link(self.fx) = 0.8260685425685428\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.19471883,  0.01281594,  0.01067682,  0.04333215, -0.00290143,\n",
      "        0.00401113,  0.01686211,  0.06440339,  0.00493508,  0.01524186,\n",
      "       -0.0010347 ,  0.00940059, -0.01760402,  0.09232641, -0.00986564])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4471841575432154)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4373185159495291\n",
      "DEBUG:shap:self.fx = 0.1739314574314574\n",
      "DEBUG:shap:self.link(self.fx) = 0.1739314574314574\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.19471883, -0.01281594, -0.01067682, -0.04333215,  0.00290143,\n",
      "       -0.00401113, -0.01686211, -0.06440339, -0.00493508, -0.01524186,\n",
      "        0.0010347 , -0.00940059,  0.01760402, -0.09232641,  0.00986564])\n",
      " 62%|██████▏   | 46/74 [01:17<00:45,  1.63s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0430114554967481)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.06452973528574835\n",
      "DEBUG:shap:self.fx = 0.45327976190476194\n",
      "DEBUG:shap:self.link(self.fx) = 0.45327976190476194\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.13075712,  0.01453951, -0.00963037,  0.05000027, -0.0240454 ,\n",
      "       -0.0083868 ,  0.00827173, -0.02567756, -0.04793397, -0.00430072,\n",
      "       -0.00435289,  0.00692357, -0.00521434, -0.03793869,  0.02151828])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.0430114554967484)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.06452973528574857\n",
      "DEBUG:shap:self.fx = 0.546720238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.546720238095238\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.13075712, -0.01453951,  0.00963037, -0.05000027,  0.0240454 ,\n",
      "        0.0083868 , -0.00827173,  0.02567756,  0.04793397,  0.00430072,\n",
      "        0.00435289, -0.00692357,  0.00521434,  0.03793869, -0.02151828])\n",
      " 64%|██████▎   | 47/74 [01:18<00:44,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2629883714423457)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.27359777609176306\n",
      "DEBUG:shap:self.fx = 0.11515225052725052\n",
      "DEBUG:shap:self.link(self.fx) = 0.11515225052725052\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.08115532,  0.01833015, -0.00729449, -0.03987646, -0.00268066,\n",
      "        0.0064992 , -0.04873182, -0.02778844, -0.01121038,  0.01590019,\n",
      "       -0.02320317, -0.01205209, -0.00451135, -0.04521374, -0.0106094 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2629883714423457)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.27359777609176306\n",
      "DEBUG:shap:self.fx = 0.8848477494727496\n",
      "DEBUG:shap:self.link(self.fx) = 0.8848477494727496\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.08115532, -0.01833015,  0.00729449,  0.03987646,  0.00268066,\n",
      "       -0.0064992 ,  0.04873182,  0.02778844,  0.01121038, -0.01590019,\n",
      "        0.02320317,  0.01205209,  0.00451135,  0.04521374,  0.0106094 ])\n",
      " 65%|██████▍   | 48/74 [01:20<00:42,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2676708734095905)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.25711757799859114\n",
      "DEBUG:shap:self.fx = 0.6458676046176047\n",
      "DEBUG:shap:self.link(self.fx) = 0.6458676046176047\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.20579447,  0.01021203, -0.01442252,  0.07245189, -0.00414953,\n",
      "       -0.00594842,  0.0156929 , -0.06057242, -0.00248034,  0.0051641 ,\n",
      "        0.01065725, -0.01601627,  0.00933855,  0.04194919, -0.0105533 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2676708734095905)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2571175779985912\n",
      "DEBUG:shap:self.fx = 0.3541323953823953\n",
      "DEBUG:shap:self.link(self.fx) = 0.3541323953823953\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.20579447, -0.01021203,  0.01442252, -0.07245189,  0.00414953,\n",
      "        0.00594842, -0.0156929 ,  0.06057242,  0.00248034, -0.0051641 ,\n",
      "       -0.01065725,  0.01601627, -0.00933855, -0.04194919,  0.0105533 ])\n",
      " 66%|██████▌   | 49/74 [01:22<00:41,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.18856714661436105)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.18284706846605533\n",
      "DEBUG:shap:self.fx = 0.20590295815295825\n",
      "DEBUG:shap:self.link(self.fx) = 0.20590295815295825\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.07779636,  0.00119577,  0.00562528,  0.00420623, -0.00711086,\n",
      "       -0.01213782, -0.02203895, -0.03386675, -0.01569331, -0.00843827,\n",
      "        0.00067344, -0.01409775, -0.00727328, -0.00181453,  0.00572008])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1885671466143608)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.18284706846605503\n",
      "DEBUG:shap:self.fx = 0.7940970418470416\n",
      "DEBUG:shap:self.link(self.fx) = 0.7940970418470416\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.07779636, -0.00119577, -0.00562528, -0.00420623,  0.00711086,\n",
      "        0.01213782,  0.02203895,  0.03386675,  0.01569331,  0.00843827,\n",
      "       -0.00067344,  0.01409775,  0.00727328,  0.00181453, -0.00572008])\n",
      " 68%|██████▊   | 50/74 [01:23<00:40,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2004797246403764)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1950200731433705\n",
      "DEBUG:shap:self.fx = 0.1937299534756431\n",
      "DEBUG:shap:self.link(self.fx) = 0.1937299534756431\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.09855834, -0.02835876,  0.00399698,  0.01429042,  0.02927847,\n",
      "       -0.01040315,  0.00600128, -0.02964175,  0.00937199, -0.01313608,\n",
      "        0.00113411, -0.00516328, -0.00384416, -0.07544745,  0.00545965])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2004797246403761)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.19502007314337022\n",
      "DEBUG:shap:self.fx = 0.8062700465243567\n",
      "DEBUG:shap:self.link(self.fx) = 0.8062700465243567\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.09855834,  0.02835876, -0.00399698, -0.01429042, -0.02927847,\n",
      "        0.01040315, -0.00600128,  0.02964175, -0.00937199,  0.01313608,\n",
      "       -0.00113411,  0.00516328,  0.00384416,  0.07544745, -0.00545965])\n",
      " 69%|██████▉   | 51/74 [01:25<00:39,  1.70s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4984843577623236)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4797341003651133\n",
      "DEBUG:shap:self.fx = 0.8684841269841269\n",
      "DEBUG:shap:self.link(self.fx) = 0.8684841269841269\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.21918576,  0.01246896,  0.00666008,  0.05353384,  0.        ,\n",
      "        0.0031396 ,  0.02217251,  0.10026551, -0.01867065, -0.00443152,\n",
      "        0.00850616,  0.00630824,  0.00354002,  0.08580585, -0.01875026])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4984843577623238)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.47973410036511355\n",
      "DEBUG:shap:self.fx = 0.13151587301587297\n",
      "DEBUG:shap:self.link(self.fx) = 0.13151587301587297\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.21918576, -0.01246896, -0.00666008, -0.05353384,  0.        ,\n",
      "       -0.0031396 , -0.02217251, -0.10026551,  0.01867065,  0.00443152,\n",
      "       -0.00850616, -0.00630824, -0.00354002, -0.08580585,  0.01875026])\n",
      " 70%|███████   | 52/74 [01:27<00:36,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2835825837692731)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.29004752225203556\n",
      "DEBUG:shap:self.fx = 0.09870250436697804\n",
      "DEBUG:shap:self.link(self.fx) = 0.09870250436697804\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10518599, -0.01045588,  0.00305625, -0.07215032,  0.00627468,\n",
      "        0.0159059 ,  0.0030837 , -0.0307889 , -0.00098388, -0.01269781,\n",
      "       -0.00977111, -0.00430925,  0.00189529, -0.06745525, -0.00646494])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.28358258376927326)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2900475222520358\n",
      "DEBUG:shap:self.fx = 0.9012974956330223\n",
      "DEBUG:shap:self.link(self.fx) = 0.9012974956330223\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10518599,  0.01045588, -0.00305625,  0.07215032, -0.00627468,\n",
      "       -0.0159059 , -0.0030837 ,  0.0307889 ,  0.00098388,  0.01269781,\n",
      "        0.00977111,  0.00430925, -0.00189529,  0.06745525,  0.00646494])\n",
      " 72%|███████▏  | 53/74 [01:28<00:35,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.30474182119764165)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.31142747643348945\n",
      "DEBUG:shap:self.fx = 0.700177503052503\n",
      "DEBUG:shap:self.link(self.fx) = 0.700177503052503\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.194471  ,  0.01942704, -0.00190935, -0.04875413,  0.01400853,\n",
      "        0.01704084,  0.0271071 , -0.01292548,  0.00949385, -0.00187613,\n",
      "       -0.01323383,  0.01740436,  0.0042088 ,  0.08027924,  0.00668566])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.30474182119764176)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.31142747643348956\n",
      "DEBUG:shap:self.fx = 0.29982249694749696\n",
      "DEBUG:shap:self.link(self.fx) = 0.29982249694749696\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.194471  , -0.01942704,  0.00190935,  0.04875413, -0.01400853,\n",
      "       -0.01704084, -0.0271071 ,  0.01292548, -0.00949385,  0.00187613,\n",
      "        0.01323383, -0.01740436, -0.0042088 , -0.08027924, -0.00668566])\n",
      " 73%|███████▎  | 54/74 [01:30<00:33,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.06647921870587176)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.016717017961004943\n",
      "DEBUG:shap:self.fx = 0.37203300865800865\n",
      "DEBUG:shap:self.link(self.fx) = 0.37203300865800865\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.09178363,  0.03715429, -0.00272417, -0.04290377,  0.0181562 ,\n",
      "       -0.01233026, -0.02975493, -0.02620378,  0.00629049, -0.00096137,\n",
      "       -0.00583161, -0.00987604,  0.00312453,  0.09116481,  0.0497622 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.06647921870587173)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.016717017961005\n",
      "DEBUG:shap:self.fx = 0.6279669913419915\n",
      "DEBUG:shap:self.link(self.fx) = 0.6279669913419915\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.09178363, -0.03715429,  0.00272417,  0.04290377, -0.0181562 ,\n",
      "        0.01233026,  0.02975493,  0.02620378, -0.00629049,  0.00096137,\n",
      "        0.00583161,  0.00987604, -0.00312453, -0.09116481, -0.0497622 ])\n",
      " 74%|███████▍  | 55/74 [01:32<00:31,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.38983663283029923)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4149225924286054\n",
      "DEBUG:shap:self.fx = 0.803672619047619\n",
      "DEBUG:shap:self.link(self.fx) = 0.803672619047619\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.18280862,  0.00991086,  0.00928909,  0.06733662,  0.01215658,\n",
      "        0.02139645,  0.01998421, -0.00769313, -0.02804205,  0.01302584,\n",
      "        0.00989675,  0.0059596 ,  0.00077109,  0.07303608,  0.02508596])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3898366328302994)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4149225924286055\n",
      "DEBUG:shap:self.fx = 0.19632738095238098\n",
      "DEBUG:shap:self.link(self.fx) = 0.19632738095238098\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.18280862, -0.00991086, -0.00928909, -0.06733662, -0.01215658,\n",
      "       -0.02139645, -0.01998421,  0.00769313,  0.02804205, -0.01302584,\n",
      "       -0.00989675, -0.0059596 , -0.00077109, -0.07303608, -0.02508596])\n",
      " 76%|███████▌  | 56/74 [01:33<00:29,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12992599730797832)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12684066047167364\n",
      "DEBUG:shap:self.fx = 0.5155906870906872\n",
      "DEBUG:shap:self.link(self.fx) = 0.5155906870906872\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.10023958,  0.01886029,  0.00508959,  0.0483061 , -0.02265622,\n",
      "        0.02365747,  0.01134186, -0.03672281, -0.00120406,  0.01449263,\n",
      "        0.00633259,  0.02388618,  0.00864743, -0.07034463, -0.00308534])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.12992599730797832)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1268406604716737\n",
      "DEBUG:shap:self.fx = 0.48440931290931283\n",
      "DEBUG:shap:self.link(self.fx) = 0.48440931290931283\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.10023958, -0.01886029, -0.00508959, -0.0483061 ,  0.02265622,\n",
      "       -0.02365747, -0.01134186,  0.03672281,  0.00120406, -0.01449263,\n",
      "       -0.00633259, -0.02388618, -0.00864743,  0.07034463,  0.00308534])\n",
      " 77%|███████▋  | 57/74 [01:35<00:28,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.16493650095985948)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.17974726263463192\n",
      "DEBUG:shap:self.fx = 0.20900276398438167\n",
      "DEBUG:shap:self.link(self.fx) = 0.20900276398438167\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.12560016,  0.00041961,  0.01024276, -0.03226313,  0.00680112,\n",
      "        0.01340389,  0.01175909, -0.03988826,  0.00352238, -0.02317526,\n",
      "       -0.01321315, -0.01005553,  0.00137787,  0.03173227, -0.01481076])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.16493650095985907)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1797472626346316\n",
      "DEBUG:shap:self.fx = 0.7909972360156181\n",
      "DEBUG:shap:self.link(self.fx) = 0.7909972360156181\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.12560016, -0.00041961, -0.01024276,  0.03226313, -0.00680112,\n",
      "       -0.01340389, -0.01175909,  0.03988826, -0.00352238,  0.02317526,\n",
      "        0.01321315,  0.01005553, -0.00137787, -0.03173227,  0.01481076])\n",
      " 78%|███████▊  | 58/74 [01:37<00:26,  1.67s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2876036309817329)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.28197660272490005\n",
      "DEBUG:shap:self.fx = 0.10677342389411354\n",
      "DEBUG:shap:self.link(self.fx) = 0.10677342389411354\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.11865118, -0.0082497 , -0.0011971 , -0.06457253, -0.0034333 ,\n",
      "       -0.02517196, -0.00793142, -0.04368102, -0.01660129,  0.02947552,\n",
      "       -0.01513408,  0.00354403, -0.00072438, -0.01527526,  0.00562703])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.28760363098173286)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2819766027249\n",
      "DEBUG:shap:self.fx = 0.8932265761058865\n",
      "DEBUG:shap:self.link(self.fx) = 0.8932265761058865\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.11865118,  0.0082497 ,  0.0011971 ,  0.06457253,  0.0034333 ,\n",
      "        0.02517196,  0.00793142,  0.04368102,  0.01660129, -0.02947552,\n",
      "        0.01513408, -0.00354403,  0.00072438,  0.01527526, -0.00562703])\n",
      " 80%|███████▉  | 59/74 [01:38<00:24,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.06340277420740117)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.05503339828941134\n",
      "DEBUG:shap:self.fx = 0.44378342490842493\n",
      "DEBUG:shap:self.link(self.fx) = 0.44378342490842493\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.13054476, -0.07137148,  0.00063539,  0.04447173,  0.01430261,\n",
      "       -0.00551502,  0.01141635,  0.11431032, -0.01917532, -0.0107735 ,\n",
      "       -0.00545697,  0.00323237, -0.00582168, -0.13739679, -0.00836938])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.06340277420740123)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.05503339828941134\n",
      "DEBUG:shap:self.fx = 0.5562165750915752\n",
      "DEBUG:shap:self.link(self.fx) = 0.5562165750915752\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.13054476,  0.07137148, -0.00063539, -0.04447173, -0.01430261,\n",
      "        0.00551502, -0.01141635, -0.11431032,  0.01917532,  0.0107735 ,\n",
      "        0.00545697, -0.00323237,  0.00582168,  0.13739679,  0.00836938])\n",
      " 81%|████████  | 60/74 [01:40<00:23,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.33182342949912225)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3496845504285374\n",
      "DEBUG:shap:self.fx = 0.03906547619047619\n",
      "DEBUG:shap:self.link(self.fx) = 0.03906547619047619\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.09334933,  0.00927705, -0.00371047, -0.05136281, -0.00387131,\n",
      "       -0.01015702, -0.04580804, -0.01781904, -0.00064913, -0.01033052,\n",
      "       -0.01755115, -0.01681973, -0.00562781, -0.06404413, -0.01786112])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3318234294991221)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3496845504285372\n",
      "DEBUG:shap:self.fx = 0.9609345238095237\n",
      "DEBUG:shap:self.link(self.fx) = 0.9609345238095237\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.09334933, -0.00927705,  0.00371047,  0.05136281,  0.00387131,\n",
      "        0.01015702,  0.04580804,  0.01781904,  0.00064913,  0.01033052,\n",
      "        0.01755115,  0.01681973,  0.00562781,  0.06404413,  0.01786112])\n",
      " 82%|████████▏ | 61/74 [01:42<00:21,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.31229327575980287)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3191463108902979\n",
      "DEBUG:shap:self.fx = 0.06960371572871574\n",
      "DEBUG:shap:self.link(self.fx) = 0.06960371572871574\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10854893,  0.00058753, -0.00082631, -0.05739853, -0.00045388,\n",
      "       -0.01738073,  0.        , -0.03296524, -0.00242563, -0.01628219,\n",
      "       -0.01177877,  0.0049132 ,  0.0005226 , -0.07025639, -0.00685304])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3122932757598026)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.31914631089029755\n",
      "DEBUG:shap:self.fx = 0.9303962842712841\n",
      "DEBUG:shap:self.link(self.fx) = 0.9303962842712841\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10854893, -0.00058753,  0.00082631,  0.05739853,  0.00045388,\n",
      "        0.01738073,  0.        ,  0.03296524,  0.00242563,  0.01628219,\n",
      "        0.01177877, -0.0049132 , -0.0005226 ,  0.07025639,  0.00685304])\n",
      " 84%|████████▍ | 62/74 [01:43<00:19,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19542722056602171)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.20859297533696225\n",
      "DEBUG:shap:self.fx = 0.18015705128205134\n",
      "DEBUG:shap:self.link(self.fx) = 0.18015705128205134\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10112648,  0.00716719,  0.00588557, -0.04110939, -0.00967955,\n",
      "       -0.01396484, -0.05146119, -0.01970137, -0.03091968,  0.0196681 ,\n",
      "       -0.0003915 , -0.00479022,  0.00600959,  0.03898654, -0.01316575])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19542722056602171)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2085929753369623\n",
      "DEBUG:shap:self.fx = 0.8198429487179488\n",
      "DEBUG:shap:self.link(self.fx) = 0.8198429487179488\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10112648, -0.00716719, -0.00588557,  0.04110939,  0.00967955,\n",
      "        0.01396484,  0.05146119,  0.01970137,  0.03091968, -0.0196681 ,\n",
      "        0.0003915 ,  0.00479022, -0.00600959, -0.03898654,  0.01316575])\n",
      " 85%|████████▌ | 63/74 [01:45<00:18,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.18553403966404852)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13913644575543269\n",
      "DEBUG:shap:self.fx = 0.2496135808635809\n",
      "DEBUG:shap:self.link(self.fx) = 0.2496135808635809\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.08776929,  0.00794474, -0.00262596, -0.06084735,  0.01185998,\n",
      "       -0.00562009, -0.06556355,  0.09338578,  0.00068497, -0.00938831,\n",
      "       -0.02454478, -0.01538459,  0.00903899, -0.03670458,  0.04639759])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1855340396640485)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1391364457554327\n",
      "DEBUG:shap:self.fx = 0.7503864191364192\n",
      "DEBUG:shap:self.link(self.fx) = 0.7503864191364192\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.08776929, -0.00794474,  0.00262596,  0.06084735, -0.01185998,\n",
      "        0.00562009,  0.06556355, -0.09338578, -0.00068497,  0.00938831,\n",
      "        0.02454478,  0.01538459, -0.00903899,  0.03670458, -0.04639759])\n",
      " 86%|████████▋ | 64/74 [01:47<00:16,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.07293401947212699)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08346072564221257\n",
      "DEBUG:shap:self.fx = 0.305289300976801\n",
      "DEBUG:shap:self.link(self.fx) = 0.305289300976801\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.01782229, -0.0242754 ,  0.00248173, -0.06629605,  0.00376133,\n",
      "        0.03655849,  0.00450552, -0.04245322, -0.00451884, -0.0070334 ,\n",
      "       -0.01648868,  0.00150979, -0.00258105,  0.05971804, -0.01052671])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.07293401947212677)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.0834607256422123\n",
      "DEBUG:shap:self.fx = 0.6947106990231988\n",
      "DEBUG:shap:self.link(self.fx) = 0.6947106990231988\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.01782229,  0.0242754 , -0.00248173,  0.06629605, -0.00376133,\n",
      "       -0.03655849, -0.00450552,  0.04245322,  0.00451884,  0.0070334 ,\n",
      "        0.01648868, -0.00150979,  0.00258105, -0.05971804,  0.01052671])\n",
      " 88%|████████▊ | 65/74 [01:48<00:14,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20570631387797483)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.20470736788885488\n",
      "DEBUG:shap:self.fx = 0.1840426587301587\n",
      "DEBUG:shap:self.link(self.fx) = 0.1840426587301587\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.13702941, -0.00179768, -0.0032439 , -0.03749909,  0.00900317,\n",
      "        0.01458066, -0.01678465, -0.01971694, -0.00617561,  0.00628103,\n",
      "       -0.01394552,  0.00382235, -0.00298716, -0.00021358,  0.00099895])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20570631387797472)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2047073678888548\n",
      "DEBUG:shap:self.fx = 0.8159573412698413\n",
      "DEBUG:shap:self.link(self.fx) = 0.8159573412698413\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.13702941,  0.00179768,  0.0032439 ,  0.03749909, -0.00900317,\n",
      "       -0.01458066,  0.01678465,  0.01971694,  0.00617561, -0.00628103,\n",
      "        0.01394552, -0.00382235,  0.00298716,  0.00021358, -0.00099895])\n",
      " 89%|████████▉ | 66/74 [01:50<00:13,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.014010732087060385)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.0026340453780323014\n",
      "DEBUG:shap:self.fx = 0.3861159812409813\n",
      "DEBUG:shap:self.link(self.fx) = 0.3861159812409813\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.11993773,  0.01295766, -0.01188146,  0.04243783, -0.01148124,\n",
      "        0.01802294,  0.00423679, -0.03092928, -0.01516069,  0.        ,\n",
      "        0.00203178, -0.03942007,  0.00573869, -0.1105014 ,  0.01137669])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.014010732087060149)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.002634045378032024\n",
      "DEBUG:shap:self.fx = 0.6138840187590185\n",
      "DEBUG:shap:self.link(self.fx) = 0.6138840187590185\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.11993773, -0.01295766,  0.01188146, -0.04243783,  0.01148124,\n",
      "       -0.01802294, -0.00423679,  0.03092928,  0.01516069,  0.        ,\n",
      "       -0.00203178,  0.03942007, -0.00573869,  0.1105014 , -0.01137669])\n",
      " 91%|█████████ | 67/74 [01:52<00:11,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.08511255178987985)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.05949096849698138\n",
      "DEBUG:shap:self.fx = 0.44824099511599497\n",
      "DEBUG:shap:self.link(self.fx) = 0.44824099511599497\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.06666743,  0.00027538, -0.00384314,  0.0567037 , -0.00905601,\n",
      "        0.00691178,  0.00999601,  0.02555342,  0.00723299,  0.02470173,\n",
      "       -0.00417673,  0.00456311,  0.00536586, -0.10578298, -0.02562158])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.08511255178987999)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.059490968496981544\n",
      "DEBUG:shap:self.fx = 0.551759004884005\n",
      "DEBUG:shap:self.link(self.fx) = 0.551759004884005\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.06666743, -0.00027538,  0.00384314, -0.0567037 ,  0.00905601,\n",
      "       -0.00691178, -0.00999601, -0.02555342, -0.00723299, -0.02470173,\n",
      "        0.00417673, -0.00456311, -0.00536586,  0.10578298,  0.02562158])\n",
      " 92%|█████████▏| 68/74 [01:53<00:10,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.16777228474523637)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13868586855485548\n",
      "DEBUG:shap:self.fx = 0.2500641580641581\n",
      "DEBUG:shap:self.link(self.fx) = 0.2500641580641581\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.10261326, -0.01495426, -0.00325698,  0.0015475 ,  0.00061481,\n",
      "       -0.00927256, -0.038214  , -0.03825652, -0.01916041, -0.00941577,\n",
      "        0.00366781, -0.00550871, -0.00875116, -0.12942529,  0.02908642])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1677722847452362)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.13868586855485532\n",
      "DEBUG:shap:self.fx = 0.7499358419358418\n",
      "DEBUG:shap:self.link(self.fx) = 0.7499358419358418\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.10261326,  0.01495426,  0.00325698, -0.0015475 , -0.00061481,\n",
      "        0.00927256,  0.038214  ,  0.03825652,  0.01916041,  0.00941577,\n",
      "       -0.00366781,  0.00550871,  0.00875116,  0.12942529, -0.02908642])\n",
      " 93%|█████████▎| 69/74 [01:55<00:08,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.059179816296691674)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.05465494114892816\n",
      "DEBUG:shap:self.fx = 0.33409508547008543\n",
      "DEBUG:shap:self.link(self.fx) = 0.33409508547008543\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.1374253 ,  0.0109501 ,  0.00712266, -0.05533999,  0.00576124,\n",
      "       -0.00549544,  0.01804169,  0.10396605,  0.00346298, -0.00475835,\n",
      "        0.00469653,  0.00019447, -0.00329322, -0.00706325,  0.00452488])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.059179816296691404)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.05465494114892788\n",
      "DEBUG:shap:self.fx = 0.6659049145299144\n",
      "DEBUG:shap:self.link(self.fx) = 0.6659049145299144\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.1374253 , -0.0109501 , -0.00712266,  0.05533999, -0.00576124,\n",
      "        0.00549544, -0.01804169, -0.10396605, -0.00346298,  0.00475835,\n",
      "       -0.00469653, -0.00019447,  0.00329322,  0.00706325, -0.00452488])\n",
      " 95%|█████████▍| 70/74 [01:57<00:06,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22442619850220719)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2082174503484634\n",
      "DEBUG:shap:self.fx = 0.596967476967477\n",
      "DEBUG:shap:self.link(self.fx) = 0.596967476967477\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.18971296,  0.01320275, -0.00593675,  0.06281746,  0.02437085,\n",
      "       -0.01615366,  0.0119059 , -0.03956066, -0.04940088, -0.00924163,\n",
      "       -0.00960098,  0.02326982,  0.00270733,  0.0263337 , -0.01620875])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2244261985022073)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2082174503484635\n",
      "DEBUG:shap:self.fx = 0.403032523032523\n",
      "DEBUG:shap:self.link(self.fx) = 0.403032523032523\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.18971296, -0.01320275,  0.00593675, -0.06281746, -0.02437085,\n",
      "        0.01615366, -0.0119059 ,  0.03956066,  0.04940088,  0.00924163,\n",
      "        0.00960098, -0.02326982, -0.00270733, -0.0263337 ,  0.01620875])\n",
      " 96%|█████████▌| 71/74 [01:59<00:05,  1.70s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.11930521108277546)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13145533519932218\n",
      "DEBUG:shap:self.fx = 0.2572946914196914\n",
      "DEBUG:shap:self.link(self.fx) = 0.2572946914196914\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.11210031,  0.00995708,  0.00322982, -0.02310192,  0.0095339 ,\n",
      "        0.01667265, -0.01498598, -0.02067081, -0.01028987,  0.03802442,\n",
      "       -0.00845897, -0.01666046, -0.00394476,  0.01349001, -0.01215012])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.11930521108277536)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.13145533519932218\n",
      "DEBUG:shap:self.fx = 0.7427053085803087\n",
      "DEBUG:shap:self.link(self.fx) = 0.7427053085803087\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.11210031, -0.00995708, -0.00322982,  0.02310192, -0.0095339 ,\n",
      "       -0.01667265,  0.01498598,  0.02067081,  0.01028987, -0.03802442,\n",
      "        0.00845897,  0.01666046,  0.00394476, -0.01349001,  0.01215012])\n",
      " 97%|█████████▋| 72/74 [02:00<00:03,  1.67s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20719081195126965)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.22933741371842675\n",
      "DEBUG:shap:self.fx = 0.6180874403374403\n",
      "DEBUG:shap:self.link(self.fx) = 0.6180874403374403\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.15134237,  0.01547573,  0.00668955,  0.06698761,  0.00150773,\n",
      "        0.02417875,  0.01160662, -0.00804117,  0.00960278,  0.02375007,\n",
      "       -0.00159867,  0.00417564,  0.03054002, -0.12902621,  0.0221466 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20719081195126973)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2293374137184268\n",
      "DEBUG:shap:self.fx = 0.3819125596625597\n",
      "DEBUG:shap:self.link(self.fx) = 0.3819125596625597\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.15134237, -0.01547573, -0.00668955, -0.06698761, -0.00150773,\n",
      "       -0.02417875, -0.01160662,  0.00804117, -0.00960278, -0.02375007,\n",
      "        0.00159867, -0.00417564, -0.03054002,  0.12902621, -0.0221466 ])\n",
      " 99%|█████████▊| 73/74 [02:02<00:01,  1.70s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.29170939104198834)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.31654849430450716\n",
      "DEBUG:shap:self.fx = 0.7052985209235207\n",
      "DEBUG:shap:self.link(self.fx) = 0.7052985209235207\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.17866445, -0.0090458 , -0.01316276,  0.07318511, -0.02260881,\n",
      "        0.0222096 ,  0.01570815, -0.00923042, -0.0020316 ,  0.01007408,\n",
      "        0.0072396 , -0.00302005,  0.0082152 ,  0.03551263,  0.0248391 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.29170939104198845)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3165484943045075\n",
      "DEBUG:shap:self.fx = 0.29470147907647903\n",
      "DEBUG:shap:self.link(self.fx) = 0.29470147907647903\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.17866445,  0.0090458 ,  0.01316276, -0.07318511,  0.02260881,\n",
      "       -0.0222096 , -0.01570815,  0.00923042,  0.0020316 , -0.01007408,\n",
      "       -0.0072396 ,  0.00302005, -0.0082152 , -0.03551263, -0.0248391 ])\n",
      "100%|██████████| 74/74 [02:04<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8020833333333333,\n",
      "                0.8397435897435898,\n",
      "                0.7131410256410257,\n",
      "                0.6145833333333333,\n",
      "                0.5737179487179487,\n",
      "                0.5817307692307693,\n",
      "                0.5825320512820513,\n",
      "                0.6145833333333334,\n",
      "                0.6386217948717948,\n",
      "                0.6810897435897435,\n",
      "                0.6602564102564104,\n",
      "                0.6518429487179487,\n",
      "                0.7471955128205128,\n",
      "                0.6947115384615384,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5333619228350892,\n",
      "                0.5854290017917382,\n",
      "                0.7117184396839162,\n",
      "                0.7458745657755351,\n",
      "                0.7882211683938165,\n",
      "                0.81629281154797,\n",
      "                0.8518784974388885,\n",
      "                0.8782272567565552,\n",
      "                0.8603662885864408,\n",
      "                0.8846268030968748,\n",
      "                0.9209466010297434,\n",
      "                0.9438895036052928,\n",
      "                0.9230942930370424,\n",
      "                0.942150054860188,\n",
      "                0.9272027411818561\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17575241929729749,\n",
      "                0.1986929523104957,\n",
      "                0.2597070037610788,\n",
      "                0.27604349501841946,\n",
      "                0.2965766383981693,\n",
      "                0.3094726358791318,\n",
      "                0.3252681944157605,\n",
      "                0.3367758697199785,\n",
      "                0.3291563975002879,\n",
      "                0.3395284163415068,\n",
      "                0.354542866188551,\n",
      "                0.3641007792104075,\n",
      "                0.3560428205920232,\n",
      "                0.3635532888116729,\n",
      "                0.3581441230715909\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6597222222222222,\n",
      "            \"cross_entropy\": 0.82088532997473,\n",
      "            \"brier\": 0.3095571933677581\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8565705128205129,\n",
      "                0.8325320512820513,\n",
      "                0.8445512820512819,\n",
      "                0.8878205128205128,\n",
      "                0.8782051282051282,\n",
      "                0.8838141025641025,\n",
      "                0.8878205128205129,\n",
      "                0.8838141025641025,\n",
      "                0.8822115384615383,\n",
      "                0.8766025641025641,\n",
      "                0.875,\n",
      "                0.875801282051282,\n",
      "                0.8701923076923077,\n",
      "                0.875801282051282,\n",
      "                0.8782051282051282\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5577995700528187,\n",
      "                0.5201346733885938,\n",
      "                0.4655374628351458,\n",
      "                0.4380237734852441,\n",
      "                0.43838018080987795,\n",
      "                0.4360449867580237,\n",
      "                0.42697233630539444,\n",
      "                0.4353986306482422,\n",
      "                0.4363295317869158,\n",
      "                0.4388482578823135,\n",
      "                0.44277956858477674,\n",
      "                0.4479181639936016,\n",
      "                0.4411853843562204,\n",
      "                0.43669113234623613,\n",
      "                0.43130759728033224\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18281475287193621,\n",
      "                0.16834113484809304,\n",
      "                0.145363733060362,\n",
      "                0.13537964233817612,\n",
      "                0.13578212969515902,\n",
      "                0.1345341998682114,\n",
      "                0.1312264121027697,\n",
      "                0.1356495060143545,\n",
      "                0.1352525686591906,\n",
      "                0.13748507467713983,\n",
      "                0.13884812722942685,\n",
      "                0.14046081786348746,\n",
      "                0.13793953188590014,\n",
      "                0.13646746105293178,\n",
      "                0.13441740529050694\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.872596153846154,\n",
      "            \"cross_entropy\": 0.4528900833675824,\n",
      "            \"brier\": 0.14199749983050972\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/74 [00:00<?, ?it/s]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.27678796843625)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2756445436944241\n",
      "DEBUG:shap:self.fx = 0.6749630926444653\n",
      "DEBUG:shap:self.link(self.fx) = 0.6749630926444653\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.2017999 ,  0.0271786 , -0.00033244,  0.09964273,  0.00637291,\n",
      "       -0.01298279,  0.02917157, -0.02738782, -0.00783265, -0.00173201,\n",
      "        0.00196725,  0.01117128,  0.02924102, -0.07948959, -0.00114342])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2767879684362497)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.27564454369442387\n",
      "DEBUG:shap:self.fx = 0.32503690735553487\n",
      "DEBUG:shap:self.link(self.fx) = 0.32503690735553487\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.2017999 , -0.0271786 ,  0.00033244, -0.09964273, -0.00637291,\n",
      "        0.01298279, -0.02917157,  0.02738782,  0.00783265,  0.00173201,\n",
      "       -0.00196725, -0.01117128, -0.02924102,  0.07948959,  0.00114342])\n",
      "  1%|▏         | 1/74 [00:02<02:45,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22974861923562265)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2373706104454989\n",
      "DEBUG:shap:self.fx = 0.1619479385045423\n",
      "DEBUG:shap:self.link(self.fx) = 0.1619479385045423\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.1560494 ,  0.05130451,  0.01028373, -0.06063561, -0.00555516,\n",
      "       -0.01586947, -0.01900141, -0.02634468,  0.00042112, -0.00885417,\n",
      "       -0.02186089, -0.00740835, -0.00347823,  0.03329938, -0.00762199])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22974861923562284)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.237370610445499\n",
      "DEBUG:shap:self.fx = 0.8380520614954577\n",
      "DEBUG:shap:self.link(self.fx) = 0.8380520614954577\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.1560494 , -0.05130451, -0.01028373,  0.06063561,  0.00555516,\n",
      "        0.01586947,  0.01900141,  0.02634468, -0.00042112,  0.00885417,\n",
      "        0.02186089,  0.00740835,  0.00347823, -0.03329938,  0.00762199])\n",
      "  3%|▎         | 2/74 [00:04<02:40,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.08656965909312911)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08844081801570658\n",
      "DEBUG:shap:self.fx = 0.31087773093433463\n",
      "DEBUG:shap:self.link(self.fx) = 0.31087773093433463\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.16372654,  0.00125026,  0.01026172, -0.05362372,  0.00247549,\n",
      "       -0.01985236,  0.0291535 ,  0.03863178, -0.00267566,  0.03658878,\n",
      "       -0.00560807, -0.00048366, -0.01246481,  0.05350362, -0.00187116])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.08656965909312897)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08844081801570647\n",
      "DEBUG:shap:self.fx = 0.6891222690656652\n",
      "DEBUG:shap:self.link(self.fx) = 0.6891222690656652\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.16372654, -0.00125026, -0.01026172,  0.05362372, -0.00247549,\n",
      "        0.01985236, -0.0291535 , -0.03863178,  0.00267566, -0.03658878,\n",
      "        0.00560807,  0.00048366,  0.01246481, -0.05350362,  0.00187116])\n",
      "  4%|▍         | 3/74 [00:06<02:36,  2.21s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3124188559198798)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3189241040992156\n",
      "DEBUG:shap:self.fx = 0.7182426530492568\n",
      "DEBUG:shap:self.link(self.fx) = 0.7182426530492568\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.23661822,  0.02083283, -0.00227873, -0.02244465, -0.00630095,\n",
      "        0.01868008,  0.04059353,  0.01109673,  0.00482572, -0.00030264,\n",
      "       -0.00417193,  0.01622315, -0.02170387,  0.02075136,  0.00650525])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.31241885591987956)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3189241040992155\n",
      "DEBUG:shap:self.fx = 0.2817573469507432\n",
      "DEBUG:shap:self.link(self.fx) = 0.2817573469507432\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.23661822, -0.02083283,  0.00227873,  0.02244465,  0.00630095,\n",
      "       -0.01868008, -0.04059353, -0.01109673, -0.00482572,  0.00030264,\n",
      "        0.00417193, -0.01622315,  0.02170387, -0.02075136, -0.00650525])\n",
      "  5%|▌         | 4/74 [00:08<02:35,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1228259866755429)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.11995346958496172\n",
      "DEBUG:shap:self.fx = 0.2793650793650795\n",
      "DEBUG:shap:self.link(self.fx) = 0.2793650793650795\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.03525158, -0.04229583,  0.00344969, -0.04907609,  0.01366168,\n",
      "        0.07048535,  0.00740564, -0.05015137, -0.01780168, -0.00826769,\n",
      "       -0.03064862,  0.00514499, -0.01766778,  0.0281873 ,  0.00287252])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12282598667554281)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.11995346958496167\n",
      "DEBUG:shap:self.fx = 0.7206349206349204\n",
      "DEBUG:shap:self.link(self.fx) = 0.7206349206349204\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.03525158,  0.04229583, -0.00344969,  0.04907609, -0.01366168,\n",
      "       -0.07048535, -0.00740564,  0.05015137,  0.01780168,  0.00826769,\n",
      "        0.03064862, -0.00514499,  0.01766778, -0.0281873 , -0.00287252])\n",
      "  7%|▋         | 5/74 [00:11<02:31,  2.20s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17469777862096944)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2140995806164981\n",
      "DEBUG:shap:self.fx = 0.18521896833354312\n",
      "DEBUG:shap:self.link(self.fx) = 0.18521896833354312\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.10882362,  0.01573118,  0.012081  , -0.04666538,  0.        ,\n",
      "       -0.01830181, -0.04257631, -0.01746365,  0.        , -0.00107144,\n",
      "        0.02415658,  0.00472724, -0.00934204,  0.01285046, -0.0394018 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1746977786209695)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21409958061649814\n",
      "DEBUG:shap:self.fx = 0.8147810316664569\n",
      "DEBUG:shap:self.link(self.fx) = 0.8147810316664569\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.10882362, -0.01573118, -0.012081  ,  0.04666538,  0.        ,\n",
      "        0.01830181,  0.04257631,  0.01746365,  0.        ,  0.00107144,\n",
      "       -0.02415658, -0.00472724,  0.00934204, -0.01285046,  0.0394018 ])\n",
      "  8%|▊         | 6/74 [00:13<02:30,  2.21s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.28331027911950996)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2926814570063455\n",
      "DEBUG:shap:self.fx = 0.10663709194369572\n",
      "DEBUG:shap:self.link(self.fx) = 0.10663709194369572\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.16074567,  0.00909135, -0.00112331, -0.0677367 ,  0.01495482,\n",
      "       -0.01621414, -0.03339971,  0.00121717,  0.00218612, -0.00397124,\n",
      "        0.01095465, -0.00210404, -0.00702569, -0.02939388, -0.00937118])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.28331027911951007)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2926814570063455\n",
      "DEBUG:shap:self.fx = 0.8933629080563043\n",
      "DEBUG:shap:self.link(self.fx) = 0.8933629080563043\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.16074567, -0.00909135,  0.00112331,  0.0677367 , -0.01495482,\n",
      "        0.01621414,  0.03339971, -0.00121717, -0.00218612,  0.00397124,\n",
      "       -0.01095465,  0.00210404,  0.00702569,  0.02939388,  0.00937118])\n",
      "  9%|▉         | 7/74 [00:15<02:27,  2.21s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24534037381740414)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2547130245489236\n",
      "DEBUG:shap:self.fx = 0.6540315734989648\n",
      "DEBUG:shap:self.link(self.fx) = 0.6540315734989648\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.21860209,  0.01454259,  0.01498225,  0.00722165, -0.00277991,\n",
      "        0.02012229,  0.02218124, -0.02226128,  0.00136807, -0.00032133,\n",
      "        0.01309284, -0.00706447,  0.01878406, -0.05312971,  0.00937265])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2453403738174041)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2547130245489236\n",
      "DEBUG:shap:self.fx = 0.34596842650103515\n",
      "DEBUG:shap:self.link(self.fx) = 0.34596842650103515\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.21860209, -0.01454259, -0.01498225, -0.00722165,  0.00277991,\n",
      "       -0.02012229, -0.02218124,  0.02226128, -0.00136807,  0.00032133,\n",
      "       -0.01309284,  0.00706447, -0.01878406,  0.05312971, -0.00937265])\n",
      " 11%|█         | 8/74 [00:17<02:27,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.31319915983597724)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3344230795813014\n",
      "DEBUG:shap:self.fx = 0.06489546936873981\n",
      "DEBUG:shap:self.link(self.fx) = 0.06489546936873981\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.1542381 ,  0.00154209, -0.002648  , -0.07338332, -0.01146974,\n",
      "       -0.03051099, -0.04128147,  0.00125908,  0.00523371,  0.01490743,\n",
      "        0.00569624, -0.00135849, -0.0165838 , -0.0103638 , -0.02122392])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3131991598359776)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3344230795813017\n",
      "DEBUG:shap:self.fx = 0.9351045306312604\n",
      "DEBUG:shap:self.link(self.fx) = 0.9351045306312604\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.1542381 , -0.00154209,  0.002648  ,  0.07338332,  0.01146974,\n",
      "        0.03051099,  0.04128147, -0.00125908, -0.00523371, -0.01490743,\n",
      "       -0.00569624,  0.00135849,  0.0165838 ,  0.0103638 ,  0.02122392])\n",
      " 12%|█▏        | 9/74 [00:20<02:25,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.21648131012957295)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21513556835039396\n",
      "DEBUG:shap:self.fx = 0.18418298059964724\n",
      "DEBUG:shap:self.link(self.fx) = 0.18418298059964724\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.11923592, -0.03362855,  0.00322279,  0.01276078,  0.03320215,\n",
      "       -0.01440904, -0.00420464, -0.02584971,  0.00316524, -0.0105282 ,\n",
      "        0.00906773,  0.00406131, -0.02237136, -0.05173388,  0.00134574])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.21648131012957286)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2151355683503937\n",
      "DEBUG:shap:self.fx = 0.8158170194003525\n",
      "DEBUG:shap:self.link(self.fx) = 0.8158170194003525\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.11923592,  0.03362855, -0.00322279, -0.01276078, -0.03320215,\n",
      "        0.01440904,  0.00420464,  0.02584971, -0.00316524,  0.0105282 ,\n",
      "       -0.00906773, -0.00406131,  0.02237136,  0.05173388, -0.00134574])\n",
      " 14%|█▎        | 10/74 [00:22<02:24,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.285297753157668)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.28734018120868904\n",
      "DEBUG:shap:self.fx = 0.6866587301587302\n",
      "DEBUG:shap:self.link(self.fx) = 0.6866587301587302\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.20297962, -0.09150793, -0.01740207,  0.08340043,  0.00516075,\n",
      "        0.00654642,  0.0166982 ,  0.03887922, -0.01109756,  0.00897191,\n",
      "        0.00734604, -0.00127839, -0.0280096 ,  0.06461072,  0.00204243])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.28529775315766787)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2873401812086888\n",
      "DEBUG:shap:self.fx = 0.3133412698412699\n",
      "DEBUG:shap:self.link(self.fx) = 0.3133412698412699\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.20297962,  0.09150793,  0.01740207, -0.08340043, -0.00516075,\n",
      "       -0.00654642, -0.0166982 , -0.03887922,  0.01109756, -0.00897191,\n",
      "       -0.00734604,  0.00127839,  0.0280096 , -0.06461072, -0.00204243])\n",
      " 15%|█▍        | 11/74 [00:24<02:19,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24185052761526485)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2486157944843022\n",
      "DEBUG:shap:self.fx = 0.6479343434343434\n",
      "DEBUG:shap:self.link(self.fx) = 0.6479343434343434\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.17890127,  0.01103737, -0.00538841,  0.08741894, -0.00952002,\n",
      "        0.02796451, -0.01570936, -0.01773775, -0.00363921, -0.00697813,\n",
      "        0.01739542, -0.04747034,  0.00407939,  0.02149687,  0.00676527])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.24185052761526474)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2486157944843022\n",
      "DEBUG:shap:self.fx = 0.3520656565656565\n",
      "DEBUG:shap:self.link(self.fx) = 0.3520656565656565\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.17890127, -0.01103737,  0.00538841, -0.08741894,  0.00952002,\n",
      "       -0.02796451,  0.01570936,  0.01773775,  0.00363921,  0.00697813,\n",
      "       -0.01739542,  0.04747034, -0.00407939, -0.02149687, -0.00676527])\n",
      " 16%|█▌        | 12/74 [00:26<02:18,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4342152636018026)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.38302668914519694\n",
      "DEBUG:shap:self.fx = 0.7823452380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.7823452380952381\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.19622845,  0.0126738 ,  0.00910075,  0.10237877, -0.00350615,\n",
      "       -0.02508773,  0.02056579,  0.0419387 , -0.00403671,  0.01543243,\n",
      "        0.00108491,  0.00263677,  0.00859828,  0.0562072 , -0.05118857])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4342152636018026)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3830266891451968\n",
      "DEBUG:shap:self.fx = 0.21765476190476193\n",
      "DEBUG:shap:self.link(self.fx) = 0.21765476190476193\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.19622845, -0.0126738 , -0.00910075, -0.10237877,  0.00350615,\n",
      "        0.02508773, -0.02056579, -0.0419387 ,  0.00403671, -0.01543243,\n",
      "       -0.00108491, -0.00263677, -0.00859828, -0.0562072 ,  0.05118857])\n",
      " 18%|█▊        | 13/74 [00:28<02:15,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19615816174798675)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.20959777605821567\n",
      "DEBUG:shap:self.fx = 0.18972077289182554\n",
      "DEBUG:shap:self.link(self.fx) = 0.18972077289182554\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.11797672,  0.04156793,  0.00890288, -0.05637928,  0.01483119,\n",
      "       -0.00975041, -0.02374274, -0.02827919,  0.00682675, -0.01390853,\n",
      "       -0.01952299,  0.00257925,  0.00523131, -0.00653762, -0.01343961])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19615816174798664)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2095977760582156\n",
      "DEBUG:shap:self.fx = 0.8102792271081743\n",
      "DEBUG:shap:self.link(self.fx) = 0.8102792271081743\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.11797672, -0.04156793, -0.00890288,  0.05637928, -0.01483119,\n",
      "        0.00975041,  0.02374274,  0.02827919, -0.00682675,  0.01390853,\n",
      "        0.01952299, -0.00257925, -0.00523131,  0.00653762,  0.01343961])\n",
      " 19%|█▉        | 14/74 [00:31<02:13,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.0263351631967872)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.027654629536121744\n",
      "DEBUG:shap:self.fx = 0.37166391941391946\n",
      "DEBUG:shap:self.link(self.fx) = 0.37166391941391946\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.13805202,  0.01740489,  0.01098563,  0.09515314,  0.00243365,\n",
      "        0.05843967, -0.03502832, -0.02157908,  0.00047758, -0.00461842,\n",
      "       -0.00590175, -0.00641748,  0.00211325, -0.0017459 , -0.00131947])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.026335163196787307)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.027654629536121855\n",
      "DEBUG:shap:self.fx = 0.6283360805860806\n",
      "DEBUG:shap:self.link(self.fx) = 0.6283360805860806\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.13805202, -0.01740489, -0.01098563, -0.09515314, -0.00243365,\n",
      "       -0.05843967,  0.03502832,  0.02157908, -0.00047758,  0.00461842,\n",
      "        0.00590175,  0.00641748, -0.00211325,  0.0017459 ,  0.00131947])\n",
      " 20%|██        | 15/74 [00:33<02:13,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3012673283918976)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.30846669709818936\n",
      "DEBUG:shap:self.fx = 0.09085185185185186\n",
      "DEBUG:shap:self.link(self.fx) = 0.09085185185185186\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.11603512,  0.00196522, -0.00633794, -0.05651237, -0.00455161,\n",
      "        0.0084279 , -0.01932278, -0.02535548, -0.02518704, -0.01294019,\n",
      "       -0.00650322, -0.00256976, -0.01056457, -0.02578036, -0.00719937])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3012673283918978)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3084666970981895\n",
      "DEBUG:shap:self.fx = 0.9091481481481483\n",
      "DEBUG:shap:self.link(self.fx) = 0.9091481481481483\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.11603512, -0.00196522,  0.00633794,  0.05651237,  0.00455161,\n",
      "       -0.0084279 ,  0.01932278,  0.02535548,  0.02518704,  0.01294019,\n",
      "        0.00650322,  0.00256976,  0.01056457,  0.02578036,  0.00719937])\n",
      " 22%|██▏       | 16/74 [00:35<02:08,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.33672040669275594)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3087846256531332\n",
      "DEBUG:shap:self.fx = 0.7081031746031744\n",
      "DEBUG:shap:self.link(self.fx) = 0.7081031746031744\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.18722473, -0.08878707, -0.02042939,  0.07044894, -0.00493115,\n",
      "        0.03061269,  0.01414012,  0.07012925, -0.01077892,  0.01067212,\n",
      "        0.00082627,  0.01588553,  0.00799774,  0.05370954, -0.02793578])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3367204066927562)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3087846256531333\n",
      "DEBUG:shap:self.fx = 0.29189682539682543\n",
      "DEBUG:shap:self.link(self.fx) = 0.29189682539682543\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.18722473,  0.08878707,  0.02042939, -0.07044894,  0.00493115,\n",
      "       -0.03061269, -0.01414012, -0.07012925,  0.01077892, -0.01067212,\n",
      "       -0.00082627, -0.01588553, -0.00799774, -0.05370954,  0.02793578])\n",
      " 23%|██▎       | 17/74 [00:37<02:05,  2.19s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2300312187104887)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24595922882773663\n",
      "DEBUG:shap:self.fx = 0.6452777777777778\n",
      "DEBUG:shap:self.link(self.fx) = 0.6452777777777778\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.17635041, -0.03423233, -0.01741424,  0.01915286,  0.0042732 ,\n",
      "       -0.01240763,  0.03491068,  0.07228232,  0.00717785, -0.00565918,\n",
      "       -0.02634798,  0.01765028, -0.0240743 ,  0.01836928,  0.01592801])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23003121871048865)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.24595922882773652\n",
      "DEBUG:shap:self.fx = 0.3547222222222222\n",
      "DEBUG:shap:self.link(self.fx) = 0.3547222222222222\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.17635041,  0.03423233,  0.01741424, -0.01915286, -0.0042732 ,\n",
      "        0.01240763, -0.03491068, -0.07228232, -0.00717785,  0.00565918,\n",
      "        0.02634798, -0.01765028,  0.0240743 , -0.01836928, -0.01592801])\n",
      " 24%|██▍       | 18/74 [00:39<02:01,  2.17s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.49551949024800196)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5075889602074681\n",
      "DEBUG:shap:self.fx = 0.9069075091575093\n",
      "DEBUG:shap:self.link(self.fx) = 0.9069075091575093\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.20796668,  0.02612372,  0.00557317,  0.07980426, -0.01266303,\n",
      "        0.04810855,  0.02579609,  0.05323809, -0.00050067, -0.00149847,\n",
      "       -0.00915453,  0.00375338,  0.01644211,  0.05253015,  0.01206947])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.495519490248002)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5075889602074679\n",
      "DEBUG:shap:self.fx = 0.09309249084249084\n",
      "DEBUG:shap:self.link(self.fx) = 0.09309249084249084\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.20796668, -0.02612372, -0.00557317, -0.07980426,  0.01266303,\n",
      "       -0.04810855, -0.02579609, -0.05323809,  0.00050067,  0.00149847,\n",
      "        0.00915453, -0.00375338, -0.01644211, -0.05253015, -0.01206947])\n",
      " 26%|██▌       | 19/74 [00:42<01:58,  2.16s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.058721292184113316)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.05477778043600223\n",
      "DEBUG:shap:self.fx = 0.344540768514039\n",
      "DEBUG:shap:self.link(self.fx) = 0.344540768514039\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.19023001,  0.01012693, -0.00373409, -0.05757103,  0.        ,\n",
      "       -0.02811222, -0.02877667, -0.02210854,  0.00110153, -0.00408415,\n",
      "       -0.00026591, -0.0137504 , -0.02660974, -0.075167  ,  0.00394351])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.05872129218411355)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.054777780436002343\n",
      "DEBUG:shap:self.fx = 0.6554592314859611\n",
      "DEBUG:shap:self.link(self.fx) = 0.6554592314859611\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.19023001, -0.01012693,  0.00373409,  0.05757103,  0.        ,\n",
      "        0.02811222,  0.02877667,  0.02210854, -0.00110153,  0.00408415,\n",
      "        0.00026591,  0.0137504 ,  0.02660974,  0.075167  , -0.00394351])\n",
      " 27%|██▋       | 20/74 [00:44<01:56,  2.16s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.27922105053794466)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.288160237485126\n",
      "DEBUG:shap:self.fx = 0.11115831146491525\n",
      "DEBUG:shap:self.link(self.fx) = 0.11115831146491525\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.11349794,  0.04923115, -0.01100165, -0.04936306, -0.00867273,\n",
      "       -0.0355058 , -0.03962021, -0.01678852,  0.00084953, -0.01205038,\n",
      "        0.01027285, -0.00524271, -0.00726296, -0.04056861, -0.00893919])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.27922105053794494)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2881602374851262\n",
      "DEBUG:shap:self.fx = 0.8888416885350849\n",
      "DEBUG:shap:self.link(self.fx) = 0.8888416885350849\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.11349794, -0.04923115,  0.01100165,  0.04936306,  0.00867273,\n",
      "        0.0355058 ,  0.03962021,  0.01678852, -0.00084953,  0.01205038,\n",
      "       -0.01027285,  0.00524271,  0.00726296,  0.04056861,  0.00893919])\n",
      " 28%|██▊       | 21/74 [00:46<01:55,  2.17s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.25221853916513043)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.26769172182493534\n",
      "DEBUG:shap:self.fx = 0.6670102707749765\n",
      "DEBUG:shap:self.link(self.fx) = 0.6670102707749765\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.19559065, -0.08565738,  0.0161184 ,  0.07382494,  0.00917473,\n",
      "        0.01295441,  0.01919516, -0.02291404,  0.00663135, -0.00088062,\n",
      "        0.00973823,  0.00148537, -0.03825494,  0.05521228,  0.01547318])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2522185391651306)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2676917218249355\n",
      "DEBUG:shap:self.fx = 0.33298972922502323\n",
      "DEBUG:shap:self.link(self.fx) = 0.33298972922502323\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.19559065,  0.08565738, -0.0161184 , -0.07382494, -0.00917473,\n",
      "       -0.01295441, -0.01919516,  0.02291404, -0.00663135,  0.00088062,\n",
      "       -0.00973823, -0.00148537,  0.03825494, -0.05521228, -0.01547318])\n",
      " 30%|██▉       | 22/74 [00:48<01:54,  2.21s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3651545633384782)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3710284254932511\n",
      "DEBUG:shap:self.fx = 0.02829012345679013\n",
      "DEBUG:shap:self.link(self.fx) = 0.02829012345679013\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14154249, -0.00196169, -0.0005177 , -0.06563371, -0.00409182,\n",
      "       -0.02619517, -0.01354238, -0.02935764, -0.00146852, -0.01083802,\n",
      "       -0.01640386,  0.        , -0.01700112, -0.03660045, -0.00587386])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.36515456333847823)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3710284254932511\n",
      "DEBUG:shap:self.fx = 0.9717098765432098\n",
      "DEBUG:shap:self.link(self.fx) = 0.9717098765432098\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([0.14154249, 0.00196169, 0.0005177 , 0.06563371, 0.00409182,\n",
      "       0.02619517, 0.01354238, 0.02935764, 0.00146852, 0.01083802,\n",
      "       0.01640386, 0.        , 0.01700112, 0.03660045, 0.00587386])\n",
      " 31%|███       | 23/74 [00:50<01:50,  2.17s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4164666784629632)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.42394335581186354\n",
      "DEBUG:shap:self.fx = 0.8232619047619048\n",
      "DEBUG:shap:self.link(self.fx) = 0.8232619047619048\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.21759206,  0.01394141,  0.01219377,  0.08402092,  0.00670567,\n",
      "       -0.02472736,  0.03162766,  0.09883622, -0.02351588, -0.0076438 ,\n",
      "        0.01503349,  0.00038836, -0.03632667,  0.02834081,  0.00747668])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.41646667846296315)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4239433558118635\n",
      "DEBUG:shap:self.fx = 0.17673809523809528\n",
      "DEBUG:shap:self.link(self.fx) = 0.17673809523809528\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.21759206, -0.01394141, -0.01219377, -0.08402092, -0.00670567,\n",
      "        0.02472736, -0.03162766, -0.09883622,  0.02351588,  0.0076438 ,\n",
      "       -0.01503349, -0.00038836,  0.03632667, -0.02834081, -0.00747668])\n",
      " 32%|███▏      | 24/74 [00:53<01:51,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.26504669933557845)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2721240889746939\n",
      "DEBUG:shap:self.fx = 0.6714426379247351\n",
      "DEBUG:shap:self.link(self.fx) = 0.6714426379247351\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.21006182, -0.02087969,  0.00930629,  0.07031549,  0.01010338,\n",
      "       -0.01040101,  0.01908109, -0.04626163, -0.00062627, -0.00207169,\n",
      "       -0.01704902,  0.00208024, -0.03047048,  0.07185818,  0.00707739])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.26504669933557845)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2721240889746939\n",
      "DEBUG:shap:self.fx = 0.3285573620752648\n",
      "DEBUG:shap:self.link(self.fx) = 0.3285573620752648\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.21006182,  0.02087969, -0.00930629, -0.07031549, -0.01010338,\n",
      "        0.01040101, -0.01908109,  0.04626163,  0.00062627,  0.00207169,\n",
      "        0.01704902, -0.00208024,  0.03047048, -0.07185818, -0.00707739])\n",
      " 34%|███▍      | 25/74 [00:55<01:49,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.11817577976501215)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12318145104995876\n",
      "DEBUG:shap:self.fx = 0.5225\n",
      "DEBUG:shap:self.link(self.fx) = 0.5225\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.16913228, -0.01795084,  0.00156513,  0.06060971, -0.00489628,\n",
      "        0.04299446, -0.0070499 ,  0.02556689, -0.05683356, -0.00074764,\n",
      "        0.0171473 , -0.00145988, -0.0128922 , -0.0970097 ,  0.00500567])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.11817577976501213)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.12318145104995865\n",
      "DEBUG:shap:self.fx = 0.4775000000000001\n",
      "DEBUG:shap:self.link(self.fx) = 0.4775000000000001\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.16913228,  0.01795084, -0.00156513, -0.06060971,  0.00489628,\n",
      "       -0.04299446,  0.0070499 , -0.02556689,  0.05683356,  0.00074764,\n",
      "       -0.0171473 ,  0.00145988,  0.0128922 ,  0.0970097 , -0.00500567])\n",
      " 35%|███▌      | 26/74 [00:57<01:47,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2655125509701229)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.28349098081586926\n",
      "DEBUG:shap:self.fx = 0.11582756813417193\n",
      "DEBUG:shap:self.link(self.fx) = 0.11582756813417193\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14501604, -0.00247668, -0.00216823, -0.0548003 , -0.01131455,\n",
      "        0.01019486, -0.03256888, -0.02848892, -0.00120547,  0.0100916 ,\n",
      "        0.01886028,  0.01738077, -0.01878959, -0.02521139, -0.01797843])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.26551255097012333)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.28349098081586954\n",
      "DEBUG:shap:self.fx = 0.8841724318658283\n",
      "DEBUG:shap:self.link(self.fx) = 0.8841724318658283\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.14501604,  0.00247668,  0.00216823,  0.0548003 ,  0.01131455,\n",
      "       -0.01019486,  0.03256888,  0.02848892,  0.00120547, -0.0100916 ,\n",
      "       -0.01886028, -0.01738077,  0.01878959,  0.02521139,  0.01797843])\n",
      " 36%|███▋      | 27/74 [00:59<01:44,  2.21s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1643694003710993)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1674852156167078\n",
      "DEBUG:shap:self.fx = 0.23183333333333342\n",
      "DEBUG:shap:self.link(self.fx) = 0.23183333333333342\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.11540455, -0.0498512 , -0.00963817,  0.03549337, -0.00119664,\n",
      "       -0.02803725, -0.02028446, -0.0150125 ,  0.00322344,  0.01739577,\n",
      "       -0.00485401,  0.03495639,  0.01315284, -0.02431243, -0.00311582])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.16436940037109954)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16748521561670804\n",
      "DEBUG:shap:self.fx = 0.7681666666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.7681666666666668\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.11540455,  0.0498512 ,  0.00963817, -0.03549337,  0.00119664,\n",
      "        0.02803725,  0.02028446,  0.0150125 , -0.00322344, -0.01739577,\n",
      "        0.00485401, -0.03495639, -0.01315284,  0.02431243,  0.00311582])\n",
      " 38%|███▊      | 28/74 [01:01<01:41,  2.20s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2985390766107573)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.27252393615542847\n",
      "DEBUG:shap:self.fx = 0.12679461279461277\n",
      "DEBUG:shap:self.link(self.fx) = 0.12679461279461277\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.15637744,  0.00287318,  0.0047264 , -0.0649693 ,  0.00148689,\n",
      "        0.01299082, -0.00782552, -0.0121395 , -0.00368345, -0.00625946,\n",
      "       -0.02099704, -0.01201865,  0.01166271, -0.04800871,  0.02601514])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2985390766107571)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.27252393615542836\n",
      "DEBUG:shap:self.fx = 0.8732053872053871\n",
      "DEBUG:shap:self.link(self.fx) = 0.8732053872053871\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.15637744, -0.00287318, -0.0047264 ,  0.0649693 , -0.00148689,\n",
      "       -0.01299082,  0.00782552,  0.0121395 ,  0.00368345,  0.00625946,\n",
      "        0.02099704,  0.01201865, -0.01166271,  0.04800871, -0.02601514])\n",
      " 39%|███▉      | 29/74 [01:04<01:41,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.36029971503034663)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3634830383515461\n",
      "DEBUG:shap:self.fx = 0.7628015873015873\n",
      "DEBUG:shap:self.link(self.fx) = 0.7628015873015873\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.2027074 ,  0.02482925, -0.000406  ,  0.08896296, -0.02295126,\n",
      "        0.01266388,  0.01375975,  0.07922692,  0.00874619, -0.00270058,\n",
      "       -0.01188659,  0.00173421, -0.05751897,  0.02313256,  0.00318332])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3602997150303468)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.36348303835154605\n",
      "DEBUG:shap:self.fx = 0.2371984126984127\n",
      "DEBUG:shap:self.link(self.fx) = 0.2371984126984127\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.2027074 , -0.02482925,  0.000406  , -0.08896296,  0.02295126,\n",
      "       -0.01266388, -0.01375975, -0.07922692, -0.00874619,  0.00270058,\n",
      "        0.01188659, -0.00173421,  0.05751897, -0.02313256, -0.00318332])\n",
      " 41%|████      | 30/74 [01:06<01:39,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3949074235707314)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.40229256216106984\n",
      "DEBUG:shap:self.fx = 0.801611111111111\n",
      "DEBUG:shap:self.link(self.fx) = 0.801611111111111\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.1899577 ,  0.00957145, -0.02171758,  0.09703413,  0.00446499,\n",
      "        0.04614857,  0.02302539,  0.07079308, -0.01855492, -0.00611465,\n",
      "        0.00067489,  0.02034162,  0.02008555, -0.04080278,  0.00738514])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3949074235707316)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.40229256216106984\n",
      "DEBUG:shap:self.fx = 0.1983888888888889\n",
      "DEBUG:shap:self.link(self.fx) = 0.1983888888888889\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.1899577 , -0.00957145,  0.02171758, -0.09703413, -0.00446499,\n",
      "       -0.04614857, -0.02302539, -0.07079308,  0.01855492,  0.00611465,\n",
      "       -0.00067489, -0.02034162, -0.02008555,  0.04080278, -0.00738514])\n",
      " 42%|████▏     | 31/74 [01:08<01:36,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.056724225724094954)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.05808621295472077\n",
      "DEBUG:shap:self.fx = 0.457404761904762\n",
      "DEBUG:shap:self.link(self.fx) = 0.457404761904762\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.15003452,  0.01469944,  0.00154961,  0.05155409, -0.01066932,\n",
      "        0.04899391,  0.01580159, -0.04053424, -0.04181868,  0.00999896,\n",
      "       -0.0046093 ,  0.00689021, -0.07624843, -0.06891815,  0.00136199])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.056724225724094815)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.05808621295472072\n",
      "DEBUG:shap:self.fx = 0.542595238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.542595238095238\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.15003452, -0.01469944, -0.00154961, -0.05155409,  0.01066932,\n",
      "       -0.04899391, -0.01580159,  0.04053424,  0.04181868, -0.00999896,\n",
      "        0.0046093 , -0.00689021,  0.07624843,  0.06891815, -0.00136199])\n",
      " 43%|████▎     | 32/74 [01:10<01:33,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17349936413428962)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.15383224470075246\n",
      "DEBUG:shap:self.fx = 0.5531507936507937\n",
      "DEBUG:shap:self.link(self.fx) = 0.5531507936507937\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.17866134,  0.01755439,  0.00109506,  0.08525573, -0.00117451,\n",
      "       -0.01378952,  0.01039201, -0.03258171, -0.04361406,  0.00094455,\n",
      "        0.00802303, -0.00437244,  0.02090279, -0.05379729, -0.01966712])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17349936413428974)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.15383224470075257\n",
      "DEBUG:shap:self.fx = 0.44684920634920616\n",
      "DEBUG:shap:self.link(self.fx) = 0.44684920634920616\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.17866134, -0.01755439, -0.00109506, -0.08525573,  0.00117451,\n",
      "        0.01378952, -0.01039201,  0.03258171,  0.04361406, -0.00094455,\n",
      "       -0.00802303,  0.00437244, -0.02090279,  0.05379729,  0.01966712])\n",
      " 45%|████▍     | 33/74 [01:13<01:32,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0004051528026526169)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.014908689994589053\n",
      "DEBUG:shap:self.fx = 0.41422723894463026\n",
      "DEBUG:shap:self.link(self.fx) = 0.41422723894463026\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.11538258, -0.0612235 ,  0.0140727 , -0.03824051,  0.00275904,\n",
      "        0.01201848,  0.01816607, -0.0164492 , -0.00210076, -0.00269864,\n",
      "       -0.02598404, -0.00240164, -0.04341482,  0.03051941,  0.01450354])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.00040515280265249545)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.014908689994588942\n",
      "DEBUG:shap:self.fx = 0.5857727610553698\n",
      "DEBUG:shap:self.link(self.fx) = 0.5857727610553698\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.11538258,  0.0612235 , -0.0140727 ,  0.03824051, -0.00275904,\n",
      "       -0.01201848, -0.01816607,  0.0164492 ,  0.00210076,  0.00269864,\n",
      "        0.02598404,  0.00240164,  0.04341482, -0.03051941, -0.01450354])\n",
      " 46%|████▌     | 34/74 [01:15<01:30,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.32736500429956067)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3266939513254436\n",
      "DEBUG:shap:self.fx = 0.07262459762459762\n",
      "DEBUG:shap:self.link(self.fx) = 0.07262459762459762\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.15546322,  0.00048503, -0.00025507, -0.06848776, -0.00039394,\n",
      "       -0.02063737, -0.01565863, -0.02800541,  0.00259486, -0.00317212,\n",
      "       -0.00337062, -0.00428447,  0.00577138, -0.03648767,  0.00067105])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3273650042995607)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.32669395132544365\n",
      "DEBUG:shap:self.fx = 0.9273754023754024\n",
      "DEBUG:shap:self.link(self.fx) = 0.9273754023754024\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.15546322, -0.00048503,  0.00025507,  0.06848776,  0.00039394,\n",
      "        0.02063737,  0.01565863,  0.02800541, -0.00259486,  0.00317212,\n",
      "        0.00337062,  0.00428447, -0.00577138,  0.03648767, -0.00067105])\n",
      " 47%|████▋     | 35/74 [01:17<01:27,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.03944064076920711)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.0429375965690888\n",
      "DEBUG:shap:self.fx = 0.3563809523809524\n",
      "DEBUG:shap:self.link(self.fx) = 0.3563809523809524\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14402538,  0.0591714 ,  0.0071813 , -0.03905311,  0.014616  ,\n",
      "        0.06745313, -0.04739855,  0.01568214,  0.00828181,  0.03589285,\n",
      "       -0.00847626,  0.        , -0.00597964, -0.00278634, -0.00349696])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03944064076920737)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.04293759656908902\n",
      "DEBUG:shap:self.fx = 0.6436190476190478\n",
      "DEBUG:shap:self.link(self.fx) = 0.6436190476190478\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.14402538, -0.0591714 , -0.0071813 ,  0.03905311, -0.014616  ,\n",
      "       -0.06745313,  0.04739855, -0.01568214, -0.00828181, -0.03589285,\n",
      "        0.00847626,  0.        ,  0.00597964,  0.00278634,  0.00349696])\n",
      " 49%|████▊     | 36/74 [01:19<01:25,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20387456591575603)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21511879440835474\n",
      "DEBUG:shap:self.fx = 0.614437343358396\n",
      "DEBUG:shap:self.link(self.fx) = 0.614437343358396\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.19771155,  0.0041865 ,  0.00492749, -0.02376635,  0.00556599,\n",
      "        0.0612495 , -0.06262168,  0.04402901,  0.00493038, -0.00795295,\n",
      "        0.01146501,  0.00364478,  0.01455784, -0.05405251,  0.01124423])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20387456591575603)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21511879440835474\n",
      "DEBUG:shap:self.fx = 0.385562656641604\n",
      "DEBUG:shap:self.link(self.fx) = 0.385562656641604\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.19771155, -0.0041865 , -0.00492749,  0.02376635, -0.00556599,\n",
      "       -0.0612495 ,  0.06262168, -0.04402901, -0.00493038,  0.00795295,\n",
      "       -0.01146501, -0.00364478, -0.01455784,  0.05405251, -0.01124423])\n",
      " 50%|█████     | 37/74 [01:22<01:21,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.340494445844992)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3347766891451969\n",
      "DEBUG:shap:self.fx = 0.7340952380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.7340952380952381\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.1884619 ,  0.01992528,  0.00504573,  0.073442  , -0.00131202,\n",
      "        0.04559255,  0.02949244, -0.01313044, -0.06065774, -0.00592125,\n",
      "       -0.00127121,  0.01602852,  0.0220164 ,  0.02278228, -0.00571776])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.340494445844992)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.33477668914519676\n",
      "DEBUG:shap:self.fx = 0.265904761904762\n",
      "DEBUG:shap:self.link(self.fx) = 0.265904761904762\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.1884619 , -0.01992528, -0.00504573, -0.073442  ,  0.00131202,\n",
      "       -0.04559255, -0.02949244,  0.01313044,  0.06065774,  0.00592125,\n",
      "        0.00127121, -0.01602852, -0.0220164 , -0.02278228,  0.00571776])\n",
      " 51%|█████▏    | 38/74 [01:24<01:20,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.13160438518649265)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.0756029213924817\n",
      "DEBUG:shap:self.fx = 0.4749214703425229\n",
      "DEBUG:shap:self.link(self.fx) = 0.4749214703425229\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.13695878,  0.01159184, -0.00726486, -0.06257521,  0.01176506,\n",
      "        0.06948124, -0.01156757, -0.01755223, -0.00686676, -0.0120383 ,\n",
      "       -0.0208515 , -0.00217071,  0.01055758,  0.03213703, -0.05600146])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.13160438518649265)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.07560292139248181\n",
      "DEBUG:shap:self.fx = 0.5250785296574769\n",
      "DEBUG:shap:self.link(self.fx) = 0.5250785296574769\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.13695878, -0.01159184,  0.00726486,  0.06257521, -0.01176506,\n",
      "       -0.06948124,  0.01156757,  0.01755223,  0.00686676,  0.0120383 ,\n",
      "        0.0208515 ,  0.00217071, -0.01055758, -0.03213703,  0.05600146])\n",
      " 53%|█████▎    | 39/74 [01:26<01:17,  2.21s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20843873579282995)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21056044074402488\n",
      "DEBUG:shap:self.fx = 0.18875810820601632\n",
      "DEBUG:shap:self.link(self.fx) = 0.18875810820601632\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14012667,  0.04751925,  0.00977969, -0.06368589, -0.00497511,\n",
      "       -0.04061593,  0.02636405,  0.00928467, -0.00879655, -0.00359351,\n",
      "       -0.00112028, -0.00689535, -0.0008071 , -0.03077002, -0.0021217 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20843873579283015)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21056044074402502\n",
      "DEBUG:shap:self.fx = 0.8112418917939838\n",
      "DEBUG:shap:self.link(self.fx) = 0.8112418917939838\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.14012667, -0.04751925, -0.00977969,  0.06368589,  0.00497511,\n",
      "        0.04061593, -0.02636405, -0.00928467,  0.00879655,  0.00359351,\n",
      "        0.00112028,  0.00689535,  0.0008071 ,  0.03077002,  0.0021217 ])\n",
      " 54%|█████▍    | 40/74 [01:28<01:16,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2313087760094359)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.23977886641035867\n",
      "DEBUG:shap:self.fx = 0.15953968253968254\n",
      "DEBUG:shap:self.link(self.fx) = 0.15953968253968254\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.12526807, -0.01203776,  0.00529431,  0.01071484,  0.01104393,\n",
      "        0.02558101,  0.01402596, -0.02473052, -0.0015864 , -0.01414592,\n",
      "       -0.02218854, -0.00766668, -0.03931674, -0.05102818, -0.00847009])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23130877600943606)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.23977886641035884\n",
      "DEBUG:shap:self.fx = 0.8404603174603176\n",
      "DEBUG:shap:self.link(self.fx) = 0.8404603174603176\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.12526807,  0.01203776, -0.00529431, -0.01071484, -0.01104393,\n",
      "       -0.02558101, -0.01402596,  0.02473052,  0.0015864 ,  0.01414592,\n",
      "        0.02218854,  0.00766668,  0.03931674,  0.05102818,  0.00847009])\n",
      " 55%|█████▌    | 41/74 [01:31<01:14,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.18127184203604088)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2047371134773014\n",
      "DEBUG:shap:self.fx = 0.19458143547273982\n",
      "DEBUG:shap:self.link(self.fx) = 0.19458143547273982\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.108777  ,  0.0263981 ,  0.0028059 , -0.06064636,  0.00891479,\n",
      "       -0.01443147, -0.03328208, -0.02017193,  0.00846492, -0.01036529,\n",
      "       -0.01269099, -0.01698071,  0.00873149,  0.04075881, -0.02346527])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.18127184203604083)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2047371134773014\n",
      "DEBUG:shap:self.fx = 0.8054185645272601\n",
      "DEBUG:shap:self.link(self.fx) = 0.8054185645272601\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.108777  , -0.0263981 , -0.0028059 ,  0.06064636, -0.00891479,\n",
      "        0.01443147,  0.03328208,  0.02017193, -0.00846492,  0.01036529,\n",
      "        0.01269099,  0.01698071, -0.00873149, -0.04075881,  0.02346527])\n",
      " 57%|█████▋    | 42/74 [01:33<01:11,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5122483019777984)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.47718938755789536\n",
      "DEBUG:shap:self.fx = 0.8765079365079366\n",
      "DEBUG:shap:self.link(self.fx) = 0.8765079365079366\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.22526303,  0.0179241 ,  0.00371048,  0.08002793, -0.00229128,\n",
      "        0.00147627,  0.03883159,  0.07574759, -0.00556722, -0.00253444,\n",
      "        0.01506476,  0.00571112,  0.00955204,  0.04933234, -0.03505891])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5122483019777982)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.47718938755789525\n",
      "DEBUG:shap:self.fx = 0.12349206349206349\n",
      "DEBUG:shap:self.link(self.fx) = 0.12349206349206349\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.22526303, -0.0179241 , -0.00371048, -0.08002793,  0.00229128,\n",
      "       -0.00147627, -0.03883159, -0.07574759,  0.00556722,  0.00253444,\n",
      "       -0.01506476, -0.00571112, -0.00955204, -0.04933234,  0.03505891])\n",
      " 58%|█████▊    | 43/74 [01:35<01:08,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.10490697276055137)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.10634907398056631\n",
      "DEBUG:shap:self.fx = 0.2929694749694749\n",
      "DEBUG:shap:self.link(self.fx) = 0.2929694749694749\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.00347996,  0.0142728 , -0.00367423,  0.08622052,  0.00488737,\n",
      "       -0.01694625,  0.01235893, -0.0330136 , -0.04333033,  0.00280669,\n",
      "       -0.00395525,  0.01678769, -0.05947709, -0.07836428, -0.0014421 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1049069727605513)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.10634907398056626\n",
      "DEBUG:shap:self.fx = 0.707030525030525\n",
      "DEBUG:shap:self.link(self.fx) = 0.707030525030525\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.00347996, -0.0142728 ,  0.00367423, -0.08622052, -0.00488737,\n",
      "        0.01694625, -0.01235893,  0.0330136 ,  0.04333033, -0.00280669,\n",
      "        0.00395525, -0.01678769,  0.05947709,  0.07836428,  0.0014421 ])\n",
      " 59%|█████▉    | 44/74 [01:37<01:07,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.11880232731607654)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12298029109879888\n",
      "DEBUG:shap:self.fx = 0.5222988400488401\n",
      "DEBUG:shap:self.link(self.fx) = 0.5222988400488401\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.11678841,  0.01859234, -0.01289392,  0.08814439,  0.0040024 ,\n",
      "        0.01614734, -0.00198002, -0.02578325, -0.0643876 ,  0.00963358,\n",
      "        0.00344559,  0.01803734, -0.07020858,  0.01926429,  0.00417796])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.11880232731607648)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.12298029109879877\n",
      "DEBUG:shap:self.fx = 0.47770115995115997\n",
      "DEBUG:shap:self.link(self.fx) = 0.47770115995115997\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.11678841, -0.01859234,  0.01289392, -0.08814439, -0.0040024 ,\n",
      "       -0.01614734,  0.00198002,  0.02578325,  0.0643876 , -0.00963358,\n",
      "       -0.00344559, -0.01803734,  0.07020858, -0.01926429, -0.00417796])\n",
      " 61%|██████    | 45/74 [01:40<01:04,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.18132382010951326)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.183295340199176\n",
      "DEBUG:shap:self.fx = 0.2160232087508652\n",
      "DEBUG:shap:self.link(self.fx) = 0.2160232087508652\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.03368189,  0.00251917,  0.00730245, -0.07054307, -0.00318441,\n",
      "       -0.01073853, -0.03365379, -0.03629542,  0.00214991, -0.00496679,\n",
      "       -0.01059448, -0.00209487,  0.00519961,  0.0072583 , -0.00197152])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.18132382010951345)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.18329534019917615\n",
      "DEBUG:shap:self.fx = 0.7839767912491349\n",
      "DEBUG:shap:self.link(self.fx) = 0.7839767912491349\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.03368189, -0.00251917, -0.00730245,  0.07054307,  0.00318441,\n",
      "        0.01073853,  0.03365379,  0.03629542, -0.00214991,  0.00496679,\n",
      "        0.01059448,  0.00209487, -0.00519961, -0.0072583 ,  0.00197152])\n",
      " 62%|██████▏   | 46/74 [01:42<01:03,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.26053813750323757)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.24878066335555182\n",
      "DEBUG:shap:self.fx = 0.15053788559448938\n",
      "DEBUG:shap:self.link(self.fx) = 0.15053788559448938\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14105382,  0.00452692, -0.00316582, -0.06565867, -0.00302045,\n",
      "       -0.01391639, -0.04185751,  0.05646475,  0.00288177, -0.01324996,\n",
      "       -0.00671966, -0.01111248, -0.01591327, -0.00874356,  0.01175747])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.26053813750323757)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24878066335555182\n",
      "DEBUG:shap:self.fx = 0.8494621144055106\n",
      "DEBUG:shap:self.link(self.fx) = 0.8494621144055106\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.14105382, -0.00452692,  0.00316582,  0.06565867,  0.00302045,\n",
      "        0.01391639,  0.04185751, -0.05646475, -0.00288177,  0.01324996,\n",
      "        0.00671966,  0.01111248,  0.01591327,  0.00874356, -0.01175747])\n",
      " 64%|██████▎   | 47/74 [01:44<00:59,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22901014009646753)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.20421584258435005\n",
      "DEBUG:shap:self.fx = 0.6035343915343913\n",
      "DEBUG:shap:self.link(self.fx) = 0.6035343915343913\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.17527156, -0.05015878,  0.0043303 ,  0.09114993,  0.00791025,\n",
      "        0.039682  ,  0.02008662,  0.02123295, -0.0061774 , -0.00434503,\n",
      "        0.00907128, -0.00903361,  0.01287928, -0.08288918, -0.0247943 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22901014009646764)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.20421584258435027\n",
      "DEBUG:shap:self.fx = 0.39646560846560847\n",
      "DEBUG:shap:self.link(self.fx) = 0.39646560846560847\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.17527156,  0.05015878, -0.0043303 , -0.09114993, -0.00791025,\n",
      "       -0.039682  , -0.02008662, -0.02123295,  0.0061774 ,  0.00434503,\n",
      "       -0.00907128,  0.00903361, -0.01287928,  0.08288918,  0.0247943 ])\n",
      " 65%|██████▍   | 48/74 [01:46<00:57,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09146031089479942)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09244970483119702\n",
      "DEBUG:shap:self.fx = 0.3068688441188442\n",
      "DEBUG:shap:self.link(self.fx) = 0.3068688441188442\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.13481505,  0.06348936,  0.00125118, -0.03693321,  0.00704054,\n",
      "        0.07436646, -0.02527166, -0.0251959 ,  0.00554875, -0.00865513,\n",
      "        0.00974543, -0.00250417, -0.01172447, -0.00780243, -0.00098939])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0914603108947995)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09244970483119719\n",
      "DEBUG:shap:self.fx = 0.6931311558811559\n",
      "DEBUG:shap:self.link(self.fx) = 0.6931311558811559\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.13481505, -0.06348936, -0.00125118,  0.03693321, -0.00704054,\n",
      "       -0.07436646,  0.02527166,  0.0251959 , -0.00554875,  0.00865513,\n",
      "       -0.00974543,  0.00250417,  0.01172447,  0.00780243,  0.00098939])\n",
      " 66%|██████▌   | 49/74 [01:48<00:55,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.24165651072617428)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2503582314897238\n",
      "DEBUG:shap:self.fx = 0.14896031746031743\n",
      "DEBUG:shap:self.link(self.fx) = 0.14896031746031743\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.1150638 , -0.00114626,  0.00366035, -0.04274431,  0.00823324,\n",
      "        0.06641729, -0.02672631, -0.02030593, -0.00623651, -0.01763801,\n",
      "       -0.02914414, -0.00813558, -0.02156116, -0.03126537, -0.00870172])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24165651072617428)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2503582314897237\n",
      "DEBUG:shap:self.fx = 0.8510396825396824\n",
      "DEBUG:shap:self.link(self.fx) = 0.8510396825396824\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.1150638 ,  0.00114626, -0.00366035,  0.04274431, -0.00823324,\n",
      "       -0.06641729,  0.02672631,  0.02030593,  0.00623651,  0.01763801,\n",
      "        0.02914414,  0.00813558,  0.02156116,  0.03126537,  0.00870172])\n",
      " 68%|██████▊   | 50/74 [01:51<00:53,  2.21s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2556300362758998)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.25413317506961963\n",
      "DEBUG:shap:self.fx = 0.14518537388042158\n",
      "DEBUG:shap:self.link(self.fx) = 0.14518537388042158\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.13133715, -0.00323807, -0.00032046, -0.07525174, -0.00595082,\n",
      "        0.01167218, -0.02444369,  0.00483223,  0.00434717, -0.01664659,\n",
      "        0.00906206, -0.00418875,  0.00501436, -0.02918075,  0.00149686])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2556300362758999)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.25413317506961963\n",
      "DEBUG:shap:self.fx = 0.8548146261195784\n",
      "DEBUG:shap:self.link(self.fx) = 0.8548146261195784\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.13133715,  0.00323807,  0.00032046,  0.07525174,  0.00595082,\n",
      "       -0.01167218,  0.02444369, -0.00483223, -0.00434717,  0.01664659,\n",
      "       -0.00906206,  0.00418875, -0.00501436,  0.02918075, -0.00149686])\n",
      " 69%|██████▉   | 51/74 [01:53<00:51,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0652984917361902)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.07262589549440318\n",
      "DEBUG:shap:self.fx = 0.4719444444444444\n",
      "DEBUG:shap:self.link(self.fx) = 0.4719444444444444\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.09359633,  0.02567638, -0.01025166,  0.02038242, -0.0011921 ,\n",
      "       -0.01682251,  0.02201974, -0.02861267, -0.04356249,  0.022553  ,\n",
      "       -0.00656471,  0.02947026,  0.01779322, -0.05918673,  0.0073274 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.0652984917361902)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.07262589549440324\n",
      "DEBUG:shap:self.fx = 0.5280555555555555\n",
      "DEBUG:shap:self.link(self.fx) = 0.5280555555555555\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.09359633, -0.02567638,  0.01025166, -0.02038242,  0.0011921 ,\n",
      "        0.01682251, -0.02201974,  0.02861267,  0.04356249, -0.022553  ,\n",
      "        0.00656471, -0.02947026, -0.01779322,  0.05918673, -0.0073274 ])\n",
      " 70%|███████   | 52/74 [01:55<00:49,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1507362643289087)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1646260163364559\n",
      "DEBUG:shap:self.fx = 0.2346925326135853\n",
      "DEBUG:shap:self.link(self.fx) = 0.2346925326135853\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14879094,  0.02109707,  0.00371404, -0.05615041, -0.00229242,\n",
      "       -0.00919436,  0.02594556,  0.06988569, -0.03026234, -0.006842  ,\n",
      "       -0.02652298, -0.0028316 ,  0.01031956,  0.00118885, -0.01388975])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.15073626432890894)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16462601633645624\n",
      "DEBUG:shap:self.fx = 0.765307467386415\n",
      "DEBUG:shap:self.link(self.fx) = 0.765307467386415\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.14879094, -0.02109707, -0.00371404,  0.05615041,  0.00229242,\n",
      "        0.00919436, -0.02594556, -0.06988569,  0.03026234,  0.006842  ,\n",
      "        0.02652298,  0.0028316 , -0.01031956, -0.00118885,  0.01388975])\n",
      " 72%|███████▏  | 53/74 [01:57<00:47,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.24911120718853044)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.25991731438213994\n",
      "DEBUG:shap:self.fx = 0.13940123456790124\n",
      "DEBUG:shap:self.link(self.fx) = 0.13940123456790124\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14605216,  0.00577588, -0.00545216, -0.06478171,  0.00314323,\n",
      "       -0.00987493,  0.02548264, -0.01394557,  0.00045794, -0.01354655,\n",
      "       -0.01220789, -0.004669  ,  0.00700091, -0.02044184, -0.01080611])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2491112071885307)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2599173143821403\n",
      "DEBUG:shap:self.fx = 0.860598765432099\n",
      "DEBUG:shap:self.link(self.fx) = 0.860598765432099\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.14605216, -0.00577588,  0.00545216,  0.06478171, -0.00314323,\n",
      "        0.00987493, -0.02548264,  0.01394557, -0.00045794,  0.01354655,\n",
      "        0.01220789,  0.004669  , -0.00700091,  0.02044184,  0.01080611])\n",
      " 73%|███████▎  | 54/74 [02:00<00:44,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23032645424834328)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21085568773718003\n",
      "DEBUG:shap:self.fx = 0.18846286121286118\n",
      "DEBUG:shap:self.link(self.fx) = 0.18846286121286118\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.11225888,  0.04066294,  0.00643626, -0.04258679, -0.00105401,\n",
      "       -0.03287123, -0.02948393, -0.01611664, -0.03700064, -0.00759566,\n",
      "       -0.0036065 , -0.00344321,  0.04042033, -0.0318285 ,  0.01947077])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23032645424834336)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2108556877371801\n",
      "DEBUG:shap:self.fx = 0.8115371387871388\n",
      "DEBUG:shap:self.link(self.fx) = 0.8115371387871388\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.11225888, -0.04066294, -0.00643626,  0.04258679,  0.00105401,\n",
      "        0.03287123,  0.02948393,  0.01611664,  0.03700064,  0.00759566,\n",
      "        0.0036065 ,  0.00344321, -0.04042033,  0.0318285 , -0.01947077])\n",
      " 74%|███████▍  | 55/74 [02:02<00:42,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2285615881292928)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.23641995988478545\n",
      "DEBUG:shap:self.fx = 0.16289858906525576\n",
      "DEBUG:shap:self.link(self.fx) = 0.16289858906525576\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14731429, -0.02545429, -0.0010968 , -0.05253252, -0.00906546,\n",
      "       -0.01170848, -0.02410581,  0.00071182,  0.00639394,  0.01103494,\n",
      "        0.00473615, -0.00435877,  0.00639326,  0.01780472, -0.00785837])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22856158812929264)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.23641995988478526\n",
      "DEBUG:shap:self.fx = 0.837101410934744\n",
      "DEBUG:shap:self.link(self.fx) = 0.837101410934744\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.14731429,  0.02545429,  0.0010968 ,  0.05253252,  0.00906546,\n",
      "        0.01170848,  0.02410581, -0.00071182, -0.00639394, -0.01103494,\n",
      "       -0.00473615,  0.00435877, -0.00639326, -0.01780472,  0.00785837])\n",
      " 76%|███████▌  | 56/74 [02:04<00:40,  2.27s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3966763345123598)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.41129256216106974\n",
      "DEBUG:shap:self.fx = 0.810611111111111\n",
      "DEBUG:shap:self.link(self.fx) = 0.810611111111111\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 2.35613989e-01,  2.36887693e-02,  1.03246211e-02,  3.01979369e-02,\n",
      "        6.91905819e-03,  1.32598484e-02,  1.55949900e-02,  2.02187058e-02,\n",
      "        1.40514542e-04, -2.05923534e-03, -3.23507198e-02,  6.06122066e-03,\n",
      "        8.58424603e-03,  6.04823896e-02,  1.46162276e-02])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3966763345123599)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4112925621610698\n",
      "DEBUG:shap:self.fx = 0.1893888888888889\n",
      "DEBUG:shap:self.link(self.fx) = 0.1893888888888889\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-2.35613989e-01, -2.36887693e-02, -1.03246211e-02, -3.01979369e-02,\n",
      "       -6.91905819e-03, -1.32598484e-02, -1.55949900e-02, -2.02187058e-02,\n",
      "       -1.40514542e-04,  2.05923534e-03,  3.23507198e-02, -6.06122066e-03,\n",
      "       -8.58424603e-03, -6.04823896e-02, -1.46162276e-02])\n",
      " 77%|███████▋  | 57/74 [02:06<00:38,  2.27s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.022572750389237957)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.0039512923198000705\n",
      "DEBUG:shap:self.fx = 0.4032698412698413\n",
      "DEBUG:shap:self.link(self.fx) = 0.4032698412698413\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.15520483, -0.00870671,  0.00950091,  0.08689035,  0.00690004,\n",
      "        0.01646351,  0.01880892, -0.02168261,  0.00654059,  0.02840967,\n",
      "        0.00905102, -0.00797456,  0.0138819 ,  0.01969456, -0.01862146])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.022572750389238137)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.0039512923198001815\n",
      "DEBUG:shap:self.fx = 0.5967301587301586\n",
      "DEBUG:shap:self.link(self.fx) = 0.5967301587301586\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.15520483,  0.00870671, -0.00950091, -0.08689035, -0.00690004,\n",
      "       -0.01646351, -0.01880892,  0.02168261, -0.00654059, -0.02840967,\n",
      "       -0.00905102,  0.00797456, -0.0138819 , -0.01969456,  0.01862146])\n",
      " 78%|███████▊  | 58/74 [02:09<00:36,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.07645574911341421)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.06157018293696942\n",
      "DEBUG:shap:self.fx = 0.3377483660130718\n",
      "DEBUG:shap:self.link(self.fx) = 0.3377483660130718\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.16986013, -0.02289955, -0.01183035,  0.01731687,  0.00420981,\n",
      "       -0.00921703, -0.04374796, -0.03916137, -0.03698335, -0.00202934,\n",
      "        0.01077177, -0.00158469, -0.04039929, -0.07076141,  0.01488557])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.07645574911341416)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.061570182936969364\n",
      "DEBUG:shap:self.fx = 0.6622516339869281\n",
      "DEBUG:shap:self.link(self.fx) = 0.6622516339869281\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.16986013,  0.02289955,  0.01183035, -0.01731687, -0.00420981,\n",
      "        0.00921703,  0.04374796,  0.03916137,  0.03698335,  0.00202934,\n",
      "       -0.01077177,  0.00158469,  0.04039929,  0.07076141, -0.01488557])\n",
      " 80%|███████▉  | 59/74 [02:11<00:34,  2.27s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2840266455022025)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2871893875578953\n",
      "DEBUG:shap:self.fx = 0.6865079365079365\n",
      "DEBUG:shap:self.link(self.fx) = 0.6865079365079365\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.20014546, -0.12814708,  0.0032976 ,  0.1008971 ,  0.00275068,\n",
      "        0.01428519,  0.00283053,  0.04187039,  0.00678484,  0.00381918,\n",
      "        0.        ,  0.00280898,  0.01829928,  0.01438449,  0.00316274])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2840266455022025)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2871893875578953\n",
      "DEBUG:shap:self.fx = 0.31349206349206343\n",
      "DEBUG:shap:self.link(self.fx) = 0.31349206349206343\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.20014546,  0.12814708, -0.0032976 , -0.1008971 , -0.00275068,\n",
      "       -0.01428519, -0.00283053, -0.04187039, -0.00678484, -0.00381918,\n",
      "        0.        , -0.00280898, -0.01829928, -0.01438449, -0.00316274])\n",
      " 81%|████████  | 60/74 [02:13<00:31,  2.27s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2627347415660743)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2698560542245619\n",
      "DEBUG:shap:self.fx = 0.6691746031746031\n",
      "DEBUG:shap:self.link(self.fx) = 0.6691746031746031\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.18467954,  0.02325908,  0.00400906,  0.0819091 ,  0.0008196 ,\n",
      "        0.05729332,  0.01299846, -0.06148458, -0.00223041,  0.        ,\n",
      "        0.00325575, -0.0045354 ,  0.01848118, -0.05571996,  0.00712131])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2627347415660743)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.26985605422456194\n",
      "DEBUG:shap:self.fx = 0.3308253968253968\n",
      "DEBUG:shap:self.link(self.fx) = 0.3308253968253968\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.18467954, -0.02325908, -0.00400906, -0.0819091 , -0.0008196 ,\n",
      "       -0.05729332, -0.01299846,  0.06148458,  0.00223041,  0.        ,\n",
      "       -0.00325575,  0.0045354 , -0.01848118,  0.05571996, -0.00712131])\n",
      " 82%|████████▏ | 61/74 [02:15<00:29,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.25068911363641694)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2521202380017302\n",
      "DEBUG:shap:self.fx = 0.14719831094831096\n",
      "DEBUG:shap:self.link(self.fx) = 0.14719831094831096\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.12585594,  0.04650341,  0.0081434 , -0.03852479, -0.00819184,\n",
      "       -0.02302529, -0.01192396, -0.02268636, -0.01252504, -0.01030068,\n",
      "       -0.00027437, -0.005845  , -0.01173804, -0.03444463, -0.00143112])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.25068911363641705)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.25212023800173033\n",
      "DEBUG:shap:self.fx = 0.8528016890516891\n",
      "DEBUG:shap:self.link(self.fx) = 0.8528016890516891\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.12585594, -0.04650341, -0.0081434 ,  0.03852479,  0.00819184,\n",
      "        0.02302529,  0.01192396,  0.02268636,  0.01252504,  0.01030068,\n",
      "        0.00027437,  0.005845  ,  0.01173804,  0.03444463,  0.00143112])\n",
      " 84%|████████▍ | 62/74 [02:18<00:27,  2.28s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.32634942075090473)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3409574378389301\n",
      "DEBUG:shap:self.fx = 0.05836111111111111\n",
      "DEBUG:shap:self.link(self.fx) = 0.05836111111111111\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.13015239,  0.00961231, -0.00773601, -0.06080939, -0.00953595,\n",
      "       -0.014452  , -0.04348495, -0.01563407, -0.02491168,  0.03248362,\n",
      "       -0.01092224, -0.01443717,  0.00047901, -0.03684851, -0.01460802])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3263494207509047)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3409574378389302\n",
      "DEBUG:shap:self.fx = 0.9416388888888889\n",
      "DEBUG:shap:self.link(self.fx) = 0.9416388888888889\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.13015239, -0.00961231,  0.00773601,  0.06080939,  0.00953595,\n",
      "        0.014452  ,  0.04348495,  0.01563407,  0.02491168, -0.03248362,\n",
      "        0.01092224,  0.01443717, -0.00047901,  0.03684851,  0.01460802])\n",
      " 85%|████████▌ | 63/74 [02:20<00:24,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.008889055069429122)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.019427482795990714\n",
      "DEBUG:shap:self.fx = 0.4187460317460319\n",
      "DEBUG:shap:self.link(self.fx) = 0.4187460317460319\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.16783178, -0.04239898,  0.00230432,  0.07621603,  0.00093146,\n",
      "        0.0114716 ,  0.01410912, -0.07542387, -0.04509762, -0.00302275,\n",
      "       -0.00760953, -0.00308073, -0.01557743, -0.07176434,  0.01053843])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.008889055069428914)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.01942748279599049\n",
      "DEBUG:shap:self.fx = 0.5812539682539682\n",
      "DEBUG:shap:self.link(self.fx) = 0.5812539682539682\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.16783178,  0.04239898, -0.00230432, -0.07621603, -0.00093146,\n",
      "       -0.0114716 , -0.01410912,  0.07542387,  0.04509762,  0.00302275,\n",
      "        0.00760953,  0.00308073,  0.01557743,  0.07176434, -0.01053843])\n",
      " 86%|████████▋ | 64/74 [02:22<00:22,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.0787066478892773)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.07989822966076116\n",
      "DEBUG:shap:self.fx = 0.31942031928928005\n",
      "DEBUG:shap:self.link(self.fx) = 0.31942031928928005\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.15669128,  0.0247582 ,  0.01019302, -0.05396371, -0.00747004,\n",
      "       -0.00397713,  0.03624622,  0.0675106 ,  0.00396964, -0.0028324 ,\n",
      "        0.01075765, -0.00104988, -0.00124348, -0.00491407, -0.00119158])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.07870664788927724)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.0798982296607611\n",
      "DEBUG:shap:self.fx = 0.6805796807107198\n",
      "DEBUG:shap:self.link(self.fx) = 0.6805796807107198\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.15669128, -0.0247582 , -0.01019302,  0.05396371,  0.00747004,\n",
      "        0.00397713, -0.03624622, -0.0675106 , -0.00396964,  0.0028324 ,\n",
      "       -0.01075765,  0.00104988,  0.00124348,  0.00491407,  0.00119158])\n",
      " 88%|████████▊ | 65/74 [02:25<00:20,  2.30s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.09162098533891427)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.0861258954944033\n",
      "DEBUG:shap:self.fx = 0.4854444444444445\n",
      "DEBUG:shap:self.link(self.fx) = 0.4854444444444445\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.02057598, -0.03583007, -0.00513626,  0.09659565,  0.00541876,\n",
      "        0.05033047,  0.01183035, -0.02766925,  0.00103299,  0.02763893,\n",
      "       -0.01955343, -0.01421329,  0.01217836,  0.00957375, -0.00549509])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09162098533891408)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08612589549440319\n",
      "DEBUG:shap:self.fx = 0.5145555555555555\n",
      "DEBUG:shap:self.link(self.fx) = 0.5145555555555555\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.02057598,  0.03583007,  0.00513626, -0.09659565, -0.00541876,\n",
      "       -0.05033047, -0.01183035,  0.02766925, -0.00103299, -0.02763893,\n",
      "        0.01955343,  0.01421329, -0.01217836, -0.00957375,  0.00549509])\n",
      " 89%|████████▉ | 66/74 [02:27<00:18,  2.32s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2780386308644945)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2342216273531196\n",
      "DEBUG:shap:self.fx = 0.1650969215969216\n",
      "DEBUG:shap:self.link(self.fx) = 0.1650969215969216\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14493088, -0.01313007,  0.01216605, -0.05400525, -0.00088761,\n",
      "       -0.01602776, -0.00839807, -0.03766652,  0.00429182,  0.00223812,\n",
      "        0.00619502, -0.00673878,  0.00654515, -0.02768986,  0.043817  ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2780386308644944)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2342216273531197\n",
      "DEBUG:shap:self.fx = 0.8349030784030784\n",
      "DEBUG:shap:self.link(self.fx) = 0.8349030784030784\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.14493088,  0.01313007, -0.01216605,  0.05400525,  0.00088761,\n",
      "        0.01602776,  0.00839807,  0.03766652, -0.00429182, -0.00223812,\n",
      "       -0.00619502,  0.00673878, -0.00654515,  0.02768986, -0.043817  ])\n",
      " 91%|█████████ | 67/74 [02:29<00:16,  2.34s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20890126948674057)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.17894817857967082\n",
      "DEBUG:shap:self.fx = 0.22037037037037038\n",
      "DEBUG:shap:self.link(self.fx) = 0.22037037037037038\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.15731356, -0.01953828, -0.00321094, -0.06704791,  0.0017043 ,\n",
      "       -0.01537679, -0.01625013,  0.09403588,  0.005388  , -0.01177566,\n",
      "       -0.00400857, -0.00484919,  0.00833105, -0.01898946,  0.02995309])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20890126948674076)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.17894817857967094\n",
      "DEBUG:shap:self.fx = 0.7796296296296297\n",
      "DEBUG:shap:self.link(self.fx) = 0.7796296296296297\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.15731356,  0.01953828,  0.00321094,  0.06704791, -0.0017043 ,\n",
      "        0.01537679,  0.01625013, -0.09403588, -0.005388  ,  0.01177566,\n",
      "        0.00400857,  0.00484919, -0.00833105,  0.01898946, -0.02995309])\n",
      " 92%|█████████▏| 68/74 [02:32<00:13,  2.31s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.39866410193024754)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.36970922882773655\n",
      "DEBUG:shap:self.fx = 0.7690277777777778\n",
      "DEBUG:shap:self.link(self.fx) = 0.7690277777777778\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.20290636,  0.01819936,  0.00172752,  0.08793225, -0.00348413,\n",
      "        0.01289745,  0.02487206,  0.05685748, -0.00492692, -0.01340457,\n",
      "       -0.01342051,  0.00118323, -0.03890819,  0.06623271, -0.02895487])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3986641019302475)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3697092288277365\n",
      "DEBUG:shap:self.fx = 0.23097222222222225\n",
      "DEBUG:shap:self.link(self.fx) = 0.23097222222222225\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.20290636, -0.01819936, -0.00172752, -0.08793225,  0.00348413,\n",
      "       -0.01289745, -0.02487206, -0.05685748,  0.00492692,  0.01340457,\n",
      "        0.01342051, -0.00118323,  0.03890819, -0.06623271,  0.02895487])\n",
      " 93%|█████████▎| 69/74 [02:34<00:11,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4142065474096112)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.42568541930392706\n",
      "DEBUG:shap:self.fx = 0.8250039682539683\n",
      "DEBUG:shap:self.link(self.fx) = 0.8250039682539683\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.20192365,  0.02171294, -0.01160366,  0.03013878, -0.00255842,\n",
      "        0.05375977,  0.03781757,  0.02884154, -0.00472803,  0.00646646,\n",
      "        0.01545521,  0.01764582,  0.00123509,  0.01809982,  0.01147887])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.41420654740961116)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.42568541930392695\n",
      "DEBUG:shap:self.fx = 0.1749960317460318\n",
      "DEBUG:shap:self.link(self.fx) = 0.1749960317460318\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.20192365, -0.02171294,  0.01160366, -0.03013878,  0.00255842,\n",
      "       -0.05375977, -0.03781757, -0.02884154,  0.00472803, -0.00646646,\n",
      "       -0.01545521, -0.01764582, -0.00123509, -0.01809982, -0.01147887])\n",
      " 95%|█████████▍| 70/74 [02:36<00:08,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24268076261699023)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24744335581186377\n",
      "DEBUG:shap:self.fx = 0.646761904761905\n",
      "DEBUG:shap:self.link(self.fx) = 0.646761904761905\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.172025  ,  0.00565447,  0.00224042,  0.07842584,  0.00357285,\n",
      "        0.01834863,  0.02957429,  0.06171971, -0.05746936,  0.00551485,\n",
      "       -0.01968096, -0.00249771,  0.01841508, -0.07316234,  0.00476259])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.24268076261698976)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.24744335581186333\n",
      "DEBUG:shap:self.fx = 0.3532380952380954\n",
      "DEBUG:shap:self.link(self.fx) = 0.3532380952380954\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.172025  , -0.00565447, -0.00224042, -0.07842584, -0.00357285,\n",
      "       -0.01834863, -0.02957429, -0.06171971,  0.05746936, -0.00551485,\n",
      "        0.01968096,  0.00249771, -0.01841508,  0.07316234, -0.00476259])\n",
      " 96%|█████████▌| 71/74 [02:38<00:06,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4573000742751856)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4634314510499586\n",
      "DEBUG:shap:self.fx = 0.8627499999999998\n",
      "DEBUG:shap:self.link(self.fx) = 0.8627499999999998\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.20693692,  0.01965528,  0.00241431,  0.09835098, -0.00981923,\n",
      "        0.01604274,  0.03810212,  0.06798934,  0.00586934,  0.00103938,\n",
      "        0.01441729,  0.01989226,  0.00690224, -0.03049289,  0.00613138])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.45730007427518593)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.46343145104995875\n",
      "DEBUG:shap:self.fx = 0.13724999999999998\n",
      "DEBUG:shap:self.link(self.fx) = 0.13724999999999998\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.20693692, -0.01965528, -0.00241431, -0.09835098,  0.00981923,\n",
      "       -0.01604274, -0.03810212, -0.06798934, -0.00586934, -0.00103938,\n",
      "       -0.01441729, -0.01989226, -0.00690224,  0.03049289, -0.00613138])\n",
      " 97%|█████████▋| 72/74 [02:40<00:04,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3089904930581165)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.323616269747762\n",
      "DEBUG:shap:self.fx = 0.07570227920227922\n",
      "DEBUG:shap:self.link(self.fx) = 0.07570227920227922\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.16488178, -0.02669943,  0.00703334, -0.04519847,  0.00266391,\n",
      "       -0.01130859, -0.02497439, -0.02391315, -0.01992771, -0.01235762,\n",
      "        0.        ,  0.00408699,  0.00648641,  0.        , -0.01462578])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.30899049305811643)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.32361626974776203\n",
      "DEBUG:shap:self.fx = 0.9242977207977208\n",
      "DEBUG:shap:self.link(self.fx) = 0.9242977207977208\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.16488178,  0.02669943, -0.00703334,  0.04519847, -0.00266391,\n",
      "        0.01130859,  0.02497439,  0.02391315,  0.01992771,  0.01235762,\n",
      "        0.        , -0.00408699, -0.00648641,  0.        ,  0.01462578])\n",
      " 99%|█████████▊| 73/74 [02:43<00:02,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2569603684157078)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2723014549329472\n",
      "DEBUG:shap:self.fx = 0.12701709401709402\n",
      "DEBUG:shap:self.link(self.fx) = 0.12701709401709402\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.13069068,  0.00173339, -0.01214048, -0.05679102,  0.00158771,\n",
      "        0.01088723, -0.04028745, -0.01921966, -0.00413405, -0.00811139,\n",
      "        0.00768213, -0.02255409,  0.04108347, -0.02600548, -0.01534109])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2569603684157079)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.27230145493294744\n",
      "DEBUG:shap:self.fx = 0.8729829059829062\n",
      "DEBUG:shap:self.link(self.fx) = 0.8729829059829062\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.13069068, -0.00173339,  0.01214048,  0.05679102, -0.00158771,\n",
      "       -0.01088723,  0.04028745,  0.01921966,  0.00413405,  0.00811139,\n",
      "       -0.00768213,  0.02255409, -0.04108347,  0.02600548,  0.01534109])\n",
      "100%|██████████| 74/74 [02:45<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7875,\n",
      "                0.7458333333333332,\n",
      "                0.6608333333333333,\n",
      "                0.56,\n",
      "                0.6216666666666666,\n",
      "                0.6291666666666667,\n",
      "                0.5275000000000001,\n",
      "                0.5741666666666667,\n",
      "                0.5783333333333334,\n",
      "                0.6258333333333334,\n",
      "                0.5991666666666667,\n",
      "                0.6058333333333333,\n",
      "                0.5204166666666666,\n",
      "                0.5454166666666667,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5893880935369175,\n",
      "                0.6939687843745195,\n",
      "                0.7861497864710774,\n",
      "                0.8458936405573276,\n",
      "                0.8828703216757898,\n",
      "                0.9095310509334874,\n",
      "                0.9373059843816347,\n",
      "                0.8598579037819417,\n",
      "                0.8939732945679326,\n",
      "                0.8995061653339594,\n",
      "                0.9145578564540002,\n",
      "                0.896320847839611,\n",
      "                0.9219070985617821,\n",
      "                0.9268913809609458,\n",
      "                0.9404186671352546\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.20014143968821002,\n",
      "                0.25060080888344277,\n",
      "                0.29290152701464217,\n",
      "                0.3204676327258146,\n",
      "                0.33733786946181604,\n",
      "                0.34798900723300935,\n",
      "                0.36022320636546296,\n",
      "                0.32889035475869166,\n",
      "                0.3442630343753096,\n",
      "                0.3469030473976222,\n",
      "                0.35334002172356127,\n",
      "                0.34556837299259124,\n",
      "                0.35703636063854377,\n",
      "                0.3591017801705773,\n",
      "                0.3649649438114703\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6054444444444443,\n",
      "            \"cross_entropy\": 0.859902725104412,\n",
      "            \"brier\": 0.32731529381605096\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7708333333333334,\n",
      "                0.7929166666666666,\n",
      "                0.8433333333333333,\n",
      "                0.8591666666666667,\n",
      "                0.845,\n",
      "                0.835,\n",
      "                0.8333333333333334,\n",
      "                0.8108333333333333,\n",
      "                0.8108333333333333,\n",
      "                0.8116666666666666,\n",
      "                0.8116666666666666,\n",
      "                0.8116666666666665,\n",
      "                0.8275,\n",
      "                0.8400000000000001,\n",
      "                0.8291666666666667\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.6613720387481131,\n",
      "                0.5813672929279904,\n",
      "                0.5108789761289761,\n",
      "                0.4728810069891966,\n",
      "                0.48131751388641597,\n",
      "                0.4882776563809955,\n",
      "                0.4842780747559211,\n",
      "                0.5228003413035268,\n",
      "                0.5075128233163185,\n",
      "                0.5094612179574532,\n",
      "                0.5042806321029312,\n",
      "                0.5050633476645214,\n",
      "                0.49699225583757406,\n",
      "                0.4902744787977843,\n",
      "                0.4891898601283233\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.22809981569093526,\n",
      "                0.19605940381276157,\n",
      "                0.16857600403574025,\n",
      "                0.15332288574781724,\n",
      "                0.15633375593993196,\n",
      "                0.15930476736063756,\n",
      "                0.15613386367060075,\n",
      "                0.16939742395066504,\n",
      "                0.1646962467012852,\n",
      "                0.1639675945631498,\n",
      "                0.16366221928609567,\n",
      "                0.16480046604569373,\n",
      "                0.16180537509758922,\n",
      "                0.15947555799223034,\n",
      "                0.15935898123209713\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8221944444444446,\n",
      "            \"cross_entropy\": 0.513729834461736,\n",
      "            \"brier\": 0.16833295740848203\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/74 [00:00<?, ?it/s]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.27893225204108973)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2820994472269981\n",
      "DEBUG:shap:self.fx = 0.08578769841269838\n",
      "DEBUG:shap:self.link(self.fx) = 0.08578769841269838\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10464954, -0.03099638, -0.00373699, -0.00566534,  0.        ,\n",
      "        0.01819693,  0.01472868, -0.05484793, -0.00828634, -0.01505646,\n",
      "       -0.00785655, -0.00808084, -0.00992054, -0.06276097, -0.0031672 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.27893225204108996)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2820994472269984\n",
      "DEBUG:shap:self.fx = 0.9142123015873017\n",
      "DEBUG:shap:self.link(self.fx) = 0.9142123015873017\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10464954,  0.03099638,  0.00373699,  0.00566534,  0.        ,\n",
      "       -0.01819693, -0.01472868,  0.05484793,  0.00828634,  0.01505646,\n",
      "        0.00785655,  0.00808084,  0.00992054,  0.06276097,  0.0031672 ])\n",
      "  1%|▏         | 1/74 [00:01<02:05,  1.71s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.14951464068588588)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.16172047897302982\n",
      "DEBUG:shap:self.fx = 0.20616666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.20616666666666666\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.09407001, -0.02789031,  0.00721369, -0.09098891,  0.00991532,\n",
      "       -0.01443961,  0.02375899,  0.01888117, -0.00563258, -0.00943991,\n",
      "       -0.01392286,  0.00544979, -0.00153922,  0.0431898 , -0.01220584])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.14951464068588605)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16172047897303\n",
      "DEBUG:shap:self.fx = 0.7938333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.7938333333333333\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.09407001,  0.02789031, -0.00721369,  0.09098891, -0.00991532,\n",
      "        0.01443961, -0.02375899, -0.01888117,  0.00563258,  0.00943991,\n",
      "        0.01392286, -0.00544979,  0.00153922, -0.0431898 ,  0.01220584])\n",
      "  3%|▎         | 2/74 [00:03<02:05,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1800047717738268)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1942561932587441\n",
      "DEBUG:shap:self.fx = 0.17363095238095239\n",
      "DEBUG:shap:self.link(self.fx) = 0.17363095238095239\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.13768565,  0.00140882,  0.00604483, -0.05700054,  0.00999813,\n",
      "       -0.01177587,  0.02066737, -0.03455398, -0.00512354,  0.00039735,\n",
      "        0.00413226, -0.00376015,  0.01012721,  0.01711898, -0.01425142])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.18000477177382682)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.19425619325874421\n",
      "DEBUG:shap:self.fx = 0.8263690476190475\n",
      "DEBUG:shap:self.link(self.fx) = 0.8263690476190475\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.13768565, -0.00140882, -0.00604483,  0.05700054, -0.00999813,\n",
      "        0.01177587, -0.02066737,  0.03455398,  0.00512354, -0.00039735,\n",
      "       -0.00413226,  0.00376015, -0.01012721, -0.01711898,  0.01425142])\n",
      "  4%|▍         | 3/74 [00:05<02:05,  1.76s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.16878127638384632)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.18769071706826798\n",
      "DEBUG:shap:self.fx = 0.1801964285714285\n",
      "DEBUG:shap:self.link(self.fx) = 0.1801964285714285\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.11920414, -0.00197464,  0.02267357, -0.05379741,  0.01497643,\n",
      "        0.02470693,  0.02172841, -0.05633103,  0.00828875, -0.00992557,\n",
      "       -0.00849397, -0.01528625, -0.01337929,  0.01723692, -0.01890944])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.16878127638384682)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.18769071706826845\n",
      "DEBUG:shap:self.fx = 0.8198035714285717\n",
      "DEBUG:shap:self.link(self.fx) = 0.8198035714285717\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.11920414,  0.00197464, -0.02267357,  0.05379741, -0.01497643,\n",
      "       -0.02470693, -0.02172841,  0.05633103, -0.00828875,  0.00992557,\n",
      "        0.00849397,  0.01528625,  0.01337929, -0.01723692,  0.01890944])\n",
      "  5%|▌         | 4/74 [00:06<02:02,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2564735704915268)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.23862920913175997\n",
      "DEBUG:shap:self.fx = 0.12925793650793652\n",
      "DEBUG:shap:self.link(self.fx) = 0.12925793650793652\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10396352,  0.0048131 , -0.00646425, -0.05180378, -0.00215684,\n",
      "       -0.01909761,  0.01052384, -0.04400835, -0.01490284, -0.00858428,\n",
      "       -0.00583711,  0.0296075 ,  0.00321133, -0.04781078,  0.01784436])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2564735704915271)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.23862920913176022\n",
      "DEBUG:shap:self.fx = 0.8707420634920635\n",
      "DEBUG:shap:self.link(self.fx) = 0.8707420634920635\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10396352, -0.0048131 ,  0.00646425,  0.05180378,  0.00215684,\n",
      "        0.01909761, -0.01052384,  0.04400835,  0.01490284,  0.00858428,\n",
      "        0.00583711, -0.0296075 , -0.00321133,  0.04781078, -0.01784436])\n",
      "  7%|▋         | 5/74 [00:08<01:59,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.14416783223872034)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.14228547340792275\n",
      "DEBUG:shap:self.fx = 0.5101726190476192\n",
      "DEBUG:shap:self.link(self.fx) = 0.5101726190476192\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.1668957 ,  0.00843667, -0.01253959,  0.08292631, -0.01279907,\n",
      "        0.0169681 ,  0.01389027, -0.05272207, -0.00461122, -0.00571517,\n",
      "        0.01938641, -0.00250864,  0.00573878, -0.07917867, -0.00188236])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.14416783223871998)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.14228547340792236\n",
      "DEBUG:shap:self.fx = 0.48982738095238093\n",
      "DEBUG:shap:self.link(self.fx) = 0.48982738095238093\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.1668957 , -0.00843667,  0.01253959, -0.08292631,  0.01279907,\n",
      "       -0.0169681 , -0.01389027,  0.05272207,  0.00461122,  0.00571517,\n",
      "       -0.01938641,  0.00250864, -0.00573878,  0.07917867,  0.00188236])\n",
      "  8%|▊         | 6/74 [00:10<01:57,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12272073505596713)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.10468031467776379\n",
      "DEBUG:shap:self.fx = 0.4725674603174603\n",
      "DEBUG:shap:self.link(self.fx) = 0.4725674603174603\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.02924968, -0.00400783, -0.01091529,  0.0819059 , -0.00961842,\n",
      "        0.0130999 ,  0.02184527,  0.04152172,  0.00815859,  0.0028393 ,\n",
      "        0.00927847,  0.00081016,  0.02206382, -0.08351053, -0.01804042])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.12272073505596706)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.10468031467776362\n",
      "DEBUG:shap:self.fx = 0.5274325396825397\n",
      "DEBUG:shap:self.link(self.fx) = 0.5274325396825397\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.02924968,  0.00400783,  0.01091529, -0.0819059 ,  0.00961842,\n",
      "       -0.0130999 , -0.02184527, -0.04152172, -0.00815859, -0.0028393 ,\n",
      "       -0.00927847, -0.00081016, -0.02206382,  0.08351053,  0.01804042])\n",
      "  9%|▉         | 7/74 [00:12<01:55,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.07969614611223871)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.062047859925410676\n",
      "DEBUG:shap:self.fx = 0.3058392857142858\n",
      "DEBUG:shap:self.link(self.fx) = 0.3058392857142858\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.12449235,  0.01869005,  0.01496947, -0.05998419, -0.00303503,\n",
      "       -0.0150538 , -0.03104821,  0.05761776,  0.0100457 ,  0.01549442,\n",
      "        0.02625231, -0.00536721,  0.01553161,  0.00068332,  0.01764829])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0796961461122392)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.062047859925411175\n",
      "DEBUG:shap:self.fx = 0.6941607142857145\n",
      "DEBUG:shap:self.link(self.fx) = 0.6941607142857145\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.12449235, -0.01869005, -0.01496947,  0.05998419,  0.00303503,\n",
      "        0.0150538 ,  0.03104821, -0.05761776, -0.0100457 , -0.01549442,\n",
      "       -0.02625231,  0.00536721, -0.01553161, -0.00068332, -0.01764829])\n",
      " 11%|█         | 8/74 [00:13<01:54,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03222434488180047)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.031521584519033696\n",
      "DEBUG:shap:self.fx = 0.3994087301587302\n",
      "DEBUG:shap:self.link(self.fx) = 0.3994087301587302\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.14624752,  0.00518383,  0.0136619 ,  0.08930681,  0.0093166 ,\n",
      "       -0.01757835,  0.00430893, -0.05174929, -0.041542  , -0.00545235,\n",
      "        0.00768505, -0.02136368, -0.01612055, -0.08968006, -0.00070276])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.032224344881800426)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.03152158451903364\n",
      "DEBUG:shap:self.fx = 0.6005912698412696\n",
      "DEBUG:shap:self.link(self.fx) = 0.6005912698412696\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.14624752, -0.00518383, -0.0136619 , -0.08930681, -0.0093166 ,\n",
      "        0.01757835, -0.00430893,  0.05174929,  0.041542  ,  0.00545235,\n",
      "       -0.00768505,  0.02136368,  0.01612055,  0.08968006,  0.00070276])\n",
      " 12%|█▏        | 9/74 [00:15<01:52,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.28342618714859047)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2791371456396965\n",
      "DEBUG:shap:self.fx = 0.08875\n",
      "DEBUG:shap:self.link(self.fx) = 0.08875\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10262297, -0.02185337,  0.00411207, -0.03426993,  0.00472685,\n",
      "       -0.02851994, -0.01558465, -0.02474885,  0.00804454, -0.01024631,\n",
      "        0.0070383 , -0.00132052,  0.0014571 , -0.06963849,  0.00428904])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2834261871485908)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2791371456396967\n",
      "DEBUG:shap:self.fx = 0.91125\n",
      "DEBUG:shap:self.link(self.fx) = 0.91125\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10262297,  0.02185337, -0.00411207,  0.03426993, -0.00472685,\n",
      "        0.02851994,  0.01558465,  0.02474885, -0.00804454,  0.01024631,\n",
      "       -0.0070383 ,  0.00132052, -0.0014571 ,  0.06963849, -0.00428904])\n",
      " 14%|█▎        | 10/74 [00:17<01:48,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20391198976194966)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1828930980206489\n",
      "DEBUG:shap:self.fx = 0.18499404761904759\n",
      "DEBUG:shap:self.link(self.fx) = 0.18499404761904759\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10638836,  0.0029214 ,  0.        , -0.06776368, -0.00483936,\n",
      "       -0.01290357, -0.04659036,  0.0698955 , -0.0049463 , -0.01279228,\n",
      "        0.00417167, -0.02128033,  0.        , -0.00339632,  0.02101889])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20391198976195013)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.18289309802064924\n",
      "DEBUG:shap:self.fx = 0.8150059523809525\n",
      "DEBUG:shap:self.link(self.fx) = 0.8150059523809525\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10638836, -0.0029214 ,  0.        ,  0.06776368,  0.00483936,\n",
      "        0.01290357,  0.04659036, -0.0698955 ,  0.0049463 ,  0.01279228,\n",
      "       -0.00417167,  0.02128033,  0.        ,  0.00339632, -0.02101889])\n",
      " 15%|█▍        | 11/74 [00:18<01:45,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.199463144367651)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21364905040160126\n",
      "DEBUG:shap:self.fx = 0.15423809523809523\n",
      "DEBUG:shap:self.link(self.fx) = 0.15423809523809523\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.13054531, -0.00170465,  0.00835263, -0.06559588, -0.004969  ,\n",
      "        0.00767904, -0.02021706, -0.03298808,  0.00808312, -0.01529937,\n",
      "        0.00340977,  0.000713  , -0.00443467,  0.04805332, -0.01418591])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19946314436765142)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21364905040160165\n",
      "DEBUG:shap:self.fx = 0.8457619047619049\n",
      "DEBUG:shap:self.link(self.fx) = 0.8457619047619049\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.13054531,  0.00170465, -0.00835263,  0.06559588,  0.004969  ,\n",
      "       -0.00767904,  0.02021706,  0.03298808, -0.00808312,  0.01529937,\n",
      "       -0.00340977, -0.000713  ,  0.00443467, -0.04805332,  0.01418591])\n",
      " 16%|█▌        | 12/74 [00:20<01:43,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.47493480009617534)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.48495015594760527\n",
      "DEBUG:shap:self.fx = 0.8528373015873018\n",
      "DEBUG:shap:self.link(self.fx) = 0.8528373015873018\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.17800832,  0.00922416, -0.01148486,  0.09490497,  0.00369753,\n",
      "        0.01794904,  0.03542761,  0.08446255, -0.00705957,  0.00595449,\n",
      "        0.00541709,  0.00712059,  0.03497146,  0.0163414 ,  0.01001536])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.47493480009617495)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4849501559476049\n",
      "DEBUG:shap:self.fx = 0.1471626984126984\n",
      "DEBUG:shap:self.link(self.fx) = 0.1471626984126984\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.17800832, -0.00922416,  0.01148486, -0.09490497, -0.00369753,\n",
      "       -0.01794904, -0.03542761, -0.08446255,  0.00705957, -0.00595449,\n",
      "       -0.00541709, -0.00712059, -0.03497146, -0.0163414 , -0.01001536])\n",
      " 18%|█▊        | 13/74 [00:22<01:42,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2356587705519333)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2650776218301727\n",
      "DEBUG:shap:self.fx = 0.1028095238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.1028095238095238\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.09487027,  0.01075905, -0.01090683, -0.0452584 ,  0.01927031,\n",
      "       -0.01448726, -0.0442361 , -0.02061047, -0.01687102, -0.00375186,\n",
      "       -0.01089801, -0.03833129, -0.00039162,  0.03492501, -0.02941885])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2356587705519335)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.265077621830173\n",
      "DEBUG:shap:self.fx = 0.8971904761904763\n",
      "DEBUG:shap:self.link(self.fx) = 0.8971904761904763\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.09487027, -0.01075905,  0.01090683,  0.0452584 , -0.01927031,\n",
      "        0.01448726,  0.0442361 ,  0.02061047,  0.01687102,  0.00375186,\n",
      "        0.01089801,  0.03833129,  0.00039162, -0.03492501,  0.02941885])\n",
      " 19%|█▉        | 14/74 [00:23<01:40,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.031135069732888057)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.02250619325874409\n",
      "DEBUG:shap:self.fx = 0.3453809523809524\n",
      "DEBUG:shap:self.link(self.fx) = 0.3453809523809524\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.11228008,  0.02012495,  0.01108167, -0.04750117, -0.00633716,\n",
      "       -0.00549914,  0.0424084 ,  0.07527934,  0.01129899,  0.01688376,\n",
      "        0.00230317, -0.00369623, -0.00374533, -0.03145622,  0.00862888])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03113506973288839)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.022506193258744478\n",
      "DEBUG:shap:self.fx = 0.6546190476190478\n",
      "DEBUG:shap:self.link(self.fx) = 0.6546190476190478\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.11228008, -0.02012495, -0.01108167,  0.04750117,  0.00633716,\n",
      "        0.00549914, -0.0424084 , -0.07527934, -0.01129899, -0.01688376,\n",
      "       -0.00230317,  0.00369623,  0.00374533,  0.03145622, -0.00862888])\n",
      " 20%|██        | 15/74 [00:25<01:40,  1.70s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.003056763867631585)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.008553812306363207\n",
      "DEBUG:shap:self.fx = 0.3593333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.3593333333333333\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.09038708, -0.03068715,  0.00323558, -0.02192769,  0.00778547,\n",
      "        0.03457992,  0.02386431,  0.11060297, -0.02206778,  0.01274573,\n",
      "       -0.00815441, -0.0005019 ,  0.00109731, -0.02324205, -0.00549705])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0030567638676316233)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.008553812306363318\n",
      "DEBUG:shap:self.fx = 0.6406666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.6406666666666666\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.09038708,  0.03068715, -0.00323558,  0.02192769, -0.00778547,\n",
      "       -0.03457992, -0.02386431, -0.11060297,  0.02206778, -0.01274573,\n",
      "        0.00815441,  0.0005019 , -0.00109731,  0.02324205,  0.00549705])\n",
      " 22%|██▏       | 16/74 [00:27<01:40,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.27051595353132685)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2635572988047481\n",
      "DEBUG:shap:self.fx = 0.6314444444444446\n",
      "DEBUG:shap:self.link(self.fx) = 0.6314444444444446\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.19019727,  0.01493422, -0.00567087,  0.08161531,  0.00366523,\n",
      "        0.0164943 ,  0.0106667 , -0.06036419, -0.0054599 , -0.0042712 ,\n",
      "       -0.01424656, -0.015286  ,  0.00703068,  0.05121096, -0.00695865])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.27051595353132646)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.26355729880474765\n",
      "DEBUG:shap:self.fx = 0.36855555555555564\n",
      "DEBUG:shap:self.link(self.fx) = 0.36855555555555564\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.19019727, -0.01493422,  0.00567087, -0.08161531, -0.00366523,\n",
      "       -0.0164943 , -0.0106667 ,  0.06036419,  0.0054599 ,  0.0042712 ,\n",
      "        0.01424656,  0.015286  , -0.00703068, -0.05121096,  0.00695865])\n",
      " 23%|██▎       | 17/74 [00:29<01:38,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.07463614427768589)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08333952659207744\n",
      "DEBUG:shap:self.fx = 0.28454761904761905\n",
      "DEBUG:shap:self.link(self.fx) = 0.28454761904761905\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.06966907,  0.00960204,  0.00604295, -0.03991837,  0.00980371,\n",
      "        0.041316  , -0.04052133,  0.04718002,  0.00584538, -0.01550225,\n",
      "        0.02064583,  0.00416519,  0.00437763, -0.05800388, -0.00870338])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0746361442776862)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08333952659207777\n",
      "DEBUG:shap:self.fx = 0.7154523809523811\n",
      "DEBUG:shap:self.link(self.fx) = 0.7154523809523811\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.06966907, -0.00960204, -0.00604295,  0.03991837, -0.00980371,\n",
      "       -0.041316  ,  0.04052133, -0.04718002, -0.00584538,  0.01550225,\n",
      "       -0.02064583, -0.00416519, -0.00437763,  0.05800388,  0.00870338])\n",
      " 24%|██▍       | 18/74 [00:30<01:36,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1390949252482795)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09795262183017267\n",
      "DEBUG:shap:self.fx = 0.2699345238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.2699345238095238\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.12556093, -0.00392268, -0.01270673, -0.06089006,  0.00765141,\n",
      "       -0.00726758,  0.01454995,  0.02289777,  0.00722409,  0.00522903,\n",
      "       -0.00972782,  0.00525996, -0.00787558,  0.02604424,  0.0411423 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1390949252482799)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09795262183017306\n",
      "DEBUG:shap:self.fx = 0.7300654761904763\n",
      "DEBUG:shap:self.link(self.fx) = 0.7300654761904763\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.12556093,  0.00392268,  0.01270673,  0.06089006, -0.00765141,\n",
      "        0.00726758, -0.01454995, -0.02289777, -0.00722409, -0.00522903,\n",
      "        0.00972782, -0.00525996,  0.00787558, -0.02604424, -0.0411423 ])\n",
      " 26%|██▌       | 19/74 [00:32<01:34,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.04066766535317735)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.03169801919546844\n",
      "DEBUG:shap:self.fx = 0.39958516483516493\n",
      "DEBUG:shap:self.link(self.fx) = 0.39958516483516493\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.05903536, -0.01978   ,  0.01415616,  0.07480337, -0.00175973,\n",
      "        0.02899391,  0.0088535 , -0.02623076,  0.00830651,  0.01297439,\n",
      "        0.00641789, -0.01661522,  0.00247898,  0.00710401, -0.00896965])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.04066766535317718)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.03169801919546822\n",
      "DEBUG:shap:self.fx = 0.6004148351648351\n",
      "DEBUG:shap:self.link(self.fx) = 0.6004148351648351\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.05903536,  0.01978   , -0.01415616, -0.07480337,  0.00175973,\n",
      "       -0.02899391, -0.0088535 ,  0.02623076, -0.00830651, -0.01297439,\n",
      "       -0.00641789,  0.01661522, -0.00247898, -0.00710401,  0.00896965])\n",
      " 27%|██▋       | 20/74 [00:34<01:32,  1.71s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.13999178721513225)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.14346254246509332\n",
      "DEBUG:shap:self.fx = 0.22442460317460317\n",
      "DEBUG:shap:self.link(self.fx) = 0.22442460317460317\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10111532, -0.00030639,  0.00930932, -0.07780466,  0.00594032,\n",
      "        0.0389046 , -0.05971766,  0.01684923,  0.00221314, -0.00663749,\n",
      "        0.01105845, -0.00730699,  0.03066417, -0.00204252, -0.00347076])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1399917872151322)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.14346254246509327\n",
      "DEBUG:shap:self.fx = 0.7755753968253966\n",
      "DEBUG:shap:self.link(self.fx) = 0.7755753968253966\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10111532,  0.00030639, -0.00930932,  0.07780466, -0.00594032,\n",
      "       -0.0389046 ,  0.05971766, -0.01684923, -0.00221314,  0.00663749,\n",
      "       -0.01105845,  0.00730699, -0.03066417,  0.00204252,  0.00347076])\n",
      " 28%|██▊       | 21/74 [00:35<01:30,  1.71s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2916092302064902)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2568692884968394\n",
      "DEBUG:shap:self.fx = 0.11101785714285713\n",
      "DEBUG:shap:self.link(self.fx) = 0.11101785714285713\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.08889506,  0.00205289,  0.00664781, -0.04949254,  0.00196626,\n",
      "       -0.01307361, -0.03152562, -0.01677548, -0.00964314, -0.00147635,\n",
      "        0.00231066, -0.01317561, -0.00957937, -0.07095007,  0.03473994])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2916092302064902)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.25686928849683943\n",
      "DEBUG:shap:self.fx = 0.8889821428571427\n",
      "DEBUG:shap:self.link(self.fx) = 0.8889821428571427\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.08889506, -0.00205289, -0.00664781,  0.04949254, -0.00196626,\n",
      "        0.01307361,  0.03152562,  0.01677548,  0.00964314,  0.00147635,\n",
      "       -0.00231066,  0.01317561,  0.00957937,  0.07095007, -0.03473994])\n",
      " 30%|██▉       | 22/74 [00:37<01:28,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.25493939774980057)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2586783305507798\n",
      "DEBUG:shap:self.fx = 0.6265654761904763\n",
      "DEBUG:shap:self.link(self.fx) = 0.6265654761904763\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.15358559,  0.02130475,  0.00222841, -0.01530963,  0.00662838,\n",
      "       -0.00346042,  0.03307221,  0.13932893,  0.0136812 , -0.0073316 ,\n",
      "        0.0001774 ,  0.01327524,  0.00228357, -0.10452462,  0.00373893])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2549393977498003)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2586783305507796\n",
      "DEBUG:shap:self.fx = 0.3734345238095237\n",
      "DEBUG:shap:self.link(self.fx) = 0.3734345238095237\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.15358559, -0.02130475, -0.00222841,  0.01530963, -0.00662838,\n",
      "        0.00346042, -0.03307221, -0.13932893, -0.0136812 ,  0.0073316 ,\n",
      "       -0.0001774 , -0.01327524, -0.00228357,  0.10452462, -0.00373893])\n",
      " 31%|███       | 23/74 [00:39<01:27,  1.71s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.07550846813400508)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09529142578887506\n",
      "DEBUG:shap:self.fx = 0.46317857142857155\n",
      "DEBUG:shap:self.link(self.fx) = 0.46317857142857155\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.1352233 , -0.0394241 , -0.02501368,  0.01035671, -0.00132423,\n",
      "       -0.00054084,  0.02553357,  0.03437469,  0.00434298, -0.00823544,\n",
      "        0.00277523,  0.03056141,  0.01961544, -0.11273656,  0.01978296])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.07550846813400475)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09529142578887484\n",
      "DEBUG:shap:self.fx = 0.5368214285714284\n",
      "DEBUG:shap:self.link(self.fx) = 0.5368214285714284\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.1352233 ,  0.0394241 ,  0.02501368, -0.01035671,  0.00132423,\n",
      "        0.00054084, -0.02553357, -0.03437469, -0.00434298,  0.00823544,\n",
      "       -0.00277523, -0.03056141, -0.01961544,  0.11273656, -0.01978296])\n",
      " 32%|███▏      | 24/74 [00:41<01:26,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2823130207389406)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3104407170682679\n",
      "DEBUG:shap:self.fx = 0.05744642857142858\n",
      "DEBUG:shap:self.link(self.fx) = 0.05744642857142858\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.08100053,  0.00883477, -0.0094718 , -0.07268196, -0.00035007,\n",
      "       -0.01423004, -0.04119383, -0.03955216,  0.00330789, -0.00655112,\n",
      "        0.01414885, -0.03562582, -0.00647476, -0.00147244, -0.0281277 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2823130207389409)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.31044071706826826\n",
      "DEBUG:shap:self.fx = 0.9425535714285715\n",
      "DEBUG:shap:self.link(self.fx) = 0.9425535714285715\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.08100053, -0.00883477,  0.0094718 ,  0.07268196,  0.00035007,\n",
      "        0.01423004,  0.04119383,  0.03955216, -0.00330789,  0.00655112,\n",
      "       -0.01414885,  0.03562582,  0.00647476,  0.00147244,  0.0281277 ])\n",
      " 34%|███▍      | 25/74 [00:42<01:24,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.24536802460269777)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.25697643135398224\n",
      "DEBUG:shap:self.fx = 0.11091071428571427\n",
      "DEBUG:shap:self.link(self.fx) = 0.11091071428571427\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.11186666,  0.00918771, -0.00106158, -0.07063751, -0.01068065,\n",
      "       -0.01987861, -0.03248062,  0.02550417,  0.00945555, -0.00167087,\n",
      "        0.01347462, -0.00124614, -0.00567991, -0.04778752, -0.01160841])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24536802460269802)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2569764313539825\n",
      "DEBUG:shap:self.fx = 0.8890892857142858\n",
      "DEBUG:shap:self.link(self.fx) = 0.8890892857142858\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.11186666, -0.00918771,  0.00106158,  0.07063751,  0.01068065,\n",
      "        0.01987861,  0.03248062, -0.02550417, -0.00945555,  0.00167087,\n",
      "       -0.01347462,  0.00124614,  0.00567991,  0.04778752,  0.01160841])\n",
      " 35%|███▌      | 26/74 [00:44<01:22,  1.71s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.02283981510944675)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.0027800027825536366\n",
      "DEBUG:shap:self.fx = 0.36510714285714285\n",
      "DEBUG:shap:self.link(self.fx) = 0.36510714285714285\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.04234487,  0.0246071 , -0.02357009,  0.0792964 ,  0.0050859 ,\n",
      "       -0.01307056,  0.01289609, -0.03409187,  0.01165792, -0.00156645,\n",
      "        0.01338776,  0.02795242, -0.00579122, -0.07728836,  0.02005981])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.02283981510944693)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.0027800027825538587\n",
      "DEBUG:shap:self.fx = 0.6348928571428571\n",
      "DEBUG:shap:self.link(self.fx) = 0.6348928571428571\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.04234487, -0.0246071 ,  0.02357009, -0.0792964 , -0.0050859 ,\n",
      "        0.01307056, -0.01289609,  0.03409187, -0.01165792,  0.00156645,\n",
      "       -0.01338776, -0.02795242,  0.00579122,  0.07728836, -0.02005981])\n",
      " 36%|███▋      | 27/74 [00:46<01:21,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2194637806151783)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2111371456396965\n",
      "DEBUG:shap:self.fx = 0.15675\n",
      "DEBUG:shap:self.link(self.fx) = 0.15675\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.09096114, -0.01372607, -0.00216159, -0.03041457,  0.00563434,\n",
      "        0.01341642, -0.01852401, -0.0262307 , -0.01803071,  0.0080624 ,\n",
      "        0.00349935, -0.00634228, -0.00324325, -0.04044197,  0.00832663])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.21946378061517857)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21113714563969688\n",
      "DEBUG:shap:self.fx = 0.8432500000000002\n",
      "DEBUG:shap:self.link(self.fx) = 0.8432500000000002\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.09096114,  0.01372607,  0.00216159,  0.03041457, -0.00563434,\n",
      "       -0.01341642,  0.01852401,  0.0262307 ,  0.01803071, -0.0080624 ,\n",
      "       -0.00349935,  0.00634228,  0.00324325,  0.04044197, -0.00832663])\n",
      " 38%|███▊      | 28/74 [00:48<01:19,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19468195893036644)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.18765650515395416\n",
      "DEBUG:shap:self.fx = 0.5555436507936506\n",
      "DEBUG:shap:self.link(self.fx) = 0.5555436507936506\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.18507664,  0.00767014,  0.00952289, -0.03235243,  0.00563619,\n",
      "       -0.02733213, -0.04277508,  0.10459261, -0.02837606, -0.0107612 ,\n",
      "       -0.00297907,  0.0044121 ,  0.00598585,  0.0163615 , -0.00702545])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19468195893036647)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.18765650515395405\n",
      "DEBUG:shap:self.fx = 0.44445634920634924\n",
      "DEBUG:shap:self.link(self.fx) = 0.44445634920634924\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.18507664, -0.00767014, -0.00952289,  0.03235243, -0.00563619,\n",
      "        0.02733213,  0.04277508, -0.10459261,  0.02837606,  0.0107612 ,\n",
      "        0.00297907, -0.0044121 , -0.00598585, -0.0163615 ,  0.00702545])\n",
      " 39%|███▉      | 29/74 [00:49<01:17,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.49678252818206925)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5038985686460178\n",
      "DEBUG:shap:self.fx = 0.8717857142857143\n",
      "DEBUG:shap:self.link(self.fx) = 0.8717857142857143\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.19476725,  0.01646234, -0.00326438,  0.09244422,  0.00816033,\n",
      "       -0.01372907,  0.02901032,  0.07247118, -0.00359252,  0.00150022,\n",
      "       -0.0148578 ,  0.02579145,  0.02392261,  0.06769638,  0.00711604])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.496782528182069)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5038985686460176\n",
      "DEBUG:shap:self.fx = 0.1282142857142857\n",
      "DEBUG:shap:self.link(self.fx) = 0.1282142857142857\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.19476725, -0.01646234,  0.00326438, -0.09244422, -0.00816033,\n",
      "        0.01372907, -0.02901032, -0.07247118,  0.00359252, -0.00150022,\n",
      "        0.0148578 , -0.02579145, -0.02392261, -0.06769638, -0.00711604])\n",
      " 41%|████      | 30/74 [00:51<01:16,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.31077006460875645)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2852795210269704\n",
      "DEBUG:shap:self.fx = 0.6531666666666669\n",
      "DEBUG:shap:self.link(self.fx) = 0.6531666666666669\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.17552864,  0.00921912,  0.01196185,  0.10259237,  0.00782617,\n",
      "       -0.00503919,  0.02381212, -0.07629124, -0.00286506, -0.00611457,\n",
      "        0.01132298, -0.0072192 ,  0.02928877,  0.03674732, -0.02549054])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3107700646087559)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2852795210269699\n",
      "DEBUG:shap:self.fx = 0.3468333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.3468333333333334\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.17552864, -0.00921912, -0.01196185, -0.10259237, -0.00782617,\n",
      "        0.00503919, -0.02381212,  0.07629124,  0.00286506,  0.00611457,\n",
      "       -0.01132298,  0.0072192 , -0.02928877, -0.03674732,  0.02549054])\n",
      " 42%|████▏     | 31/74 [00:53<01:14,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3623219030282451)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.36665452102697027\n",
      "DEBUG:shap:self.fx = 0.7345416666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.7345416666666668\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.15239732,  0.02140511,  0.00682296,  0.08054608, -0.02015054,\n",
      "        0.00633968,  0.03123182,  0.06465597, -0.0105529 , -0.0006887 ,\n",
      "        0.00422039,  0.00293556,  0.00668376,  0.01647538,  0.00433262])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3623219030282447)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.36665452102697\n",
      "DEBUG:shap:self.fx = 0.2654583333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.2654583333333333\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.15239732, -0.02140511, -0.00682296, -0.08054608,  0.02015054,\n",
      "       -0.00633968, -0.03123182, -0.06465597,  0.0105529 ,  0.0006887 ,\n",
      "       -0.00422039, -0.00293556, -0.00668376, -0.01647538, -0.00433262])\n",
      " 43%|████▎     | 32/74 [00:55<01:13,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17570931261284378)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.19363666388411305\n",
      "DEBUG:shap:self.fx = 0.5615238095238095\n",
      "DEBUG:shap:self.link(self.fx) = 0.5615238095238095\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.18074749,  0.01620669,  0.01582575, -0.10895439,  0.        ,\n",
      "       -0.01398086,  0.03370138, -0.03680846,  0.00729301,  0.0044426 ,\n",
      "        0.0063399 ,  0.00569354, -0.00047413,  0.06567679,  0.01792735])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1757093126128435)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.19363666388411271\n",
      "DEBUG:shap:self.fx = 0.4384761904761906\n",
      "DEBUG:shap:self.link(self.fx) = 0.4384761904761906\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.18074749, -0.01620669, -0.01582575,  0.10895439,  0.        ,\n",
      "        0.01398086, -0.03370138,  0.03680846, -0.00729301, -0.0044426 ,\n",
      "       -0.0063399 , -0.00569354,  0.00047413, -0.06567679, -0.01792735])\n",
      " 45%|████▍     | 33/74 [00:56<01:11,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.101055697328056)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.10172047897302977\n",
      "DEBUG:shap:self.fx = 0.2661666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.2661666666666667\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.08455068,  0.04590644,  0.01955333, -0.07034258, -0.01260605,\n",
      "       -0.03416565,  0.02710616,  0.05230028, -0.01058849,  0.00123159,\n",
      "        0.0122106 , -0.00828324,  0.01517861, -0.05400602, -0.00066478])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.10105569732805636)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.10172047897303016\n",
      "DEBUG:shap:self.fx = 0.7338333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.7338333333333334\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.08455068, -0.04590644, -0.01955333,  0.07034258,  0.01260605,\n",
      "        0.03416565, -0.02710616, -0.05230028,  0.01058849, -0.00123159,\n",
      "       -0.0122106 ,  0.00828324, -0.01517861,  0.05400602,  0.00066478])\n",
      " 46%|████▌     | 34/74 [00:58<01:09,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23458315032885707)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.25931571706826795\n",
      "DEBUG:shap:self.fx = 0.10857142857142855\n",
      "DEBUG:shap:self.link(self.fx) = 0.10857142857142855\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.07252398,  0.01815588, -0.01303672, -0.06504785,  0.        ,\n",
      "       -0.01765274, -0.05381097, -0.019842  ,  0.00558632,  0.00504911,\n",
      "        0.02020849, -0.03514631, -0.00702901,  0.00050665, -0.02473257])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23458315032885743)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2593157170682683\n",
      "DEBUG:shap:self.fx = 0.8914285714285716\n",
      "DEBUG:shap:self.link(self.fx) = 0.8914285714285716\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.07252398, -0.01815588,  0.01303672,  0.06504785,  0.        ,\n",
      "        0.01765274,  0.05381097,  0.019842  , -0.00558632, -0.00504911,\n",
      "       -0.02020849,  0.03514631,  0.00702901, -0.00050665,  0.02473257])\n",
      " 47%|████▋     | 35/74 [01:00<01:07,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.486832355520392)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4976366638841131\n",
      "DEBUG:shap:self.fx = 0.8655238095238096\n",
      "DEBUG:shap:self.link(self.fx) = 0.8655238095238096\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.20228749,  0.00984006,  0.02487963,  0.08477939,  0.00696568,\n",
      "       -0.00800813,  0.03628746,  0.10133578, -0.02627092,  0.00067188,\n",
      "        0.00978518,  0.00669982, -0.01047482,  0.04805384,  0.01080431])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4868323555203916)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4976366638841128\n",
      "DEBUG:shap:self.fx = 0.13447619047619047\n",
      "DEBUG:shap:self.link(self.fx) = 0.13447619047619047\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.20228749, -0.00984006, -0.02487963, -0.08477939, -0.00696568,\n",
      "        0.00800813, -0.03628746, -0.10133578,  0.02627092, -0.00067188,\n",
      "       -0.00978518, -0.00669982,  0.01047482, -0.04805384, -0.01080431])\n",
      " 49%|████▊     | 36/74 [01:01<01:05,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4871331951451177)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4932140448364941\n",
      "DEBUG:shap:self.fx = 0.8611011904761906\n",
      "DEBUG:shap:self.link(self.fx) = 0.8611011904761906\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.18758151,  0.01074127, -0.03453785,  0.09362335,  0.00724784,\n",
      "       -0.00489385,  0.02394316,  0.07268981,  0.0148509 ,  0.00159869,\n",
      "        0.00548586,  0.03254501,  0.01287295,  0.06338455,  0.00608085])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4871331951451173)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4932140448364938\n",
      "DEBUG:shap:self.fx = 0.13889880952380954\n",
      "DEBUG:shap:self.link(self.fx) = 0.13889880952380954\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.18758151, -0.01074127,  0.03453785, -0.09362335, -0.00724784,\n",
      "        0.00489385, -0.02394316, -0.07268981, -0.0148509 , -0.00159869,\n",
      "       -0.00548586, -0.03254501, -0.01287295, -0.06338455, -0.00608085])\n",
      " 50%|█████     | 37/74 [01:03<01:03,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22665558772663358)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.24614905040160126\n",
      "DEBUG:shap:self.fx = 0.12173809523809523\n",
      "DEBUG:shap:self.link(self.fx) = 0.12173809523809523\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.1059248 ,  0.01543001, -0.00582616, -0.06315488,  0.0138106 ,\n",
      "       -0.00427335, -0.06414989,  0.00816219,  0.00450832,  0.00698644,\n",
      "       -0.01218633, -0.00625844,  0.01026372, -0.02404301, -0.01949346])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22665558772663347)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24614905040160118\n",
      "DEBUG:shap:self.fx = 0.8782619047619045\n",
      "DEBUG:shap:self.link(self.fx) = 0.8782619047619045\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.1059248 , -0.01543001,  0.00582616,  0.06315488, -0.0138106 ,\n",
      "        0.00427335,  0.06414989, -0.00816219, -0.00450832, -0.00698644,\n",
      "        0.01218633,  0.00625844, -0.01026372,  0.02404301,  0.01949346])\n",
      " 51%|█████▏    | 38/74 [01:05<01:02,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000007)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4559767881995639)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4542378543603036\n",
      "DEBUG:shap:self.fx = 0.8221250000000001\n",
      "DEBUG:shap:self.link(self.fx) = 0.8221250000000001\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.19221403,  0.0160732 ,  0.01622743,  0.09578567,  0.00206272,\n",
      "       -0.01844641,  0.03893579,  0.03880377, -0.00973578,  0.00182984,\n",
      "        0.00399223,  0.00359447, -0.00268393,  0.07732376, -0.00173893])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000007)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4559767881995636)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4542378543603033\n",
      "DEBUG:shap:self.fx = 0.177875\n",
      "DEBUG:shap:self.link(self.fx) = 0.177875\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.19221403, -0.0160732 , -0.01622743, -0.09578567, -0.00206272,\n",
      "        0.01844641, -0.03893579, -0.03880377,  0.00973578, -0.00182984,\n",
      "       -0.00399223, -0.00359447,  0.00268393, -0.07732376,  0.00173893])\n",
      " 53%|█████▎    | 39/74 [01:07<01:01,  1.76s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2777062999166183)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2954104734079226\n",
      "DEBUG:shap:self.fx = 0.6632976190476191\n",
      "DEBUG:shap:self.link(self.fx) = 0.6632976190476191\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.153073  , -0.04131393, -0.00868358,  0.0849879 , -0.02516474,\n",
      "       -0.00105412,  0.02373363,  0.06288849,  0.02138333,  0.00343962,\n",
      "        0.00789022,  0.01115621,  0.00168095, -0.01631069,  0.01770417])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.27770629991661816)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.29541047340792226\n",
      "DEBUG:shap:self.fx = 0.33670238095238103\n",
      "DEBUG:shap:self.link(self.fx) = 0.33670238095238103\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.153073  ,  0.04131393,  0.00868358, -0.0849879 ,  0.02516474,\n",
      "        0.00105412, -0.02373363, -0.06288849, -0.02138333, -0.00343962,\n",
      "       -0.00789022, -0.01115621, -0.00168095,  0.01631069, -0.01770417])\n",
      " 54%|█████▍    | 40/74 [01:08<00:59,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4648782187559663)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4674997591222083\n",
      "DEBUG:shap:self.fx = 0.8353869047619048\n",
      "DEBUG:shap:self.link(self.fx) = 0.8353869047619048\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.1734571 ,  0.01243357, -0.03352806,  0.09012951,  0.00493712,\n",
      "        0.01615321,  0.02409087,  0.08187064, -0.01131948, -0.00243468,\n",
      "        0.00178314,  0.03465606,  0.02135881,  0.05129039,  0.00262154])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.46487821875596613)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4674997591222081\n",
      "DEBUG:shap:self.fx = 0.16461309523809523\n",
      "DEBUG:shap:self.link(self.fx) = 0.16461309523809523\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.1734571 , -0.01243357,  0.03352806, -0.09012951, -0.00493712,\n",
      "       -0.01615321, -0.02409087, -0.08187064,  0.01131948,  0.00243468,\n",
      "       -0.00178314, -0.03465606, -0.02135881, -0.05129039, -0.00262154])\n",
      " 55%|█████▌    | 41/74 [01:10<00:57,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.39377346316715284)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4284819019793512\n",
      "DEBUG:shap:self.fx = 0.7963690476190477\n",
      "DEBUG:shap:self.link(self.fx) = 0.7963690476190477\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.20718121,  0.01079525,  0.00407351,  0.08830408,  0.00788465,\n",
      "        0.01376408,  0.02184573, -0.04430424,  0.01308879,  0.00232572,\n",
      "       -0.01925429,  0.0055536 ,  0.0060766 ,  0.07643878,  0.03470844])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.39377346316715256)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4284819019793509\n",
      "DEBUG:shap:self.fx = 0.20363095238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.20363095238095238\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.20718121, -0.01079525, -0.00407351, -0.08830408, -0.00788465,\n",
      "       -0.01376408, -0.02184573,  0.04430424, -0.01308879, -0.00232572,\n",
      "        0.01925429, -0.0055536 , -0.0060766 , -0.07643878, -0.03470844])\n",
      " 57%|█████▋    | 42/74 [01:12<00:55,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5397894846923253)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5562676162650655\n",
      "DEBUG:shap:self.fx = 0.924154761904762\n",
      "DEBUG:shap:self.link(self.fx) = 0.924154761904762\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.20508536,  0.01776534,  0.01284212,  0.0987821 , -0.00240847,\n",
      "        0.0227173 ,  0.0350306 ,  0.04388297,  0.0140865 ,  0.00321349,\n",
      "       -0.00823922,  0.00880351,  0.01562882,  0.07259905,  0.01647813])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5397894846923253)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5562676162650652\n",
      "DEBUG:shap:self.fx = 0.0758452380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.0758452380952381\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.20508536, -0.01776534, -0.01284212, -0.0987821 ,  0.00240847,\n",
      "       -0.0227173 , -0.0350306 , -0.04388297, -0.0140865 , -0.00321349,\n",
      "        0.00823922, -0.00880351, -0.01562882, -0.07259905, -0.01647813])\n",
      " 58%|█████▊    | 43/74 [01:14<00:53,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.28730207096586036)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2808811932587441\n",
      "DEBUG:shap:self.fx = 0.08700595238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.08700595238095238\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.12379055, -0.00546666,  0.00861356, -0.04655858,  0.00414453,\n",
      "        0.00453688,  0.01853252, -0.03779694,  0.0043202 , -0.01540061,\n",
      "       -0.01213125, -0.00991954, -0.01184642, -0.06453922,  0.00642088])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2873020709658605)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2808811932587443\n",
      "DEBUG:shap:self.fx = 0.9129940476190476\n",
      "DEBUG:shap:self.link(self.fx) = 0.9129940476190476\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.12379055,  0.00546666, -0.00861356,  0.04655858, -0.00414453,\n",
      "       -0.00453688, -0.01853252,  0.03779694, -0.0043202 ,  0.01540061,\n",
      "        0.01213125,  0.00991954,  0.01184642,  0.06453922, -0.00642088])\n",
      " 59%|█████▉    | 44/74 [01:15<00:52,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2264023870533315)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1875776218301727\n",
      "DEBUG:shap:self.fx = 0.18030952380952378\n",
      "DEBUG:shap:self.link(self.fx) = 0.18030952380952378\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.12616552,  0.00821041, -0.00915217, -0.04919011,  0.00069031,\n",
      "       -0.00852121,  0.0056    , -0.0227107 , -0.01836361,  0.00266963,\n",
      "       -0.00197132, -0.00699344, -0.00765297,  0.00714831,  0.03882477])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22640238705333166)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1875776218301729\n",
      "DEBUG:shap:self.fx = 0.8196904761904762\n",
      "DEBUG:shap:self.link(self.fx) = 0.8196904761904762\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.12616552, -0.00821041,  0.00915217,  0.04919011, -0.00069031,\n",
      "        0.00852121, -0.0056    ,  0.0227107 ,  0.01836361, -0.00266963,\n",
      "        0.00197132,  0.00699344,  0.00765297, -0.00714831, -0.03882477])\n",
      " 61%|██████    | 45/74 [01:17<00:50,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3148333575530665)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3178038123063631\n",
      "DEBUG:shap:self.fx = 0.05008333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.05008333333333334\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10222801,  0.00207688,  0.00163129, -0.06890556, -0.00871935,\n",
      "       -0.02045019, -0.00821106, -0.03500566,  0.00211606, -0.00965749,\n",
      "       -0.00632252,  0.00260396, -0.00797242, -0.0557893 , -0.00297045])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.31483335755306674)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.31780381230636345\n",
      "DEBUG:shap:self.fx = 0.9499166666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.9499166666666667\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10222801, -0.00207688, -0.00163129,  0.06890556,  0.00871935,\n",
      "        0.02045019,  0.00821106,  0.03500566, -0.00211606,  0.00965749,\n",
      "        0.00632252, -0.00260396,  0.00797242,  0.0557893 ,  0.00297045])\n",
      " 62%|██████▏   | 46/74 [01:19<00:48,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3672182247085901)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.38798587023331943\n",
      "DEBUG:shap:self.fx = 0.7558730158730159\n",
      "DEBUG:shap:self.link(self.fx) = 0.7558730158730159\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.19070364,  0.01128982, -0.01422734, -0.03075834,  0.00260238,\n",
      "        0.03133879,  0.021534  ,  0.02647321,  0.01096191,  0.01007757,\n",
      "        0.00921408,  0.03828224, -0.00908969,  0.06881597,  0.02076765])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3672182247085899)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3879858702333192\n",
      "DEBUG:shap:self.fx = 0.24412698412698408\n",
      "DEBUG:shap:self.link(self.fx) = 0.24412698412698408\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.19070364, -0.01128982,  0.01422734,  0.03075834, -0.00260238,\n",
      "       -0.03133879, -0.021534  , -0.02647321, -0.01096191, -0.01007757,\n",
      "       -0.00921408, -0.03828224,  0.00908969, -0.06881597, -0.02076765])\n",
      " 64%|██████▎   | 47/74 [01:21<00:46,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3468864587811225)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.33167833055077967\n",
      "DEBUG:shap:self.fx = 0.6995654761904762\n",
      "DEBUG:shap:self.link(self.fx) = 0.6995654761904762\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.1662543 , -0.05167708, -0.03891129,  0.06868877,  0.        ,\n",
      "        0.00510924,  0.01937804,  0.07796577, -0.00729796,  0.0037393 ,\n",
      "        0.005812  ,  0.02728871,  0.00882688,  0.06170977, -0.01520813])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3468864587811225)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.33167833055077955\n",
      "DEBUG:shap:self.fx = 0.30043452380952373\n",
      "DEBUG:shap:self.link(self.fx) = 0.30043452380952373\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.1662543 ,  0.05167708,  0.03891129, -0.06868877,  0.        ,\n",
      "       -0.00510924, -0.01937804, -0.07796577,  0.00729796, -0.0037393 ,\n",
      "       -0.005812  , -0.02728871, -0.00882688, -0.06170977,  0.01520813])\n",
      " 65%|██████▍   | 48/74 [01:22<00:45,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2503975156888809)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.26470857421112504\n",
      "DEBUG:shap:self.fx = 0.10317857142857143\n",
      "DEBUG:shap:self.link(self.fx) = 0.10317857142857143\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.09771884,  0.00305572, -0.00528471, -0.07726119,  0.00202166,\n",
      "        0.01158422, -0.06923174,  0.04371853,  0.00571654, -0.01377076,\n",
      "       -0.00496338, -0.01865226,  0.02148595, -0.05109725, -0.01431106])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.25039751568888124)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.26470857421112537\n",
      "DEBUG:shap:self.fx = 0.8968214285714287\n",
      "DEBUG:shap:self.link(self.fx) = 0.8968214285714287\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.09771884, -0.00305572,  0.00528471,  0.07726119, -0.00202166,\n",
      "       -0.01158422,  0.06923174, -0.04371853, -0.00571654,  0.01377076,\n",
      "        0.00496338,  0.01865226, -0.02148595,  0.05109725,  0.01431106])\n",
      " 66%|██████▌   | 49/74 [01:24<00:42,  1.70s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.06204108086627051)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.05603595516350596\n",
      "DEBUG:shap:self.fx = 0.31185119047619053\n",
      "DEBUG:shap:self.link(self.fx) = 0.31185119047619053\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.15494834,  0.00636295,  0.00504705, -0.0473423 , -0.0024522 ,\n",
      "       -0.01966667, -0.00173201,  0.08439721,  0.01221197,  0.0051638 ,\n",
      "        0.02959074, -0.00560722,  0.00213309,  0.02480085,  0.00600513])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.06204108086627096)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.056035955163506346\n",
      "DEBUG:shap:self.fx = 0.6881488095238096\n",
      "DEBUG:shap:self.link(self.fx) = 0.6881488095238096\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.15494834, -0.00636295, -0.00504705,  0.0473423 ,  0.0024522 ,\n",
      "        0.01966667,  0.00173201, -0.08439721, -0.01221197, -0.0051638 ,\n",
      "       -0.02959074,  0.00560722, -0.00213309, -0.02480085, -0.00600513])\n",
      " 68%|██████▊   | 50/74 [01:26<00:41,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4846249022223824)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.48799777499522423\n",
      "DEBUG:shap:self.fx = 0.8558849206349207\n",
      "DEBUG:shap:self.link(self.fx) = 0.8558849206349207\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.19142085,  0.02190415, -0.00132074,  0.08444358,  0.01007405,\n",
      "        0.02231396,  0.03571175,  0.07563531, -0.0133989 ,  0.01307622,\n",
      "       -0.00977932,  0.01051884,  0.01322249,  0.03080267,  0.00337287])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.48462490222238186)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4879977749952239\n",
      "DEBUG:shap:self.fx = 0.14411507936507936\n",
      "DEBUG:shap:self.link(self.fx) = 0.14411507936507936\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.19142085, -0.02190415,  0.00132074, -0.08444358, -0.01007405,\n",
      "       -0.02231396, -0.03571175, -0.07563531,  0.0133989 , -0.01307622,\n",
      "        0.00977932, -0.01051884, -0.01322249, -0.03080267, -0.00337287])\n",
      " 69%|██████▉   | 51/74 [01:27<00:40,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.0517574913615158)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.05992285992541069\n",
      "DEBUG:shap:self.fx = 0.3079642857142858\n",
      "DEBUG:shap:self.link(self.fx) = 0.3079642857142858\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.11504081,  0.01719816,  0.00562074, -0.06594433,  0.00708371,\n",
      "        0.00212938,  0.0253449 ,  0.09597397, -0.02469178,  0.00508648,\n",
      "       -0.00627008, -0.00199407,  0.0021137 ,  0.00163254, -0.00816537])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.051757491361516014)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.05992285992541102\n",
      "DEBUG:shap:self.fx = 0.6920357142857143\n",
      "DEBUG:shap:self.link(self.fx) = 0.6920357142857143\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.11504081, -0.01719816, -0.00562074,  0.06594433, -0.00708371,\n",
      "       -0.00212938, -0.0253449 , -0.09597397,  0.02469178, -0.00508648,\n",
      "        0.00627008,  0.00199407, -0.0021137 , -0.00163254,  0.00816537])\n",
      " 70%|███████   | 52/74 [01:29<00:38,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.39397527304085617)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4196247591222082\n",
      "DEBUG:shap:self.fx = 0.7875119047619047\n",
      "DEBUG:shap:self.link(self.fx) = 0.7875119047619047\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.18006279,  0.01377639,  0.01985804, -0.03245105,  0.00826301,\n",
      "        0.01226132,  0.03282642,  0.07811503,  0.01287098,  0.0047902 ,\n",
      "        0.01298865, -0.0020051 , -0.01155078,  0.06416938,  0.02564949])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.39397527304085606)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4196247591222081\n",
      "DEBUG:shap:self.fx = 0.2124880952380952\n",
      "DEBUG:shap:self.link(self.fx) = 0.2124880952380952\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.18006279, -0.01377639, -0.01985804,  0.03245105, -0.00826301,\n",
      "       -0.01226132, -0.03282642, -0.07811503, -0.01287098, -0.0047902 ,\n",
      "       -0.01298865,  0.0020051 ,  0.01155078, -0.06416938, -0.02564949])\n",
      " 72%|███████▏  | 53/74 [01:31<00:36,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5000078253731433)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5060017432491927\n",
      "DEBUG:shap:self.fx = 0.8738888888888892\n",
      "DEBUG:shap:self.link(self.fx) = 0.8738888888888892\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.17891976,  0.01189752,  0.00126908,  0.11635778,  0.004384  ,\n",
      "        0.01382482,  0.02981495,  0.07193564,  0.0188272 , -0.00410587,\n",
      "       -0.00210938,  0.02926831,  0.00986577,  0.01985827,  0.00599392])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5000078253731429)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5060017432491921\n",
      "DEBUG:shap:self.fx = 0.12611111111111112\n",
      "DEBUG:shap:self.link(self.fx) = 0.12611111111111112\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.17891976, -0.01189752, -0.00126908, -0.11635778, -0.004384  ,\n",
      "       -0.01382482, -0.02981495, -0.07193564, -0.0188272 ,  0.00410587,\n",
      "        0.00210938, -0.02926831, -0.00986577, -0.01985827, -0.00599392])\n",
      " 73%|███████▎  | 54/74 [01:34<00:41,  2.09s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23020015139619832)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2174283305507797\n",
      "DEBUG:shap:self.fx = 0.5853154761904762\n",
      "DEBUG:shap:self.link(self.fx) = 0.5853154761904762\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.18885722,  0.0158783 , -0.0222231 ,  0.08464473,  0.01106592,\n",
      "       -0.01558564,  0.01927422, -0.04702872, -0.04389703, -0.00220144,\n",
      "       -0.01843238,  0.0342712 ,  0.00368367,  0.02189321, -0.01277182])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23020015139619798)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21742833055077948\n",
      "DEBUG:shap:self.fx = 0.4146845238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.4146845238095238\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.18885722, -0.0158783 ,  0.0222231 , -0.08464473, -0.01106592,\n",
      "        0.01558564, -0.01927422,  0.04702872,  0.04389703,  0.00220144,\n",
      "        0.01843238, -0.0342712 , -0.00368367, -0.02189321,  0.01277182])\n",
      " 74%|███████▍  | 55/74 [01:36<00:39,  2.09s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1957929195453293)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.19706174881429964\n",
      "DEBUG:shap:self.fx = 0.17082539682539685\n",
      "DEBUG:shap:self.link(self.fx) = 0.17082539682539685\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10221494,  0.0036547 ,  0.01220025,  0.00583252,  0.00109315,\n",
      "       -0.02135839, -0.05410726,  0.03021913,  0.00265414,  0.01816883,\n",
      "        0.00492149, -0.0270524 , -0.00160627, -0.06819788, -0.00126883])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19579291954532962)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.19706174881429994\n",
      "DEBUG:shap:self.fx = 0.8291746031746032\n",
      "DEBUG:shap:self.link(self.fx) = 0.8291746031746032\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10221494, -0.0036547 , -0.01220025, -0.00583252, -0.00109315,\n",
      "        0.02135839,  0.05410726, -0.03021913, -0.00265414, -0.01816883,\n",
      "       -0.00492149,  0.0270524 ,  0.00160627,  0.06819788,  0.00126883])\n",
      " 76%|███████▌  | 56/74 [01:38<00:36,  2.01s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.293283915218599)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3064228599254108\n",
      "DEBUG:shap:self.fx = 0.061464285714285714\n",
      "DEBUG:shap:self.link(self.fx) = 0.061464285714285714\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.13114421, -0.02092949, -0.00019554, -0.07637045, -0.00728334,\n",
      "       -0.02420569,  0.01475665, -0.0331115 ,  0.00622906, -0.00159515,\n",
      "       -0.00472795, -0.00710852, -0.00545118, -0.00214661, -0.01313894])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.29328391521859914)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.30642285992541096\n",
      "DEBUG:shap:self.fx = 0.9385357142857143\n",
      "DEBUG:shap:self.link(self.fx) = 0.9385357142857143\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.13114421,  0.02092949,  0.00019554,  0.07637045,  0.00728334,\n",
      "        0.02420569, -0.01475665,  0.0331115 , -0.00622906,  0.00159515,\n",
      "        0.00472795,  0.00710852,  0.00545118,  0.00214661,  0.01313894])\n",
      " 77%|███████▋  | 57/74 [01:40<00:33,  1.99s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2696949110322158)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2787621456396965\n",
      "DEBUG:shap:self.fx = 0.08912500000000001\n",
      "DEBUG:shap:self.link(self.fx) = 0.08912500000000001\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.0990622 ,  0.00723436,  0.        , -0.04552349, -0.00377688,\n",
      "       -0.01599639, -0.05493628,  0.0179881 ,  0.00475994, -0.00158027,\n",
      "       -0.00303996, -0.02336371,  0.0080065 , -0.06040462, -0.00906723])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.26969491103221593)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2787621456396966\n",
      "DEBUG:shap:self.fx = 0.9108749999999999\n",
      "DEBUG:shap:self.link(self.fx) = 0.9108749999999999\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.0990622 , -0.00723436,  0.        ,  0.04552349,  0.00377688,\n",
      "        0.01599639,  0.05493628, -0.0179881 , -0.00475994,  0.00158027,\n",
      "        0.00303996,  0.02336371, -0.0080065 ,  0.06040462,  0.00906723])\n",
      " 78%|███████▊  | 58/74 [01:42<00:31,  1.96s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.14294750063140838)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.14500619325874411\n",
      "DEBUG:shap:self.fx = 0.22288095238095237\n",
      "DEBUG:shap:self.link(self.fx) = 0.22288095238095237\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.07087873, -0.001474  ,  0.00155728, -0.05911285,  0.00641241,\n",
      "        0.02020053,  0.03093094,  0.03997741, -0.01269803, -0.01315927,\n",
      "       -0.00800228, -0.01119219,  0.01468067, -0.08018939, -0.00205869])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1429475006314087)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.14500619325874442\n",
      "DEBUG:shap:self.fx = 0.7771190476190477\n",
      "DEBUG:shap:self.link(self.fx) = 0.7771190476190477\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.07087873,  0.001474  , -0.00155728,  0.05911285, -0.00641241,\n",
      "       -0.02020053, -0.03093094, -0.03997741,  0.01269803,  0.01315927,\n",
      "        0.00800228,  0.01119219, -0.01468067,  0.08018939,  0.00205869])\n",
      " 80%|███████▉  | 59/74 [01:43<00:28,  1.92s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17474796937378664)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.06027952102697026\n",
      "DEBUG:shap:self.fx = 0.42816666666666675\n",
      "DEBUG:shap:self.link(self.fx) = 0.42816666666666675\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.12062897, -0.00831372, -0.00316732,  0.04888024, -0.00722293,\n",
      "        0.01361785,  0.01070513,  0.03940605, -0.04486501,  0.00330341,\n",
      "        0.01598061, -0.00387976, -0.01032556, -0.11446845,  0.        ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17474796937378653)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.060279521026970095\n",
      "DEBUG:shap:self.fx = 0.5718333333333332\n",
      "DEBUG:shap:self.link(self.fx) = 0.5718333333333332\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.12062897,  0.00831372,  0.00316732, -0.04888024,  0.00722293,\n",
      "       -0.01361785, -0.01070513, -0.03940605,  0.04486501, -0.00330341,\n",
      "       -0.01598061,  0.00387976,  0.01032556,  0.11446845,  0.        ])\n",
      " 81%|████████  | 60/74 [01:45<00:26,  1.87s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5705771939984109)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5947795210269702\n",
      "DEBUG:shap:self.fx = 0.9626666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.9626666666666667\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.1962219 ,  0.01116404,  0.00790555,  0.09692793,  0.00674464,\n",
      "       -0.01201198,  0.03619564,  0.09368614,  0.01012337,  0.00229658,\n",
      "        0.01240207,  0.00940975,  0.03029419,  0.06921736,  0.02420233])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5705771939984108)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.59477952102697\n",
      "DEBUG:shap:self.fx = 0.037333333333333336\n",
      "DEBUG:shap:self.link(self.fx) = 0.037333333333333336\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.1962219 , -0.01116404, -0.00790555, -0.09692793, -0.00674464,\n",
      "        0.01201198, -0.03619564, -0.09368614, -0.01012337, -0.00229658,\n",
      "       -0.01240207, -0.00940975, -0.03029419, -0.06921736, -0.02420233])\n",
      " 82%|████████▏ | 61/74 [01:47<00:24,  1.87s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.02885765951868168)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.03285738373493452\n",
      "DEBUG:shap:self.fx = 0.33502976190476197\n",
      "DEBUG:shap:self.link(self.fx) = 0.33502976190476197\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.12061624,  0.06756382,  0.00588227, -0.05642622, -0.01983103,\n",
      "        0.02042601, -0.03182611,  0.02307555,  0.01164234,  0.02083947,\n",
      "        0.002294  ,  0.00608744,  0.02270644,  0.0193246 , -0.00399972])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.028857659518682167)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.032857383734934964\n",
      "DEBUG:shap:self.fx = 0.6649702380952383\n",
      "DEBUG:shap:self.link(self.fx) = 0.6649702380952383\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.12061624, -0.06756382, -0.00588227,  0.05642622,  0.01983103,\n",
      "       -0.02042601,  0.03182611, -0.02307555, -0.01164234, -0.02083947,\n",
      "       -0.002294  , -0.00608744, -0.02270644, -0.0193246 ,  0.00399972])\n",
      " 84%|████████▍ | 62/74 [01:49<00:22,  1.87s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.25317244787957094)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.26011333611588694\n",
      "DEBUG:shap:self.fx = 0.10777380952380952\n",
      "DEBUG:shap:self.link(self.fx) = 0.10777380952380952\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10870154, -0.0010631 ,  0.00598117, -0.06939858,  0.00377824,\n",
      "        0.01083111, -0.02495222, -0.02387097, -0.00233593, -0.0123719 ,\n",
      "        0.00762541, -0.00415313, -0.0079312 , -0.02660982, -0.00694089])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.253172447879571)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.26011333611588705\n",
      "DEBUG:shap:self.fx = 0.8922261904761903\n",
      "DEBUG:shap:self.link(self.fx) = 0.8922261904761903\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10870154,  0.0010631 , -0.00598117,  0.06939858, -0.00377824,\n",
      "       -0.01083111,  0.02495222,  0.02387097,  0.00233593,  0.0123719 ,\n",
      "       -0.00762541,  0.00415313,  0.0079312 ,  0.02660982,  0.00694089])\n",
      " 85%|████████▌ | 63/74 [01:51<00:20,  1.87s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.21854141095923935)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.17992881230636315\n",
      "DEBUG:shap:self.fx = 0.18795833333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.18795833333333334\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.09697995,  0.00671481,  0.00409711, -0.07138303, -0.00356781,\n",
      "       -0.00740073, -0.05834379,  0.05884585,  0.0019849 , -0.00802403,\n",
      "       -0.01802739, -0.0245271 ,  0.02328493, -0.02521518,  0.0386126 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.21854141095923976)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.17992881230636348\n",
      "DEBUG:shap:self.fx = 0.8120416666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.8120416666666668\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.09697995, -0.00671481, -0.00409711,  0.07138303,  0.00356781,\n",
      "        0.00740073,  0.05834379, -0.05884585, -0.0019849 ,  0.00802403,\n",
      "        0.01802739,  0.0245271 , -0.02328493,  0.02521518, -0.0386126 ])\n",
      " 86%|████████▋ | 64/74 [01:53<00:18,  1.83s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1874620902292916)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.20812524087779172\n",
      "DEBUG:shap:self.fx = 0.15976190476190477\n",
      "DEBUG:shap:self.link(self.fx) = 0.15976190476190477\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.07746434,  0.00694397, -0.01600907, -0.06049668,  0.01446416,\n",
      "        0.03769256,  0.00118786,  0.01106221, -0.00770649, -0.0157009 ,\n",
      "       -0.0078782 , -0.0430041 ,  0.02631324, -0.0568663 , -0.02066315])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.18746209022929186)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.20812524087779205\n",
      "DEBUG:shap:self.fx = 0.8402380952380953\n",
      "DEBUG:shap:self.link(self.fx) = 0.8402380952380953\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.07746434, -0.00694397,  0.01600907,  0.06049668, -0.01446416,\n",
      "       -0.03769256, -0.00118786, -0.01106221,  0.00770649,  0.0157009 ,\n",
      "        0.0078782 ,  0.0430041 , -0.02631324,  0.0568663 ,  0.02066315])\n",
      " 88%|████████▊ | 65/74 [01:54<00:16,  1.83s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2690938133041107)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2704823837349346\n",
      "DEBUG:shap:self.fx = 0.09740476190476191\n",
      "DEBUG:shap:self.link(self.fx) = 0.09740476190476191\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.09524745,  0.03523457,  0.00572241, -0.05738641, -0.01305745,\n",
      "       -0.00988409, -0.00352766, -0.03078213, -0.00456065, -0.01195111,\n",
      "       -0.01315816, -0.00919335, -0.00888334, -0.052419  , -0.00138857])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.26909381330411064)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2704823837349346\n",
      "DEBUG:shap:self.fx = 0.9025952380952379\n",
      "DEBUG:shap:self.link(self.fx) = 0.9025952380952379\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.09524745, -0.03523457, -0.00572241,  0.05738641,  0.01305745,\n",
      "        0.00988409,  0.00352766,  0.03078213,  0.00456065,  0.01195111,\n",
      "        0.01315816,  0.00919335,  0.00888334,  0.052419  ,  0.00138857])\n",
      " 89%|████████▉ | 66/74 [01:56<00:14,  1.82s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2418840378554108)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2433871456396965\n",
      "DEBUG:shap:self.fx = 0.1245\n",
      "DEBUG:shap:self.link(self.fx) = 0.1245\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10913653, -0.01277941,  0.00656694, -0.04393236, -0.00389719,\n",
      "        0.01215014,  0.00683113, -0.02427728,  0.00553242, -0.0098554 ,\n",
      "       -0.00403536,  0.        , -0.00243217, -0.06261895, -0.00150311])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24188403785541093)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24338714563969666\n",
      "DEBUG:shap:self.fx = 0.8755\n",
      "DEBUG:shap:self.link(self.fx) = 0.8755\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10913653,  0.01277941, -0.00656694,  0.04393236,  0.00389719,\n",
      "       -0.01215014, -0.00683113,  0.02427728, -0.00553242,  0.0098554 ,\n",
      "        0.00403536,  0.        ,  0.00243217,  0.06261895,  0.00150311])\n",
      " 91%|█████████ | 67/74 [01:58<00:12,  1.80s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20055610582032785)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21337524087779178\n",
      "DEBUG:shap:self.fx = 0.1545119047619047\n",
      "DEBUG:shap:self.link(self.fx) = 0.1545119047619047\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.07088115,  0.0190218 , -0.00280194, -0.05300059,  0.        ,\n",
      "        0.00824801, -0.0515807 ,  0.01566639, -0.01158077, -0.00687297,\n",
      "        0.01308305, -0.02089596, -0.00765498, -0.0313063 , -0.01281914])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20055610582032796)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21337524087779192\n",
      "DEBUG:shap:self.fx = 0.8454880952380952\n",
      "DEBUG:shap:self.link(self.fx) = 0.8454880952380952\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.07088115, -0.0190218 ,  0.00280194,  0.05300059,  0.        ,\n",
      "       -0.00824801,  0.0515807 , -0.01566639,  0.01158077,  0.00687297,\n",
      "       -0.01308305,  0.02089596,  0.00765498,  0.0313063 ,  0.01281914])\n",
      " 92%|█████████▏| 68/74 [02:00<00:10,  1.81s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.190827163711882)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.20233159008414092\n",
      "DEBUG:shap:self.fx = 0.16555555555555557\n",
      "DEBUG:shap:self.link(self.fx) = 0.16555555555555557\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.12756431,  0.0200487 ,  0.00496467, -0.05772061, -0.00081302,\n",
      "       -0.02099593, -0.06532205,  0.01581881,  0.00889848, -0.00119457,\n",
      "       -0.02415904,  0.03661191, -0.00695697,  0.02755677, -0.01150443])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1908271637118821)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.20233159008414103\n",
      "DEBUG:shap:self.fx = 0.8344444444444443\n",
      "DEBUG:shap:self.link(self.fx) = 0.8344444444444443\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.12756431, -0.0200487 , -0.00496467,  0.05772061,  0.00081302,\n",
      "        0.02099593,  0.06532205, -0.01581881, -0.00889848,  0.00119457,\n",
      "        0.02415904, -0.03661191,  0.00695697, -0.02755677,  0.01150443])\n",
      " 93%|█████████▎| 69/74 [02:02<00:09,  1.81s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2730628266442426)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.25522047897302985\n",
      "DEBUG:shap:self.fx = 0.11266666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.11266666666666665\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.08749137,  0.02906351,  0.00553593, -0.05215298,  0.00070938,\n",
      "       -0.02495706, -0.03381998, -0.01870248, -0.01772658, -0.00882765,\n",
      "       -0.0131893 , -0.02095894,  0.01585403, -0.04639933,  0.01784235])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.27306282664424253)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2552204789730299\n",
      "DEBUG:shap:self.fx = 0.8873333333333332\n",
      "DEBUG:shap:self.link(self.fx) = 0.8873333333333332\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.08749137, -0.02906351, -0.00553593,  0.05215298, -0.00070938,\n",
      "        0.02495706,  0.03381998,  0.01870248,  0.01772658,  0.00882765,\n",
      "        0.0131893 ,  0.02095894, -0.01585403,  0.04639933, -0.01784235])\n",
      " 95%|█████████▍| 70/74 [02:03<00:07,  1.81s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3657410496055957)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3707973781698273\n",
      "DEBUG:shap:self.fx = 0.7386845238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.7386845238095238\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.15919139,  0.01944641, -0.01753382, -0.00246565, -0.00646043,\n",
      "        0.02125209,  0.02499897,  0.05073974, -0.00279691,  0.00393671,\n",
      "        0.01494359,  0.02499783,  0.02150295,  0.05398817,  0.00505633])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3657410496055956)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.37079737816982716\n",
      "DEBUG:shap:self.fx = 0.2613154761904761\n",
      "DEBUG:shap:self.link(self.fx) = 0.2613154761904761\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.15919139, -0.01944641,  0.01753382,  0.00246565,  0.00646043,\n",
      "       -0.02125209, -0.02499897, -0.05073974,  0.00279691, -0.00393671,\n",
      "       -0.01494359, -0.02499783, -0.02150295, -0.05398817, -0.00505633])\n",
      " 96%|█████████▌| 71/74 [02:05<00:05,  1.84s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5892584868069595)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5775533305507797\n",
      "DEBUG:shap:self.fx = 0.9454404761904762\n",
      "DEBUG:shap:self.link(self.fx) = 0.9454404761904762\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.20130892,  0.01268957,  0.00890214,  0.11094766,  0.00375937,\n",
      "        0.02509101,  0.03891993,  0.08572619,  0.01439903,  0.00070218,\n",
      "        0.0198462 ,  0.01148575,  0.00430736,  0.05117316, -0.01170516])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5892584868069591)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5775533305507795\n",
      "DEBUG:shap:self.fx = 0.05455952380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.05455952380952381\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.20130892, -0.01268957, -0.00890214, -0.11094766, -0.00375937,\n",
      "       -0.02509101, -0.03891993, -0.08572619, -0.01439903, -0.00070218,\n",
      "       -0.0198462 , -0.01148575, -0.00430736, -0.05117316,  0.01170516])\n",
      " 97%|█████████▋| 72/74 [02:07<00:03,  1.92s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0697083899535073)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.07726761626506545\n",
      "DEBUG:shap:self.fx = 0.44515476190476194\n",
      "DEBUG:shap:self.link(self.fx) = 0.44515476190476194\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.14197781,  0.00301533,  0.02306403,  0.08050626, -0.00179389,\n",
      "        0.00344875,  0.00867066, -0.0444417 , -0.0407534 ,  0.01226936,\n",
      "        0.00845389, -0.00366726, -0.01986195, -0.10117949,  0.00755923])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.06970838995350705)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.07726761626506518\n",
      "DEBUG:shap:self.fx = 0.5548452380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.5548452380952381\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.14197781, -0.00301533, -0.02306403, -0.08050626,  0.00179389,\n",
      "       -0.00344875, -0.00867066,  0.0444417 ,  0.0407534 , -0.01226936,\n",
      "       -0.00845389,  0.00366726,  0.01986195,  0.10117949, -0.00755923])\n",
      " 99%|█████████▊| 73/74 [02:09<00:01,  1.89s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.04455293952131627)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.035100949598398656\n",
      "DEBUG:shap:self.fx = 0.40298809523809515\n",
      "DEBUG:shap:self.link(self.fx) = 0.40298809523809515\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.14827449,  0.00504334,  0.00028469,  0.06441217, -0.0032201 ,\n",
      "       -0.01382358,  0.012368  , -0.04133082, -0.04449579, -0.00178417,\n",
      "        0.00930893, -0.00028105,  0.00085748, -0.09106064, -0.00945199])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.04455293952131631)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.0351009495983986\n",
      "DEBUG:shap:self.fx = 0.5970119047619047\n",
      "DEBUG:shap:self.link(self.fx) = 0.5970119047619047\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.14827449, -0.00504334, -0.00028469, -0.06441217,  0.0032201 ,\n",
      "        0.01382358, -0.012368  ,  0.04133082,  0.04449579,  0.00178417,\n",
      "       -0.00930893,  0.00028105, -0.00085748,  0.09106064,  0.00945199])\n",
      "100%|██████████| 74/74 [02:11<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8387096774193548,\n",
      "                0.7741935483870968,\n",
      "                0.7599399849962492,\n",
      "                0.7351837959489873,\n",
      "                0.6781695423855963,\n",
      "                0.6834208552138036,\n",
      "                0.5858964741185296,\n",
      "                0.5596399099774944,\n",
      "                0.5558889722430608,\n",
      "                0.4951237809452363,\n",
      "                0.4028507126781695,\n",
      "                0.46174043510877716,\n",
      "                0.4246061515378845,\n",
      "                0.41747936984246065,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5193068224943925,\n",
      "                0.5884276777641769,\n",
      "                0.606017463133041,\n",
      "                0.6769923018390795,\n",
      "                0.713251049802941,\n",
      "                0.777170066168812,\n",
      "                0.8097615528760742,\n",
      "                0.8325013104183201,\n",
      "                0.8454462470235794,\n",
      "                0.880687022675766,\n",
      "                0.8618255137513322,\n",
      "                0.8627240321533328,\n",
      "                0.8789419861761316,\n",
      "                0.8881107626199484,\n",
      "                0.8937715432763311\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.16720830628118008,\n",
      "                0.20064877500497325,\n",
      "                0.20862298219047065,\n",
      "                0.24276897776608453,\n",
      "                0.26001066333595496,\n",
      "                0.28937136524704976,\n",
      "                0.3037600035015351,\n",
      "                0.3140788994549396,\n",
      "                0.31916146808575163,\n",
      "                0.334362746881767,\n",
      "                0.3272903945763365,\n",
      "                0.32787975107537387,\n",
      "                0.3345552101040773,\n",
      "                0.33825577726387107,\n",
      "                0.3406323110321205\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.59152288072018,\n",
      "            \"cross_entropy\": 0.7756623568115507,\n",
      "            \"brier\": 0.2872405087867657\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8945986496624156,\n",
      "                0.8807201800450112,\n",
      "                0.9024756189047263,\n",
      "                0.9167291822955739,\n",
      "                0.9047261815453863,\n",
      "                0.9069767441860466,\n",
      "                0.9182295573893473,\n",
      "                0.9092273068267066,\n",
      "                0.8994748687171792,\n",
      "                0.9024756189047262,\n",
      "                0.9009752438109526,\n",
      "                0.891972993248312,\n",
      "                0.8942235558889722,\n",
      "                0.8987246811702926,\n",
      "                0.8994748687171792\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5339335987660522,\n",
      "                0.4644702556151713,\n",
      "                0.42012108956571426,\n",
      "                0.38370294811830236,\n",
      "                0.38350528284408963,\n",
      "                0.38379002741618,\n",
      "                0.3739531897443354,\n",
      "                0.37935897981210503,\n",
      "                0.38579319122015177,\n",
      "                0.39109098435741246,\n",
      "                0.39038645629215213,\n",
      "                0.4059026829970491,\n",
      "                0.40390593142719505,\n",
      "                0.4041106260777957,\n",
      "                0.40118807518577815\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17395977258876588,\n",
      "                0.14233368561447618,\n",
      "                0.1271685787310535,\n",
      "                0.11529523911652789,\n",
      "                0.1162465477795363,\n",
      "                0.11600668857275998,\n",
      "                0.11253308562957226,\n",
      "                0.11440429261501137,\n",
      "                0.11511658703687726,\n",
      "                0.11738495698531191,\n",
      "                0.11733943412805545,\n",
      "                0.1209865031782178,\n",
      "                0.12115912697505885,\n",
      "                0.12118795043758877,\n",
      "                0.11986653926437998\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.901400350087522,\n",
      "            \"cross_entropy\": 0.40701422129596565,\n",
      "            \"brier\": 0.12339926591021291\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/74 [00:00<?, ?it/s]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.042006284900791294)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08728100214417595\n",
      "DEBUG:shap:self.fx = 0.33379761904761907\n",
      "DEBUG:shap:self.link(self.fx) = 0.33379761904761907\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.11683146, -0.05823946,  0.00143906,  0.06335488, -0.00252588,\n",
      "        0.01271716,  0.02425497, -0.00115818,  0.01124938,  0.00172614,\n",
      "       -0.0072631 ,  0.00700997,  0.04579216, -0.02353192, -0.04527472])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.042006284900791536)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08728100214417622\n",
      "DEBUG:shap:self.fx = 0.666202380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.666202380952381\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.11683146,  0.05823946, -0.00143906, -0.06335488,  0.00252588,\n",
      "       -0.01271716, -0.02425497,  0.00115818, -0.01124938, -0.00172614,\n",
      "        0.0072631 , -0.00700997, -0.04579216,  0.02353192,  0.04527472])\n",
      "  1%|▏         | 1/74 [00:01<02:07,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17930704551875587)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.17249528785846174\n",
      "DEBUG:shap:self.fx = 0.24858333333333327\n",
      "DEBUG:shap:self.link(self.fx) = 0.24858333333333327\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.16096407,  0.06952013,  0.00596314, -0.07060762, -0.02080829,\n",
      "       -0.03354617, -0.00650694,  0.00679437,  0.00110779,  0.019595  ,\n",
      "       -0.02012026,  0.01133982,  0.00439875,  0.0145273 ,  0.00681176])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17930704551875593)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1724952878584618\n",
      "DEBUG:shap:self.fx = 0.7514166666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.7514166666666666\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.16096407, -0.06952013, -0.00596314,  0.07060762,  0.02080829,\n",
      "        0.03354617,  0.00650694, -0.00679437, -0.00110779, -0.019595  ,\n",
      "        0.02012026, -0.01133982, -0.00439875, -0.0145273 , -0.00681176])\n",
      "  3%|▎         | 2/74 [00:03<02:05,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17675112058596457)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.10571304547487165\n",
      "DEBUG:shap:self.fx = 0.5267916666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.5267916666666667\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.13114847,  0.00112956, -0.00344364,  0.07216041, -0.01242404,\n",
      "        0.01102873,  0.03701753, -0.0389457 ,  0.0085898 , -0.00976128,\n",
      "       -0.00210452, -0.01512283, -0.00060567, -0.00191568, -0.07103808])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17675112058596432)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.10571304547487148\n",
      "DEBUG:shap:self.fx = 0.47320833333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.47320833333333334\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.13114847, -0.00112956,  0.00344364, -0.07216041,  0.01242404,\n",
      "       -0.01102873, -0.03701753,  0.0389457 , -0.0085898 ,  0.00976128,\n",
      "        0.00210452,  0.01512283,  0.00060567,  0.00191568,  0.07103808])\n",
      "  4%|▍         | 3/74 [00:05<02:04,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3217262176104461)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.36523523750385717\n",
      "DEBUG:shap:self.fx = 0.7863138586956522\n",
      "DEBUG:shap:self.link(self.fx) = 0.7863138586956522\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.17141308,  0.00720122,  0.01010406,  0.05687273,  0.00055691,\n",
      "        0.01180484, -0.02843057, -0.03793618,  0.00772817,  0.01564143,\n",
      "        0.0092746 ,  0.00357381,  0.01116419,  0.08275792,  0.04350902])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.32172621761044595)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.365235237503857\n",
      "DEBUG:shap:self.fx = 0.21368614130434782\n",
      "DEBUG:shap:self.link(self.fx) = 0.21368614130434782\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.17141308, -0.00720122, -0.01010406, -0.05687273, -0.00055691,\n",
      "       -0.01180484,  0.02843057,  0.03793618, -0.00772817, -0.01564143,\n",
      "       -0.0092746 , -0.00357381, -0.01116419, -0.08275792, -0.04350902])\n",
      "  5%|▌         | 4/74 [00:06<02:01,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.27897473989693705)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2754833830965569\n",
      "DEBUG:shap:self.fx = 0.1455952380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.1455952380952381\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.13271103,  0.05161686,  0.00556872, -0.05065891,  0.00439418,\n",
      "       -0.00823598,  0.00076362, -0.03162368, -0.03604621, -0.00529991,\n",
      "       -0.01518018, -0.01198577,  0.01597823, -0.06555469,  0.00349136])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.27897473989693705)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.27548338309655696\n",
      "DEBUG:shap:self.fx = 0.8544047619047618\n",
      "DEBUG:shap:self.link(self.fx) = 0.8544047619047618\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.13271103, -0.05161686, -0.00556872,  0.05065891, -0.00439418,\n",
      "        0.00823598, -0.00076362,  0.03162368,  0.03604621,  0.00529991,\n",
      "        0.01518018,  0.01198577, -0.01597823,  0.06555469, -0.00349136])\n",
      "  7%|▋         | 5/74 [00:08<02:02,  1.77s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1930045167277554)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1841545140489378\n",
      "DEBUG:shap:self.fx = 0.23692410714285722\n",
      "DEBUG:shap:self.link(self.fx) = 0.23692410714285722\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.09889992,  0.062859  ,  0.00082185, -0.04022744, -0.02035722,\n",
      "       -0.02160141, -0.06307047, -0.02053113, -0.00535337,  0.01228619,\n",
      "       -0.01626052,  0.00416726,  0.00512397,  0.00803869,  0.00885   ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19300451672775557)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.184154514048938\n",
      "DEBUG:shap:self.fx = 0.7630758928571428\n",
      "DEBUG:shap:self.link(self.fx) = 0.7630758928571428\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.09889992, -0.062859  , -0.00082185,  0.04022744,  0.02035722,\n",
      "        0.02160141,  0.06307047,  0.02053113,  0.00535337, -0.01228619,\n",
      "        0.01626052, -0.00416726, -0.00512397, -0.00803869, -0.00885   ])\n",
      "  8%|▊         | 6/74 [00:10<02:08,  1.89s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.28622869823101815)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.32383010928703315\n",
      "DEBUG:shap:self.fx = 0.09724851190476189\n",
      "DEBUG:shap:self.link(self.fx) = 0.09724851190476189\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.13970959, -0.00880064, -0.00121791, -0.05019748, -0.01327698,\n",
      "        0.00250551, -0.04513387, -0.03487562, -0.00124687,  0.02300895,\n",
      "        0.01513167,  0.00588674, -0.00109964, -0.03720298, -0.03760141])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.28622869823101815)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.32383010928703326\n",
      "DEBUG:shap:self.fx = 0.9027514880952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.9027514880952381\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.13970959,  0.00880064,  0.00121791,  0.05019748,  0.01327698,\n",
      "       -0.00250551,  0.04513387,  0.03487562,  0.00124687, -0.02300895,\n",
      "       -0.01513167, -0.00588674,  0.00109964,  0.03720298,  0.03760141])\n",
      "  9%|▉         | 7/74 [00:12<02:08,  1.92s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19636240902713548)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13414112119179505\n",
      "DEBUG:shap:self.fx = 0.28693749999999996\n",
      "DEBUG:shap:self.link(self.fx) = 0.28693749999999996\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.14667499,  0.02006982, -0.00788852, -0.04327511, -0.00195262,\n",
      "       -0.0107396 ,  0.01294415, -0.03137801, -0.02902791,  0.00596687,\n",
      "        0.00855728,  0.01578989,  0.00901209,  0.00223425,  0.06222129])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1963624090271355)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1341411211917951\n",
      "DEBUG:shap:self.fx = 0.7130624999999999\n",
      "DEBUG:shap:self.link(self.fx) = 0.7130624999999999\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.14667499, -0.02006982,  0.00788852,  0.04327511,  0.00195262,\n",
      "        0.0107396 , -0.01294415,  0.03137801,  0.02902791, -0.00596687,\n",
      "       -0.00855728, -0.01578989, -0.00901209, -0.00223425, -0.06222129])\n",
      " 11%|█         | 8/74 [00:14<02:05,  1.90s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2626121605421772)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2558643354775093\n",
      "DEBUG:shap:self.fx = 0.16521428571428573\n",
      "DEBUG:shap:self.link(self.fx) = 0.16521428571428573\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.13055667, -0.00468673, -0.00690398, -0.08500871,  0.0020847 ,\n",
      "        0.01171007,  0.03377339,  0.00219474,  0.        , -0.00466661,\n",
      "       -0.01036219, -0.01772391,  0.00294575, -0.05541201,  0.00674783])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.26261216054217723)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2558643354775094\n",
      "DEBUG:shap:self.fx = 0.8347857142857142\n",
      "DEBUG:shap:self.link(self.fx) = 0.8347857142857142\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.13055667,  0.00468673,  0.00690398,  0.08500871, -0.0020847 ,\n",
      "       -0.01171007, -0.03377339, -0.00219474,  0.        ,  0.00466661,\n",
      "        0.01036219,  0.01772391, -0.00294575,  0.05541201, -0.00674783])\n",
      " 12%|█▏        | 9/74 [00:16<01:58,  1.82s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.08659168457306265)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.11709945452512832\n",
      "DEBUG:shap:self.fx = 0.3039791666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.3039791666666667\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.1438444 , -0.00214844, -0.00564389, -0.0429493 ,  0.00376693,\n",
      "        0.02110194,  0.02703589, -0.03550706, -0.02135405,  0.02915324,\n",
      "        0.00317708,  0.00523968,  0.01206103,  0.06331966, -0.03050777])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.08659168457306274)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.11709945452512849\n",
      "DEBUG:shap:self.fx = 0.6960208333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.6960208333333333\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.1438444 ,  0.00214844,  0.00564389,  0.0429493 , -0.00376693,\n",
      "       -0.02110194, -0.02703589,  0.03550706,  0.02135405, -0.02915324,\n",
      "       -0.00317708, -0.00523968, -0.01206103, -0.06331966,  0.03050777])\n",
      " 14%|█▎        | 10/74 [00:18<01:53,  1.77s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4058228485390034)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.40933804547487157\n",
      "DEBUG:shap:self.fx = 0.8304166666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.8304166666666666\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.19968176,  0.02036103,  0.00291673,  0.07726562,  0.00083778,\n",
      "       -0.01688952,  0.0053944 ,  0.09114633,  0.00571092,  0.00834487,\n",
      "       -0.02611078,  0.00612741,  0.01723211,  0.0138042 ,  0.0035152 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.40582284853900336)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.40933804547487146\n",
      "DEBUG:shap:self.fx = 0.16958333333333336\n",
      "DEBUG:shap:self.link(self.fx) = 0.16958333333333336\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.19968176, -0.02036103, -0.00291673, -0.07726562, -0.00083778,\n",
      "        0.01688952, -0.0053944 , -0.09114633, -0.00571092, -0.00834487,\n",
      "        0.02611078, -0.00612741, -0.01723211, -0.0138042 , -0.0035152 ])\n",
      " 15%|█▍        | 11/74 [00:19<01:52,  1.79s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23675397295150444)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.16423338309655688\n",
      "DEBUG:shap:self.fx = 0.2568452380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.2568452380952381\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.14098089,  0.01555547,  0.00406925, -0.04804892, -0.00232582,\n",
      "       -0.01100032, -0.03117065, -0.03849078,  0.00120524,  0.00378804,\n",
      "        0.00676626,  0.00108383,  0.01421637, -0.01142106,  0.07252059])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23675397295150447)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16423338309655688\n",
      "DEBUG:shap:self.fx = 0.7431547619047617\n",
      "DEBUG:shap:self.link(self.fx) = 0.7431547619047617\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.14098089, -0.01555547, -0.00406925,  0.04804892,  0.00232582,\n",
      "        0.01100032,  0.03117065,  0.03849078, -0.00120524, -0.00378804,\n",
      "       -0.00676626, -0.00108383, -0.01421637,  0.01142106, -0.07252059])\n",
      " 16%|█▌        | 12/74 [00:21<01:50,  1.78s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.04398290995061981)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.05381374023941404\n",
      "DEBUG:shap:self.fx = 0.36726488095238097\n",
      "DEBUG:shap:self.link(self.fx) = 0.36726488095238097\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.10000159,  0.01037869, -0.00349672,  0.07422328, -0.00228085,\n",
      "        0.00963601,  0.03440521, -0.00149429, -0.04555502, -0.00253773,\n",
      "        0.01631907,  0.00507341,  0.01093843, -0.04959079, -0.00983083])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.04398290995062011)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.05381374023941432\n",
      "DEBUG:shap:self.fx = 0.6327351190476191\n",
      "DEBUG:shap:self.link(self.fx) = 0.6327351190476191\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.10000159, -0.01037869,  0.00349672, -0.07422328,  0.00228085,\n",
      "       -0.00963601, -0.03440521,  0.00149429,  0.04555502,  0.00253773,\n",
      "       -0.01631907, -0.00507341, -0.01093843,  0.04959079,  0.00983083])\n",
      " 18%|█▊        | 13/74 [00:23<01:48,  1.77s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.527364593453495)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5487547121415384\n",
      "DEBUG:shap:self.fx = 0.9698333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.9698333333333333\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.19379387,  0.02114315,  0.01116354,  0.07074096,  0.00894846,\n",
      "        0.00681141,  0.05173948,  0.0722043 , -0.00428377, -0.0064055 ,\n",
      "        0.00588367,  0.01189622,  0.00871011,  0.07501869,  0.02139012])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5273645934534948)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5487547121415381\n",
      "DEBUG:shap:self.fx = 0.030166666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.030166666666666665\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.19379387, -0.02114315, -0.01116354, -0.07074096, -0.00894846,\n",
      "       -0.00681141, -0.05173948, -0.0722043 ,  0.00428377,  0.0064055 ,\n",
      "       -0.00588367, -0.01189622, -0.00871011, -0.07501869, -0.02139012])\n",
      " 19%|█▉        | 14/74 [00:25<01:50,  1.85s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.42449232038130885)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4354516818385081\n",
      "DEBUG:shap:self.fx = 0.8565303030303031\n",
      "DEBUG:shap:self.link(self.fx) = 0.8565303030303031\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.20264604,  0.0220788 ,  0.00592637,  0.05665375,  0.01316099,\n",
      "       -0.00524779,  0.04559626,  0.10055836, -0.03385693, -0.00485793,\n",
      "        0.01329952, -0.01019179,  0.00312331,  0.01560336,  0.01095936])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.42449232038130874)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.43545168183850785\n",
      "DEBUG:shap:self.fx = 0.14346969696969697\n",
      "DEBUG:shap:self.link(self.fx) = 0.14346969696969697\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.20264604, -0.0220788 , -0.00592637, -0.05665375, -0.01316099,\n",
      "        0.00524779, -0.04559626, -0.10055836,  0.03385693,  0.00485793,\n",
      "       -0.01329952,  0.01019179, -0.00312331, -0.01560336, -0.01095936])\n",
      " 20%|██        | 15/74 [00:27<01:54,  1.95s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.24007653069856183)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.286373134649352\n",
      "DEBUG:shap:self.fx = 0.13470548654244305\n",
      "DEBUG:shap:self.link(self.fx) = 0.13470548654244305\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.13632708,  0.03851048, -0.00395688, -0.06401009,  0.01216499,\n",
      "       -0.01079084, -0.05433711, -0.00505682, -0.00160008,  0.0139786 ,\n",
      "        0.00460422, -0.01141393, -0.00137986, -0.02046213, -0.0462966 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24007653069856189)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2863731346493521\n",
      "DEBUG:shap:self.fx = 0.8652945134575569\n",
      "DEBUG:shap:self.link(self.fx) = 0.8652945134575569\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.13632708, -0.03851048,  0.00395688,  0.06401009, -0.01216499,\n",
      "        0.01079084,  0.05433711,  0.00505682,  0.00160008, -0.0139786 ,\n",
      "       -0.00460422,  0.01141393,  0.00137986,  0.02046213,  0.0462966 ])\n",
      " 22%|██▏       | 16/74 [00:29<02:00,  2.08s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.48189954907699345)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.41817137880820493\n",
      "DEBUG:shap:self.fx = 0.8392499999999999\n",
      "DEBUG:shap:self.link(self.fx) = 0.8392499999999999\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.19783551,  0.02273942,  0.00810735,  0.07158033,  0.00823977,\n",
      "       -0.01351892,  0.04841635,  0.04268516,  0.00401523,  0.01037573,\n",
      "        0.00398367,  0.00320583,  0.01023456,  0.06399955, -0.06372817])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4818995490769933)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.41817137880820476\n",
      "DEBUG:shap:self.fx = 0.16075000000000003\n",
      "DEBUG:shap:self.link(self.fx) = 0.16075000000000003\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.19783551, -0.02273942, -0.00810735, -0.07158033, -0.00823977,\n",
      "        0.01351892, -0.04841635, -0.04268516, -0.00401523, -0.01037573,\n",
      "       -0.00398367, -0.00320583, -0.01023456, -0.06399955,  0.06372817])\n",
      " 23%|██▎       | 17/74 [00:32<02:02,  2.15s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.07477205028641969)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.017292906906080818\n",
      "DEBUG:shap:self.fx = 0.4037857142857142\n",
      "DEBUG:shap:self.link(self.fx) = 0.4037857142857142\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.15041842,  0.02754323,  0.0003324 , -0.05279498,  0.0099133 ,\n",
      "        0.00955015,  0.032874  ,  0.0621254 ,  0.00267561, -0.00810151,\n",
      "        0.01006315,  0.0283764 ,  0.0153057 , -0.06221649,  0.05747914])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.07477205028641998)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.017292906906080985\n",
      "DEBUG:shap:self.fx = 0.5962142857142858\n",
      "DEBUG:shap:self.link(self.fx) = 0.5962142857142858\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.15041842, -0.02754323, -0.0003324 ,  0.05279498, -0.0099133 ,\n",
      "       -0.00955015, -0.032874  , -0.0621254 , -0.00267561,  0.00810151,\n",
      "       -0.01006315, -0.0283764 , -0.0153057 ,  0.06221649, -0.05747914])\n",
      " 24%|██▍       | 18/74 [00:34<02:02,  2.19s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.29836358496876225)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.31378732083719046\n",
      "DEBUG:shap:self.fx = 0.7348659420289855\n",
      "DEBUG:shap:self.link(self.fx) = 0.7348659420289855\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.18502286,  0.03076925, -0.00906492,  0.05767767, -0.00899085,\n",
      "        0.01493908,  0.03135818, -0.00989734, -0.02836805, -0.01420567,\n",
      "       -0.005035  , -0.00746585,  0.01310959,  0.04851465,  0.01542374])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2983635849687621)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.31378732083719035\n",
      "DEBUG:shap:self.fx = 0.26513405797101447\n",
      "DEBUG:shap:self.link(self.fx) = 0.26513405797101447\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.18502286, -0.03076925,  0.00906492, -0.05767767,  0.00899085,\n",
      "       -0.01493908, -0.03135818,  0.00989734,  0.02836805,  0.01420567,\n",
      "        0.005035  ,  0.00746585, -0.01310959, -0.04851465, -0.01542374])\n",
      " 26%|██▌       | 19/74 [00:36<02:04,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.25980630496884344)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21218874023941403\n",
      "DEBUG:shap:self.fx = 0.20888988095238098\n",
      "DEBUG:shap:self.link(self.fx) = 0.20888988095238098\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.11428129, -0.06533883, -0.00614862,  0.00824766, -0.00205185,\n",
      "       -0.00940416,  0.00670837, -0.06450328,  0.00281796,  0.02172407,\n",
      "       -0.00400049,  0.00228672, -0.00711854, -0.02874402,  0.04761756])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.25980630496884377)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21218874023941425\n",
      "DEBUG:shap:self.fx = 0.7911101190476191\n",
      "DEBUG:shap:self.link(self.fx) = 0.7911101190476191\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.11428129,  0.06533883,  0.00614862, -0.00824766,  0.00205185,\n",
      "        0.00940416, -0.00670837,  0.06450328, -0.00281796, -0.02172407,\n",
      "        0.00400049, -0.00228672,  0.00711854,  0.02874402, -0.04761756])\n",
      " 27%|██▋       | 20/74 [00:39<02:03,  2.30s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2663120483913403)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2719952878584616\n",
      "DEBUG:shap:self.fx = 0.14908333333333337\n",
      "DEBUG:shap:self.link(self.fx) = 0.14908333333333337\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.15093697, -0.00761291,  0.00178869, -0.05469906, -0.00466332,\n",
      "       -0.01353889,  0.02839671, -0.0382057 , -0.01745102,  0.02357597,\n",
      "        0.01403144,  0.00935708,  0.00408148, -0.06043556, -0.00568324])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.26631204839134076)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.27199528785846205\n",
      "DEBUG:shap:self.fx = 0.8509166666666669\n",
      "DEBUG:shap:self.link(self.fx) = 0.8509166666666669\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.15093697,  0.00761291, -0.00178869,  0.05469906,  0.00466332,\n",
      "        0.01353889, -0.02839671,  0.0382057 ,  0.01745102, -0.02357597,\n",
      "       -0.01403144, -0.00935708, -0.00408148,  0.06043556,  0.00568324])\n",
      " 28%|██▊       | 21/74 [00:41<02:03,  2.32s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2279024326761549)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2165880454748716\n",
      "DEBUG:shap:self.fx = 0.6376666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.6376666666666666\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.18943569,  0.02721153, -0.00855701,  0.05777076,  0.00861218,\n",
      "       -0.01512262,  0.04055907, -0.04369099, -0.05108823,  0.00376642,\n",
      "       -0.00954738,  0.01013264,  0.01197918,  0.00644119, -0.01131439])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22790243267615465)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21658804547487148\n",
      "DEBUG:shap:self.fx = 0.36233333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.36233333333333334\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.18943569, -0.02721153,  0.00855701, -0.05777076, -0.00861218,\n",
      "        0.01512262, -0.04055907,  0.04369099,  0.05108823, -0.00376642,\n",
      "        0.00954738, -0.01013264, -0.01197918, -0.00644119,  0.01131439])\n",
      " 30%|██▉       | 22/74 [00:44<02:01,  2.33s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.44671226367374756)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4566297121415383\n",
      "DEBUG:shap:self.fx = 0.8777083333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.8777083333333333\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.17761589,  0.01946737, -0.0171291 ,  0.05883485,  0.01621438,\n",
      "        0.00705037,  0.04594846,  0.07396106, -0.02992283, -0.0021531 ,\n",
      "       -0.00666321,  0.00850973,  0.02509342,  0.06988498,  0.00991745])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.44671226367374745)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.45662971214153814\n",
      "DEBUG:shap:self.fx = 0.12229166666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.12229166666666667\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.17761589, -0.01946737,  0.0171291 , -0.05883485, -0.01621438,\n",
      "       -0.00705037, -0.04594846, -0.07396106,  0.02992283,  0.0021531 ,\n",
      "        0.00666321, -0.00850973, -0.02509342, -0.06988498, -0.00991745])\n",
      " 31%|███       | 23/74 [00:46<01:58,  2.33s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.13139339893890542)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13915600214417595\n",
      "DEBUG:shap:self.fx = 0.28192261904761906\n",
      "DEBUG:shap:self.link(self.fx) = 0.28192261904761906\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.11250918,  0.01721925, -0.00841276,  0.04684757,  0.0024478 ,\n",
      "       -0.0022794 ,  0.02547966, -0.03540223, -0.01621301,  0.02336475,\n",
      "       -0.02372323, -0.01992295, -0.01284286, -0.01544679, -0.0077626 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.13139339893890575)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.13915600214417623\n",
      "DEBUG:shap:self.fx = 0.718077380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.718077380952381\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.11250918, -0.01721925,  0.00841276, -0.04684757, -0.0024478 ,\n",
      "        0.0022794 , -0.02547966,  0.03540223,  0.01621301, -0.02336475,\n",
      "        0.02372323,  0.01992295,  0.01284286,  0.01544679,  0.0077626 ])\n",
      " 32%|███▏      | 24/74 [00:48<01:57,  2.35s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17959543644225592)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.17806315958177926\n",
      "DEBUG:shap:self.fx = 0.5991417807735743\n",
      "DEBUG:shap:self.link(self.fx) = 0.5991417807735743\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 1.88904138e-01,  3.34714129e-03,  5.43192297e-04, -3.58513895e-03,\n",
      "        1.83491216e-04,  1.09604349e-02,  3.47616493e-02, -4.12263893e-02,\n",
      "        1.16230240e-02,  1.19131474e-02,  1.07133787e-02, -1.66811895e-02,\n",
      "        1.22538398e-02, -4.41152829e-02, -1.53227686e-03])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17959543644225578)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.17806315958177904\n",
      "DEBUG:shap:self.fx = 0.4008582192264258\n",
      "DEBUG:shap:self.link(self.fx) = 0.4008582192264258\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-1.88904138e-01, -3.34714129e-03, -5.43192297e-04,  3.58513895e-03,\n",
      "       -1.83491216e-04, -1.09604349e-02, -3.47616493e-02,  4.12263893e-02,\n",
      "       -1.16230240e-02, -1.19131474e-02, -1.07133787e-02,  1.66811895e-02,\n",
      "       -1.22538398e-02,  4.41152829e-02,  1.53227686e-03])\n",
      " 34%|███▍      | 25/74 [00:51<01:54,  2.35s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23026705635645336)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.27728695452512836\n",
      "DEBUG:shap:self.fx = 0.14379166666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.14379166666666665\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.08812444,  0.04306767, -0.01124302, -0.07223436,  0.00972052,\n",
      "        0.00381232, -0.06675474,  0.00233505, -0.02460644,  0.00155773,\n",
      "        0.01198738, -0.01731176,  0.00257468, -0.02504765, -0.0470199 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23026705635645334)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2772869545251284\n",
      "DEBUG:shap:self.fx = 0.8562083333333332\n",
      "DEBUG:shap:self.link(self.fx) = 0.8562083333333332\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.08812444, -0.04306767,  0.01124302,  0.07223436, -0.00972052,\n",
      "       -0.00381232,  0.06675474, -0.00233505,  0.02460644, -0.00155773,\n",
      "       -0.01198738,  0.01731176, -0.00257468,  0.02504765,  0.0470199 ])\n",
      " 35%|███▌      | 26/74 [00:53<01:52,  2.34s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.035121969158656785)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.07837028785846173\n",
      "DEBUG:shap:self.fx = 0.3427083333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.3427083333333333\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.14622904,  0.01143541,  0.        ,  0.06853816,  0.00373755,\n",
      "       -0.00686302,  0.03076875, -0.04147482,  0.00327173,  0.0065826 ,\n",
      "       -0.00827962, -0.01743129,  0.01066133,  0.05016028, -0.04324832])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03512196915865689)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.07837028785846178\n",
      "DEBUG:shap:self.fx = 0.6572916666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.6572916666666666\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.14622904, -0.01143541,  0.        , -0.06853816, -0.00373755,\n",
      "        0.00686302, -0.03076875,  0.04147482, -0.00327173, -0.0065826 ,\n",
      "        0.00827962,  0.01743129, -0.01066133, -0.05016028,  0.04324832])\n",
      " 36%|███▋      | 27/74 [00:55<01:46,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1222244680884382)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08646498482815868\n",
      "DEBUG:shap:self.fx = 0.33461363636363634\n",
      "DEBUG:shap:self.link(self.fx) = 0.33461363636363634\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.12561845, -0.01806174, -0.00553573,  0.0172619 ,  0.00206397,\n",
      "       -0.00613108, -0.06385919, -0.04072928, -0.02409853, -0.00181564,\n",
      "        0.01249965, -0.00638113, -0.01761515, -0.09544097,  0.03575948])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12222446808843834)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08646498482815879\n",
      "DEBUG:shap:self.fx = 0.6653863636363636\n",
      "DEBUG:shap:self.link(self.fx) = 0.6653863636363636\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.12561845,  0.01806174,  0.00553573, -0.0172619 , -0.00206397,\n",
      "        0.00613108,  0.06385919,  0.04072928,  0.02409853,  0.00181564,\n",
      "       -0.01249965,  0.00638113,  0.01761515,  0.09544097, -0.03575948])\n",
      " 38%|███▊      | 28/74 [00:57<01:45,  2.30s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.11826171680860752)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1440280259536998\n",
      "DEBUG:shap:self.fx = 0.2770505952380952\n",
      "DEBUG:shap:self.link(self.fx) = 0.2770505952380952\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.08372057,  0.00286965,  0.00449694,  0.0587573 ,  0.00158836,\n",
      "       -0.00900857,  0.02169126, -0.05077541, -0.01629297, -0.00042561,\n",
      "        0.00925026, -0.01608263,  0.00794329, -0.04855302, -0.02576631])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.11826171680860782)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.14402802595370012\n",
      "DEBUG:shap:self.fx = 0.722949404761905\n",
      "DEBUG:shap:self.link(self.fx) = 0.722949404761905\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.08372057, -0.00286965, -0.00449694, -0.0587573 , -0.00158836,\n",
      "        0.00900857, -0.02169126,  0.05077541,  0.01629297,  0.00042561,\n",
      "       -0.00925026,  0.01608263, -0.00794329,  0.04855302,  0.02576631])\n",
      " 39%|███▉      | 29/74 [01:00<01:43,  2.31s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3676363921070047)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.36567137880820494\n",
      "DEBUG:shap:self.fx = 0.78675\n",
      "DEBUG:shap:self.link(self.fx) = 0.78675\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.20039071, -0.07947514, -0.01151029,  0.05840315,  0.00633095,\n",
      "       -0.00286925,  0.04009368,  0.0408563 ,  0.00184161,  0.01358499,\n",
      "        0.00898334,  0.00656581, -0.00222646,  0.086667  , -0.00196501])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.36763639210700455)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3656713788082048\n",
      "DEBUG:shap:self.fx = 0.21325000000000005\n",
      "DEBUG:shap:self.link(self.fx) = 0.21325000000000005\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.20039071,  0.07947514,  0.01151029, -0.05840315, -0.00633095,\n",
      "        0.00286925, -0.04009368, -0.0408563 , -0.00184161, -0.01358499,\n",
      "       -0.00898334, -0.00656581,  0.00222646, -0.086667  ,  0.00196501])\n",
      " 41%|████      | 30/74 [01:02<01:42,  2.33s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17052421327912198)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.16366195452512833\n",
      "DEBUG:shap:self.fx = 0.2574166666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.2574166666666667\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.10554506, -0.00128048,  0.00652721,  0.02484388,  0.0024343 ,\n",
      "       -0.00638984, -0.02914536, -0.03712619, -0.01193508, -0.01362173,\n",
      "        0.0032482 , -0.01177296, -0.00151943,  0.0107583 ,  0.00686226])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17052421327912234)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16366195452512877\n",
      "DEBUG:shap:self.fx = 0.7425833333333336\n",
      "DEBUG:shap:self.link(self.fx) = 0.7425833333333336\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.10554506,  0.00128048, -0.00652721, -0.02484388, -0.0024343 ,\n",
      "        0.00638984,  0.02914536,  0.03712619,  0.01193508,  0.01362173,\n",
      "       -0.0032482 ,  0.01177296,  0.00151943, -0.0107583 , -0.00686226])\n",
      " 42%|████▏     | 31/74 [01:05<01:41,  2.35s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20482501741273657)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.24084052595369979\n",
      "DEBUG:shap:self.fx = 0.18023809523809523\n",
      "DEBUG:shap:self.link(self.fx) = 0.18023809523809523\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.12093498,  0.02617696, -0.0106884 , -0.05047572,  0.02420045,\n",
      "       -0.00739149, -0.04907117, -0.01794389, -0.01425025,  0.00391283,\n",
      "       -0.00909544, -0.01255526, -0.00332535,  0.0366167 , -0.03601551])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20482501741273687)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2408405259537001\n",
      "DEBUG:shap:self.fx = 0.8197619047619049\n",
      "DEBUG:shap:self.link(self.fx) = 0.8197619047619049\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.12093498, -0.02617696,  0.0106884 ,  0.05047572, -0.02420045,\n",
      "        0.00739149,  0.04907117,  0.01794389,  0.01425025, -0.00391283,\n",
      "        0.00909544,  0.01255526,  0.00332535, -0.0366167 ,  0.03601551])\n",
      " 43%|████▎     | 32/74 [01:07<01:40,  2.39s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.24710080719794789)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2553820632207805\n",
      "DEBUG:shap:self.fx = 0.1656965579710145\n",
      "DEBUG:shap:self.link(self.fx) = 0.1656965579710145\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.14831966, -0.01133082,  0.00310921, -0.05290393,  0.01868848,\n",
      "        0.00848596,  0.03418009, -0.03742745, -0.02928029, -0.0200204 ,\n",
      "        0.00652314, -0.00094577, -0.01340832, -0.00445105, -0.00828126])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24710080719794802)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2553820632207807\n",
      "DEBUG:shap:self.fx = 0.8343034420289855\n",
      "DEBUG:shap:self.link(self.fx) = 0.8343034420289855\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.14831966,  0.01133082, -0.00310921,  0.05290393, -0.01868848,\n",
      "       -0.00848596, -0.03418009,  0.03742745,  0.02928029,  0.0200204 ,\n",
      "       -0.00652314,  0.00094577,  0.01340832,  0.00445105,  0.00828126])\n",
      " 45%|████▍     | 33/74 [01:10<01:38,  2.41s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19709069015712066)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1480880454748717\n",
      "DEBUG:shap:self.fx = 0.5691666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.5691666666666667\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.15743356, -0.06001993,  0.0103098 ,  0.03878561, -0.00851538,\n",
      "        0.01444163,  0.02429813, -0.03950558, -0.03652537,  0.02627872,\n",
      "       -0.00418955,  0.00596562, -0.00608006,  0.07441348, -0.04900264])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19709069015712055)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1480880454748716\n",
      "DEBUG:shap:self.fx = 0.43083333333333323\n",
      "DEBUG:shap:self.link(self.fx) = 0.43083333333333323\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.15743356,  0.06001993, -0.0103098 , -0.03878561,  0.00851538,\n",
      "       -0.01444163, -0.02429813,  0.03950558,  0.03652537, -0.02627872,\n",
      "        0.00418955, -0.00596562,  0.00608006, -0.07441348,  0.04900264])\n",
      " 46%|████▌     | 34/74 [01:12<01:34,  2.37s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20928798811565355)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13694469262036646\n",
      "DEBUG:shap:self.fx = 0.28413392857142855\n",
      "DEBUG:shap:self.link(self.fx) = 0.28413392857142855\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.15049363,  0.02557217, -0.00310877, -0.04223792,  0.00570533,\n",
      "       -0.00906752,  0.02106315, -0.03314731, -0.03549289,  0.00283443,\n",
      "        0.00241214,  0.01152566, -0.00853515,  0.00368231,  0.0723433 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20928798811565347)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.13694469262036635\n",
      "DEBUG:shap:self.fx = 0.7158660714285712\n",
      "DEBUG:shap:self.link(self.fx) = 0.7158660714285712\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.15049363, -0.02557217,  0.00310877,  0.04223792, -0.00570533,\n",
      "        0.00906752, -0.02106315,  0.03314731,  0.03549289, -0.00283443,\n",
      "       -0.00241214, -0.01152566,  0.00853515, -0.00368231, -0.0723433 ])\n",
      " 47%|████▋     | 35/74 [01:14<01:32,  2.38s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.28556036289550946)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.25607862119179503\n",
      "DEBUG:shap:self.fx = 0.165\n",
      "DEBUG:shap:self.link(self.fx) = 0.165\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.10575748,  0.04636035, -0.00174555, -0.04902906, -0.00824076,\n",
      "       -0.01668377, -0.04436838, -0.02408277, -0.03193326, -0.00904201,\n",
      "       -0.00903352, -0.0088917 ,  0.0226306 , -0.04574304,  0.02948174])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.28556036289550946)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.25607862119179503\n",
      "DEBUG:shap:self.fx = 0.8349999999999999\n",
      "DEBUG:shap:self.link(self.fx) = 0.8349999999999999\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.10575748, -0.04636035,  0.00174555,  0.04902906,  0.00824076,\n",
      "        0.01668377,  0.04436838,  0.02408277,  0.03193326,  0.00904201,\n",
      "        0.00903352,  0.0088917 , -0.0226306 ,  0.04574304, -0.02948174])\n",
      " 49%|████▊     | 36/74 [01:17<01:31,  2.41s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.08109773423829111)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08417137880820486\n",
      "DEBUG:shap:self.fx = 0.5052499999999999\n",
      "DEBUG:shap:self.link(self.fx) = 0.5052499999999999\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.14442727,  0.00222168,  0.01022265,  0.04593088,  0.00151811,\n",
      "        0.01293117,  0.03002836, -0.04382318, -0.03608097,  0.02373212,\n",
      "       -0.00093976,  0.00612647, -0.03519895, -0.07999811,  0.00307364])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.08109773423829102)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08417137880820474\n",
      "DEBUG:shap:self.fx = 0.4947500000000001\n",
      "DEBUG:shap:self.link(self.fx) = 0.4947500000000001\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.14442727, -0.00222168, -0.01022265, -0.04593088, -0.00151811,\n",
      "       -0.01293117, -0.03002836,  0.04382318,  0.03608097, -0.02373212,\n",
      "        0.00093976, -0.00612647,  0.03519895,  0.07999811, -0.00307364])\n",
      " 50%|█████     | 37/74 [01:19<01:29,  2.42s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2749084822452301)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.26474528785846163\n",
      "DEBUG:shap:self.fx = 0.15633333333333335\n",
      "DEBUG:shap:self.link(self.fx) = 0.15633333333333335\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.10058158, -0.03075956, -0.00253741, -0.05375281, -0.00241019,\n",
      "       -0.00070683,  0.0166858 , -0.03260811, -0.01190255,  0.01158561,\n",
      "       -0.00326178,  0.00249455, -0.0232909 , -0.04386272,  0.01016319])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2749084822452305)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2647452878584621\n",
      "DEBUG:shap:self.fx = 0.8436666666666669\n",
      "DEBUG:shap:self.link(self.fx) = 0.8436666666666669\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.10058158,  0.03075956,  0.00253741,  0.05375281,  0.00241019,\n",
      "        0.00070683, -0.0166858 ,  0.03260811,  0.01190255, -0.01158561,\n",
      "        0.00326178, -0.00249455,  0.0232909 ,  0.04386272, -0.01016319])\n",
      " 51%|█████▏    | 38/74 [01:21<01:26,  2.40s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2236361845228112)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.24993278785846168\n",
      "DEBUG:shap:self.fx = 0.17114583333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.17114583333333333\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.15909398, -0.00401532,  0.00231984, -0.07018964, -0.00549122,\n",
      "       -0.00662286, -0.08473701,  0.0455076 ,  0.0174655 ,  0.0240599 ,\n",
      "        0.00633047,  0.0026031 ,  0.00207508,  0.00615234, -0.0262966 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2236361845228111)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24993278785846174\n",
      "DEBUG:shap:self.fx = 0.8288541666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.8288541666666666\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.15909398,  0.00401532, -0.00231984,  0.07018964,  0.00549122,\n",
      "        0.00662286,  0.08473701, -0.0455076 , -0.0174655 , -0.0240599 ,\n",
      "       -0.00633047, -0.0026031 , -0.00207508, -0.00615234,  0.0262966 ])\n",
      " 53%|█████▎    | 39/74 [01:24<01:23,  2.40s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2645634021770023)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1693062997632236\n",
      "DEBUG:shap:self.fx = 0.2517723214285714\n",
      "DEBUG:shap:self.link(self.fx) = 0.2517723214285714\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.12837341, -0.01714496,  0.0069171 , -0.04550071,  0.00391519,\n",
      "       -0.01175861, -0.01343039, -0.04468695,  0.00182946,  0.00659219,\n",
      "        0.        ,  0.00124942,  0.00866226, -0.03283399,  0.0952571 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2645634021770026)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16930629976322387\n",
      "DEBUG:shap:self.fx = 0.7482276785714287\n",
      "DEBUG:shap:self.link(self.fx) = 0.7482276785714287\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.12837341,  0.01714496, -0.0069171 ,  0.04550071, -0.00391519,\n",
      "        0.01175861,  0.01343039,  0.04468695, -0.00182946, -0.00659219,\n",
      "        0.        , -0.00124942, -0.00866226,  0.03283399, -0.0952571 ])\n",
      " 54%|█████▍    | 40/74 [01:26<01:21,  2.38s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09299847181322311)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.06993278785846174\n",
      "DEBUG:shap:self.fx = 0.35114583333333327\n",
      "DEBUG:shap:self.link(self.fx) = 0.35114583333333327\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.12208928, -0.05111367,  0.00513184,  0.05645628,  0.00642835,\n",
      "        0.0098168 ,  0.02466745, -0.04153373, -0.02583009,  0.00610195,\n",
      "        0.0061367 ,  0.00080838,  0.00721548,  0.02480505,  0.02306568])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.09299847181322324)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.0699327878584618\n",
      "DEBUG:shap:self.fx = 0.6488541666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.6488541666666666\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.12208928,  0.05111367, -0.00513184, -0.05645628, -0.00642835,\n",
      "       -0.0098168 , -0.02466745,  0.04153373,  0.02583009, -0.00610195,\n",
      "       -0.0061367 , -0.00080838, -0.00721548, -0.02480505, -0.02306568])\n",
      " 55%|█████▌    | 41/74 [01:29<01:19,  2.41s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.21726761509673076)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.18626612119179498\n",
      "DEBUG:shap:self.fx = 0.23481250000000004\n",
      "DEBUG:shap:self.link(self.fx) = 0.23481250000000004\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.12676551, -0.05527133, -0.00705625, -0.04443699,  0.00124166,\n",
      "       -0.01255437,  0.01685555, -0.04204149, -0.01400314, -0.00895097,\n",
      "        0.00160065,  0.01336118, -0.00777362,  0.06852703,  0.03100149])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.21726761509673093)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1862661211917952\n",
      "DEBUG:shap:self.fx = 0.7651875\n",
      "DEBUG:shap:self.link(self.fx) = 0.7651875\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.12676551,  0.05527133,  0.00705625,  0.04443699, -0.00124166,\n",
      "        0.01255437, -0.01685555,  0.04204149,  0.01400314,  0.00895097,\n",
      "       -0.00160065, -0.01336118,  0.00777362, -0.06852703, -0.03100149])\n",
      " 57%|█████▋    | 42/74 [01:31<01:16,  2.39s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.25586557759777523)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2773076584588757\n",
      "DEBUG:shap:self.fx = 0.14377096273291926\n",
      "DEBUG:shap:self.link(self.fx) = 0.14377096273291926\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.1142858 ,  0.02347027, -0.0088652 , -0.03256262, -0.00301678,\n",
      "       -0.00981223, -0.05225726,  0.00245766, -0.0051333 , -0.00168737,\n",
      "        0.00306805, -0.01240043,  0.01462875, -0.05946932, -0.02144208])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2558655775977755)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.27730765845887595\n",
      "DEBUG:shap:self.fx = 0.8562290372670808\n",
      "DEBUG:shap:self.link(self.fx) = 0.8562290372670808\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.1142858 , -0.02347027,  0.0088652 ,  0.03256262,  0.00301678,\n",
      "        0.00981223,  0.05225726, -0.00245766,  0.0051333 ,  0.00168737,\n",
      "       -0.00306805,  0.01240043, -0.01462875,  0.05946932,  0.02144208])\n",
      " 58%|█████▊    | 43/74 [01:33<01:14,  2.40s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.14439158487948198)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.128828621191795\n",
      "DEBUG:shap:self.fx = 0.29225\n",
      "DEBUG:shap:self.link(self.fx) = 0.29225\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.11998915,  0.0059485 ,  0.00353736,  0.06804437,  0.00169758,\n",
      "        0.00640225, -0.05120804, -0.0490497 , -0.01574664, -0.00155255,\n",
      "       -0.01141871,  0.00520851,  0.00669964,  0.00703501,  0.01556296])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.14439158487948214)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12882862119179528\n",
      "DEBUG:shap:self.fx = 0.7077500000000001\n",
      "DEBUG:shap:self.link(self.fx) = 0.7077500000000001\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.11998915, -0.0059485 , -0.00353736, -0.06804437, -0.00169758,\n",
      "       -0.00640225,  0.05120804,  0.0490497 ,  0.01574664,  0.00155255,\n",
      "        0.01141871, -0.00520851, -0.00669964, -0.00703501, -0.01556296])\n",
      " 59%|█████▉    | 44/74 [01:36<01:12,  2.41s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2052113133752696)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.24768278785846165\n",
      "DEBUG:shap:self.fx = 0.17339583333333336\n",
      "DEBUG:shap:self.link(self.fx) = 0.17339583333333336\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.11262646, -0.05810203,  0.00702993, -0.07365695,  0.01361223,\n",
      "       -0.00439806,  0.02318728,  0.00255198, -0.02290371, -0.00159071,\n",
      "       -0.02141721,  0.0037982 , -0.00810021,  0.04740441, -0.04247147])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2052113133752698)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24768278785846176\n",
      "DEBUG:shap:self.fx = 0.8266041666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.8266041666666666\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.11262646,  0.05810203, -0.00702993,  0.07365695, -0.01361223,\n",
      "        0.00439806, -0.02318728, -0.00255198,  0.02290371,  0.00159071,\n",
      "        0.02141721, -0.0037982 ,  0.00810021, -0.04740441,  0.04247147])\n",
      " 61%|██████    | 45/74 [01:38<01:09,  2.38s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1412710137883428)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.15068576404893785\n",
      "DEBUG:shap:self.fx = 0.27039285714285716\n",
      "DEBUG:shap:self.link(self.fx) = 0.27039285714285716\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.10721288,  0.03034026,  0.00862349, -0.05496762, -0.01978831,\n",
      "       -0.02532153, -0.06208413, -0.01895463,  0.00485184,  0.02460102,\n",
      "        0.0065961 ,  0.00570301,  0.        ,  0.06634238, -0.00941475])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1412710137883431)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1506857640489382\n",
      "DEBUG:shap:self.fx = 0.729607142857143\n",
      "DEBUG:shap:self.link(self.fx) = 0.729607142857143\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.10721288, -0.03034026, -0.00862349,  0.05496762,  0.01978831,\n",
      "        0.02532153,  0.06208413,  0.01895463, -0.00485184, -0.02460102,\n",
      "       -0.0065961 , -0.00570301,  0.        , -0.06634238,  0.00941475])\n",
      " 62%|██████▏   | 46/74 [01:41<01:07,  2.40s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3257217040432876)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.34541195452512835\n",
      "DEBUG:shap:self.fx = 0.07566666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.07566666666666667\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.12014994,  0.02221676, -0.00470413, -0.05529688, -0.01112698,\n",
      "       -0.01200925, -0.05848492, -0.0220628 , -0.02730633,  0.02403814,\n",
      "       -0.00425281, -0.01006952,  0.00195966, -0.0484727 , -0.01969025])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.32572170404328754)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3454119545251284\n",
      "DEBUG:shap:self.fx = 0.9243333333333332\n",
      "DEBUG:shap:self.link(self.fx) = 0.9243333333333332\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.12014994, -0.02221676,  0.00470413,  0.05529688,  0.01112698,\n",
      "        0.01200925,  0.05848492,  0.0220628 ,  0.02730633, -0.02403814,\n",
      "        0.00425281,  0.01006952, -0.00195966,  0.0484727 ,  0.01969025])\n",
      " 64%|██████▎   | 47/74 [01:43<01:04,  2.40s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1715695824852885)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1801708830965569\n",
      "DEBUG:shap:self.fx = 0.2409077380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.2409077380952381\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.14131681,  0.00704188,  0.00860291, -0.04692716, -0.00533539,\n",
      "       -0.01277389, -0.06843758,  0.06757256, -0.01479333,  0.01913819,\n",
      "       -0.00698333,  0.00763588, -0.0032398 ,  0.01824629, -0.0086013 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17156958248528872)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.18017088309655704\n",
      "DEBUG:shap:self.fx = 0.7590922619047619\n",
      "DEBUG:shap:self.link(self.fx) = 0.7590922619047619\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.14131681, -0.00704188, -0.00860291,  0.04692716,  0.00533539,\n",
      "        0.01277389,  0.06843758, -0.06757256,  0.01479333, -0.01913819,\n",
      "        0.00698333, -0.00763588,  0.0032398 , -0.01824629,  0.0086013 ])\n",
      " 65%|██████▍   | 48/74 [01:45<01:01,  2.38s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999995)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.15785749799400056)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.19774528785846163\n",
      "DEBUG:shap:self.fx = 0.22333333333333338\n",
      "DEBUG:shap:self.link(self.fx) = 0.22333333333333338\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.15346661,  0.01186587,  0.00433209, -0.05757507, -0.00798355,\n",
      "       -0.01648039, -0.04939428,  0.07457094,  0.01422249,  0.02568431,\n",
      "        0.01179668, -0.01429112,  0.01390336, -0.01504222, -0.03988779])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999995)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.15785749799400078)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1977452878584618\n",
      "DEBUG:shap:self.fx = 0.7766666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.7766666666666666\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.15346661, -0.01186587, -0.00433209,  0.05757507,  0.00798355,\n",
      "        0.01648039,  0.04939428, -0.07457094, -0.01422249, -0.02568431,\n",
      "       -0.01179668,  0.01429112, -0.01390336,  0.01504222,  0.03988779])\n",
      " 66%|██████▌   | 49/74 [01:48<00:59,  2.39s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.29513666642795455)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.31827789655411387\n",
      "DEBUG:shap:self.fx = 0.10280072463768114\n",
      "DEBUG:shap:self.link(self.fx) = 0.10280072463768114\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.11933255,  0.04497293, -0.01227964, -0.05820897, -0.01157   ,\n",
      "       -0.01705002, -0.0645244 , -0.02535242, -0.00855469,  0.01888858,\n",
      "       -0.00412221, -0.01389308,  0.00914406, -0.03325426, -0.02314123])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2951366664279548)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.318277896554114\n",
      "DEBUG:shap:self.fx = 0.8971992753623188\n",
      "DEBUG:shap:self.link(self.fx) = 0.8971992753623188\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.11933255, -0.04497293,  0.01227964,  0.05820897,  0.01157   ,\n",
      "        0.01705002,  0.0645244 ,  0.02535242,  0.00855469, -0.01888858,\n",
      "        0.00412221,  0.01389308, -0.00914406,  0.03325426,  0.02314123])\n",
      " 68%|██████▊   | 50/74 [01:50<00:57,  2.40s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1691189291005844)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12448523750385715\n",
      "DEBUG:shap:self.fx = 0.5455638586956522\n",
      "DEBUG:shap:self.link(self.fx) = 0.5455638586956522\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.1948517 ,  0.03509284,  0.0096208 , -0.07165656,  0.00898101,\n",
      "       -0.02105322,  0.00883841, -0.03291511,  0.01284105, -0.0070733 ,\n",
      "        0.00340195, -0.00884837, -0.00633554,  0.04337328, -0.04463369])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.16911892910058435)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.12448523750385698\n",
      "DEBUG:shap:self.fx = 0.45443614130434784\n",
      "DEBUG:shap:self.link(self.fx) = 0.45443614130434784\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.1948517 , -0.03509284, -0.0096208 ,  0.07165656, -0.00898101,\n",
      "        0.02105322, -0.00883841,  0.03291511, -0.01284105,  0.0070733 ,\n",
      "       -0.00340195,  0.00884837,  0.00633554, -0.04337328,  0.04463369])\n",
      " 69%|██████▉   | 51/74 [01:53<00:55,  2.39s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19785384523247007)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21418576404893788\n",
      "DEBUG:shap:self.fx = 0.20689285714285713\n",
      "DEBUG:shap:self.link(self.fx) = 0.20689285714285713\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.12381664, -0.00239591,  0.00399277, -0.07181328, -0.01121268,\n",
      "       -0.00817486, -0.033549  , -0.0356311 ,  0.00859421,  0.01644831,\n",
      "        0.00180383, -0.01203107,  0.0101431 ,  0.05978848, -0.01633192])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19785384523247043)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2141857640489383\n",
      "DEBUG:shap:self.fx = 0.7931071428571431\n",
      "DEBUG:shap:self.link(self.fx) = 0.7931071428571431\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.12381664,  0.00239591, -0.00399277,  0.07181328,  0.01121268,\n",
      "        0.00817486,  0.033549  ,  0.0356311 , -0.00859421, -0.01644831,\n",
      "       -0.00180383,  0.01203107, -0.0101431 , -0.05978848,  0.01633192])\n",
      " 70%|███████   | 52/74 [01:55<00:52,  2.38s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.21687220092251785)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2348807045251283\n",
      "DEBUG:shap:self.fx = 0.1861979166666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.1861979166666667\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.06187488,  0.03849071, -0.00929286, -0.0489767 , -0.01637701,\n",
      "       -0.01169797, -0.06025399, -0.0163523 , -0.00553908,  0.02233078,\n",
      "       -0.00293741, -0.00698248, -0.00178344, -0.03562556, -0.0180085 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.216872200922518)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.23488070452512844\n",
      "DEBUG:shap:self.fx = 0.8138020833333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.8138020833333333\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.06187488, -0.03849071,  0.00929286,  0.0489767 ,  0.01637701,\n",
      "        0.01169797,  0.06025399,  0.0163523 ,  0.00553908, -0.02233078,\n",
      "        0.00293741,  0.00698248,  0.00178344,  0.03562556,  0.0180085 ])\n",
      " 72%|███████▏  | 53/74 [01:57<00:49,  2.36s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3048901462645083)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3338762402394141\n",
      "DEBUG:shap:self.fx = 0.08720238095238093\n",
      "DEBUG:shap:self.link(self.fx) = 0.08720238095238093\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.1290616 ,  0.01229773, -0.00567723, -0.0583322 ,  0.00950677,\n",
      "       -0.00284523, -0.04646903, -0.02023035,  0.01326166, -0.0193359 ,\n",
      "       -0.01917699, -0.00851135, -0.00639905, -0.02391737, -0.02898609])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3048901462645085)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3338762402394143\n",
      "DEBUG:shap:self.fx = 0.9127976190476191\n",
      "DEBUG:shap:self.link(self.fx) = 0.9127976190476191\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.1290616 , -0.01229773,  0.00567723,  0.0583322 , -0.00950677,\n",
      "        0.00284523,  0.04646903,  0.02023035, -0.01326166,  0.0193359 ,\n",
      "        0.01917699,  0.00851135,  0.00639905,  0.02391737,  0.02898609])\n",
      " 73%|███████▎  | 54/74 [02:00<00:47,  2.35s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5209979022521382)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5455880454748716\n",
      "DEBUG:shap:self.fx = 0.9666666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.9666666666666667\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.1905747 ,  0.01362229, -0.00304826,  0.07299384,  0.00665422,\n",
      "        0.01172902,  0.04637125,  0.05919498,  0.00769819,  0.00358494,\n",
      "        0.01451779,  0.0214793 , -0.00464463,  0.08027027,  0.02459014])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.520997902252138)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5455880454748715\n",
      "DEBUG:shap:self.fx = 0.03333333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.03333333333333333\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.1905747 , -0.01362229,  0.00304826, -0.07299384, -0.00665422,\n",
      "       -0.01172902, -0.04637125, -0.05919498, -0.00769819, -0.00358494,\n",
      "       -0.01451779, -0.0214793 ,  0.00464463, -0.08027027, -0.02459014])\n",
      " 74%|███████▍  | 55/74 [02:02<00:44,  2.34s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22667515831686322)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.26581820452512833\n",
      "DEBUG:shap:self.fx = 0.15526041666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.15526041666666668\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.13692706, -0.00767334,  0.01002305, -0.05686512,  0.0087705 ,\n",
      "        0.00801785,  0.02153636, -0.04626341,  0.01067323, -0.02033007,\n",
      "       -0.00669886, -0.01774848, -0.00285258,  0.00966276, -0.03914305])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22667515831686358)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2658182045251286\n",
      "DEBUG:shap:self.fx = 0.8447395833333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.8447395833333334\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.13692706,  0.00767334, -0.01002305,  0.05686512, -0.0087705 ,\n",
      "       -0.00801785, -0.02153636,  0.04626341, -0.01067323,  0.02033007,\n",
      "        0.00669886,  0.01774848,  0.00285258, -0.00966276,  0.03914305])\n",
      " 76%|███████▌  | 56/74 [02:04<00:42,  2.34s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12182949167709806)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.06367137880820495\n",
      "DEBUG:shap:self.fx = 0.48474999999999996\n",
      "DEBUG:shap:self.link(self.fx) = 0.48474999999999996\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.01691166,  0.00110192,  0.00104909,  0.06206681, -0.00302724,\n",
      "        0.00256397,  0.03280939,  0.04708364, -0.00832332, -0.00250377,\n",
      "        0.00579192,  0.00968484,  0.0116241 , -0.05500353, -0.05815811])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.12182949167709778)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.06367137880820473\n",
      "DEBUG:shap:self.fx = 0.5152500000000001\n",
      "DEBUG:shap:self.link(self.fx) = 0.5152500000000001\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.01691166, -0.00110192, -0.00104909, -0.06206681,  0.00302724,\n",
      "       -0.00256397, -0.03280939, -0.04708364,  0.00832332,  0.00250377,\n",
      "       -0.00579192, -0.00968484, -0.0116241 ,  0.05500353,  0.05815811])\n",
      " 77%|███████▋  | 57/74 [02:07<00:40,  2.36s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.25969236797774026)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2961112298874472\n",
      "DEBUG:shap:self.fx = 0.12496739130434782\n",
      "DEBUG:shap:self.link(self.fx) = 0.12496739130434782\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.09679531,  0.        , -0.00337705, -0.05993786,  0.00232334,\n",
      "       -0.01707072, -0.02989944, -0.02834243,  0.00876841, -0.01119456,\n",
      "        0.01016236, -0.01668688,  0.00497474, -0.02261697, -0.03641886])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.25969236797774037)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2961112298874474\n",
      "DEBUG:shap:self.fx = 0.8750326086956522\n",
      "DEBUG:shap:self.link(self.fx) = 0.8750326086956522\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.09679531,  0.        ,  0.00337705,  0.05993786, -0.00232334,\n",
      "        0.01707072,  0.02989944,  0.02834243, -0.00876841,  0.01119456,\n",
      "       -0.01016236,  0.01668688, -0.00497474,  0.02261697,  0.03641886])\n",
      " 78%|███████▊  | 58/74 [02:09<00:37,  2.35s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24907943158869947)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2598380454748717\n",
      "DEBUG:shap:self.fx = 0.6809166666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.6809166666666667\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.17765441, -0.08199414,  0.00780353,  0.06628537,  0.0030599 ,\n",
      "       -0.00293433,  0.04759287,  0.06729437, -0.05436977, -0.00735192,\n",
      "        0.00084736,  0.00611989,  0.00869266,  0.01037925,  0.01075861])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.24907943158869922)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.25983804547487144\n",
      "DEBUG:shap:self.fx = 0.3190833333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.3190833333333334\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.17765441,  0.08199414, -0.00780353, -0.06628537, -0.0030599 ,\n",
      "        0.00293433, -0.04759287, -0.06729437,  0.05436977,  0.00735192,\n",
      "       -0.00084736, -0.00611989, -0.00869266, -0.01037925, -0.01075861])\n",
      " 80%|███████▉  | 59/74 [02:11<00:35,  2.39s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.13882031987598553)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1724327424445687\n",
      "DEBUG:shap:self.fx = 0.5935113636363637\n",
      "DEBUG:shap:self.link(self.fx) = 0.5935113636363637\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.1272182 ,  0.01159455, -0.00970378,  0.05322514,  0.00332586,\n",
      "        0.02089437,  0.02088596, -0.04090994, -0.07274938, -0.01277543,\n",
      "        0.01239979,  0.00123621,  0.01027093,  0.01390784,  0.03361242])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.13882031987598528)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.17243274244456847\n",
      "DEBUG:shap:self.fx = 0.40648863636363636\n",
      "DEBUG:shap:self.link(self.fx) = 0.40648863636363636\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.1272182 , -0.01159455,  0.00970378, -0.05322514, -0.00332586,\n",
      "       -0.02089437, -0.02088596,  0.04090994,  0.07274938,  0.01277543,\n",
      "       -0.01239979, -0.00123621, -0.01027093, -0.01390784, -0.03361242])\n",
      " 81%|████████  | 60/74 [02:14<00:33,  2.40s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0956568051608874)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1363706541705238\n",
      "DEBUG:shap:self.fx = 0.5574492753623188\n",
      "DEBUG:shap:self.link(self.fx) = 0.5574492753623188\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.13818829,  0.03514716, -0.01072906,  0.03216537,  0.00433954,\n",
      "       -0.0137087 ,  0.03549892, -0.03808007, -0.01219307, -0.00644597,\n",
      "       -0.01194456,  0.00117144,  0.01922576, -0.07697824,  0.04071385])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09565680516088726)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13637065417052358\n",
      "DEBUG:shap:self.fx = 0.44255072463768125\n",
      "DEBUG:shap:self.link(self.fx) = 0.44255072463768125\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.13818829, -0.03514716,  0.01072906, -0.03216537, -0.00433954,\n",
      "        0.0137087 , -0.03549892,  0.03808007,  0.01219307,  0.00644597,\n",
      "        0.01194456, -0.00117144, -0.01922576,  0.07697824, -0.04071385])\n",
      " 82%|████████▏ | 61/74 [02:16<00:31,  2.39s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.25974581185246204)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21712971214153848\n",
      "DEBUG:shap:self.fx = 0.6382083333333335\n",
      "DEBUG:shap:self.link(self.fx) = 0.6382083333333335\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.15997333, -0.09477741, -0.01959948,  0.03805736, -0.00288147,\n",
      "       -0.00340111,  0.03022415,  0.07316523, -0.03364116,  0.01403948,\n",
      "        0.0070462 ,  0.01219055,  0.00193422,  0.07741592, -0.0426161 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.25974581185246187)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2171297121415383\n",
      "DEBUG:shap:self.fx = 0.3617916666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.3617916666666665\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.15997333,  0.09477741,  0.01959948, -0.03805736,  0.00288147,\n",
      "        0.00340111, -0.03022415, -0.07316523,  0.03364116, -0.01403948,\n",
      "       -0.0070462 , -0.01219055, -0.00193422, -0.07741592,  0.0426161 ])\n",
      " 84%|████████▍ | 62/74 [02:19<00:28,  2.36s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.34472370816709114)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3654267060779234\n",
      "DEBUG:shap:self.fx = 0.05565191511387165\n",
      "DEBUG:shap:self.link(self.fx) = 0.05565191511387165\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.15581449, -0.00201446,  0.00391802, -0.06977135, -0.00673515,\n",
      "       -0.02259192, -0.04451563, -0.04516698,  0.00249676,  0.0155989 ,\n",
      "       -0.00603674, -0.0029798 ,  0.00615468, -0.01726554, -0.020703  ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3447237081670912)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3654267060779236\n",
      "DEBUG:shap:self.fx = 0.9443480848861284\n",
      "DEBUG:shap:self.link(self.fx) = 0.9443480848861284\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.15581449,  0.00201446, -0.00391802,  0.06977135,  0.00673515,\n",
      "        0.02259192,  0.04451563,  0.04516698, -0.00249676, -0.0155989 ,\n",
      "        0.00603674,  0.0029798 , -0.00615468,  0.01726554,  0.020703  ])\n",
      " 85%|████████▌ | 63/74 [02:21<00:26,  2.40s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.09486888641052099)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09095168183850794\n",
      "DEBUG:shap:self.fx = 0.512030303030303\n",
      "DEBUG:shap:self.link(self.fx) = 0.512030303030303\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.15984541,  0.00357814, -0.00827796, -0.03653672,  0.0007879 ,\n",
      "        0.02456308,  0.03189389, -0.03821676, -0.02063794, -0.01634535,\n",
      "       -0.01564606,  0.01227793, -0.00840942,  0.00599273, -0.0039172 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09486888641052092)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09095168183850777\n",
      "DEBUG:shap:self.fx = 0.48796969696969705\n",
      "DEBUG:shap:self.link(self.fx) = 0.48796969696969705\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.15984541, -0.00357814,  0.00827796,  0.03653672, -0.0007879 ,\n",
      "       -0.02456308, -0.03189389,  0.03821676,  0.02063794,  0.01634535,\n",
      "        0.01564606, -0.01227793,  0.00840942, -0.00599273,  0.0039172 ])\n",
      " 86%|████████▋ | 64/74 [02:24<00:24,  2.43s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22924208556421893)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.19123040690608076\n",
      "DEBUG:shap:self.fx = 0.22984821428571425\n",
      "DEBUG:shap:self.link(self.fx) = 0.22984821428571425\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.16285568, -0.01385192,  0.01171528, -0.06008421, -0.00330482,\n",
      "       -0.01140225,  0.01825796, -0.03383781,  0.00869392, -0.00605765,\n",
      "        0.02018027, -0.01053574, -0.01439169,  0.02823224,  0.03801168])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22924208556421935)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.19123040690608106\n",
      "DEBUG:shap:self.fx = 0.7701517857142859\n",
      "DEBUG:shap:self.link(self.fx) = 0.7701517857142859\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.16285568,  0.01385192, -0.01171528,  0.06008421,  0.00330482,\n",
      "        0.01140225, -0.01825796,  0.03383781, -0.00869392,  0.00605765,\n",
      "       -0.02018027,  0.01053574,  0.01439169, -0.02823224, -0.03801168])\n",
      " 88%|████████▊ | 65/74 [02:26<00:22,  2.45s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5308970858668443)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4897547121415384\n",
      "DEBUG:shap:self.fx = 0.9108333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.9108333333333334\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.21112761,  0.01960984,  0.00524135,  0.08015596,  0.01120903,\n",
      "        0.01145137,  0.04981226,  0.07904685,  0.0028118 ,  0.00495289,\n",
      "        0.01273742,  0.01723595,  0.00534641,  0.02015833, -0.04114237])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5308970858668441)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.48975471214153815\n",
      "DEBUG:shap:self.fx = 0.08916666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.08916666666666667\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.21112761, -0.01960984, -0.00524135, -0.08015596, -0.01120903,\n",
      "       -0.01145137, -0.04981226, -0.07904685, -0.0028118 , -0.00495289,\n",
      "       -0.01273742, -0.01723595, -0.00534641, -0.02015833,  0.04114237])\n",
      " 89%|████████▉ | 66/74 [02:28<00:19,  2.42s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.25041974177161863)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.29298622988744716\n",
      "DEBUG:shap:self.fx = 0.12809239130434782\n",
      "DEBUG:shap:self.link(self.fx) = 0.12809239130434782\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.10379254,  0.04016252, -0.01666697, -0.06039809,  0.00217262,\n",
      "        0.00302998, -0.04394156, -0.00150538, -0.02130481, -0.00888905,\n",
      "        0.00159723, -0.02288398, -0.0016178 , -0.0163819 , -0.04256649])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2504197417716188)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.29298622988744727\n",
      "DEBUG:shap:self.fx = 0.8719076086956521\n",
      "DEBUG:shap:self.link(self.fx) = 0.8719076086956521\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.10379254, -0.04016252,  0.01666697,  0.06039809, -0.00217262,\n",
      "       -0.00302998,  0.04394156,  0.00150538,  0.02130481,  0.00888905,\n",
      "       -0.00159723,  0.02288398,  0.0016178 ,  0.0163819 ,  0.04256649])\n",
      " 91%|█████████ | 67/74 [02:31<00:16,  2.35s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.44073411963068543)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.44661834850517484\n",
      "DEBUG:shap:self.fx = 0.8676969696969699\n",
      "DEBUG:shap:self.link(self.fx) = 0.8676969696969699\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.1829006 ,  0.01513046, -0.00142574,  0.0807123 ,  0.00069541,\n",
      "        0.01063106,  0.05546016,  0.07491254,  0.01113446,  0.01066833,\n",
      "        0.02026852,  0.00961223,  0.00036804, -0.03033425,  0.00588423])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4407341196306852)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.44661834850517457\n",
      "DEBUG:shap:self.fx = 0.13230303030303028\n",
      "DEBUG:shap:self.link(self.fx) = 0.13230303030303028\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.1829006 , -0.01513046,  0.00142574, -0.0807123 , -0.00069541,\n",
      "       -0.01063106, -0.05546016, -0.07491254, -0.01113446, -0.01066833,\n",
      "       -0.02026852, -0.00961223, -0.00036804,  0.03033425, -0.00588423])\n",
      " 92%|█████████▏| 68/74 [02:33<00:14,  2.38s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3486784837953292)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3807868251255424\n",
      "DEBUG:shap:self.fx = 0.04029179606625259\n",
      "DEBUG:shap:self.link(self.fx) = 0.04029179606625259\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.1353502 , -0.02204416,  0.00228558, -0.06112411, -0.00676546,\n",
      "       -0.01321759, -0.04048352, -0.03741569, -0.00595998,  0.014375  ,\n",
      "        0.        , -0.00199363,  0.        , -0.04098473, -0.03210834])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.34867848379532934)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3807868251255425\n",
      "DEBUG:shap:self.fx = 0.9597082039337473\n",
      "DEBUG:shap:self.link(self.fx) = 0.9597082039337473\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.1353502 ,  0.02204416, -0.00228558,  0.06112411,  0.00676546,\n",
      "        0.01321759,  0.04048352,  0.03741569,  0.00595998, -0.014375  ,\n",
      "        0.        ,  0.00199363,  0.        ,  0.04098473,  0.03210834])\n",
      " 93%|█████████▎| 69/74 [02:35<00:11,  2.35s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999995)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.30922010557576324)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2550324902394141\n",
      "DEBUG:shap:self.fx = 0.16604613095238094\n",
      "DEBUG:shap:self.link(self.fx) = 0.16604613095238094\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.12560523, -0.04455879, -0.00804119, -0.03905616,  0.00274784,\n",
      "       -0.01250164,  0.01417613, -0.06461539,  0.00718587, -0.00292463,\n",
      "       -0.00095797, -0.00270492, -0.00355586, -0.02880818,  0.05418762])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999995)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3092201055757632)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2550324902394141\n",
      "DEBUG:shap:self.fx = 0.8339538690476189\n",
      "DEBUG:shap:self.link(self.fx) = 0.8339538690476189\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.12560523,  0.04455879,  0.00804119,  0.03905616, -0.00274784,\n",
      "        0.01250164, -0.01417613,  0.06461539, -0.00718587,  0.00292463,\n",
      "        0.00095797,  0.00270492,  0.00355586,  0.02880818, -0.05418762])\n",
      " 95%|█████████▍| 70/74 [02:38<00:09,  2.41s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4819226110672185)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4850404264272528\n",
      "DEBUG:shap:self.fx = 0.9061190476190478\n",
      "DEBUG:shap:self.link(self.fx) = 0.9061190476190478\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.22225001,  0.02835606,  0.01127516,  0.08848213,  0.00839292,\n",
      "       -0.00550657,  0.05007335,  0.0283999 ,  0.00855854,  0.00678684,\n",
      "        0.00101269,  0.00943761,  0.01263064,  0.01177332,  0.00311782])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.48192261106721834)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4850404264272524\n",
      "DEBUG:shap:self.fx = 0.09388095238095237\n",
      "DEBUG:shap:self.link(self.fx) = 0.09388095238095237\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.22225001, -0.02835606, -0.01127516, -0.08848213, -0.00839292,\n",
      "        0.00550657, -0.05007335, -0.0283999 , -0.00855854, -0.00678684,\n",
      "       -0.00101269, -0.00943761, -0.01263064, -0.01177332, -0.00311782])\n",
      " 96%|█████████▌| 71/74 [02:40<00:07,  2.36s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0624966263926665)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.06855774244456853\n",
      "DEBUG:shap:self.fx = 0.48963636363636354\n",
      "DEBUG:shap:self.link(self.fx) = 0.48963636363636354\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.15884419,  0.02265267,  0.0063541 ,  0.04674976,  0.00081012,\n",
      "       -0.00515538, -0.07171301, -0.05473271, -0.0279015 , -0.00922355,\n",
      "        0.00821887, -0.02017443,  0.0077675 ,  0.00606112,  0.        ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.062496626392666496)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.06855774244456836\n",
      "DEBUG:shap:self.fx = 0.5103636363636365\n",
      "DEBUG:shap:self.link(self.fx) = 0.5103636363636365\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.15884419, -0.02265267, -0.0063541 , -0.04674976, -0.00081012,\n",
      "        0.00515538,  0.07171301,  0.05473271,  0.0279015 ,  0.00922355,\n",
      "       -0.00821887,  0.02017443, -0.0077675 , -0.00606112,  0.        ])\n",
      " 97%|█████████▋| 72/74 [02:42<00:04,  2.37s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.11917144032080104)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.169578621191795\n",
      "DEBUG:shap:self.fx = 0.2515\n",
      "DEBUG:shap:self.link(self.fx) = 0.2515\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.11297218,  0.05680642,  0.00622099, -0.04236977,  0.01030549,\n",
      "       -0.01689657, -0.06677336, -0.02166317, -0.00725989,  0.02293374,\n",
      "        0.02073671,  0.00433594, -0.00149927,  0.02892349, -0.05040718])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1191714403208011)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16957862119179512\n",
      "DEBUG:shap:self.fx = 0.7484999999999999\n",
      "DEBUG:shap:self.link(self.fx) = 0.7484999999999999\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.11297218, -0.05680642, -0.00622099,  0.04236977, -0.01030549,\n",
      "        0.01689657,  0.06677336,  0.02166317,  0.00725989, -0.02293374,\n",
      "       -0.02073671, -0.00433594,  0.00149927, -0.02892349,  0.05040718])\n",
      " 99%|█████████▊| 73/74 [02:45<00:02,  2.34s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.06610812987582126)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.017084573572747397\n",
      "DEBUG:shap:self.fx = 0.4039940476190476\n",
      "DEBUG:shap:self.link(self.fx) = 0.4039940476190476\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.16027944,  0.01205257, -0.00892861,  0.01778473,  0.0130019 ,\n",
      "       -0.01134201,  0.0129392 , -0.07219635,  0.00658652,  0.00413246,\n",
      "        0.01104935,  0.01426865,  0.01506392,  0.07975897,  0.04902356])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.06610812987582157)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.01708457357274773\n",
      "DEBUG:shap:self.fx = 0.5960059523809526\n",
      "DEBUG:shap:self.link(self.fx) = 0.5960059523809526\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.16027944, -0.01205257,  0.00892861, -0.01778473, -0.0130019 ,\n",
      "        0.01134201, -0.0129392 ,  0.07219635, -0.00658652, -0.00413246,\n",
      "       -0.01104935, -0.01426865, -0.01506392, -0.07975897, -0.04902356])\n",
      "100%|██████████| 74/74 [02:47<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8286445012787723,\n",
      "                0.7468030690537085,\n",
      "                0.7178175618073316,\n",
      "                0.6317135549872123,\n",
      "                0.5524296675191817,\n",
      "                0.6086956521739131,\n",
      "                0.6325660699062234,\n",
      "                0.6982097186700768,\n",
      "                0.711849957374254,\n",
      "                0.6368286445012787,\n",
      "                0.5592497868712702,\n",
      "                0.5196078431372548,\n",
      "                0.48763853367433935,\n",
      "                0.550298380221654,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5247611733780392,\n",
      "                0.5992980891784528,\n",
      "                0.6364483622529632,\n",
      "                0.7030805887135134,\n",
      "                0.764792833477202,\n",
      "                0.7780820786677748,\n",
      "                0.7962646706446573,\n",
      "                0.8106359100631979,\n",
      "                0.8076533497670039,\n",
      "                0.853825796631459,\n",
      "                0.8787514646182164,\n",
      "                0.8711167992531359,\n",
      "                0.8791571272222569,\n",
      "                0.842185806284067,\n",
      "                0.8697720218315294\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17191309223617363,\n",
      "                0.20559231482901733,\n",
      "                0.22279499813175022,\n",
      "                0.2545604943132168,\n",
      "                0.2847126378229196,\n",
      "                0.2913512652958653,\n",
      "                0.3000969222074143,\n",
      "                0.30701958898035975,\n",
      "                0.30565095216923893,\n",
      "                0.3266958740886581,\n",
      "                0.33818781347887356,\n",
      "                0.33490890991635586,\n",
      "                0.33843748071383184,\n",
      "                0.32205690043346263,\n",
      "                0.3348469112139148\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6254901960784314,\n",
      "            \"cross_entropy\": 0.774388404798898,\n",
      "            \"brier\": 0.28925507705540354\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8047740835464622,\n",
      "                0.8405797101449275,\n",
      "                0.8350383631713556,\n",
      "                0.8644501278772379,\n",
      "                0.8584825234441602,\n",
      "                0.8533674339300937,\n",
      "                0.8337595907928389,\n",
      "                0.8277919863597613,\n",
      "                0.8260869565217391,\n",
      "                0.8312020460358056,\n",
      "                0.8380221653878944,\n",
      "                0.8473998294970163,\n",
      "                0.8533674339300937,\n",
      "                0.8550724637681159,\n",
      "                0.8533674339300937\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.6304875596901828,\n",
      "                0.5231308843317846,\n",
      "                0.49239532464583374,\n",
      "                0.45061291867255465,\n",
      "                0.4401524189059828,\n",
      "                0.44338652637942283,\n",
      "                0.4593776936160279,\n",
      "                0.4696961164785607,\n",
      "                0.4750169900067638,\n",
      "                0.4644041914235581,\n",
      "                0.4605469896397578,\n",
      "                0.4587796723398221,\n",
      "                0.4584951335150209,\n",
      "                0.45552697280724835,\n",
      "                0.45297774690534315\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.21120993032259455,\n",
      "                0.1662162563773505,\n",
      "                0.15263013176691798,\n",
      "                0.13865086965929263,\n",
      "                0.1341011290204091,\n",
      "                0.13534384534591934,\n",
      "                0.14268394260144285,\n",
      "                0.14585743977563176,\n",
      "                0.1484783540859465,\n",
      "                0.1443902529909404,\n",
      "                0.1437225696035937,\n",
      "                0.14301879153988858,\n",
      "                0.14238037453950478,\n",
      "                0.14122245896534602,\n",
      "                0.14064052329750873\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8415174765558397,\n",
      "            \"cross_entropy\": 0.47566580929052427,\n",
      "            \"brier\": 0.14870312465948582\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/74 [00:00<?, ?it/s]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17894642139490638)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1660816326530612\n",
      "DEBUG:shap:self.fx = 0.20566666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.20566666666666666\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11385852,  0.01430519,  0.00254306, -0.07051476,  0.        ,\n",
      "       -0.00504029, -0.04330775, -0.0354833 , -0.02110535,  0.02492751,\n",
      "       -0.00178847,  0.        ,  0.00604721,  0.06432906,  0.01286479])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17894642139490619)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16608163265306097\n",
      "DEBUG:shap:self.fx = 0.7943333333333332\n",
      "DEBUG:shap:self.link(self.fx) = 0.7943333333333332\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11385852, -0.01430519, -0.00254306,  0.07051476,  0.        ,\n",
      "        0.00504029,  0.04330775,  0.0354833 ,  0.02110535, -0.02492751,\n",
      "        0.00178847,  0.        , -0.00604721, -0.06432906, -0.01286479])\n",
      "  1%|▏         | 1/74 [00:01<01:54,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19719096421529775)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1939183673469388\n",
      "DEBUG:shap:self.fx = 0.5656666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.5656666666666667\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.11998376, -0.10323777,  0.00769699,  0.09711363, -0.00606974,\n",
      "        0.00949418,  0.02354199,  0.03569   ,  0.00702176, -0.02654364,\n",
      "        0.        ,  0.00632846,  0.03144277, -0.00527145, -0.0032726 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19719096421529794)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.19391836734693896\n",
      "DEBUG:shap:self.fx = 0.4343333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.4343333333333333\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.11998376,  0.10323777, -0.00769699, -0.09711363,  0.00606974,\n",
      "       -0.00949418, -0.02354199, -0.03569   , -0.00702176,  0.02654364,\n",
      "        0.        , -0.00632846, -0.03144277,  0.00527145,  0.0032726 ])\n",
      "  3%|▎         | 2/74 [00:03<01:55,  1.60s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.48793149403814523)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4974183673469389\n",
      "DEBUG:shap:self.fx = 0.8691666666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.8691666666666668\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.1517085 ,  0.01898166,  0.        ,  0.10951409,  0.01533393,\n",
      "        0.01709268,  0.04659729,  0.08311176,  0.00199739, -0.01898863,\n",
      "        0.00041146,  0.02425186,  0.03124968,  0.00666982,  0.00948687])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4879314940381453)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4974183673469389\n",
      "DEBUG:shap:self.fx = 0.13083333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.13083333333333333\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.1517085 , -0.01898166,  0.        , -0.10951409, -0.01533393,\n",
      "       -0.01709268, -0.04659729, -0.08311176, -0.00199739,  0.01898863,\n",
      "       -0.00041146, -0.02425186, -0.03124968, -0.00666982, -0.00948687])\n",
      "  4%|▍         | 3/74 [00:04<01:51,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2745331617001855)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.28924829931972784\n",
      "DEBUG:shap:self.fx = 0.0825\n",
      "DEBUG:shap:self.link(self.fx) = 0.0825\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11699639,  0.00353936,  0.00255745, -0.05397552, -0.00233151,\n",
      "        0.00949851, -0.03901811, -0.03016358,  0.00689118, -0.00359308,\n",
      "        0.00817316, -0.02156694,  0.0069257 , -0.04447337, -0.01471514])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2745331617001854)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.28924829931972773\n",
      "DEBUG:shap:self.fx = 0.9175\n",
      "DEBUG:shap:self.link(self.fx) = 0.9175\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11699639, -0.00353936, -0.00255745,  0.05397552,  0.00233151,\n",
      "       -0.00949851,  0.03901811,  0.03016358, -0.00689118,  0.00359308,\n",
      "       -0.00817316,  0.02156694, -0.0069257 ,  0.04447337,  0.01471514])\n",
      "  5%|▌         | 4/74 [00:06<01:50,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0634156818324165)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.050085034013605534\n",
      "DEBUG:shap:self.fx = 0.4218333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.4218333333333334\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.14990634,  0.01045958, -0.00568065, -0.06199696,  0.01673906,\n",
      "       -0.03106693, -0.05245377,  0.07251409, -0.01688163,  0.        ,\n",
      "       -0.00664925, -0.00918523, -0.00106337, -0.00122561, -0.01333065])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.0634156818324166)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.050085034013605645\n",
      "DEBUG:shap:self.fx = 0.5781666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.5781666666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.14990634, -0.01045958,  0.00568065,  0.06199696, -0.01673906,\n",
      "        0.03106693,  0.05245377, -0.07251409,  0.01688163,  0.        ,\n",
      "        0.00664925,  0.00918523,  0.00106337,  0.00122561,  0.01333065])\n",
      "  7%|▋         | 5/74 [00:07<01:48,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.08322489550810187)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09313265306122448\n",
      "DEBUG:shap:self.fx = 0.46488095238095234\n",
      "DEBUG:shap:self.link(self.fx) = 0.46488095238095234\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.10714055,  0.003143  ,  0.01121951,  0.0578135 ,  0.00629299,\n",
      "       -0.01152771,  0.0262638 , -0.05124677, -0.02700265, -0.0139335 ,\n",
      "       -0.00523482,  0.01127178,  0.00528189, -0.0362567 ,  0.00990776])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.08322489550810193)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09313265306122454\n",
      "DEBUG:shap:self.fx = 0.5351190476190477\n",
      "DEBUG:shap:self.link(self.fx) = 0.5351190476190477\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.10714055, -0.003143  , -0.01121951, -0.0578135 , -0.00629299,\n",
      "        0.01152771, -0.0262638 ,  0.05124677,  0.02700265,  0.0139335 ,\n",
      "        0.00523482, -0.01127178, -0.00528189,  0.0362567 , -0.00990776])\n",
      "  8%|▊         | 6/74 [00:09<01:47,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3779155973780005)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3914183673469388\n",
      "DEBUG:shap:self.fx = 0.7631666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.7631666666666667\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.16102053,  0.03801767, -0.01434766, -0.03079805,  0.01463653,\n",
      "        0.0438996 ,  0.03333193,  0.0286876 , -0.00845662, -0.00879231,\n",
      "        0.0037793 ,  0.04570183,  0.00638891,  0.06484635,  0.01350277])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3779155973780007)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3914183673469389\n",
      "DEBUG:shap:self.fx = 0.23683333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.23683333333333334\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.16102053, -0.03801767,  0.01434766,  0.03079805, -0.01463653,\n",
      "       -0.0438996 , -0.03333193, -0.0286876 ,  0.00845662,  0.00879231,\n",
      "       -0.0037793 , -0.04570183, -0.00638891, -0.06484635, -0.01350277])\n",
      "  9%|▉         | 7/74 [00:11<01:45,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4175864274160517)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.44908503401360544\n",
      "DEBUG:shap:self.fx = 0.8208333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.8208333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.17764375,  0.01252321,  0.        ,  0.01283651,  0.00118145,\n",
      "       -0.0041954 ,  0.04135077,  0.07949009,  0.00089082,  0.00482978,\n",
      "        0.00190925,  0.00667629, -0.00891563,  0.09136555,  0.03149861])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4175864274160517)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.44908503401360556\n",
      "DEBUG:shap:self.fx = 0.17916666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.17916666666666667\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.17764375, -0.01252321,  0.        , -0.01283651, -0.00118145,\n",
      "        0.0041954 , -0.04135077, -0.07949009, -0.00089082, -0.00482978,\n",
      "       -0.00190925, -0.00667629,  0.00891563, -0.09136555, -0.03149861])\n",
      " 11%|█         | 8/74 [00:12<01:46,  1.62s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1353677098631376)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1434149659863945\n",
      "DEBUG:shap:self.fx = 0.22833333333333336\n",
      "DEBUG:shap:self.link(self.fx) = 0.22833333333333336\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.06668187,  0.00966784,  0.00475418, -0.06736374,  0.00590436,\n",
      "        0.02926281, -0.06194591,  0.03321113, -0.00146587,  0.00391658,\n",
      "        0.01528454,  0.01487955, -0.00030076, -0.05449054, -0.00804726])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1353677098631375)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.14341496598639436\n",
      "DEBUG:shap:self.fx = 0.7716666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.7716666666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.06668187, -0.00966784, -0.00475418,  0.06736374, -0.00590436,\n",
      "       -0.02926281,  0.06194591, -0.03321113,  0.00146587, -0.00391658,\n",
      "       -0.01528454, -0.01487955,  0.00030076,  0.05449054,  0.00804726])\n",
      " 12%|█▏        | 9/74 [00:14<01:43,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.21216634421310276)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2184149659863945\n",
      "DEBUG:shap:self.fx = 0.15333333333333335\n",
      "DEBUG:shap:self.link(self.fx) = 0.15333333333333335\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.13185561, -0.00449072, -0.00090159, -0.05247922,  0.01727986,\n",
      "        0.00714653, -0.05030272, -0.01513821, -0.00139247,  0.0209575 ,\n",
      "       -0.00967312,  0.00894374,  0.00568991, -0.00595021, -0.00624862])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2121663442131026)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21841496598639432\n",
      "DEBUG:shap:self.fx = 0.8466666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.8466666666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.13185561,  0.00449072,  0.00090159,  0.05247922, -0.01727986,\n",
      "       -0.00714653,  0.05030272,  0.01513821,  0.00139247, -0.0209575 ,\n",
      "        0.00967312, -0.00894374, -0.00568991,  0.00595021,  0.00624862])\n",
      " 14%|█▎        | 10/74 [00:15<01:39,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1234106789797155)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13458163265306117\n",
      "DEBUG:shap:self.fx = 0.2371666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.2371666666666667\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11900793,  0.00274052,  0.01709965, -0.03679797, -0.00999209,\n",
      "        0.01692206,  0.03222491, -0.03536488,  0.00406308, -0.00505224,\n",
      "       -0.00467947, -0.01231112, -0.00042075,  0.02716554, -0.01117095])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1234106789797153)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1345816326530611\n",
      "DEBUG:shap:self.fx = 0.7628333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.7628333333333334\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11900793, -0.00274052, -0.01709965,  0.03679797,  0.00999209,\n",
      "       -0.01692206, -0.03222491,  0.03536488, -0.00406308,  0.00505224,\n",
      "        0.00467947,  0.01231112,  0.00042075, -0.02716554,  0.01117095])\n",
      " 15%|█▍        | 11/74 [00:17<01:40,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.0028625997299634998)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.009414965986394519\n",
      "DEBUG:shap:self.fx = 0.36233333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.36233333333333334\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.08603604, -0.05124457,  0.00990767,  0.07376373,  0.00913474,\n",
      "        0.02036335, -0.02002458,  0.05902627, -0.00179333,  0.02373476,\n",
      "        0.00332512,  0.01283532, -0.00954817, -0.04630687, -0.00655237])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0028625997299633055)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.009414965986394352\n",
      "DEBUG:shap:self.fx = 0.6376666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.6376666666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.08603604,  0.05124457, -0.00990767, -0.07376373, -0.00913474,\n",
      "       -0.02036335,  0.02002458, -0.05902627,  0.00179333, -0.02373476,\n",
      "       -0.00332512, -0.01283532,  0.00954817,  0.04630687,  0.00655237])\n",
      " 16%|█▌        | 12/74 [00:18<01:37,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22779201712058192)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.17391496598639455\n",
      "DEBUG:shap:self.fx = 0.1978333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.1978333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09540839,  0.        ,  0.00907969, -0.05097937,  0.00368249,\n",
      "        0.00177941, -0.02374504, -0.01191455,  0.01263993,  0.00161805,\n",
      "        0.00100336, -0.01798559,  0.0058507 , -0.06341271,  0.05387705])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22779201712058178)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.17391496598639444\n",
      "DEBUG:shap:self.fx = 0.8021666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.8021666666666667\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09540839,  0.        , -0.00907969,  0.05097937, -0.00368249,\n",
      "       -0.00177941,  0.02374504,  0.01191455, -0.01263993, -0.00161805,\n",
      "       -0.00100336,  0.01798559, -0.0058507 ,  0.06341271, -0.05387705])\n",
      " 18%|█▊        | 13/74 [00:20<01:34,  1.54s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.01907293754598581)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.017751700680272098\n",
      "DEBUG:shap:self.fx = 0.38949999999999996\n",
      "DEBUG:shap:self.link(self.fx) = 0.38949999999999996\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.03836451,  0.05552353,  0.01175661, -0.03718719, -0.00241512,\n",
      "       -0.01572175,  0.03165235, -0.06218858,  0.01082626,  0.01173784,\n",
      "        0.00617159,  0.01870186,  0.00740485, -0.01697067,  0.03682464])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.019072937545985595)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.01775170068027232\n",
      "DEBUG:shap:self.fx = 0.6104999999999999\n",
      "DEBUG:shap:self.link(self.fx) = 0.6104999999999999\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.03836451, -0.05552353, -0.01175661,  0.03718719,  0.00241512,\n",
      "        0.01572175, -0.03165235,  0.06218858, -0.01082626, -0.01173784,\n",
      "       -0.00617159, -0.01870186, -0.00740485,  0.01697067, -0.03682464])\n",
      " 19%|█▉        | 14/74 [00:21<01:31,  1.52s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19585954675415823)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2200816326530612\n",
      "DEBUG:shap:self.fx = 0.15166666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.15166666666666667\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11728919,  0.01346825,  0.00538514, -0.04385023, -0.00314027,\n",
      "       -0.0062512 , -0.06698593, -0.04001892,  0.0092888 , -0.00709338,\n",
      "       -0.00528465,  0.0092868 , -0.0026217 ,  0.05924692, -0.02422209])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1958595467541583)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.22008163265306113\n",
      "DEBUG:shap:self.fx = 0.8483333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.8483333333333334\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11728919, -0.01346825, -0.00538514,  0.04385023,  0.00314027,\n",
      "        0.0062512 ,  0.06698593,  0.04001892, -0.0092888 ,  0.00709338,\n",
      "        0.00528465, -0.0092868 ,  0.0026217 , -0.05924692,  0.02422209])\n",
      " 20%|██        | 15/74 [00:23<01:30,  1.53s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.07030659397567268)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09124829931972783\n",
      "DEBUG:shap:self.fx = 0.2805\n",
      "DEBUG:shap:self.link(self.fx) = 0.2805\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.07179206,  0.00146979,  0.00675405, -0.04836294,  0.00215466,\n",
      "       -0.00763944, -0.04561577,  0.00609679, -0.007299  ,  0.01227238,\n",
      "       -0.00459414,  0.01111831,  0.00198579,  0.07314497, -0.02094171])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.07030659397567267)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09124829931972778\n",
      "DEBUG:shap:self.fx = 0.7195\n",
      "DEBUG:shap:self.link(self.fx) = 0.7195\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.07179206, -0.00146979, -0.00675405,  0.04836294, -0.00215466,\n",
      "        0.00763944,  0.04561577, -0.00609679,  0.007299  , -0.01227238,\n",
      "        0.00459414, -0.01111831, -0.00198579, -0.07314497,  0.02094171])\n",
      " 22%|██▏       | 16/74 [00:25<01:29,  1.55s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09136204631983225)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.06570068027210879\n",
      "DEBUG:shap:self.fx = 0.30604761904761907\n",
      "DEBUG:shap:self.link(self.fx) = 0.30604761904761907\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09987893,  0.01834004,  0.00488345,  0.06120262, -0.00539841,\n",
      "       -0.00317591,  0.0326474 , -0.04828362, -0.02253236, -0.00676669,\n",
      "        0.00179794, -0.00239579, -0.01281017, -0.00899162,  0.02566137])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.09136204631983218)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.06570068027210874\n",
      "DEBUG:shap:self.fx = 0.693952380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.693952380952381\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09987893, -0.01834004, -0.00488345, -0.06120262,  0.00539841,\n",
      "        0.00317591, -0.0326474 ,  0.04828362,  0.02253236,  0.00676669,\n",
      "       -0.00179794,  0.00239579,  0.01281017,  0.00899162, -0.02566137])\n",
      " 23%|██▎       | 17/74 [00:26<01:28,  1.55s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.13555515953416006)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.14086734693877545\n",
      "DEBUG:shap:self.fx = 0.2308809523809524\n",
      "DEBUG:shap:self.link(self.fx) = 0.2308809523809524\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.07842573,  0.01055473,  0.05072122, -0.02117496,  0.        ,\n",
      "        0.00643351, -0.05640898, -0.02301514,  0.00722728,  0.00056098,\n",
      "        0.        , -0.00719307,  0.0054728 , -0.03030782, -0.00531219])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.13555515953416003)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.14086734693877545\n",
      "DEBUG:shap:self.fx = 0.7691190476190477\n",
      "DEBUG:shap:self.link(self.fx) = 0.7691190476190477\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.07842573, -0.01055473, -0.05072122,  0.02117496,  0.        ,\n",
      "       -0.00643351,  0.05640898,  0.02301514, -0.00722728, -0.00056098,\n",
      "        0.        ,  0.00719307, -0.0054728 ,  0.03030782,  0.00531219])\n",
      " 24%|██▍       | 18/74 [00:28<01:26,  1.54s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5201959351338656)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5447993197278911\n",
      "DEBUG:shap:self.fx = 0.9165476190476189\n",
      "DEBUG:shap:self.link(self.fx) = 0.9165476190476189\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.18009842,  0.01965786,  0.00027276,  0.10866598,  0.00720739,\n",
      "        0.01294265,  0.03504629, -0.01761941,  0.00559714,  0.0106921 ,\n",
      "        0.01058359,  0.02451364,  0.0016636 ,  0.12087392,  0.02460338])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5201959351338659)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5447993197278913\n",
      "DEBUG:shap:self.fx = 0.08345238095238094\n",
      "DEBUG:shap:self.link(self.fx) = 0.08345238095238094\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.18009842, -0.01965786, -0.00027276, -0.10866598, -0.00720739,\n",
      "       -0.01294265, -0.03504629,  0.01761941, -0.00559714, -0.0106921 ,\n",
      "       -0.01058359, -0.02451364, -0.0016636 , -0.12087392, -0.02460338])\n",
      " 26%|██▌       | 19/74 [00:29<01:25,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.26707276400981556)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2790816326530612\n",
      "DEBUG:shap:self.fx = 0.09266666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.09266666666666666\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11708746, -0.01394733, -0.01128806, -0.03648548,  0.00259539,\n",
      "        0.00335341,  0.03154906, -0.02992514,  0.00119192, -0.00511411,\n",
      "       -0.00457455, -0.03225602, -0.00390888, -0.05117551, -0.01200887])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2670727640098154)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2790816326530611\n",
      "DEBUG:shap:self.fx = 0.9073333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.9073333333333333\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11708746,  0.01394733,  0.01128806,  0.03648548, -0.00259539,\n",
      "       -0.00335341, -0.03154906,  0.02992514, -0.00119192,  0.00511411,\n",
      "        0.00457455,  0.03225602,  0.00390888,  0.05117551,  0.01200887])\n",
      " 27%|██▋       | 20/74 [00:31<01:23,  1.55s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3063528633834653)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3135850340136055\n",
      "DEBUG:shap:self.fx = 0.6853333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.6853333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.15575559,  0.01808418, -0.00346153,  0.08155099, -0.00706751,\n",
      "        0.0185956 ,  0.04110765, -0.02317519, -0.01687577,  0.00688081,\n",
      "       -0.01451555,  0.00902974,  0.010592  ,  0.02985185,  0.00723217])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.30635286338346546)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3135850340136056\n",
      "DEBUG:shap:self.fx = 0.31466666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.31466666666666665\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.15575559, -0.01808418,  0.00346153, -0.08155099,  0.00706751,\n",
      "       -0.0185956 , -0.04110765,  0.02317519,  0.01687577, -0.00688081,\n",
      "        0.01451555, -0.00902974, -0.010592  , -0.02985185, -0.00723217])\n",
      " 28%|██▊       | 21/74 [00:32<01:22,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.15122817577515654)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08974829931972789\n",
      "DEBUG:shap:self.fx = 0.282\n",
      "DEBUG:shap:self.link(self.fx) = 0.282\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09343917,  0.01166516, -0.0091298 , -0.05826838,  0.02087435,\n",
      "       -0.00146487, -0.04293046, -0.02911472,  0.00725146,  0.01688537,\n",
      "       -0.00023239, -0.03917219, -0.00120458,  0.06705203,  0.06147988])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1512281757751564)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08974829931972783\n",
      "DEBUG:shap:self.fx = 0.7180000000000001\n",
      "DEBUG:shap:self.link(self.fx) = 0.7180000000000001\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09343917, -0.01166516,  0.0091298 ,  0.05826838, -0.02087435,\n",
      "        0.00146487,  0.04293046,  0.02911472, -0.00725146, -0.01688537,\n",
      "        0.00023239,  0.03917219,  0.00120458, -0.06705203, -0.06147988])\n",
      " 30%|██▉       | 22/74 [00:34<01:19,  1.52s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2455838574367194)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2545816326530612\n",
      "DEBUG:shap:self.fx = 0.11716666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.11716666666666666\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11885325, -0.04752466, -0.0035902 , -0.06718088, -0.00453527,\n",
      "       -0.01778985,  0.00841598, -0.02248294, -0.00603286,  0.01073809,\n",
      "        0.        ,  0.        , -0.00013584,  0.02338782, -0.00899778])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24558385743671915)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2545816326530609\n",
      "DEBUG:shap:self.fx = 0.8828333333333331\n",
      "DEBUG:shap:self.link(self.fx) = 0.8828333333333331\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11885325,  0.04752466,  0.0035902 ,  0.06718088,  0.00453527,\n",
      "        0.01778985, -0.00841598,  0.02248294,  0.00603286, -0.01073809,\n",
      "        0.        ,  0.        ,  0.00013584, -0.02338782,  0.00899778])\n",
      " 31%|███       | 23/74 [00:35<01:19,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.26345602115989386)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.27191496598639453\n",
      "DEBUG:shap:self.fx = 0.09983333333333336\n",
      "DEBUG:shap:self.link(self.fx) = 0.09983333333333336\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.03433486,  0.0218714 , -0.0092973 , -0.05723357,  0.00822767,\n",
      "       -0.01227147, -0.06750976, -0.02152541,  0.00741855, -0.01131239,\n",
      "       -0.00521417, -0.04390843,  0.00253016, -0.04089644, -0.00845894])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.26345602115989386)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.27191496598639453\n",
      "DEBUG:shap:self.fx = 0.9001666666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.9001666666666668\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.03433486, -0.0218714 ,  0.0092973 ,  0.05723357, -0.00822767,\n",
      "        0.01227147,  0.06750976,  0.02152541, -0.00741855,  0.01131239,\n",
      "        0.00521417,  0.04390843, -0.00253016,  0.04089644,  0.00845894])\n",
      " 32%|███▏      | 24/74 [00:37<01:17,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.14857576920211546)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1704149659863945\n",
      "DEBUG:shap:self.fx = 0.20133333333333336\n",
      "DEBUG:shap:self.link(self.fx) = 0.20133333333333336\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09005233,  0.00358624, -0.00506936, -0.04154194,  0.00216245,\n",
      "        0.00248943,  0.02502292, -0.02689826,  0.00847892, -0.01020913,\n",
      "       -0.00616195, -0.04373799,  0.00191762,  0.03143762, -0.0218392 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.14857576920211538)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.17041496598639438\n",
      "DEBUG:shap:self.fx = 0.7986666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.7986666666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09005233, -0.00358624,  0.00506936,  0.04154194, -0.00216245,\n",
      "       -0.00248943, -0.02502292,  0.02689826, -0.00847892,  0.01020913,\n",
      "        0.00616195,  0.04373799, -0.00191762, -0.03143762,  0.0218392 ])\n",
      " 34%|███▍      | 25/74 [00:39<01:16,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1322134843474819)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08991496598639453\n",
      "DEBUG:shap:self.fx = 0.2818333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.2818333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09750694, -0.02722721, -0.010495  , -0.0472232 ,  0.02636277,\n",
      "       -0.01199316,  0.01348349, -0.03954219, -0.03031337,  0.00223164,\n",
      "       -0.00049616,  0.00643304, -0.00302898,  0.0871018 ,  0.04229852])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.13221348434748162)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08991496598639426\n",
      "DEBUG:shap:self.fx = 0.7181666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.7181666666666665\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09750694,  0.02722721,  0.010495  ,  0.0472232 , -0.02636277,\n",
      "        0.01199316, -0.01348349,  0.03954219,  0.03031337, -0.00223164,\n",
      "        0.00049616, -0.00643304,  0.00302898, -0.0871018 , -0.04229852])\n",
      " 35%|███▌      | 26/74 [00:40<01:13,  1.53s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2885799441606462)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3129183673469388\n",
      "DEBUG:shap:self.fx = 0.6846666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.6846666666666666\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.13423834, -0.04036735, -0.01681409,  0.08990997, -0.00295196,\n",
      "        0.01888468,  0.0292638 ,  0.        ,  0.00397199, -0.00369582,\n",
      "        0.0024605 ,  0.00352224,  0.04133966,  0.02881798,  0.02433842])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2885799441606463)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3129183673469389\n",
      "DEBUG:shap:self.fx = 0.31533333333333335\n",
      "DEBUG:shap:self.link(self.fx) = 0.31533333333333335\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.13423834,  0.04036735,  0.01681409, -0.08990997,  0.00295196,\n",
      "       -0.01888468, -0.0292638 ,  0.        , -0.00397199,  0.00369582,\n",
      "       -0.0024605 , -0.00352224, -0.04133966, -0.02881798, -0.02433842])\n",
      " 36%|███▋      | 27/74 [00:42<01:13,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.12664471890951473)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1217482993197278\n",
      "DEBUG:shap:self.fx = 0.25000000000000006\n",
      "DEBUG:shap:self.link(self.fx) = 0.25000000000000006\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.04814911, -0.03377092,  0.01207968, -0.05480828,  0.00108036,\n",
      "        0.02144919,  0.01859001, -0.01777812,  0.01587015, -0.00764263,\n",
      "       -0.00299708,  0.00927959, -0.00412468, -0.03572286,  0.00489642])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12664471890951462)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12174829931972775\n",
      "DEBUG:shap:self.fx = 0.75\n",
      "DEBUG:shap:self.link(self.fx) = 0.75\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.04814911,  0.03377092, -0.01207968,  0.05480828, -0.00108036,\n",
      "       -0.02144919, -0.01859001,  0.01777812, -0.01587015,  0.00764263,\n",
      "        0.00299708, -0.00927959,  0.00412468,  0.03572286, -0.00489642])\n",
      " 38%|███▊      | 28/74 [00:43<01:10,  1.52s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2211018161557584)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21175170068027216\n",
      "DEBUG:shap:self.fx = 0.5835\n",
      "DEBUG:shap:self.link(self.fx) = 0.5835\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.17929505,  0.00850604,  0.0038156 , -0.05272139,  0.00565324,\n",
      "        0.02302791, -0.05050367,  0.05854632, -0.00364274,  0.00047763,\n",
      "       -0.00246349,  0.00203097, -0.0031982 ,  0.05227856, -0.00935012])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22110181615575847)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21175170068027221\n",
      "DEBUG:shap:self.fx = 0.41650000000000004\n",
      "DEBUG:shap:self.link(self.fx) = 0.41650000000000004\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.17929505, -0.00850604, -0.0038156 ,  0.05272139, -0.00565324,\n",
      "       -0.02302791,  0.05050367, -0.05854632,  0.00364274, -0.00047763,\n",
      "        0.00246349, -0.00203097,  0.0031982 , -0.05227856,  0.00935012])\n",
      " 39%|███▉      | 29/74 [00:45<01:09,  1.54s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.29358292990927437)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.30608503401360543\n",
      "DEBUG:shap:self.fx = 0.6778333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.6778333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.13990353,  0.01018081,  0.00500294,  0.08446167, -0.00168559,\n",
      "        0.01598277,  0.04051385,  0.05946508,  0.00329758, -0.00729721,\n",
      "        0.00399395,  0.00297268,  0.00713281, -0.07034195,  0.0125021 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2935829299092745)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.30608503401360554\n",
      "DEBUG:shap:self.fx = 0.3221666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.3221666666666667\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.13990353, -0.01018081, -0.00500294, -0.08446167,  0.00168559,\n",
      "       -0.01598277, -0.04051385, -0.05946508, -0.00329758,  0.00729721,\n",
      "       -0.00399395, -0.00297268, -0.00713281,  0.07034195, -0.0125021 ])\n",
      " 41%|████      | 30/74 [00:46<01:09,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22314307446596493)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2300816326530612\n",
      "DEBUG:shap:self.fx = 0.14166666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.14166666666666666\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.0956545 ,  0.00932192,  0.01215306, -0.08508521, -0.00154379,\n",
      "       -0.01971262,  0.02402587, -0.0371302 ,  0.00746485,  0.0014365 ,\n",
      "        0.00166516,  0.00065648, -0.00592711, -0.03481348, -0.00693856])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22314307446596485)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.23008163265306114\n",
      "DEBUG:shap:self.fx = 0.8583333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.8583333333333334\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.0956545 , -0.00932192, -0.01215306,  0.08508521,  0.00154379,\n",
      "        0.01971262, -0.02402587,  0.0371302 , -0.00746485, -0.0014365 ,\n",
      "       -0.00166516, -0.00065648,  0.00592711,  0.03481348,  0.00693856])\n",
      " 42%|████▏     | 31/74 [00:48<01:09,  1.61s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23781775927307505)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2550816326530612\n",
      "DEBUG:shap:self.fx = 0.11666666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.11666666666666665\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.07172484,  0.01263325, -0.02025343, -0.04520544, -0.00429542,\n",
      "       -0.01384846, -0.06464923, -0.02505394,  0.01933714, -0.00055956,\n",
      "       -0.00120269, -0.02879552,  0.03396295, -0.02816257, -0.01726387])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23781775927307486)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.25508163265306105\n",
      "DEBUG:shap:self.fx = 0.8833333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.8833333333333333\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.07172484, -0.01263325,  0.02025343,  0.04520544,  0.00429542,\n",
      "        0.01384846,  0.06464923,  0.02505394, -0.01933714,  0.00055956,\n",
      "        0.00120269,  0.02879552, -0.03396295,  0.02816257,  0.01726387])\n",
      " 43%|████▎     | 32/74 [00:50<01:07,  1.61s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3461956953140066)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.37325170068027214\n",
      "DEBUG:shap:self.fx = 0.745\n",
      "DEBUG:shap:self.link(self.fx) = 0.745\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.15036366,  0.00977561,  0.00781177, -0.04800973,  0.00072869,\n",
      "       -0.01636474,  0.01038794,  0.10769422,  0.01077027,  0.00223347,\n",
      "       -0.01208534,  0.00617931,  0.00751652,  0.10919404,  0.02705601])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3461956953140067)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3732517006802722\n",
      "DEBUG:shap:self.fx = 0.25500000000000006\n",
      "DEBUG:shap:self.link(self.fx) = 0.25500000000000006\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.15036366, -0.00977561, -0.00781177,  0.04800973, -0.00072869,\n",
      "        0.01636474, -0.01038794, -0.10769422, -0.01077027, -0.00223347,\n",
      "        0.01208534, -0.00617931, -0.00751652, -0.10919404, -0.02705601])\n",
      " 45%|████▍     | 33/74 [00:51<01:04,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.14232692697980576)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.16641496598639452\n",
      "DEBUG:shap:self.fx = 0.20533333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.20533333333333334\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11610724,  0.01004985,  0.01178445, -0.04951427, -0.00301262,\n",
      "        0.00333485, -0.02022163, -0.0452226 ,  0.00298838,  0.00036024,\n",
      "        0.01394642,  0.00872355, -0.00022069,  0.04078439, -0.02408804])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1423269269798056)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16641496598639438\n",
      "DEBUG:shap:self.fx = 0.7946666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.7946666666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11610724, -0.01004985, -0.01178445,  0.04951427,  0.00301262,\n",
      "       -0.00333485,  0.02022163,  0.0452226 , -0.00298838, -0.00036024,\n",
      "       -0.01394642, -0.00872355,  0.00022069, -0.04078439,  0.02408804])\n",
      " 46%|████▌     | 34/74 [00:53<01:03,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.31209298889952347)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.30091496598639456\n",
      "DEBUG:shap:self.fx = 0.07083333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.07083333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09317254, -0.04509793,  0.01322575, -0.04996002, -0.0034409 ,\n",
      "       -0.01191426, -0.03160223, -0.02401186,  0.00773593, -0.00824648,\n",
      "       -0.00926695, -0.0002987 , -0.00173692, -0.05430588,  0.01117802])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3120929888995233)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.30091496598639444\n",
      "DEBUG:shap:self.fx = 0.9291666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.9291666666666667\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09317254,  0.04509793, -0.01322575,  0.04996002,  0.0034409 ,\n",
      "        0.01191426,  0.03160223,  0.02401186, -0.00773593,  0.00824648,\n",
      "        0.00926695,  0.0002987 ,  0.00173692,  0.05430588, -0.01117802])\n",
      " 47%|████▋     | 35/74 [00:54<01:01,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.021525101971173924)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.016835034013605477\n",
      "DEBUG:shap:self.fx = 0.38858333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.38858333333333334\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.10192637,  0.02527886,  0.00899208, -0.01543566, -0.00493224,\n",
      "        0.01710971, -0.02785973, -0.05497851, -0.00445173,  0.0318478 ,\n",
      "       -0.00939199,  0.01260268,  0.02629285, -0.08547538, -0.00469007])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.02152510197117409)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.016835034013605643\n",
      "DEBUG:shap:self.fx = 0.6114166666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.6114166666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.10192637, -0.02527886, -0.00899208,  0.01543566,  0.00493224,\n",
      "       -0.01710971,  0.02785973,  0.05497851,  0.00445173, -0.0318478 ,\n",
      "        0.00939199, -0.01260268, -0.02629285,  0.08547538,  0.00469007])\n",
      " 49%|████▊     | 36/74 [00:56<00:59,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.10011276320981208)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09558163265306124\n",
      "DEBUG:shap:self.fx = 0.2761666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.2761666666666666\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.08754141, -0.04662807,  0.00144615,  0.08261713,  0.0074758 ,\n",
      "        0.01144465,  0.01125674, -0.0555585 ,  0.00968723, -0.01573967,\n",
      "        0.00695832,  0.01428736, -0.00444728, -0.03537119,  0.00453113])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.10011276320981184)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09558163265306097\n",
      "DEBUG:shap:self.fx = 0.7238333333333332\n",
      "DEBUG:shap:self.link(self.fx) = 0.7238333333333332\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.08754141,  0.04662807, -0.00144615, -0.08261713, -0.0074758 ,\n",
      "       -0.01144465, -0.01125674,  0.0555585 , -0.00968723,  0.01573967,\n",
      "       -0.00695832, -0.01428736,  0.00444728,  0.03537119, -0.00453113])\n",
      " 50%|█████     | 37/74 [00:57<00:58,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.32561677437234965)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3355816326530612\n",
      "DEBUG:shap:self.fx = 0.036166666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.036166666666666666\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09439887,  0.00068138, -0.0017217 , -0.06444742,  0.00466266,\n",
      "       -0.00433041, -0.03458193, -0.03624964, -0.00935436, -0.00337801,\n",
      "       -0.00306116, -0.03923604,  0.00575364, -0.04595492, -0.00996486])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3256167743723496)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.33558163265306096\n",
      "DEBUG:shap:self.fx = 0.9638333333333332\n",
      "DEBUG:shap:self.link(self.fx) = 0.9638333333333332\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09439887, -0.00068138,  0.0017217 ,  0.06444742, -0.00466266,\n",
      "        0.00433041,  0.03458193,  0.03624964,  0.00935436,  0.00337801,\n",
      "        0.00306116,  0.03923604, -0.00575364,  0.04595492,  0.00996486])\n",
      " 51%|█████▏    | 38/74 [00:59<00:56,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.002805158194732142)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.003918367346938789\n",
      "DEBUG:shap:self.fx = 0.37566666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.37566666666666665\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.12184968, -0.08064635, -0.00662464,  0.03242424, -0.0190746 ,\n",
      "        0.00130413,  0.02943652, -0.03203231, -0.00555248, -0.0172555 ,\n",
      "       -0.00623785,  0.00940109, -0.00045286, -0.02373391,  0.00111321])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.002805158194732267)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.003918367346938845\n",
      "DEBUG:shap:self.fx = 0.6243333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.6243333333333334\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.12184968,  0.08064635,  0.00662464, -0.03242424,  0.0190746 ,\n",
      "       -0.00130413, -0.02943652,  0.03203231,  0.00555248,  0.0172555 ,\n",
      "        0.00623785, -0.00940109,  0.00045286,  0.02373391, -0.00111321])\n",
      " 53%|█████▎    | 39/74 [01:01<00:55,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.303124731716052)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2979183673469388\n",
      "DEBUG:shap:self.fx = 0.6696666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.6696666666666666\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.15344308,  0.01796938, -0.01534118,  0.06693753, -0.00330203,\n",
      "        0.00585347,  0.03425206,  0.02041249,  0.00942773,  0.02330193,\n",
      "       -0.00170744, -0.06024434, -0.02610491,  0.07822694, -0.00520636])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.30312473171605214)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.29791836734693894\n",
      "DEBUG:shap:self.fx = 0.3303333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.3303333333333333\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.15344308, -0.01796938,  0.01534118, -0.06693753,  0.00330203,\n",
      "       -0.00585347, -0.03425206, -0.02041249, -0.00942773, -0.02330193,\n",
      "        0.00170744,  0.06024434,  0.02610491, -0.07822694,  0.00520636])\n",
      " 54%|█████▍    | 40/74 [01:02<00:52,  1.54s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20359570576579625)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21224829931972786\n",
      "DEBUG:shap:self.fx = 0.1595\n",
      "DEBUG:shap:self.link(self.fx) = 0.1595\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11580454, -0.00347705,  0.00435692,  0.06578613, -0.00516043,\n",
      "       -0.01056677, -0.05742093, -0.03285687, -0.00225562, -0.00434243,\n",
      "       -0.00289165, -0.05770075, -0.00237387,  0.02111215, -0.00865259])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2035957057657962)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21224829931972777\n",
      "DEBUG:shap:self.fx = 0.8405\n",
      "DEBUG:shap:self.link(self.fx) = 0.8405\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11580454,  0.00347705, -0.00435692, -0.06578613,  0.00516043,\n",
      "        0.01056677,  0.05742093,  0.03285687,  0.00225562,  0.00434243,\n",
      "        0.00289165,  0.05770075,  0.00237387, -0.02111215,  0.00865259])\n",
      " 55%|█████▌    | 41/74 [01:04<00:51,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23908285199445392)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2579149659863945\n",
      "DEBUG:shap:self.fx = 0.11383333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.11383333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09115651, -0.00370007, -0.0182177 , -0.04958034,  0.00704925,\n",
      "        0.05352608, -0.03515839, -0.01721345,  0.00538503, -0.0106183 ,\n",
      "       -0.00162352, -0.03987863,  0.00578115, -0.04367746, -0.01883211])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23908285199445384)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2579149659863943\n",
      "DEBUG:shap:self.fx = 0.8861666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.8861666666666665\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09115651,  0.00370007,  0.0182177 ,  0.04958034, -0.00704925,\n",
      "       -0.05352608,  0.03515839,  0.01721345, -0.00538503,  0.0106183 ,\n",
      "        0.00162352,  0.03987863, -0.00578115,  0.04367746,  0.01883211])\n",
      " 57%|█████▋    | 42/74 [01:05<00:49,  1.55s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.04485170256355146)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.03829931972789119\n",
      "DEBUG:shap:self.fx = 0.41004761904761905\n",
      "DEBUG:shap:self.link(self.fx) = 0.41004761904761905\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.10480366,  0.00927709,  0.01715181,  0.06829773,  0.        ,\n",
      "        0.00319974,  0.02814761, -0.04182373, -0.03934664,  0.03243696,\n",
      "        0.00155238,  0.00695246, -0.03949122, -0.10630613, -0.00655238])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.044851702563551615)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.03829931972789136\n",
      "DEBUG:shap:self.fx = 0.5899523809523809\n",
      "DEBUG:shap:self.link(self.fx) = 0.5899523809523809\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.10480366, -0.00927709, -0.01715181, -0.06829773,  0.        ,\n",
      "       -0.00319974, -0.02814761,  0.04182373,  0.03934664, -0.03243696,\n",
      "       -0.00155238, -0.00695246,  0.03949122,  0.10630613,  0.00655238])\n",
      " 58%|█████▊    | 43/74 [01:07<00:49,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.18284141290571532)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.17341496598639453\n",
      "DEBUG:shap:self.fx = 0.19833333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.19833333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.08049481,  0.00704081, -0.01295203,  0.04383964, -0.0008958 ,\n",
      "        0.01367274,  0.03602829, -0.02470212, -0.02024999, -0.01236695,\n",
      "       -0.00631596, -0.07690081, -0.00428001, -0.04426441,  0.00942645])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1828414129057153)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1734149659863945\n",
      "DEBUG:shap:self.fx = 0.8016666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.8016666666666667\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.08049481, -0.00704081,  0.01295203, -0.04383964,  0.0008958 ,\n",
      "       -0.01367274, -0.03602829,  0.02470212,  0.02024999,  0.01236695,\n",
      "        0.00631596,  0.07690081,  0.00428001,  0.04426441, -0.00942645])\n",
      " 59%|█████▉    | 44/74 [01:08<00:47,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.39794996491398565)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.41791836734693866\n",
      "DEBUG:shap:self.fx = 0.7896666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.7896666666666665\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.17093307,  0.01700972,  0.00917045,  0.06852474,  0.00648062,\n",
      "        0.02537013,  0.03913088,  0.01285106, -0.00913553, -0.02011753,\n",
      "        0.00495486,  0.00445642,  0.00633574,  0.06198535,  0.0199684 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.39794996491398593)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4179183673469389\n",
      "DEBUG:shap:self.fx = 0.21033333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.21033333333333334\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.17093307, -0.01700972, -0.00917045, -0.06852474, -0.00648062,\n",
      "       -0.02537013, -0.03913088, -0.01285106,  0.00913553,  0.02011753,\n",
      "       -0.00495486, -0.00445642, -0.00633574, -0.06198535, -0.0199684 ])\n",
      " 61%|██████    | 45/74 [01:10<00:45,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3417970833173726)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3500816326530612\n",
      "DEBUG:shap:self.fx = 0.021666666666666664\n",
      "DEBUG:shap:self.link(self.fx) = 0.021666666666666664\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.1212136 , -0.01761257, -0.00152657, -0.0701032 , -0.00391711,\n",
      "       -0.01096778, -0.04300141, -0.02790209, -0.01790188, -0.00414042,\n",
      "        0.00893578,  0.00281973, -0.00138791, -0.03387806, -0.00828455])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.34179708331737246)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.350081632653061\n",
      "DEBUG:shap:self.fx = 0.9783333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.9783333333333333\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.1212136 ,  0.01761257,  0.00152657,  0.0701032 ,  0.00391711,\n",
      "        0.01096778,  0.04300141,  0.02790209,  0.01790188,  0.00414042,\n",
      "       -0.00893578, -0.00281973,  0.00138791,  0.03387806,  0.00828455])\n",
      " 62%|██████▏   | 46/74 [01:12<00:45,  1.61s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.15656183188751233)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.14632312925170077\n",
      "DEBUG:shap:self.fx = 0.5180714285714286\n",
      "DEBUG:shap:self.link(self.fx) = 0.5180714285714286\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.14909909,  0.00966123,  0.00828076, -0.04329159, -0.00236916,\n",
      "       -0.03116619,  0.04715798,  0.04978387,  0.00484322, -0.00254661,\n",
      "        0.00326703, -0.00604431,  0.00493918, -0.03505267, -0.0102387 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.15656183188751244)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.14632312925170088\n",
      "DEBUG:shap:self.fx = 0.4819285714285714\n",
      "DEBUG:shap:self.link(self.fx) = 0.4819285714285714\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.14909909, -0.00966123, -0.00828076,  0.04329159,  0.00236916,\n",
      "        0.03116619, -0.04715798, -0.04978387, -0.00484322,  0.00254661,\n",
      "       -0.00326703,  0.00604431, -0.00493918,  0.03505267,  0.0102387 ])\n",
      " 64%|██████▎   | 47/74 [01:13<00:42,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.45707994517989353)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.47408503401360524\n",
      "DEBUG:shap:self.fx = 0.8458333333333331\n",
      "DEBUG:shap:self.link(self.fx) = 0.8458333333333331\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.15625524,  0.02154092,  0.00294267,  0.08277451, -0.01708655,\n",
      "        0.00753977,  0.03830574,  0.03587369, -0.00383908,  0.00258783,\n",
      "       -0.00485093,  0.02426216,  0.00678241,  0.10399156,  0.01700509])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.45707994517989387)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4740850340136056\n",
      "DEBUG:shap:self.fx = 0.15416666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.15416666666666665\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.15625524, -0.02154092, -0.00294267, -0.08277451,  0.01708655,\n",
      "       -0.00753977, -0.03830574, -0.03587369,  0.00383908, -0.00258783,\n",
      "        0.00485093, -0.02426216, -0.00678241, -0.10399156, -0.01700509])\n",
      " 65%|██████▍   | 48/74 [01:15<00:40,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.10933235222234487)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.12741496598639449\n",
      "DEBUG:shap:self.fx = 0.24433333333333337\n",
      "DEBUG:shap:self.link(self.fx) = 0.24433333333333337\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09740048, -0.0545362 ,  0.00031001, -0.08256005, -0.00716733,\n",
      "       -0.00666258,  0.02332838,  0.00731871,  0.00498593,  0.01556013,\n",
      "       -0.00239758,  0.01917593,  0.        ,  0.07071278, -0.01808261])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.109332352222345)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12741496598639457\n",
      "DEBUG:shap:self.fx = 0.7556666666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.7556666666666668\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09740048,  0.0545362 , -0.00031001,  0.08256005,  0.00716733,\n",
      "        0.00666258, -0.02332838, -0.00731871, -0.00498593, -0.01556013,\n",
      "        0.00239758, -0.01917593,  0.        , -0.07071278,  0.01808261])\n",
      " 66%|██████▌   | 49/74 [01:16<00:39,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09497872408352047)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.07641496598639447\n",
      "DEBUG:shap:self.fx = 0.2953333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.2953333333333334\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.02655415,  0.0493529 ,  0.00480645, -0.03190666,  0.        ,\n",
      "       -0.02544346, -0.04899071, -0.02833533, -0.0133564 ,  0.00746104,\n",
      "       -0.00155972,  0.01291083,  0.00353276,  0.00310372,  0.01856376])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.09497872408352047)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.07641496598639452\n",
      "DEBUG:shap:self.fx = 0.7046666666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.7046666666666668\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.02655415, -0.0493529 , -0.00480645,  0.03190666,  0.        ,\n",
      "        0.02544346,  0.04899071,  0.02833533,  0.0133564 , -0.00746104,\n",
      "        0.00155972, -0.01291083, -0.00353276, -0.00310372, -0.01856376])\n",
      " 68%|██████▊   | 50/74 [01:18<00:38,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.10757686794715283)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.11674829931972791\n",
      "DEBUG:shap:self.fx = 0.25499999999999995\n",
      "DEBUG:shap:self.link(self.fx) = 0.25499999999999995\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11591505,  0.00668199,  0.01323183, -0.04375233,  0.00160269,\n",
      "        0.0193698 ,  0.00885315,  0.03085374, -0.02869321, -0.00273951,\n",
      "        0.00093625,  0.01870531, -0.00489132, -0.0118202 , -0.00917143])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.10757686794715272)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.11674829931972774\n",
      "DEBUG:shap:self.fx = 0.745\n",
      "DEBUG:shap:self.link(self.fx) = 0.745\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11591505, -0.00668199, -0.01323183,  0.04375233, -0.00160269,\n",
      "       -0.0193698 , -0.00885315, -0.03085374,  0.02869321,  0.00273951,\n",
      "       -0.00093625, -0.01870531,  0.00489132,  0.0118202 ,  0.00917143])\n",
      " 69%|██████▉   | 51/74 [01:20<00:36,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.47265699461208704)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.49832312925170064\n",
      "DEBUG:shap:self.fx = 0.8700714285714285\n",
      "DEBUG:shap:self.link(self.fx) = 0.8700714285714285\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.17710259,  0.01906431, -0.00181794,  0.07333722, -0.00058121,\n",
      "        0.01640646,  0.03352397, -0.00894458,  0.00726558, -0.01396734,\n",
      "        0.0096421 ,  0.03191026,  0.00942794,  0.12028762,  0.02566613])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4726569946120872)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4983231292517008\n",
      "DEBUG:shap:self.fx = 0.12992857142857145\n",
      "DEBUG:shap:self.link(self.fx) = 0.12992857142857145\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.17710259, -0.01906431,  0.00181794, -0.07333722,  0.00058121,\n",
      "       -0.01640646, -0.03352397,  0.00894458, -0.00726558,  0.01396734,\n",
      "       -0.0096421 , -0.03191026, -0.00942794, -0.12028762, -0.02566613])\n",
      " 70%|███████   | 52/74 [01:21<00:34,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22050828379125773)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2408673469387755\n",
      "DEBUG:shap:self.fx = 0.13088095238095235\n",
      "DEBUG:shap:self.link(self.fx) = 0.13088095238095235\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.02927437,  0.03731584, -0.0114491 , -0.04268555, -0.00388492,\n",
      "        0.00411464, -0.07148773,  0.01130689, -0.03193508, -0.0007176 ,\n",
      "       -0.00122751, -0.05420366,  0.00976431, -0.03614444, -0.02035906])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22050828379125761)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24086734693877543\n",
      "DEBUG:shap:self.fx = 0.8691190476190477\n",
      "DEBUG:shap:self.link(self.fx) = 0.8691190476190477\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.02927437, -0.03731584,  0.0114491 ,  0.04268555,  0.00388492,\n",
      "       -0.00411464,  0.07148773, -0.01130689,  0.03193508,  0.0007176 ,\n",
      "        0.00122751,  0.05420366, -0.00976431,  0.03614444,  0.02035906])\n",
      " 72%|███████▏  | 53/74 [01:23<00:32,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.16600551450460493)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.152608843537415\n",
      "DEBUG:shap:self.fx = 0.5243571428571429\n",
      "DEBUG:shap:self.link(self.fx) = 0.5243571428571429\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.11794061, -0.06382482, -0.00859732,  0.07833154,  0.00166132,\n",
      "        0.01781099,  0.01637269,  0.02418206,  0.0090508 , -0.01005285,\n",
      "        0.00409265,  0.01151635,  0.05255974, -0.08503823, -0.01339667])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1660055145046051)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.15260884353741516\n",
      "DEBUG:shap:self.fx = 0.4756428571428571\n",
      "DEBUG:shap:self.link(self.fx) = 0.4756428571428571\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.11794061,  0.06382482,  0.00859732, -0.07833154, -0.00166132,\n",
      "       -0.01781099, -0.01637269, -0.02418206, -0.0090508 ,  0.01005285,\n",
      "       -0.00409265, -0.01151635, -0.05255974,  0.08503823,  0.01339667])\n",
      " 73%|███████▎  | 54/74 [01:24<00:31,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03869667106370884)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.03968027210884362\n",
      "DEBUG:shap:self.fx = 0.4114285714285715\n",
      "DEBUG:shap:self.link(self.fx) = 0.4114285714285715\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.10538691, -0.00428947, -0.01576907,  0.09194053, -0.00587336,\n",
      "       -0.01103237, -0.09146047,  0.0493213 , -0.0004569 ,  0.01372851,\n",
      "        0.0023    , -0.0619357 ,  0.01425872, -0.04742196,  0.0009836 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.03869667106370874)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.03968027210884362\n",
      "DEBUG:shap:self.fx = 0.5885714285714286\n",
      "DEBUG:shap:self.link(self.fx) = 0.5885714285714286\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.10538691,  0.00428947,  0.01576907, -0.09194053,  0.00587336,\n",
      "        0.01103237,  0.09146047, -0.0493213 ,  0.0004569 , -0.01372851,\n",
      "       -0.0023    ,  0.0619357 , -0.01425872,  0.04742196, -0.0009836 ])\n",
      " 74%|███████▍  | 55/74 [01:26<00:29,  1.55s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2113542268149965)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.22674829931972787\n",
      "DEBUG:shap:self.fx = 0.145\n",
      "DEBUG:shap:self.link(self.fx) = 0.145\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.10128943,  0.02904215, -0.00385651, -0.03271691, -0.0037791 ,\n",
      "        0.03793275, -0.03568635, -0.02108145, -0.00346636,  0.008204  ,\n",
      "        0.        , -0.04213493, -0.00407302, -0.03844905, -0.01539407])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2113542268149963)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.22674829931972773\n",
      "DEBUG:shap:self.fx = 0.855\n",
      "DEBUG:shap:self.link(self.fx) = 0.855\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.10128943, -0.02904215,  0.00385651,  0.03271691,  0.0037791 ,\n",
      "       -0.03793275,  0.03568635,  0.02108145,  0.00346636, -0.008204  ,\n",
      "        0.        ,  0.04213493,  0.00407302,  0.03844905,  0.01539407])\n",
      " 76%|███████▌  | 56/74 [01:27<00:28,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3257134068929368)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.32508503401360567\n",
      "DEBUG:shap:self.fx = 0.6968333333333335\n",
      "DEBUG:shap:self.link(self.fx) = 0.6968333333333335\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.1392561 ,  0.01352148, -0.01183004,  0.1133532 , -0.00489172,\n",
      "       -0.0043735 ,  0.03567315,  0.04083854,  0.00598567,  0.0109639 ,\n",
      "        0.01471559,  0.00672702,  0.01819799, -0.05242398, -0.00062837])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.32571340689293676)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3250850340136056\n",
      "DEBUG:shap:self.fx = 0.30316666666666664\n",
      "DEBUG:shap:self.link(self.fx) = 0.30316666666666664\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.1392561 , -0.01352148,  0.01183004, -0.1133532 ,  0.00489172,\n",
      "        0.0043735 , -0.03567315, -0.04083854, -0.00598567, -0.0109639 ,\n",
      "       -0.01471559, -0.00672702, -0.01819799,  0.05242398,  0.00062837])\n",
      " 77%|███████▋  | 57/74 [01:29<00:26,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1939641831192978)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16565646258503408\n",
      "DEBUG:shap:self.fx = 0.5374047619047619\n",
      "DEBUG:shap:self.link(self.fx) = 0.5374047619047619\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.14896201,  0.01654118, -0.00870659, -0.05614687, -0.00113952,\n",
      "        0.02258819, -0.00425598, -0.0196131 , -0.00129858, -0.00472896,\n",
      "        0.00867088,  0.00593152,  0.00451417,  0.08264584, -0.02830772])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19396418311929778)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.16565646258503414\n",
      "DEBUG:shap:self.fx = 0.4625952380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.4625952380952381\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.14896201, -0.01654118,  0.00870659,  0.05614687,  0.00113952,\n",
      "       -0.02258819,  0.00425598,  0.0196131 ,  0.00129858,  0.00472896,\n",
      "       -0.00867088, -0.00593152, -0.00451417, -0.08264584,  0.02830772])\n",
      " 78%|███████▊  | 58/74 [01:30<00:24,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.07425646741345723)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08491496598639448\n",
      "DEBUG:shap:self.fx = 0.2868333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.2868333333333334\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.13934238,  0.0014165 ,  0.01551716, -0.05268427, -0.00574221,\n",
      "       -0.01134773,  0.02134887,  0.02630061, -0.00972008,  0.01596032,\n",
      "        0.0082011 , -0.0060214 , -0.00798135,  0.06983842, -0.0106585 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.07425646741345715)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08491496598639436\n",
      "DEBUG:shap:self.fx = 0.7131666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.7131666666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.13934238, -0.0014165 , -0.01551716,  0.05268427,  0.00574221,\n",
      "        0.01134773, -0.02134887, -0.02630061,  0.00972008, -0.01596032,\n",
      "       -0.0082011 ,  0.0060214 ,  0.00798135, -0.06983842,  0.0106585 ])\n",
      " 80%|███████▉  | 59/74 [01:32<00:23,  1.54s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.43980763470388107)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.45708503401360556\n",
      "DEBUG:shap:self.fx = 0.8288333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.8288333333333334\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.16537643,  0.02905642,  0.00685094,  0.09659151, -0.01052096,\n",
      "        0.0190793 ,  0.04605745,  0.06023099, -0.0020559 , -0.01168478,\n",
      "       -0.00851901,  0.00776275,  0.01598647,  0.02559601,  0.0172774 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4398076347038812)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.45708503401360556\n",
      "DEBUG:shap:self.fx = 0.17116666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.17116666666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.16537643, -0.02905642, -0.00685094, -0.09659151,  0.01052096,\n",
      "       -0.0190793 , -0.04605745, -0.06023099,  0.0020559 ,  0.01168478,\n",
      "        0.00851901, -0.00776275, -0.01598647, -0.02559601, -0.0172774 ])\n",
      " 81%|████████  | 60/74 [01:34<00:21,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5076630468658899)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5232517006802722\n",
      "DEBUG:shap:self.fx = 0.895\n",
      "DEBUG:shap:self.link(self.fx) = 0.895\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.1698968 ,  0.01291026, -0.00712957,  0.07217566,  0.00369345,\n",
      "        0.01853678,  0.03821367,  0.0352207 ,  0.01094727,  0.00056979,\n",
      "        0.00145847,  0.03330597, -0.00495247,  0.12281628,  0.01558865])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5076630468658898)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5232517006802723\n",
      "DEBUG:shap:self.fx = 0.105\n",
      "DEBUG:shap:self.link(self.fx) = 0.105\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.1698968 , -0.01291026,  0.00712957, -0.07217566, -0.00369345,\n",
      "       -0.01853678, -0.03821367, -0.0352207 , -0.01094727, -0.00056979,\n",
      "       -0.00145847, -0.03330597,  0.00495247, -0.12281628, -0.01558865])\n",
      " 82%|████████▏ | 61/74 [01:35<00:20,  1.60s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.03940693154852383)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.03758163265306119\n",
      "DEBUG:shap:self.fx = 0.33416666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.33416666666666667\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.10735504,  0.00885959, -0.01175366,  0.04419427,  0.00386958,\n",
      "        0.00119179,  0.02437186, -0.02352394, -0.01705807,  0.02413196,\n",
      "       -0.01252811, -0.08555417, -0.02496406, -0.077999  ,  0.0018253 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03940693154852387)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.03758163265306114\n",
      "DEBUG:shap:self.fx = 0.6658333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.6658333333333334\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.10735504, -0.00885959,  0.01175366, -0.04419427, -0.00386958,\n",
      "       -0.00119179, -0.02437186,  0.02352394,  0.01705807, -0.02413196,\n",
      "        0.01252811,  0.08555417,  0.02496406,  0.077999  , -0.0018253 ])\n",
      " 84%|████████▍ | 62/74 [01:37<00:19,  1.62s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.44213736169820234)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.440251700680272\n",
      "DEBUG:shap:self.fx = 0.8119999999999998\n",
      "DEBUG:shap:self.link(self.fx) = 0.8119999999999998\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.18557271,  0.01812339,  0.01011246,  0.07867425, -0.00535983,\n",
      "        0.00820573,  0.0411042 ,  0.03726626,  0.00344447, -0.01849403,\n",
      "       -0.00314524,  0.01953911, -0.02867147,  0.09576536, -0.00188566])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4421373616982027)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4402517006802722\n",
      "DEBUG:shap:self.fx = 0.18800000000000006\n",
      "DEBUG:shap:self.link(self.fx) = 0.18800000000000006\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.18557271, -0.01812339, -0.01011246, -0.07867425,  0.00535983,\n",
      "       -0.00820573, -0.0411042 , -0.03726626, -0.00344447,  0.01849403,\n",
      "        0.00314524, -0.01953911,  0.02867147, -0.09576536,  0.00188566])\n",
      " 85%|████████▌ | 63/74 [01:38<00:17,  1.61s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.18922113145488595)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.18458163265306118\n",
      "DEBUG:shap:self.fx = 0.18716666666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.18716666666666668\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09953044,  0.00228871,  0.01008263, -0.05912462, -0.00363736,\n",
      "        0.0096333 ,  0.02857258,  0.01623924,  0.00219598, -0.00596404,\n",
      "       -0.00817483, -0.0282082 ,  0.00073614, -0.05433023,  0.0046395 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.18922113145488587)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.18458163265306105\n",
      "DEBUG:shap:self.fx = 0.8128333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.8128333333333333\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09953044, -0.00228871, -0.01008263,  0.05912462,  0.00363736,\n",
      "       -0.0096333 , -0.02857258, -0.01623924, -0.00219598,  0.00596404,\n",
      "        0.00817483,  0.0282082 , -0.00073614,  0.05433023, -0.0046395 ])\n",
      " 86%|████████▋ | 64/74 [01:40<00:16,  1.60s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09357020846330628)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.10874829931972785\n",
      "DEBUG:shap:self.fx = 0.263\n",
      "DEBUG:shap:self.link(self.fx) = 0.263\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.12656307,  0.03121911,  0.01131731, -0.04063832, -0.00086287,\n",
      "       -0.00883342, -0.0659353 ,  0.01817348,  0.00825284,  0.00300667,\n",
      "       -0.00536017,  0.02861919, -0.00366525,  0.05769959, -0.01517809])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.09357020846330626)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.10874829931972774\n",
      "DEBUG:shap:self.fx = 0.737\n",
      "DEBUG:shap:self.link(self.fx) = 0.737\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.12656307, -0.03121911, -0.01131731,  0.04063832,  0.00086287,\n",
      "        0.00883342,  0.0659353 , -0.01817348, -0.00825284, -0.00300667,\n",
      "        0.00536017, -0.02861919,  0.00366525, -0.05769959,  0.01517809])\n",
      " 88%|████████▊ | 65/74 [01:42<00:14,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19712735101468962)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2200816326530612\n",
      "DEBUG:shap:self.fx = 0.15166666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.15166666666666667\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.13585452,  0.01517657,  0.00423061, -0.06930392,  0.00028698,\n",
      "       -0.01051895, -0.02951174, -0.03461129,  0.01386745, -0.00422496,\n",
      "       -0.00565233, -0.0102866 , -0.0037622 ,  0.07303755, -0.02295428])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1971273510146896)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.22008163265306102\n",
      "DEBUG:shap:self.fx = 0.8483333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.8483333333333333\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.13585452, -0.01517657, -0.00423061,  0.06930392, -0.00028698,\n",
      "        0.01051895,  0.02951174,  0.03461129, -0.01386745,  0.00422496,\n",
      "        0.00565233,  0.0102866 ,  0.0037622 , -0.07303755,  0.02295428])\n",
      " 89%|████████▉ | 66/74 [01:43<00:12,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17500425205391107)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.19224829931972787\n",
      "DEBUG:shap:self.fx = 0.1795\n",
      "DEBUG:shap:self.link(self.fx) = 0.1795\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.1346744 , -0.00459759,  0.00715264, -0.06036218, -0.00046258,\n",
      "        0.00646036, -0.03515662, -0.04073867,  0.00926438, -0.00583451,\n",
      "       -0.00104867,  0.01259522, -0.00041206,  0.07281043, -0.01724405])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1750042520539109)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.19224829931972776\n",
      "DEBUG:shap:self.fx = 0.8205\n",
      "DEBUG:shap:self.link(self.fx) = 0.8205\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.1346744 ,  0.00459759, -0.00715264,  0.06036218,  0.00046258,\n",
      "       -0.00646036,  0.03515662,  0.04073867, -0.00926438,  0.00583451,\n",
      "        0.00104867, -0.01259522,  0.00041206, -0.07281043,  0.01724405])\n",
      " 91%|█████████ | 67/74 [01:45<00:11,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.30260931353370263)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3384897959183675\n",
      "DEBUG:shap:self.fx = 0.7102380952380953\n",
      "DEBUG:shap:self.link(self.fx) = 0.7102380952380953\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.1558776 ,  0.00449304,  0.00861487,  0.05298183, -0.00692181,\n",
      "        0.01216346, -0.04469993, -0.01583784,  0.00381489, -0.01680049,\n",
      "        0.00094229,  0.01430321,  0.00608465,  0.12759354,  0.03588048])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3026093135337027)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3384897959183675\n",
      "DEBUG:shap:self.fx = 0.2897619047619048\n",
      "DEBUG:shap:self.link(self.fx) = 0.2897619047619048\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.1558776 , -0.00449304, -0.00861487, -0.05298183,  0.00692181,\n",
      "       -0.01216346,  0.04469993,  0.01583784, -0.00381489,  0.01680049,\n",
      "       -0.00094229, -0.01430321, -0.00608465, -0.12759354, -0.03588048])\n",
      " 92%|█████████▏| 68/74 [01:46<00:09,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.36584077147789307)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.35848979591836727\n",
      "DEBUG:shap:self.fx = 0.7302380952380951\n",
      "DEBUG:shap:self.link(self.fx) = 0.7302380952380951\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.14440097,  0.01694243,  0.00343848,  0.0767321 , -0.00233266,\n",
      "        0.02175618,  0.01969431,  0.0281611 , -0.0061743 , -0.02709973,\n",
      "        0.00369776, -0.02208725,  0.00635624,  0.10235515, -0.00735098])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.36584077147789335)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3584897959183675\n",
      "DEBUG:shap:self.fx = 0.26976190476190476\n",
      "DEBUG:shap:self.link(self.fx) = 0.26976190476190476\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.14440097, -0.01694243, -0.00343848, -0.0767321 ,  0.00233266,\n",
      "       -0.02175618, -0.01969431, -0.0281611 ,  0.0061743 ,  0.02709973,\n",
      "       -0.00369776,  0.02208725, -0.00635624, -0.10235515,  0.00735098])\n",
      " 93%|█████████▎| 69/74 [01:48<00:07,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.03204905830104218)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.03641496598639454\n",
      "DEBUG:shap:self.fx = 0.3353333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.3353333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.12795152,  0.00563542,  0.01117666, -0.04430619,  0.00456248,\n",
      "       -0.00877292, -0.05144495,  0.0775267 ,  0.01097635,  0.013057  ,\n",
      "       -0.00144576,  0.00842793,  0.00477653,  0.06573322, -0.00436591])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03204905830104206)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.03641496598639449\n",
      "DEBUG:shap:self.fx = 0.6646666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.6646666666666667\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.12795152, -0.00563542, -0.01117666,  0.04430619, -0.00456248,\n",
      "        0.00877292,  0.05144495, -0.0775267 , -0.01097635, -0.013057  ,\n",
      "        0.00144576, -0.00842793, -0.00477653, -0.06573322,  0.00436591])\n",
      " 95%|█████████▍| 70/74 [01:49<00:06,  1.55s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.09971157625663746)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09548979591836743\n",
      "DEBUG:shap:self.fx = 0.4672380952380953\n",
      "DEBUG:shap:self.link(self.fx) = 0.4672380952380953\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.16016034,  0.0063243 ,  0.01396979, -0.03894309, -0.00860143,\n",
      "        0.03106816,  0.04658127, -0.01394986,  0.        , -0.00675389,\n",
      "        0.00213388, -0.03313261,  0.00521697, -0.06436225, -0.00422178])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09971157625663744)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09548979591836748\n",
      "DEBUG:shap:self.fx = 0.5327619047619048\n",
      "DEBUG:shap:self.link(self.fx) = 0.5327619047619048\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.16016034, -0.0063243 , -0.01396979,  0.03894309,  0.00860143,\n",
      "       -0.03106816, -0.04658127,  0.01394986,  0.        ,  0.00675389,\n",
      "       -0.00213388,  0.03313261, -0.00521697,  0.06436225,  0.00422178])\n",
      " 96%|█████████▌| 71/74 [01:51<00:04,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12257506033781991)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12325170068027208\n",
      "DEBUG:shap:self.fx = 0.49499999999999994\n",
      "DEBUG:shap:self.link(self.fx) = 0.49499999999999994\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.12248434, -0.06312843, -0.00091882,  0.10563473,  0.01262862,\n",
      "       -0.00480674,  0.02840784, -0.02670736, -0.00152498, -0.00688255,\n",
      "       -0.01315696,  0.01846133,  0.02697994, -0.07489591,  0.00067664])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.12257506033781992)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.12325170068027214\n",
      "DEBUG:shap:self.fx = 0.5050000000000001\n",
      "DEBUG:shap:self.link(self.fx) = 0.5050000000000001\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.12248434,  0.06312843,  0.00091882, -0.10563473, -0.01262862,\n",
      "        0.00480674, -0.02840784,  0.02670736,  0.00152498,  0.00688255,\n",
      "        0.01315696, -0.01846133, -0.02697994,  0.07489591, -0.00067664])\n",
      " 97%|█████████▋| 72/74 [01:53<00:03,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20944763990374454)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.19708163265306117\n",
      "DEBUG:shap:self.fx = 0.1746666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.1746666666666667\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.08223496,  0.05148186,  0.00507145, -0.06102913,  0.00204984,\n",
      "       -0.03672134, -0.03831818, -0.03748417,  0.00191734, -0.00061223,\n",
      "        0.01062147,  0.00913792,  0.00159728, -0.03492482,  0.01236601])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20944763990374443)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1970816326530611\n",
      "DEBUG:shap:self.fx = 0.8253333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.8253333333333334\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.08223496, -0.05148186, -0.00507145,  0.06102913, -0.00204984,\n",
      "        0.03672134,  0.03831818,  0.03748417, -0.00191734,  0.00061223,\n",
      "       -0.01062147, -0.00913792, -0.00159728,  0.03492482, -0.01236601])\n",
      " 99%|█████████▊| 73/74 [01:54<00:01,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1461798858660979)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.15403401360544217\n",
      "DEBUG:shap:self.fx = 0.2177142857142857\n",
      "DEBUG:shap:self.link(self.fx) = 0.2177142857142857\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.10490812,  0.01085939,  0.00327615,  0.07728705, -0.00707306,\n",
      "        0.02354997, -0.06878972, -0.03285433, -0.00186577, -0.00144521,\n",
      "       -0.01036584, -0.03657084,  0.01725304, -0.01453259, -0.00785413])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.14617988586609756)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1540340136054419\n",
      "DEBUG:shap:self.fx = 0.7822857142857141\n",
      "DEBUG:shap:self.link(self.fx) = 0.7822857142857141\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.10490812, -0.01085939, -0.00327615, -0.07728705,  0.00707306,\n",
      "       -0.02354997,  0.06878972,  0.03285433,  0.00186577,  0.00144521,\n",
      "        0.01036584,  0.03657084, -0.01725304,  0.01453259,  0.00785413])\n",
      "100%|██████████| 74/74 [01:56<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.77344336084021,\n",
      "                0.7531882970742686,\n",
      "                0.7381845461365341,\n",
      "                0.7464366091522882,\n",
      "                0.6459114778694673,\n",
      "                0.6504126031507876,\n",
      "                0.5746436609152288,\n",
      "                0.5333833458364591,\n",
      "                0.46999249812453114,\n",
      "                0.6204051012753188,\n",
      "                0.46924231057764443,\n",
      "                0.47261815453863465,\n",
      "                0.481245311327832,\n",
      "                0.5048762190547638,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5584202674130104,\n",
      "                0.6152823978620233,\n",
      "                0.659037108740996,\n",
      "                0.6816295750643078,\n",
      "                0.7385189827480575,\n",
      "                0.7741145693503552,\n",
      "                0.8500390166377951,\n",
      "                0.8641993400757866,\n",
      "                0.9009943646743731,\n",
      "                0.8691958201515381,\n",
      "                0.8613699932305556,\n",
      "                0.8813517850454523,\n",
      "                0.8777005361244103,\n",
      "                0.8623889178205392,\n",
      "                0.8770640441784052\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18761853207735799,\n",
      "                0.21349258921102227,\n",
      "                0.2352747003202182,\n",
      "                0.24601078231292514,\n",
      "                0.27172150430532577,\n",
      "                0.2878702796393332,\n",
      "                0.3205881073650181,\n",
      "                0.3263050304054054,\n",
      "                0.3417079947447447,\n",
      "                0.32967059496997,\n",
      "                0.32683535510510514,\n",
      "                0.3351458415915916,\n",
      "                0.334121,\n",
      "                0.3279449376876877,\n",
      "                0.3339753430930932\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.5955988997249313,\n",
      "            \"cross_entropy\": 0.7914204479411738,\n",
      "            \"brier\": 0.29455217285525326\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7996999249812454,\n",
      "                0.8435858964741185,\n",
      "                0.8522130532633159,\n",
      "                0.8439609902475619,\n",
      "                0.8499624906226556,\n",
      "                0.8529632408102025,\n",
      "                0.8439609902475619,\n",
      "                0.8312078019504877,\n",
      "                0.8477119279819955,\n",
      "                0.8469617404351087,\n",
      "                0.8342085521380345,\n",
      "                0.8375843960990248,\n",
      "                0.8184546136534134,\n",
      "                0.822205551387847,\n",
      "                0.8244561140285072\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5568416944948791,\n",
      "                0.4803972268976447,\n",
      "                0.4913084188236074,\n",
      "                0.48321531022432596,\n",
      "                0.4551934228785443,\n",
      "                0.4634261407490266,\n",
      "                0.4708180234038162,\n",
      "                0.4800239500330183,\n",
      "                0.4797757879311866,\n",
      "                0.48390886285873796,\n",
      "                0.48857339642599973,\n",
      "                0.48575438756350914,\n",
      "                0.5010832771791706,\n",
      "                0.4984998197265036,\n",
      "                0.49914526465592496\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18404619594594598,\n",
      "                0.1502662864114114,\n",
      "                0.15474233671171173,\n",
      "                0.15330450750750751,\n",
      "                0.14288727120679354,\n",
      "                0.14654385604928907,\n",
      "                0.14893739328039773,\n",
      "                0.1514153097325642,\n",
      "                0.15262029286365447,\n",
      "                0.15439245706356866,\n",
      "                0.1549040383457437,\n",
      "                0.15376700067031318,\n",
      "                0.15993943756703133,\n",
      "                0.15819850072202304,\n",
      "                0.15791030935718886\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8366091522880722,\n",
      "            \"cross_entropy\": 0.48786433225639303,\n",
      "            \"brier\": 0.15492501289567626\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 456, 789, 1010]\n",
    "\n",
    "X = X[[\"xylose\", \"xanthosine\", \"uracil\", \"ribulose/xylulose\", \"valylglutamine\", \"tryptophylglycine\", \"succinate\", \"valine betaine\", \"ursodeoxycholate sulfate (1)\", \"tricarballylate\",\"succinimide\", \"thymine\", \"syringic acid\", \"serotonin\", \"ribitol\" ]]\n",
    "\n",
    "y = df_encoded['Group']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X),columns=X.columns,index=X.index)\n",
    "\n",
    "all_scores = {\n",
    "    'deletion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    },\n",
    "    'insertion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    }\n",
    "}\n",
    "\n",
    "for i in seeds:\n",
    "    print(\"Training Random Forest model...\")\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 7],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    model_trainer = ModelTrainer(X, y, random_state=i)\n",
    "    model, best_params = model_trainer.train_random_forest(param_dist)\n",
    "\n",
    "    background_data = shap.kmeans(model_trainer.X_train, 100)\n",
    "    explainer = shap.KernelExplainer(model.predict_proba, background_data)\n",
    "\n",
    "    shap_values = explainer.shap_values(model_trainer.X_test)\n",
    "\n",
    "    result = evaluate_global_shap_scores(model, model_trainer.X_test, model_trainer.y_test, shap_values)\n",
    "\n",
    "    for method in ['deletion', 'insertion']:\n",
    "        for metric in ['auroc', 'cross_entropy', 'brier']:\n",
    "            all_scores[method][metric].append(result[method][\"average_scores\"][metric])\n",
    "\n",
    "    import json\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.6155557286380419,\n",
      "            \"std\": 0.025009852723275047\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.8044518529261528,\n",
      "            \"std\": 0.032395437669372876\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.30158404917624626,\n",
      "            \"std\": 0.015052282006838936\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.8548635154444065,\n",
      "            \"std\": 0.02849115712478812\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.4674328561344403,\n",
      "            \"std\": 0.036029267580464895\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.14747157214087334,\n",
      "            \"std\": 0.014843916537739232\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "final_results = {\n",
    "    'deletion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['deletion'].items()\n",
    "    },\n",
    "    'insertion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['insertion'].items()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(json.dumps(final_results, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBS Causal SHAP Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_paths = ['../../../result/IBS/Causal_SHAP_IBS_42.pkl', '../../../result/IBS/Causal_SHAP_IBS_123.pkl', '../../../result/IBS/Causal_SHAP_IBS_456.pkl', '../../../result/IBS/Causal_SHAP_IBS_789.pkl', '../../../result/IBS/Causal_SHAP_IBS_1010.pkl']\n",
    "\n",
    "def load_and_format_shap_values(file_path, feature_names):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    # Convert list of dicts to numpy array\n",
    "    n_samples = len(data)\n",
    "    n_features = len(feature_names)\n",
    "    shap_array = np.zeros((n_samples, n_features))\n",
    "    \n",
    "    for i, instance in enumerate(data):\n",
    "        for j, feature in enumerate(feature_names):\n",
    "            shap_array[i, j] = instance.get(feature, 0)\n",
    "    \n",
    "    return shap_array\n",
    "\n",
    "# Usage\n",
    "feature_names = X.columns.tolist()\n",
    "causal_shap_values = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    formatted_values = load_and_format_shap_values(file_path, feature_names)\n",
    "    causal_shap_values.append(formatted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8020833333333333,\n",
      "                0.7131410256410257,\n",
      "                0.7131410256410257,\n",
      "                0.6145833333333333,\n",
      "                0.6185897435897436,\n",
      "                0.6233974358974359,\n",
      "                0.5817307692307693,\n",
      "                0.594551282051282,\n",
      "                0.5953525641025641,\n",
      "                0.6073717948717949,\n",
      "                0.5945512820512819,\n",
      "                0.6378205128205129,\n",
      "                0.6422275641025641,\n",
      "                0.4911858974358975,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5333619228350892,\n",
      "                0.6176319966059503,\n",
      "                0.7117184396839162,\n",
      "                0.7458745657755351,\n",
      "                0.7544846458433045,\n",
      "                0.7643038992941047,\n",
      "                0.821400464724071,\n",
      "                0.847067025492969,\n",
      "                0.8668130379941142,\n",
      "                0.8891361917078303,\n",
      "                0.9339429947820997,\n",
      "                0.924163630982221,\n",
      "                0.9035509841238791,\n",
      "                0.8925618058423742,\n",
      "                0.9272027411818561\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17575241929729749,\n",
      "                0.21478375157982196,\n",
      "                0.2597070037610788,\n",
      "                0.27604349501841946,\n",
      "                0.27991708339961313,\n",
      "                0.2844424229388321,\n",
      "                0.31193143333661116,\n",
      "                0.3233782880092635,\n",
      "                0.33203258800467644,\n",
      "                0.3413062780808007,\n",
      "                0.35965035941518275,\n",
      "                0.3559432155331778,\n",
      "                0.34736284251859567,\n",
      "                0.3432399848039314,\n",
      "                0.3581441230715909\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6219818376068376,\n",
      "            \"cross_entropy\": 0.8088809564579544,\n",
      "            \"brier\": 0.3042423525845929\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8565705128205129,\n",
      "                0.8497596153846154,\n",
      "                0.8445512820512819,\n",
      "                0.8878205128205128,\n",
      "                0.8910256410256411,\n",
      "                0.8878205128205129,\n",
      "                0.8774038461538461,\n",
      "                0.8822115384615384,\n",
      "                0.8774038461538461,\n",
      "                0.8798076923076924,\n",
      "                0.8806089743589745,\n",
      "                0.8838141025641025,\n",
      "                0.8782051282051282,\n",
      "                0.8846153846153846,\n",
      "                0.8782051282051282\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5577995700528187,\n",
      "                0.48561723474015095,\n",
      "                0.4655374628351458,\n",
      "                0.4380237734852441,\n",
      "                0.4442835781441994,\n",
      "                0.44640795836777464,\n",
      "                0.44765061538967194,\n",
      "                0.4426989729961006,\n",
      "                0.4452145470994406,\n",
      "                0.44550351090404394,\n",
      "                0.43598045275578146,\n",
      "                0.42746930445675824,\n",
      "                0.4283525816854086,\n",
      "                0.42277047467250956,\n",
      "                0.43130759728033224\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18281475287193621,\n",
      "                0.15138956546440746,\n",
      "                0.145363733060362,\n",
      "                0.13537964233817612,\n",
      "                0.13811109520936868,\n",
      "                0.13900521757066117,\n",
      "                0.13968135646795402,\n",
      "                0.13749926306716267,\n",
      "                0.13861799075393094,\n",
      "                0.13961429267355152,\n",
      "                0.1357247122086571,\n",
      "                0.13268623870064064,\n",
      "                0.1327547844285534,\n",
      "                0.13054367695291189,\n",
      "                0.13441740529050694\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8759882478632478,\n",
      "            \"cross_entropy\": 0.45097450899102526,\n",
      "            \"brier\": 0.14090691513725204\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7875,\n",
      "                0.7458333333333332,\n",
      "                0.6608333333333333,\n",
      "                0.56,\n",
      "                0.5341666666666667,\n",
      "                0.5449999999999999,\n",
      "                0.4741666666666666,\n",
      "                0.4916666666666667,\n",
      "                0.5083333333333333,\n",
      "                0.4925,\n",
      "                0.46333333333333326,\n",
      "                0.47583333333333333,\n",
      "                0.5475,\n",
      "                0.46916666666666673,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5893880935369175,\n",
      "                0.6939687843745195,\n",
      "                0.7861497864710774,\n",
      "                0.8458936405573276,\n",
      "                0.8563292153869034,\n",
      "                0.8614756871522624,\n",
      "                0.8846286320184191,\n",
      "                0.8939189794493904,\n",
      "                0.9521357012719036,\n",
      "                0.9957748941580877,\n",
      "                1.0225135070200213,\n",
      "                1.0346153137679555,\n",
      "                0.9121359840206228,\n",
      "                0.9619538315570729,\n",
      "                0.9404186671352546\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.20014143968821002,\n",
      "                0.25060080888344277,\n",
      "                0.29290152701464217,\n",
      "                0.3204676327258146,\n",
      "                0.3250657168676518,\n",
      "                0.32722921073518113,\n",
      "                0.3375658266482527,\n",
      "                0.34093980394650514,\n",
      "                0.36567267078231797,\n",
      "                0.3832999169260126,\n",
      "                0.39332163692886773,\n",
      "                0.3976958840847826,\n",
      "                0.3522985231076693,\n",
      "                0.3737091000733354,\n",
      "                0.3649649438114703\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.5503888888888888,\n",
      "            \"cross_entropy\": 0.8820867145251824,\n",
      "            \"brier\": 0.3350583094816104\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7708333333333334,\n",
      "                0.7929166666666666,\n",
      "                0.8433333333333333,\n",
      "                0.8591666666666667,\n",
      "                0.8625,\n",
      "                0.8658333333333333,\n",
      "                0.8641666666666666,\n",
      "                0.8633333333333333,\n",
      "                0.8475,\n",
      "                0.845,\n",
      "                0.8508333333333333,\n",
      "                0.8466666666666667,\n",
      "                0.8308333333333333,\n",
      "                0.8333333333333334,\n",
      "                0.8291666666666667\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.6613720387481131,\n",
      "                0.5813672929279904,\n",
      "                0.5108789761289761,\n",
      "                0.4728810069891966,\n",
      "                0.46816023951512614,\n",
      "                0.46518595588889494,\n",
      "                0.46072975332157917,\n",
      "                0.4577855507947911,\n",
      "                0.46962335931889193,\n",
      "                0.47351118242045903,\n",
      "                0.47416295924753366,\n",
      "                0.47002089754970217,\n",
      "                0.49733548742144135,\n",
      "                0.4871241976779984,\n",
      "                0.4891898601283233\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.22809981569093526,\n",
      "                0.19605940381276157,\n",
      "                0.16857600403574025,\n",
      "                0.15332288574781724,\n",
      "                0.15190677633547675,\n",
      "                0.15081303945342128,\n",
      "                0.14896174104169768,\n",
      "                0.14710402713458515,\n",
      "                0.1504874565246574,\n",
      "                0.15216776543777213,\n",
      "                0.15248019862232925,\n",
      "                0.15122474485640175,\n",
      "                0.16156096150094154,\n",
      "                0.15805205753032267,\n",
      "                0.15935898123209713\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8403611111111112,\n",
      "            \"cross_entropy\": 0.4959552505386011,\n",
      "            \"brier\": 0.1620117239304638\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8387096774193548,\n",
      "                0.7741935483870968,\n",
      "                0.7449362340585146,\n",
      "                0.7351837959489873,\n",
      "                0.7164291072768192,\n",
      "                0.7404351087771943,\n",
      "                0.695423855963991,\n",
      "                0.6969242310577645,\n",
      "                0.6879219804951238,\n",
      "                0.6271567891972993,\n",
      "                0.568642160540135,\n",
      "                0.632033008252063,\n",
      "                0.6219054763690922,\n",
      "                0.5626406601650413,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5193068224943925,\n",
      "                0.5884276777641769,\n",
      "                0.6528984636814126,\n",
      "                0.6769923018390795,\n",
      "                0.6828393719866309,\n",
      "                0.6789103549658556,\n",
      "                0.7261480090260554,\n",
      "                0.7375841733114205,\n",
      "                0.7462689942210788,\n",
      "                0.7821190731505933,\n",
      "                0.8683993068767332,\n",
      "                0.8760320874142727,\n",
      "                0.8815356593522089,\n",
      "                0.8507441265848273,\n",
      "                0.8937715432763311\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.16720830628118008,\n",
      "                0.20064877500497325,\n",
      "                0.23147481697693523,\n",
      "                0.24276897776608453,\n",
      "                0.24557780087687597,\n",
      "                0.24383818529408438,\n",
      "                0.26630388528749843,\n",
      "                0.27150835211641267,\n",
      "                0.2756389985298862,\n",
      "                0.2921601807702154,\n",
      "                0.3288839815908064,\n",
      "                0.3317336478636907,\n",
      "                0.33372936500829065,\n",
      "                0.3223428025595217,\n",
      "                0.3406323110321205\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6761690422605651,\n",
      "            \"cross_entropy\": 0.744131864396338,\n",
      "            \"brier\": 0.2729633591305717\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8945986496624156,\n",
      "                0.8807201800450112,\n",
      "                0.9017254313578394,\n",
      "                0.9167291822955739,\n",
      "                0.9144786196549137,\n",
      "                0.9009752438109527,\n",
      "                0.8829707426856714,\n",
      "                0.8784696174043511,\n",
      "                0.8844711177794449,\n",
      "                0.886721680420105,\n",
      "                0.8927231807951987,\n",
      "                0.8972243060765192,\n",
      "                0.8912228057014253,\n",
      "                0.8957239309827456,\n",
      "                0.8994748687171792\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5339335987660522,\n",
      "                0.4644702556151713,\n",
      "                0.41740777547848185,\n",
      "                0.38370294811830236,\n",
      "                0.3864523954295421,\n",
      "                0.3985990045824139,\n",
      "                0.40193552863054616,\n",
      "                0.4066080191823932,\n",
      "                0.40705156811768256,\n",
      "                0.4035936477584196,\n",
      "                0.4019949745622336,\n",
      "                0.39591901362547177,\n",
      "                0.400364212711417,\n",
      "                0.3989797570020913,\n",
      "                0.40118807518577815\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17395977258876588,\n",
      "                0.14233368561447618,\n",
      "                0.12648882895646923,\n",
      "                0.11529523911652789,\n",
      "                0.11639516830580525,\n",
      "                0.12023709020920365,\n",
      "                0.12201136849019512,\n",
      "                0.12159425470597084,\n",
      "                0.12245391893365515,\n",
      "                0.12090561827649288,\n",
      "                0.11986550681155662,\n",
      "                0.11772343355522369,\n",
      "                0.11923461935954412,\n",
      "                0.11867717145159401,\n",
      "                0.11986653926437998\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8945486371592898,\n",
      "            \"cross_entropy\": 0.41348005165106644,\n",
      "            \"brier\": 0.12513614770932405\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8286445012787723,\n",
      "                0.7468030690537085,\n",
      "                0.710997442455243,\n",
      "                0.6317135549872123,\n",
      "                0.6351236146632566,\n",
      "                0.5524296675191817,\n",
      "                0.4876385336743393,\n",
      "                0.5831202046035806,\n",
      "                0.5950554134697357,\n",
      "                0.5507246376811594,\n",
      "                0.463768115942029,\n",
      "                0.46675191815856787,\n",
      "                0.46078431372549017,\n",
      "                0.4671781756180733,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5247611733780392,\n",
      "                0.5992980891784528,\n",
      "                0.6592960329956608,\n",
      "                0.7030805887135134,\n",
      "                0.7123429769697089,\n",
      "                0.7792986083853992,\n",
      "                0.8037872866271865,\n",
      "                0.8157944287928084,\n",
      "                0.8312201302583456,\n",
      "                0.8499798908110113,\n",
      "                0.9004801982080393,\n",
      "                0.8711329850339488,\n",
      "                0.8567397830951963,\n",
      "                0.8482023882172938,\n",
      "                0.8697720218315294\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17191309223617363,\n",
      "                0.20559231482901733,\n",
      "                0.23306026497931379,\n",
      "                0.2545604943132168,\n",
      "                0.25885472716700286,\n",
      "                0.2916288575515612,\n",
      "                0.30362085631261115,\n",
      "                0.3093286612325834,\n",
      "                0.3165553167224293,\n",
      "                0.3251276681479757,\n",
      "                0.3473243173536318,\n",
      "                0.33486828613858943,\n",
      "                0.32836808345053226,\n",
      "                0.3246201718081623,\n",
      "                0.3348469112139148\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.5787155441886899,\n",
      "            \"cross_entropy\": 0.7750124388330756,\n",
      "            \"brier\": 0.2893513348971144\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8047740835464622,\n",
      "                0.8405797101449275,\n",
      "                0.8729752770673486,\n",
      "                0.8644501278772379,\n",
      "                0.8678601875532822,\n",
      "                0.8635976129582268,\n",
      "                0.8687127024722933,\n",
      "                0.8584825234441603,\n",
      "                0.8431372549019608,\n",
      "                0.8465473145780051,\n",
      "                0.845694799658994,\n",
      "                0.8482523444160273,\n",
      "                0.855072463768116,\n",
      "                0.8533674339300937,\n",
      "                0.8533674339300937\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.6304875596901828,\n",
      "                0.5231308843317846,\n",
      "                0.4637947978058688,\n",
      "                0.45061291867255465,\n",
      "                0.4464000778634561,\n",
      "                0.43741959341963843,\n",
      "                0.4343828088814684,\n",
      "                0.44095534195423597,\n",
      "                0.449821537239907,\n",
      "                0.4488176755567255,\n",
      "                0.44574551781082855,\n",
      "                0.4432763960927437,\n",
      "                0.4416409651042574,\n",
      "                0.44278392951614776,\n",
      "                0.45297774690534315\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.21120993032259455,\n",
      "                0.1662162563773505,\n",
      "                0.14575619665769501,\n",
      "                0.13865086965929263,\n",
      "                0.13745506200715107,\n",
      "                0.13346606119201282,\n",
      "                0.13267303433366406,\n",
      "                0.13544096246814463,\n",
      "                0.14009645039920346,\n",
      "                0.13952960336446998,\n",
      "                0.1379663286517446,\n",
      "                0.13606350263967296,\n",
      "                0.13568799279153657,\n",
      "                0.13671727850999613,\n",
      "                0.14064052329750873\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8524580846831484,\n",
      "            \"cross_entropy\": 0.4634831833896762,\n",
      "            \"brier\": 0.14450467017813587\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8274568642160541,\n",
      "                0.7531882970742686,\n",
      "                0.7381845461365341,\n",
      "                0.7464366091522882,\n",
      "                0.6459114778694673,\n",
      "                0.5697674418604651,\n",
      "                0.5836459114778695,\n",
      "                0.5656414103525882,\n",
      "                0.5468867216804201,\n",
      "                0.4553638409602401,\n",
      "                0.4343585896474118,\n",
      "                0.46061515378844714,\n",
      "                0.3683420855213803,\n",
      "                0.33908477119279823,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5110473030180641,\n",
      "                0.6152823978620233,\n",
      "                0.659037108740996,\n",
      "                0.6816295750643078,\n",
      "                0.7385189827480575,\n",
      "                0.8083555665781142,\n",
      "                0.809865226540508,\n",
      "                0.816834065043128,\n",
      "                0.8645194716902611,\n",
      "                0.9089021997755932,\n",
      "                0.9303423241854474,\n",
      "                0.9146826912239642,\n",
      "                0.8917415155132613,\n",
      "                0.9101248109726001,\n",
      "                0.8770640441784052\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.1613070374934884,\n",
      "                0.21349258921102227,\n",
      "                0.2352747003202182,\n",
      "                0.24601078231292514,\n",
      "                0.27172150430532577,\n",
      "                0.30185235940277017,\n",
      "                0.30259065412606484,\n",
      "                0.30583363363363364,\n",
      "                0.32696897560060056,\n",
      "                0.34533637950450446,\n",
      "                0.35349237499999997,\n",
      "                0.3474291144894895,\n",
      "                0.33930961148648653,\n",
      "                0.34657311711711714,\n",
      "                0.3339753430930932\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.5689922480620155,\n",
      "            \"cross_entropy\": 0.7958631522089822,\n",
      "            \"brier\": 0.2954112118064493\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8038259564891225,\n",
      "                0.8435858964741185,\n",
      "                0.8522130532633159,\n",
      "                0.8439609902475619,\n",
      "                0.8499624906226556,\n",
      "                0.8454613653413353,\n",
      "                0.8372093023255813,\n",
      "                0.8267066766691673,\n",
      "                0.8173293323330834,\n",
      "                0.8300825206301575,\n",
      "                0.8364591147786947,\n",
      "                0.837959489872468,\n",
      "                0.8304576144036009,\n",
      "                0.8259564891222806,\n",
      "                0.8244561140285072\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.6925534341410899,\n",
      "                0.4803972268976447,\n",
      "                0.4913084188236074,\n",
      "                0.48321531022432596,\n",
      "                0.4551934228785443,\n",
      "                0.4621389745448629,\n",
      "                0.4766297945078694,\n",
      "                0.4832814192871908,\n",
      "                0.49814563592381705,\n",
      "                0.4937059988487875,\n",
      "                0.49149806755161485,\n",
      "                0.48823035493208217,\n",
      "                0.492851668726223,\n",
      "                0.49383665145030414,\n",
      "                0.49914526465592496\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.249799322072072,\n",
      "                0.1502662864114114,\n",
      "                0.15474233671171173,\n",
      "                0.15330450750750751,\n",
      "                0.14288727120679354,\n",
      "                0.1451331718548906,\n",
      "                0.15032873661671875,\n",
      "                0.15207793787154503,\n",
      "                0.15736487452503525,\n",
      "                0.15784162801066373,\n",
      "                0.15690941367898512,\n",
      "                0.15577429668443954,\n",
      "                0.1557842093004995,\n",
      "                0.15585027074715022,\n",
      "                0.15791030935718886\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8337084271067766,\n",
      "            \"cross_entropy\": 0.49880877622625935,\n",
      "            \"brier\": 0.15973163817044084\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 456, 789, 1010]\n",
    "\n",
    "X = X[[\"xylose\", \"xanthosine\", \"uracil\", \"ribulose/xylulose\", \"valylglutamine\", \"tryptophylglycine\", \"succinate\", \"valine betaine\", \"ursodeoxycholate sulfate (1)\", \"tricarballylate\",\"succinimide\", \"thymine\", \"syringic acid\", \"serotonin\", \"ribitol\" ]]\n",
    "\n",
    "y = df_encoded['Group']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X),columns=X.columns,index=X.index)\n",
    "\n",
    "all_scores = {\n",
    "    'deletion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    },\n",
    "    'insertion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    }\n",
    "}\n",
    "\n",
    "idx = 0\n",
    "for i in seeds:\n",
    "    print(\"Training Random Forest model...\")\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 7],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    model_trainer = ModelTrainer(X, y, random_state=i)\n",
    "    model, best_params = model_trainer.train_random_forest(param_dist)\n",
    "\n",
    "    result = evaluate_global_shap_scores(model, model_trainer.X_test, model_trainer.y_test, pd.Series(np.abs(causal_shap_values[idx]).mean(axis=0), index=feature_names), causal=True)\n",
    "\n",
    "    for method in ['deletion', 'insertion']:\n",
    "        for metric in ['auroc', 'cross_entropy', 'brier']:\n",
    "            all_scores[method][metric].append(result[method][\"average_scores\"][metric])\n",
    "\n",
    "    import json\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n",
    "\n",
    "    idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.5992495122013993,\n",
      "            \"std\": 0.04507300546645652\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.8011950252843064,\n",
      "            \"std\": 0.045984127610605406\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.2994053135800677,\n",
      "            \"std\": 0.02054626659289343\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.8594129015847148,\n",
      "            \"std\": 0.022721453409459143\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.46454035415932565,\n",
      "            \"std\": 0.0314754657562984\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.1464582190251233,\n",
      "            \"std\": 0.013471148605793222\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "final_results = {\n",
    "    'deletion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['deletion'].items()\n",
    "    },\n",
    "    'insertion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['insertion'].items()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(json.dumps(final_results, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Performing feature selection using SHAP importance...\")\n",
    "# selected_features_shap = feature_selector.shap_importance(model_trainer.X_test, threshold=0.005)\n",
    "# print(\"Feature selection (SHAP importance) completed.\")\n",
    "\n",
    "# print(\"Generating SHAP summary plot...\")\n",
    "# visualizer = Visualizer()\n",
    "# shap_summary_path = result_dir + 'shap_summary.png'\n",
    "# visualizer.plot_shap_summary(model, model_trainer.X_test, str(shap_summary_path))\n",
    "# print(f\"SHAP summary plot saved at: {shap_summary_path}\")\n",
    "\n",
    "# print(\"Performing causal inference...with SHAP selected and Group\")\n",
    "# causal_features = selected_features_shap.to_list() + ['Group']\n",
    "# df_causal = df_encoded[causal_features]\n",
    "# causal_inference = CausalInference(df_causal)\n",
    "# causal_graph = causal_inference.run_pc_algorithm()\n",
    "# print(\"Causal inference completed.\")\n",
    "\n",
    "# print(\"Drawing causal graph...\")\n",
    "# causal_graph_path = result_dir + 'causal_graph.png'\n",
    "# causal_inference.draw_graph(str(causal_graph_path))\n",
    "# print(f\"Causal graph saved at: {causal_graph_path}\")\n",
    "\n",
    "# print(\"Writing report...\")\n",
    "# with open(report_file_path, 'w') as report_file:\n",
    "#     report_file.write(\"First few rows of the dataset:\\n\")\n",
    "#     report_file.write(df.head().to_string())\n",
    "#     report_file.write(\"\\n\\n\")\n",
    "#     report_file.write(\"Best Parameters:\\n\")\n",
    "#     report_file.write(str(best_params))\n",
    "#     report_file.write(\"\\n\\n\")\n",
    "#     report_file.write(f\"Accuracy: {accuracy * 100:.2f}%\\n\\n\")\n",
    "#     report_file.write(\"Classification Report:\\n\")\n",
    "#     report_file.write(report)\n",
    "#     report_file.write(\"\\n\\n\")\n",
    "#     report_file.write(\"Selected Features (Gini Importance):\\n\")\n",
    "#     report_file.write(', '.join(selected_features_gini))\n",
    "#     report_file.write(\"\\n\\n\")\n",
    "#     report_file.write(\"Selected Features (SHAP Importance):\\n\")\n",
    "#     report_file.write(', '.join(selected_features_shap))\n",
    "#     report_file.write(\"\\n\\n\")\n",
    "#     report_file.write(f\"SHAP summary plot saved as '{shap_summary_path}'.\\n\\n\")\n",
    "#     report_file.write(f\"Causal graph saved as '{causal_graph_path}'.\\n\")\n",
    "# print(\"Report written successfully.\")\n",
    "\n",
    "# print(f\"Report generated at '{report_file_path}'.\")\n",
    "# print(\"Process completed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
