{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\snorl\\Desktop\\FYP\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "from data_processing import DataProcessor\n",
    "from models import ModelTrainer\n",
    "from feature_selection import FeatureSelector\n",
    "from visualization import Visualizer\n",
    "from causal_inference import CausalInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ML Pipeline...\n",
      "Base directory set to: ../../../\n",
      "Loading data...\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting ML Pipeline...\")\n",
    "base_dir = '../../../'\n",
    "print(f\"Base directory set to: {base_dir}\")\n",
    "\n",
    "data_path = base_dir + 'dataset/' + 'data_full.xlsx'\n",
    "raw_data_path = base_dir + 'dataset/' + 'result_raw.xlsx'\n",
    "result_dir = base_dir + 'result/'\n",
    "\n",
    "report_file_path = result_dir + 'report.txt'\n",
    "\n",
    "print(\"Loading data...\")\n",
    "data_processor = DataProcessor(data_path=str(data_path))\n",
    "df = data_processor.load_data_metabolites()\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing raw data...\n",
      "Raw data preprocessed successfully.\n",
      "Encoding labels...\n",
      "Labels encoded successfully.\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Model trained successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preprocessing raw data...\")\n",
    "raw_df = data_processor.preprocess_raw_data(raw_data_path=str(raw_data_path))\n",
    "print(\"Raw data preprocessed successfully.\")\n",
    "\n",
    "print(\"Encoding labels...\")\n",
    "df_encoded, label_encoder = data_processor.encode_labels(df, label_column='Group')\n",
    "print(\"Labels encoded successfully.\")\n",
    "\n",
    "X = df_encoded.drop(columns=['Group'])\n",
    "y = df_encoded['Group']\n",
    "\n",
    "print(\"Training Random Forest model...\")\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 7],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "model_trainer = ModelTrainer(X, y)\n",
    "model, best_params = model_trainer.train_random_forest(param_dist)\n",
    "print(\"Model trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "Model evaluation completed.\n",
      "Saving trained model...\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating model...\")\n",
    "accuracy, report = model_trainer.evaluate_model()\n",
    "print(\"Model evaluation completed.\")\n",
    "\n",
    "print(\"Saving trained model...\")\n",
    "model_trainer.save_model(str(result_dir + 'best_random_forest_model.pkl'))\n",
    "print(\"Model saved successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing feature selection using Gini importance...\n",
      "Feature selection (Gini importance) completed.\n",
      "Performing feature selection using SHAP importance...\n",
      "Feature selection (SHAP importance) completed.\n",
      "Generating SHAP summary plot...\n",
      "SHAP summary plot saved at: ../../../result/shap_summary.png\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing feature selection using Gini importance...\")\n",
    "feature_selector = FeatureSelector(model, model_trainer.X_train)\n",
    "selected_features_gini = feature_selector.gini_importance(threshold=0.01)\n",
    "print(\"Feature selection (Gini importance) completed.\")\n",
    "\n",
    "print(\"Performing feature selection using SHAP importance...\")\n",
    "selected_features_shap = feature_selector.shap_importance(model_trainer.X_test, threshold=0.005)\n",
    "print(\"Feature selection (SHAP importance) completed.\")\n",
    "\n",
    "print(\"Generating SHAP summary plot...\")\n",
    "visualizer = Visualizer()\n",
    "shap_summary_path = result_dir + 'shap_summary.png'\n",
    "visualizer.plot_shap_summary(model, model_trainer.X_test, str(shap_summary_path))\n",
    "print(f\"SHAP summary plot saved at: {shap_summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing causal inference...with SHAP selected and Group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Depth=6, working on node 20: 100%|██████████| 21/21 [00:00<00:00, 1415.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal inference completed.\n",
      "Drawing causal graph...\n",
      "Causal graph saved at: ../../../result/causal_graph.png\n",
      "Writing report...\n",
      "Report written successfully.\n",
      "Report generated at '../../../result/report.txt'.\n",
      "Process completed successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing causal inference...with SHAP selected and Group\")\n",
    "causal_features = selected_features_shap.to_list() + ['Group']\n",
    "df_causal = df_encoded[causal_features]\n",
    "causal_inference = CausalInference(df_causal)\n",
    "causal_graph = causal_inference.run_pc_algorithm()\n",
    "print(\"Causal inference completed.\")\n",
    "\n",
    "print(\"Drawing causal graph...\")\n",
    "causal_graph_path = result_dir + 'causal_graph.png'\n",
    "causal_inference.draw_graph(str(causal_graph_path))\n",
    "print(f\"Causal graph saved at: {causal_graph_path}\")\n",
    "\n",
    "print(\"Writing report...\")\n",
    "with open(report_file_path, 'w') as report_file:\n",
    "    report_file.write(\"First few rows of the dataset:\\n\")\n",
    "    report_file.write(df.head().to_string())\n",
    "    report_file.write(\"\\n\\n\")\n",
    "    report_file.write(\"Best Parameters:\\n\")\n",
    "    report_file.write(str(best_params))\n",
    "    report_file.write(\"\\n\\n\")\n",
    "    report_file.write(f\"Accuracy: {accuracy * 100:.2f}%\\n\\n\")\n",
    "    report_file.write(\"Classification Report:\\n\")\n",
    "    report_file.write(report)\n",
    "    report_file.write(\"\\n\\n\")\n",
    "    report_file.write(\"Selected Features (Gini Importance):\\n\")\n",
    "    report_file.write(', '.join(selected_features_gini))\n",
    "    report_file.write(\"\\n\\n\")\n",
    "    report_file.write(\"Selected Features (SHAP Importance):\\n\")\n",
    "    report_file.write(', '.join(selected_features_shap))\n",
    "    report_file.write(\"\\n\\n\")\n",
    "    report_file.write(f\"SHAP summary plot saved as '{shap_summary_path}'.\\n\\n\")\n",
    "    report_file.write(f\"Causal graph saved as '{causal_graph_path}'.\\n\")\n",
    "print(\"Report written successfully.\")\n",
    "\n",
    "print(f\"Report generated at '{report_file_path}'.\")\n",
    "print(\"Process completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'IDA' from 'causallearn.search' (c:\\Users\\snorl\\Desktop\\FYP\\venv\\lib\\site-packages\\causallearn\\search\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcausallearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msearch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IDA\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'IDA' from 'causallearn.search' (c:\\Users\\snorl\\Desktop\\FYP\\venv\\lib\\site-packages\\causallearn\\search\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from causallearn.search import IDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
