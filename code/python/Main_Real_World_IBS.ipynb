{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\snorl\\Desktop\\FYP\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "DEBUG:matplotlib:matplotlib data path: c:\\Users\\snorl\\Desktop\\FYP\\venv\\Lib\\site-packages\\matplotlib\\mpl-data\n",
      "DEBUG:matplotlib:CONFIGDIR=C:\\Users\\snorl\\.matplotlib\n",
      "DEBUG:matplotlib:interactive is False\n",
      "DEBUG:matplotlib:platform is win32\n",
      "DEBUG:matplotlib:CACHEDIR=C:\\Users\\snorl\\.matplotlib\n",
      "DEBUG:matplotlib.font_manager:Using fontManager instance from C:\\Users\\snorl\\.matplotlib\\fontlist-v390.json\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from evaluation import evaluate_global_shap_scores\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"numba\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"shap\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.WARNING)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from evaluation import evaluate_global_shap_scores\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from shapflow import flow\n",
    "import sys\n",
    "if '../' not in sys.path:\n",
    "    sys.path = ['../'] + sys.path\n",
    "from shapflow.flow import Node, Graph, GraphExplainer\n",
    "from on_manifold import OnManifoldExplainer, IndExplainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ML Pipeline...\n",
      "Base directory set to: ../../\n",
      "Loading data...\n",
      "Data loaded successfully.\n",
      "368\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting ML Pipeline...\")\n",
    "base_dir = '../../'\n",
    "print(f\"Base directory set to: {base_dir}\")\n",
    "\n",
    "data_path = base_dir + 'dataset/' + 'Real_World_IBS.xlsx'\n",
    "result_dir = base_dir + 'result/'\n",
    "\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_excel(data_path)\n",
    "df = df.drop(columns=['HAD_Anxiety', 'Patient', 'Batch_metabolomics', 'BH', 'Sex', 'Age', 'BMI','Race','Education','HAD_Depression','STAI_Tanxiety', 'Diet_Category','Diet_Pattern'])\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding labels...\n",
      "Labels encoded successfully.\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Model trained successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoding labels...\")\n",
    "label_encoder = LabelEncoder()\n",
    "df['Group'] = label_encoder.fit_transform(df['Group'])\n",
    "df_encoded = df\n",
    "\n",
    "print(\"Labels encoded successfully.\")\n",
    "\n",
    "X = df_encoded.drop(columns=['Group'])\n",
    "y = df_encoded['Group']\n",
    "\n",
    "print(\"Training Random Forest model...\")\n",
    "param_dist = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 7],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "random_search = RandomizedSearchCV(\n",
    "estimator=rf, param_distributions=param_dist, n_iter=50,\n",
    "        cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "print(\"Model trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "X = X[[\"xylose\", \"xanthosine\", \"uracil\", \"ribulose/xylulose\", \"valylglutamine\", \"tryptophylglycine\", \"succinate\", \"valine betaine\", \"ursodeoxycholate sulfate (1)\", \"tricarballylate\",\"succinimide\", \"thymine\", \"syringic acid\", \"serotonin\", \"ribitol\" ]]\n",
    "y = df_encoded['Group']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X),columns=X.columns,index=X.index)\n",
    "\n",
    "\n",
    "param_dist = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 7],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "random_search = RandomizedSearchCV(\n",
    "estimator=rf, param_distributions=param_dist, n_iter=50,\n",
    "            cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1600 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': model.feature_importances_  # Use model instead of rf\n",
    "})\n",
    "top_20_features = importances.nlargest(15, 'importance')['feature'].values\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(20, 16), facecolor='white')\n",
    "fig.suptitle('', fontsize=16)\n",
    "plt.subplots_adjust(wspace=1, hspace=1)\n",
    "\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(top_20_features):\n",
    "    pdp_results = partial_dependence(\n",
    "        model, \n",
    "        X_train,  \n",
    "        [feature],\n",
    "        percentiles=(0.05, 0.95),\n",
    "        grid_resolution=50,\n",
    "        kind='average'\n",
    "    )\n",
    "    feature_values = pdp_results['grid_values'][0]\n",
    "    pdp_values = pdp_results['average'][0]\n",
    "\n",
    "    ax = axes[idx]\n",
    "    ax.plot(feature_values, pdp_values, color='#532dc4', linewidth=2)\n",
    "    ax.grid(True, color='white', linewidth=1.5)\n",
    "    # ax.set_facecolor('#e7e6e6') \n",
    "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "\n",
    "    ax.set_xlabel(feature, fontsize=12) \n",
    "    ax.set_ylabel(\"Partial dependence\", fontsize=12)\n",
    "\n",
    "for idx in range(len(top_20_features), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities exported successfully to 'predicted_probabilities.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "predicted_probabilities = model.predict_proba(X)\n",
    "prob_df = pd.DataFrame(predicted_probabilities, columns=[f'Prob_Class_{i}' for i in range(predicted_probabilities.shape[1])])\n",
    "result_df = pd.concat([X.reset_index(drop=True), prob_df.reset_index(drop=True)], axis=1)\n",
    "result_df.to_excel('Real_World_IBS_Predicted_Probabilities.xlsx', index=False)\n",
    "print(\"Predicted probabilities exported successfully to 'Real_World_IBS_Predicted_Probabilities.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing feature selection using Gini importance...\n",
      "Top 30 features selected based on Gini importance:\n",
      "['xylose', 'xanthosine', 'valylglutamine', 'valine betaine', 'ursodeoxycholate sulfate (1)', 'uracil', 'tyrosine', 'tryptophylglycine', \"trigonelline (N'-methylnicotinate)\", 'tricarballylate', 'thymine', 'threonine', 'thiamin (Vitamin B1)', 'theobromine', 'syringic acid', 'succinimide', 'succinate', 'stearate (18:0)', 'stachydrine', 'sphingosine', 'serotonin', 'serine', 'salicylate', 'saccharin', 'ribulose/xylulose', 'riboflavin (Vitamin B2)', 'ribitol', 'quinolinate', 'quinate', 'pyroglutamine*']\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing feature selection using Gini importance...\")\n",
    "\n",
    "importances = model.feature_importances_\n",
    "feature_names = model.X_train.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "gini_importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "selected_features_gini = gini_importance_df[gini_importance_df['Importance'] > 0.01]['Feature']\n",
    "sorted_features = selected_features_gini.sort_values(ascending=False)\n",
    "\n",
    "top_30_features = sorted_features.head(30)\n",
    "\n",
    "print(\"Top 30 features selected based on Gini importance:\")\n",
    "print(top_30_features.to_list())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBS Kernel SHAP Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/74 [00:00<?, ?it/s]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2637457291798042)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.26703247740577474\n",
      "DEBUG:shap:self.fx = 0.12171754921323887\n",
      "DEBUG:shap:self.link(self.fx) = 0.12171754921323887\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.12330795,  0.00196381,  0.0056797 , -0.07048816, -0.00319946,\n",
      "       -0.0290135 , -0.02076631, -0.02581221,  0.00460531,  0.02617228,\n",
      "       -0.0038985 , -0.00912766, -0.00139672, -0.01515636, -0.00328675])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2637457291798043)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.26703247740577485\n",
      "DEBUG:shap:self.fx = 0.8782824507867614\n",
      "DEBUG:shap:self.link(self.fx) = 0.8782824507867614\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.12330795, -0.00196381, -0.0056797 ,  0.07048816,  0.00319946,\n",
      "        0.0290135 ,  0.02076631,  0.02581221, -0.00460531, -0.02617228,\n",
      "        0.0038985 ,  0.00912766,  0.00139672,  0.01515636,  0.00328675])\n",
      "  1%|▏         | 1/74 [00:01<02:12,  1.81s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2728209758913292)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.22211167885566582\n",
      "DEBUG:shap:self.fx = 0.16663834776334777\n",
      "DEBUG:shap:self.link(self.fx) = 0.16663834776334777\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10697033,  0.00121306, -0.00040103, -0.05927242, -0.0005072 ,\n",
      "        0.00882571, -0.00254856, -0.02211066, -0.00487678, -0.00137883,\n",
      "       -0.00681574, -0.01027585,  0.00548295, -0.07318531,  0.0507093 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.272820975891329)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.22211167885566563\n",
      "DEBUG:shap:self.fx = 0.8333616522366522\n",
      "DEBUG:shap:self.link(self.fx) = 0.8333616522366522\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10697033, -0.00121306,  0.00040103,  0.05927242,  0.0005072 ,\n",
      "       -0.00882571,  0.00254856,  0.02211066,  0.00487678,  0.00137883,\n",
      "        0.00681574,  0.01027585, -0.00548295,  0.07318531, -0.0507093 ])\n",
      "  3%|▎         | 2/74 [00:03<02:08,  1.78s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.16778991305406468)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.15599893049291746\n",
      "DEBUG:shap:self.fx = 0.23275109612609612\n",
      "DEBUG:shap:self.link(self.fx) = 0.23275109612609612\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.08814789,  0.00520283, -0.00149165, -0.06089953,  0.00460981,\n",
      "       -0.01112438, -0.05353596,  0.08357873, -0.00035235, -0.01229073,\n",
      "       -0.00017494, -0.02014549, -0.00395014, -0.00906822,  0.01179098])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.16778991305406493)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1559989304929177\n",
      "DEBUG:shap:self.fx = 0.7672489038739042\n",
      "DEBUG:shap:self.link(self.fx) = 0.7672489038739042\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.08814789, -0.00520283,  0.00149165,  0.06089953, -0.00460981,\n",
      "        0.01112438,  0.05353596, -0.08357873,  0.00035235,  0.01229073,\n",
      "        0.00017494,  0.02014549,  0.00395014,  0.00906822, -0.01179098])\n",
      "  4%|▍         | 3/74 [00:05<02:07,  1.79s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4807421175917908)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4682008697068828\n",
      "DEBUG:shap:self.fx = 0.8569508963258964\n",
      "DEBUG:shap:self.link(self.fx) = 0.8569508963258964\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.22929031,  0.01747068,  0.00564811,  0.09402373,  0.01944155,\n",
      "       -0.02034007,  0.023267  , -0.00743094,  0.00581754,  0.00805454,\n",
      "       -0.00278863,  0.00908313,  0.00588957,  0.09331561, -0.01254125])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.480742117591791)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.46820086970688285\n",
      "DEBUG:shap:self.fx = 0.14304910367410367\n",
      "DEBUG:shap:self.link(self.fx) = 0.14304910367410367\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.22929031, -0.01747068, -0.00564811, -0.09402373, -0.01944155,\n",
      "        0.02034007, -0.023267  ,  0.00743094, -0.00581754, -0.00805454,\n",
      "        0.00278863, -0.00908313, -0.00588957, -0.09331561,  0.01254125])\n",
      "  5%|▌         | 4/74 [00:07<02:08,  1.83s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.04180628290728236)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.006401888645875542\n",
      "DEBUG:shap:self.fx = 0.38234813797313805\n",
      "DEBUG:shap:self.link(self.fx) = 0.38234813797313805\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.14556034,  0.00706362, -0.01061465,  0.01612162,  0.01301802,\n",
      "       -0.01129452,  0.00637771, -0.05001509,  0.01193521,  0.00111814,\n",
      "        0.00973679,  0.02797533,  0.00031039,  0.08202149,  0.03540439])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.04180628290728214)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.00640188864587532\n",
      "DEBUG:shap:self.fx = 0.6176518620268618\n",
      "DEBUG:shap:self.link(self.fx) = 0.6176518620268618\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.14556034, -0.00706362,  0.01061465, -0.01612162, -0.01301802,\n",
      "        0.01129452, -0.00637771,  0.05001509, -0.01193521, -0.00111814,\n",
      "       -0.00973679, -0.02797533, -0.00031039, -0.08202149, -0.03540439])\n",
      "  7%|▋         | 5/74 [00:09<02:06,  1.83s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19564155181690873)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.20072882418764781\n",
      "DEBUG:shap:self.fx = 0.18802120243136577\n",
      "DEBUG:shap:self.link(self.fx) = 0.18802120243136577\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.09743486,  0.00254329, -0.01165691, -0.01539004,  0.00086895,\n",
      "       -0.00914559,  0.01044456, -0.04995402, -0.00590425,  0.02180729,\n",
      "       -0.0172643 ,  0.04009412, -0.00342772, -0.06122208, -0.00508727])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19564155181690884)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.20072882418764793\n",
      "DEBUG:shap:self.fx = 0.8119787975686344\n",
      "DEBUG:shap:self.link(self.fx) = 0.8119787975686344\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.09743486, -0.00254329,  0.01165691,  0.01539004, -0.00086895,\n",
      "        0.00914559, -0.01044456,  0.04995402,  0.00590425, -0.02180729,\n",
      "        0.0172643 , -0.04009412,  0.00342772,  0.06122208,  0.00508727])\n",
      "  8%|▊         | 6/74 [00:10<02:03,  1.82s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03152901467019348)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.021347278853291796\n",
      "DEBUG:shap:self.fx = 0.4100973054723054\n",
      "DEBUG:shap:self.link(self.fx) = 0.4100973054723054\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.14018231,  0.00726456, -0.01379454, -0.05497703, -0.00558649,\n",
      "        0.01410677,  0.00858275, -0.02643133, -0.03313154, -0.01037689,\n",
      "       -0.02420011,  0.01990547, -0.00238123,  0.01236632, -0.01018174])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.03152901467019364)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.021347278853292018\n",
      "DEBUG:shap:self.fx = 0.5899026945276945\n",
      "DEBUG:shap:self.link(self.fx) = 0.5899026945276945\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.14018231, -0.00726456,  0.01379454,  0.05497703,  0.00558649,\n",
      "       -0.01410677, -0.00858275,  0.02643133,  0.03313154,  0.01037689,\n",
      "        0.02420011, -0.01990547,  0.00238123, -0.01236632,  0.01018174])\n",
      "  9%|▉         | 7/74 [00:12<02:01,  1.81s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12194298968040529)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12272093297694608\n",
      "DEBUG:shap:self.fx = 0.5114709595959597\n",
      "DEBUG:shap:self.link(self.fx) = 0.5114709595959597\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.13503894,  0.00548627, -0.01225042,  0.06449485, -0.01155903,\n",
      "        0.00045426, -0.07426221,  0.08014534,  0.00457989,  0.00826215,\n",
      "       -0.00066268, -0.03144816,  0.01157084, -0.05790705,  0.00077794])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.12194298968040561)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.12272093297694647\n",
      "DEBUG:shap:self.fx = 0.48852904040404005\n",
      "DEBUG:shap:self.link(self.fx) = 0.48852904040404005\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.13503894, -0.00548627,  0.01225042, -0.06449485,  0.01155903,\n",
      "       -0.00045426,  0.07426221, -0.08014534, -0.00457989, -0.00826215,\n",
      "        0.00066268,  0.03144816, -0.01157084,  0.05790705, -0.00077794])\n",
      " 11%|█         | 8/74 [00:14<01:58,  1.80s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23749012079096127)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.24490209390039122\n",
      "DEBUG:shap:self.fx = 0.14384793271862237\n",
      "DEBUG:shap:self.link(self.fx) = 0.14384793271862237\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.14306165,  0.00448314,  0.00248045, -0.05525936, -0.001144  ,\n",
      "       -0.01103768, -0.06202452,  0.08225354, -0.03032235, -0.0079252 ,\n",
      "       -0.03212844, -0.00301817, -0.00060857,  0.01982271, -0.00741197])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23749012079096096)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24490209390039086\n",
      "DEBUG:shap:self.fx = 0.8561520672813774\n",
      "DEBUG:shap:self.link(self.fx) = 0.8561520672813774\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.14306165, -0.00448314, -0.00248045,  0.05525936,  0.001144  ,\n",
      "        0.01103768,  0.06202452, -0.08225354,  0.03032235,  0.0079252 ,\n",
      "        0.03212844,  0.00301817,  0.00060857, -0.01982271,  0.00741197])\n",
      " 12%|█▏        | 9/74 [00:16<01:55,  1.77s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2641032980210565)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2581053906036879\n",
      "DEBUG:shap:self.fx = 0.13064463601532567\n",
      "DEBUG:shap:self.link(self.fx) = 0.13064463601532567\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10469049,  0.00484354, -0.00175544, -0.02563756,  0.00994959,\n",
      "       -0.00919095, -0.007567  , -0.0243854 , -0.02408057, -0.00927186,\n",
      "       -0.01622822, -0.00442529, -0.00215836, -0.04950527,  0.00599791])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2641032980210565)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.25810539060368787\n",
      "DEBUG:shap:self.fx = 0.8693553639846744\n",
      "DEBUG:shap:self.link(self.fx) = 0.8693553639846744\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10469049, -0.00484354,  0.00175544,  0.02563756, -0.00994959,\n",
      "        0.00919095,  0.007567  ,  0.0243854 ,  0.02408057,  0.00927186,\n",
      "        0.01622822,  0.00442529,  0.00215836,  0.04950527, -0.00599791])\n",
      " 14%|█▎        | 10/74 [00:17<01:52,  1.76s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.13708755595030198)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1199248350481324\n",
      "DEBUG:shap:self.fx = 0.2688251915708812\n",
      "DEBUG:shap:self.link(self.fx) = 0.2688251915708812\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.105059  ,  0.0077476 , -0.00324479, -0.05286815, -0.00237401,\n",
      "       -0.00689694, -0.01387186, -0.01851437,  0.00407279,  0.01006082,\n",
      "       -0.02508573, -0.00905825, -0.00025032,  0.07825465,  0.01716272])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.13708755595030184)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.11992483504813234\n",
      "DEBUG:shap:self.fx = 0.7311748084291189\n",
      "DEBUG:shap:self.link(self.fx) = 0.7311748084291189\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.105059  , -0.0077476 ,  0.00324479,  0.05286815,  0.00237401,\n",
      "        0.00689694,  0.01387186,  0.01851437, -0.00407279, -0.01006082,\n",
      "        0.02508573,  0.00905825,  0.00025032, -0.07825465, -0.01716272])\n",
      " 15%|█▍        | 11/74 [00:19<01:49,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.13831260082139105)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.15768110942509647\n",
      "DEBUG:shap:self.fx = 0.23106891719391712\n",
      "DEBUG:shap:self.link(self.fx) = 0.23106891719391712\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.07044696,  0.01081487, -0.00310681, -0.04036804, -0.00459789,\n",
      "       -0.00765983, -0.05062372, -0.01457498,  0.00700715,  0.00381396,\n",
      "       -0.03306189, -0.00907163,  0.00992557,  0.06363761, -0.01936851])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.13831260082139096)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1576811094250964\n",
      "DEBUG:shap:self.fx = 0.7689310828060829\n",
      "DEBUG:shap:self.link(self.fx) = 0.7689310828060829\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.07044696, -0.01081487,  0.00310681,  0.04036804,  0.00459789,\n",
      "        0.00765983,  0.05062372,  0.01457498, -0.00700715, -0.00381396,\n",
      "        0.03306189,  0.00907163, -0.00992557, -0.06363761,  0.01936851])\n",
      " 16%|█▌        | 12/74 [00:21<01:47,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.31667585070536625)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.306537725031712\n",
      "DEBUG:shap:self.fx = 0.0822123015873016\n",
      "DEBUG:shap:self.link(self.fx) = 0.0822123015873016\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10220411,  0.00867918,  0.00593225, -0.05819336, -0.00022631,\n",
      "       -0.00947777, -0.04529779, -0.03213634, -0.00061107, -0.01120166,\n",
      "       -0.02094831, -0.0050764 ,  0.        , -0.04591415,  0.01013813])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.316675850705366)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.30653772503171195\n",
      "DEBUG:shap:self.fx = 0.9177876984126985\n",
      "DEBUG:shap:self.link(self.fx) = 0.9177876984126985\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10220411, -0.00867918, -0.00593225,  0.05819336,  0.00022631,\n",
      "        0.00947777,  0.04529779,  0.03213634,  0.00061107,  0.01120166,\n",
      "        0.02094831,  0.0050764 ,  0.        ,  0.04591415, -0.01013813])\n",
      " 18%|█▊        | 13/74 [00:22<01:43,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.271526561886385)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.27749620526288493\n",
      "DEBUG:shap:self.fx = 0.11125382135612866\n",
      "DEBUG:shap:self.link(self.fx) = 0.11125382135612866\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.08182575,  0.00138419,  0.00767893, -0.06193777, -0.00144289,\n",
      "       -0.02109713, -0.03857291, -0.026591  ,  0.0008172 , -0.00857664,\n",
      "       -0.00273808,  0.02972245, -0.00580626, -0.06254088, -0.00596964])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.27152656188638513)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.277496205262885\n",
      "DEBUG:shap:self.fx = 0.8887461786438715\n",
      "DEBUG:shap:self.link(self.fx) = 0.8887461786438715\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.08182575, -0.00138419, -0.00767893,  0.06193777,  0.00144289,\n",
      "        0.02109713,  0.03857291,  0.026591  , -0.0008172 ,  0.00857664,\n",
      "        0.00273808, -0.02972245,  0.00580626,  0.06254088,  0.00596964])\n",
      " 19%|█▉        | 14/74 [00:24<01:40,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.08484468216791664)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09170542071143378\n",
      "DEBUG:shap:self.fx = 0.48045544733044737\n",
      "DEBUG:shap:self.link(self.fx) = 0.48045544733044737\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.13762767,  0.01377484,  0.00844597,  0.06009772, -0.00161165,\n",
      "       -0.0018843 , -0.0639815 , -0.04540854, -0.02704133,  0.00628531,\n",
      "       -0.0028482 , -0.01237865,  0.00531416,  0.00845318,  0.00686074])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.08484468216791671)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09170542071143384\n",
      "DEBUG:shap:self.fx = 0.5195445526695527\n",
      "DEBUG:shap:self.link(self.fx) = 0.5195445526695527\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.13762767, -0.01377484, -0.00844597, -0.06009772,  0.00161165,\n",
      "        0.0018843 ,  0.0639815 ,  0.04540854,  0.02704133, -0.00628531,\n",
      "        0.0028482 ,  0.01237865, -0.00531416, -0.00845318, -0.00686074])\n",
      " 20%|██        | 15/74 [00:26<01:38,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.16724736882416258)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1799100055289925\n",
      "DEBUG:shap:self.fx = 0.2088400210900211\n",
      "DEBUG:shap:self.link(self.fx) = 0.2088400210900211\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10817245,  0.00411229,  0.00395391,  0.01714816,  0.00167688,\n",
      "       -0.00725315, -0.05717254,  0.04014642,  0.00447843,  0.02197764,\n",
      "       -0.0024918 , -0.01593294,  0.00037808, -0.0700963 , -0.01266264])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.16724736882416263)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1799100055289925\n",
      "DEBUG:shap:self.fx = 0.791159978909979\n",
      "DEBUG:shap:self.link(self.fx) = 0.791159978909979\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10817245, -0.00411229, -0.00395391, -0.01714816, -0.00167688,\n",
      "        0.00725315,  0.05717254, -0.04014642, -0.00447843, -0.02197764,\n",
      "        0.0024918 ,  0.01593294, -0.00037808,  0.0700963 ,  0.01266264])\n",
      " 22%|██▏       | 16/74 [00:27<01:35,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2976892204187032)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.29105558217456917\n",
      "DEBUG:shap:self.fx = 0.09769444444444444\n",
      "DEBUG:shap:self.link(self.fx) = 0.09769444444444444\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.1167986 , -0.02117069,  0.00252851, -0.04384457,  0.00377414,\n",
      "       -0.01506081, -0.00284476, -0.02784615,  0.00517342, -0.01824984,\n",
      "        0.0028627 , -0.00163919,  0.00125248, -0.06582587,  0.00663364])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2976892204187034)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2910555821745693\n",
      "DEBUG:shap:self.fx = 0.9023055555555558\n",
      "DEBUG:shap:self.link(self.fx) = 0.9023055555555558\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.1167986 ,  0.02117069, -0.00252851,  0.04384457, -0.00377414,\n",
      "        0.01506081,  0.00284476,  0.02784615, -0.00517342,  0.01824984,\n",
      "       -0.0028627 ,  0.00163919, -0.00125248,  0.06582587, -0.00663364])\n",
      " 23%|██▎       | 17/74 [00:29<01:32,  1.63s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.08530038665175388)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1263704778764908\n",
      "DEBUG:shap:self.fx = 0.5151205044955044\n",
      "DEBUG:shap:self.link(self.fx) = 0.5151205044955044\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.01329228, -0.01577941, -0.01193771, -0.0566394 ,  0.00570324,\n",
      "        0.        ,  0.01101319,  0.09771714,  0.00451989, -0.00387032,\n",
      "       -0.01255256, -0.00041868,  0.00482809,  0.04942464,  0.04107009])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.08530038665175396)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.12637047787649086\n",
      "DEBUG:shap:self.fx = 0.48487949550449566\n",
      "DEBUG:shap:self.link(self.fx) = 0.48487949550449566\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.01329228,  0.01577941,  0.01193771,  0.0566394 , -0.00570324,\n",
      "        0.        , -0.01101319, -0.09771714, -0.00451989,  0.00387032,\n",
      "        0.01255256,  0.00041868, -0.00482809, -0.04942464, -0.04107009])\n",
      " 24%|██▍       | 18/74 [00:31<01:30,  1.62s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.49924894013211013)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5346467987778117\n",
      "DEBUG:shap:self.fx = 0.9233968253968253\n",
      "DEBUG:shap:self.link(self.fx) = 0.9233968253968253\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.21309567,  0.01490925,  0.00969499,  0.07833029,  0.01124376,\n",
      "        0.01560578,  0.02783408, -0.00104599,  0.0124522 , -0.00379666,\n",
      "        0.        ,  0.01030538,  0.00747323,  0.10314695,  0.03539786])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.49924894013211035)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.534646798777812\n",
      "DEBUG:shap:self.fx = 0.0766031746031746\n",
      "DEBUG:shap:self.link(self.fx) = 0.0766031746031746\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.21309567, -0.01490925, -0.00969499, -0.07833029, -0.01124376,\n",
      "       -0.01560578, -0.02783408,  0.00104599, -0.0124522 ,  0.00379666,\n",
      "        0.        , -0.01030538, -0.00747323, -0.10314695, -0.03539786])\n",
      " 26%|██▌       | 19/74 [00:32<01:29,  1.63s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2717846976213506)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.28169499831398526\n",
      "DEBUG:shap:self.fx = 0.10705502830502833\n",
      "DEBUG:shap:self.link(self.fx) = 0.10705502830502833\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.09532356,  0.0088725 ,  0.0052219 , -0.0400911 , -0.00749862,\n",
      "       -0.01228132, -0.05505386, -0.01391302, -0.01985682,  0.00912237,\n",
      "        0.01550762, -0.00959334, -0.00223856, -0.05465888, -0.0099103 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2717846976213505)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.28169499831398526\n",
      "DEBUG:shap:self.fx = 0.8929449716949718\n",
      "DEBUG:shap:self.link(self.fx) = 0.8929449716949718\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.09532356, -0.0088725 , -0.0052219 ,  0.0400911 ,  0.00749862,\n",
      "        0.01228132,  0.05505386,  0.01391302,  0.01985682, -0.00912237,\n",
      "       -0.01550762,  0.00959334,  0.00223856,  0.05465888,  0.0099103 ])\n",
      " 27%|██▋       | 20/74 [00:34<01:28,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.030117826639082787)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.032052696171683104\n",
      "DEBUG:shap:self.fx = 0.3566973304473305\n",
      "DEBUG:shap:self.link(self.fx) = 0.3566973304473305\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.12449658,  0.00149759,  0.00838488, -0.0519001 , -0.00064431,\n",
      "       -0.01160944,  0.01665887,  0.0511129 , -0.00426231,  0.03207657,\n",
      "       -0.0199011 ,  0.00029169,  0.        ,  0.07267351, -0.00193487])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03011782663908262)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.03205269617168294\n",
      "DEBUG:shap:self.fx = 0.6433026695526695\n",
      "DEBUG:shap:self.link(self.fx) = 0.6433026695526695\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.12449658, -0.00149759, -0.00838488,  0.0519001 ,  0.00064431,\n",
      "        0.01160944, -0.01665887, -0.0511129 ,  0.00426231, -0.03207657,\n",
      "        0.0199011 , -0.00029169,  0.        , -0.07267351,  0.00193487])\n",
      " 28%|██▊       | 21/74 [00:35<01:26,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4718833699428553)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.48327775115876415\n",
      "DEBUG:shap:self.fx = 0.8720277777777777\n",
      "DEBUG:shap:self.link(self.fx) = 0.8720277777777777\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.18136656,  0.01444113,  0.00641926,  0.09086644,  0.01550966,\n",
      "        0.0060979 ,  0.01905645,  0.06540943,  0.00729378, -0.00248805,\n",
      "       -0.00238925,  0.02749928,  0.00772494,  0.03507584,  0.01139438])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4718833699428556)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.48327775115876437\n",
      "DEBUG:shap:self.fx = 0.12797222222222218\n",
      "DEBUG:shap:self.link(self.fx) = 0.12797222222222218\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.18136656, -0.01444113, -0.00641926, -0.09086644, -0.01550966,\n",
      "       -0.0060979 , -0.01905645, -0.06540943, -0.00729378,  0.00248805,\n",
      "        0.00238925, -0.02749928, -0.00772494, -0.03507584, -0.01139438])\n",
      " 30%|██▉       | 22/74 [00:37<01:25,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1588407588307916)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.13826546483397795\n",
      "DEBUG:shap:self.fx = 0.5270154914529915\n",
      "DEBUG:shap:self.link(self.fx) = 0.5270154914529915\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.14189341,  0.0074628 , -0.00766114, -0.05948578,  0.00117984,\n",
      "        0.01637244,  0.01398432, -0.01782963, -0.00199479, -0.0070891 ,\n",
      "       -0.01467948,  0.01017487,  0.00315396,  0.07335905, -0.02057529])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.15884075883079157)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.138265464833978\n",
      "DEBUG:shap:self.fx = 0.4729845085470085\n",
      "DEBUG:shap:self.link(self.fx) = 0.4729845085470085\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.14189341, -0.0074628 ,  0.00766114,  0.05948578, -0.00117984,\n",
      "       -0.01637244, -0.01398432,  0.01782963,  0.00199479,  0.0070891 ,\n",
      "        0.01467948, -0.01017487, -0.00315396, -0.07335905,  0.02057529])\n",
      " 31%|███       | 23/74 [00:39<01:24,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20006564895901716)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1979755065988039\n",
      "DEBUG:shap:self.fx = 0.1907745200202097\n",
      "DEBUG:shap:self.link(self.fx) = 0.1907745200202097\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.09942676, -0.00976198, -0.0041535 , -0.01719847,  0.00087662,\n",
      "        0.01046638, -0.00755219, -0.02584641, -0.02416957,  0.01239357,\n",
      "        0.00913933, -0.00340316,  0.00329992, -0.04472942,  0.00209014])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20006564895901685)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.19797550659880359\n",
      "DEBUG:shap:self.fx = 0.8092254799797901\n",
      "DEBUG:shap:self.link(self.fx) = 0.8092254799797901\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.09942676,  0.00976198,  0.0041535 ,  0.01719847, -0.00087662,\n",
      "       -0.01046638,  0.00755219,  0.02584641,  0.02416957, -0.01239357,\n",
      "       -0.00913933,  0.00340316, -0.00329992,  0.04472942, -0.00209014])\n",
      " 32%|███▏      | 24/74 [00:40<01:22,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20323880529045218)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2056077785666022\n",
      "DEBUG:shap:self.fx = 0.1831422480524114\n",
      "DEBUG:shap:self.link(self.fx) = 0.1831422480524114\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.09964568,  0.0124274 ,  0.00222142, -0.06174005,  0.01234426,\n",
      "        0.01759071, -0.00991885, -0.01941816,  0.00303491,  0.01813068,\n",
      "       -0.01672641, -0.00680546, -0.00062699, -0.05410658, -0.00236897])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20323880529045193)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.20560777856660195\n",
      "DEBUG:shap:self.fx = 0.8168577519475885\n",
      "DEBUG:shap:self.link(self.fx) = 0.8168577519475885\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.09964568, -0.0124274 , -0.00222142,  0.06174005, -0.01234426,\n",
      "       -0.01759071,  0.00991885,  0.01941816, -0.00303491, -0.01813068,\n",
      "        0.01672641,  0.00680546,  0.00062699,  0.05410658,  0.00236897])\n",
      " 34%|███▍      | 25/74 [00:42<01:20,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.125415882933995)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.11653425854027166\n",
      "DEBUG:shap:self.fx = 0.5052842851592853\n",
      "DEBUG:shap:self.link(self.fx) = 0.5052842851592853\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.12205098, -0.00445392,  0.00944457,  0.0498467 ,  0.01440207,\n",
      "        0.01113213,  0.01487552,  0.06993755, -0.04984152,  0.01261105,\n",
      "       -0.02738143,  0.0029803 ,  0.00398947, -0.10417759, -0.00888162])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.125415882933995)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.11653425854027183\n",
      "DEBUG:shap:self.fx = 0.4947157148407147\n",
      "DEBUG:shap:self.link(self.fx) = 0.4947157148407147\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.12205098,  0.00445392, -0.00944457, -0.0498467 , -0.01440207,\n",
      "       -0.01113213, -0.01487552, -0.06993755,  0.04984152, -0.01261105,\n",
      "        0.02738143, -0.0029803 , -0.00398947,  0.10417759,  0.00888162])\n",
      " 35%|███▌      | 26/74 [00:44<01:19,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.15304787848444562)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.13653072734924043\n",
      "DEBUG:shap:self.fx = 0.525280753968254\n",
      "DEBUG:shap:self.link(self.fx) = 0.525280753968254\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.20068739, -0.00466354,  0.00973008, -0.08220493,  0.        ,\n",
      "       -0.03669955,  0.00904248, -0.02283163,  0.0054477 , -0.0092597 ,\n",
      "       -0.00121755,  0.00116064,  0.00030233,  0.08355417, -0.01651715])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.15304787848444582)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13653072734924054\n",
      "DEBUG:shap:self.fx = 0.474719246031746\n",
      "DEBUG:shap:self.link(self.fx) = 0.474719246031746\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.20068739,  0.00466354, -0.00973008,  0.08220493,  0.        ,\n",
      "        0.03669955, -0.00904248,  0.02283163, -0.0054477 ,  0.0092597 ,\n",
      "        0.00121755, -0.00116064, -0.00030233, -0.08355417,  0.01651715])\n",
      " 36%|███▋      | 27/74 [00:45<01:17,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.018547141282233517)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.04369583307684605\n",
      "DEBUG:shap:self.fx = 0.43244585969585964\n",
      "DEBUG:shap:self.link(self.fx) = 0.43244585969585964\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.00493276,  0.01241877, -0.01103459,  0.06665176,  0.00687175,\n",
      "       -0.0063796 ,  0.00289381, -0.02521164,  0.01285342, -0.00882434,\n",
      "        0.0215113 ,  0.03460413, -0.00246606, -0.08040881,  0.02514869])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.01854714128223367)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.04369583307684621\n",
      "DEBUG:shap:self.fx = 0.5675541403041403\n",
      "DEBUG:shap:self.link(self.fx) = 0.5675541403041403\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.00493276, -0.01241877,  0.01103459, -0.06665176, -0.00687175,\n",
      "        0.0063796 , -0.00289381,  0.02521164, -0.01285342,  0.00882434,\n",
      "       -0.0215113 , -0.03460413,  0.00246606,  0.08040881, -0.02514869])\n",
      " 38%|███▊      | 28/74 [00:47<01:16,  1.67s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.464343991823964)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.48581743369844677\n",
      "DEBUG:shap:self.fx = 0.8745674603174604\n",
      "DEBUG:shap:self.link(self.fx) = 0.8745674603174604\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.2082698 ,  0.01577309,  0.00072919,  0.08047325,  0.00910085,\n",
      "       -0.01233529,  0.0246883 ,  0.03364933, -0.0012951 , -0.00659749,\n",
      "       -0.02133753,  0.01625089,  0.00788505,  0.10908967,  0.02147344])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.46434399182396396)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4858174336984468\n",
      "DEBUG:shap:self.fx = 0.1254325396825397\n",
      "DEBUG:shap:self.link(self.fx) = 0.1254325396825397\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.2082698 , -0.01577309, -0.00072919, -0.08047325, -0.00910085,\n",
      "        0.01233529, -0.0246883 , -0.03364933,  0.0012951 ,  0.00659749,\n",
      "        0.02133753, -0.01625089, -0.00788505, -0.10908967, -0.02147344])\n",
      " 39%|███▉      | 29/74 [00:49<01:13,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.32600379790977774)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3489012665322794\n",
      "DEBUG:shap:self.fx = 0.737651293151293\n",
      "DEBUG:shap:self.link(self.fx) = 0.737651293151293\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.18834253,  0.01362859,  0.        ,  0.02147212,  0.00218846,\n",
      "        0.00368584,  0.01391644, -0.0014945 , -0.00500204, -0.00617837,\n",
      "       -0.01763375,  0.00520138,  0.0038006 ,  0.1040765 ,  0.02289747])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.32600379790977796)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3489012665322796\n",
      "DEBUG:shap:self.fx = 0.2623487068487069\n",
      "DEBUG:shap:self.link(self.fx) = 0.2623487068487069\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.18834253, -0.01362859,  0.        , -0.02147212, -0.00218846,\n",
      "       -0.00368584, -0.01391644,  0.0014945 ,  0.00500204,  0.00617837,\n",
      "        0.01763375, -0.00520138, -0.0038006 , -0.1040765 , -0.02289747])\n",
      " 41%|████      | 30/74 [00:50<01:11,  1.63s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3058315760878354)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2685858852048722\n",
      "DEBUG:shap:self.fx = 0.1201641414141414\n",
      "DEBUG:shap:self.link(self.fx) = 0.1201641414141414\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10559649, -0.00133273, -0.00194437, -0.05385   ,  0.00328324,\n",
      "        0.00533784,  0.00814814, -0.03271186,  0.0026944 , -0.0184745 ,\n",
      "       -0.01686175, -0.00830114, -0.00460884, -0.08161352,  0.03724569])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3058315760878354)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.26858588520487214\n",
      "DEBUG:shap:self.fx = 0.8798358585858587\n",
      "DEBUG:shap:self.link(self.fx) = 0.8798358585858587\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10559649,  0.00133273,  0.00194437,  0.05385   , -0.00328324,\n",
      "       -0.00533784, -0.00814814,  0.03271186, -0.0026944 ,  0.0184745 ,\n",
      "        0.01686175,  0.00830114,  0.00460884,  0.08161352, -0.03724569])\n",
      " 42%|████▏     | 31/74 [00:52<01:09,  1.62s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.15163710063113597)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13903123152521846\n",
      "DEBUG:shap:self.fx = 0.24971879509379513\n",
      "DEBUG:shap:self.link(self.fx) = 0.24971879509379513\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10068443,  0.01564488,  0.00649733, -0.04023807, -0.00234913,\n",
      "       -0.01319011,  0.01197547, -0.03767918,  0.0077762 ,  0.0379439 ,\n",
      "       -0.02053137, -0.00057773, -0.00357389, -0.01265098,  0.01260587])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.15163710063113578)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.13903123152521824\n",
      "DEBUG:shap:self.fx = 0.7502812049062048\n",
      "DEBUG:shap:self.link(self.fx) = 0.7502812049062048\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10068443, -0.01564488, -0.00649733,  0.04023807,  0.00234913,\n",
      "        0.01319011, -0.01197547,  0.03767918, -0.0077762 , -0.0379439 ,\n",
      "        0.02053137,  0.00057773,  0.00357389,  0.01265098, -0.01260587])\n",
      " 43%|████▎     | 32/74 [00:54<01:08,  1.63s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1841877485490173)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.19200269755918453\n",
      "DEBUG:shap:self.fx = 0.19674732905982906\n",
      "DEBUG:shap:self.link(self.fx) = 0.19674732905982906\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.01804745,  0.00043553,  0.00698077, -0.0740162 , -0.00167366,\n",
      "       -0.00826985, -0.02000251, -0.04238881,  0.00435342, -0.00427351,\n",
      "       -0.02946714,  0.00125304, -0.00112165,  0.00205027, -0.00781495])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.18418774854901715)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.19200269755918442\n",
      "DEBUG:shap:self.fx = 0.8032526709401709\n",
      "DEBUG:shap:self.link(self.fx) = 0.8032526709401709\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.01804745, -0.00043553, -0.00698077,  0.0740162 ,  0.00167366,\n",
      "        0.00826985,  0.02000251,  0.04238881, -0.00435342,  0.00427351,\n",
      "        0.02946714, -0.00125304,  0.00112165, -0.00205027,  0.00781495])\n",
      " 45%|████▍     | 33/74 [00:55<01:06,  1.62s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12524998530051346)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.13105370437221753\n",
      "DEBUG:shap:self.fx = 0.5198037309912311\n",
      "DEBUG:shap:self.link(self.fx) = 0.5198037309912311\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 1.62398122e-01,  9.00924708e-03, -1.03792948e-02, -5.01200213e-02,\n",
      "       -7.98966959e-03,  8.61408269e-03,  1.70030560e-02, -2.57426897e-02,\n",
      "        3.50284983e-04,  1.39538518e-04, -5.62078142e-03, -1.15032258e-02,\n",
      "        5.79266801e-03,  3.32986689e-02,  5.80371907e-03])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1252499853005135)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13105370437221753\n",
      "DEBUG:shap:self.fx = 0.480196269008769\n",
      "DEBUG:shap:self.link(self.fx) = 0.480196269008769\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-1.62398122e-01, -9.00924708e-03,  1.03792948e-02,  5.01200213e-02,\n",
      "        7.98966959e-03, -8.61408269e-03, -1.70030560e-02,  2.57426897e-02,\n",
      "       -3.50284983e-04, -1.39538518e-04,  5.62078142e-03,  1.15032258e-02,\n",
      "       -5.79266801e-03, -3.32986689e-02, -5.80371907e-03])\n",
      " 46%|████▌     | 34/74 [00:57<01:06,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.001768868984087374)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.007655204774191626\n",
      "DEBUG:shap:self.fx = 0.38109482184482196\n",
      "DEBUG:shap:self.link(self.fx) = 0.38109482184482196\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.14552644, -0.00119743,  0.00358114,  0.03981466, -0.01544995,\n",
      "       -0.01008066,  0.00981518, -0.03428235, -0.03335888, -0.00888172,\n",
      "        0.00094394,  0.00492463,  0.0074235 , -0.11054738, -0.00588634])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0017688689840870964)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.007655204774191349\n",
      "DEBUG:shap:self.fx = 0.6189051781551779\n",
      "DEBUG:shap:self.link(self.fx) = 0.6189051781551779\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.14552644,  0.00119743, -0.00358114, -0.03981466,  0.01544995,\n",
      "        0.01008066, -0.00981518,  0.03428235,  0.03335888,  0.00888172,\n",
      "       -0.00094394, -0.00492463, -0.0074235 ,  0.11054738,  0.00588634])\n",
      " 47%|████▋     | 35/74 [00:59<01:05,  1.67s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.36653585170214326)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3856843168153299\n",
      "DEBUG:shap:self.fx = 0.7744343434343435\n",
      "DEBUG:shap:self.link(self.fx) = 0.7744343434343435\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.20403171, -0.02754724, -0.0098195 ,  0.09071421,  0.02213438,\n",
      "       -0.02157049,  0.01353976, -0.0066885 ,  0.01217943, -0.0025801 ,\n",
      "       -0.00115608,  0.00781782,  0.00280061,  0.08267983,  0.01914847])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3665358517021431)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3856843168153299\n",
      "DEBUG:shap:self.fx = 0.22556565656565664\n",
      "DEBUG:shap:self.link(self.fx) = 0.22556565656565664\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.20403171,  0.02754724,  0.0098195 , -0.09071421, -0.02213438,\n",
      "        0.02157049, -0.01353976,  0.0066885 , -0.01217943,  0.0025801 ,\n",
      "        0.00115608, -0.00781782, -0.00280061, -0.08267983, -0.01914847])\n",
      " 49%|████▊     | 36/74 [01:00<01:03,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0069416379030128594)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.015894814650827815\n",
      "DEBUG:shap:self.fx = 0.4046448412698414\n",
      "DEBUG:shap:self.link(self.fx) = 0.4046448412698414\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.13710667,  0.0237323 ,  0.0026235 ,  0.04692296,  0.01215019,\n",
      "       -0.00770722,  0.00616621, -0.05170577, -0.0443738 ,  0.02843336,\n",
      "       -0.00476578,  0.00279288, -0.03358987, -0.11084398,  0.00895318])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.006941637903012665)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.01589481465082776\n",
      "DEBUG:shap:self.fx = 0.5953551587301588\n",
      "DEBUG:shap:self.link(self.fx) = 0.5953551587301588\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.13710667, -0.0237323 , -0.0026235 , -0.04692296, -0.01215019,\n",
      "        0.00770722, -0.00616621,  0.05170577,  0.0443738 , -0.02843336,\n",
      "        0.00476578, -0.00279288,  0.03358987,  0.11084398, -0.00895318])\n",
      " 50%|█████     | 37/74 [01:02<01:01,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09460205537339562)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08007758794657499\n",
      "DEBUG:shap:self.fx = 0.3086724386724386\n",
      "DEBUG:shap:self.link(self.fx) = 0.3086724386724386\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.05603658,  0.02661347,  0.00041835, -0.0255528 , -0.01476541,\n",
      "       -0.0229776 , -0.04849035, -0.01992819,  0.01090797,  0.00776038,\n",
      "        0.00196637, -0.00375426,  0.00518923,  0.04404737,  0.01452447])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.09460205537339537)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08007758794657471\n",
      "DEBUG:shap:self.fx = 0.6913275613275612\n",
      "DEBUG:shap:self.link(self.fx) = 0.6913275613275612\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.05603658, -0.02661347, -0.00041835,  0.0255528 ,  0.01476541,\n",
      "        0.0229776 ,  0.04849035,  0.01992819, -0.01090797, -0.00776038,\n",
      "       -0.00196637,  0.00375426, -0.00518923, -0.04404737, -0.01452447])\n",
      " 51%|█████▏    | 38/74 [01:03<00:59,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4140536573386449)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3822624192684323\n",
      "DEBUG:shap:self.fx = 0.7710124458874459\n",
      "DEBUG:shap:self.link(self.fx) = 0.7710124458874459\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.19886133,  0.01248072,  0.00606078,  0.06400711,  0.0137025 ,\n",
      "       -0.01024469,  0.01632862,  0.02041206, -0.01433588,  0.01363712,\n",
      "       -0.00104644,  0.00771776,  0.00031346,  0.08615921, -0.03179124])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4140536573386449)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3822624192684324\n",
      "DEBUG:shap:self.fx = 0.2289875541125541\n",
      "DEBUG:shap:self.link(self.fx) = 0.2289875541125541\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.19886133, -0.01248072, -0.00606078, -0.06400711, -0.0137025 ,\n",
      "        0.01024469, -0.01632862, -0.02041206,  0.01433588, -0.01363712,\n",
      "        0.00104644, -0.00771776, -0.00031346, -0.08615921,  0.03179124])\n",
      " 53%|█████▎    | 39/74 [01:05<00:58,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.16534302942904086)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.12834400208798907\n",
      "DEBUG:shap:self.fx = 0.2604060245310245\n",
      "DEBUG:shap:self.link(self.fx) = 0.2604060245310245\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.11814006, -0.02285252, -0.00697099, -0.04151352,  0.01872748,\n",
      "       -0.02674708,  0.01034315, -0.03982123, -0.01464178, -0.00801776,\n",
      "       -0.00414412,  0.02256282, -0.00096971,  0.06684229,  0.03699903])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.16534302942904067)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12834400208798902\n",
      "DEBUG:shap:self.fx = 0.7395939754689755\n",
      "DEBUG:shap:self.link(self.fx) = 0.7395939754689755\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.11814006,  0.02285252,  0.00697099,  0.04151352, -0.01872748,\n",
      "        0.02674708, -0.01034315,  0.03982123,  0.01464178,  0.00801776,\n",
      "        0.00414412, -0.02256282,  0.00096971, -0.06684229, -0.03699903])\n",
      " 54%|█████▍    | 40/74 [01:07<00:55,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.18441068465872373)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.185941585060572\n",
      "DEBUG:shap:self.fx = 0.20280844155844158\n",
      "DEBUG:shap:self.link(self.fx) = 0.20280844155844158\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.11281822,  0.        ,  0.00475813, -0.06901795, -0.00243855,\n",
      "       -0.01771107,  0.00205189,  0.05664664, -0.00699321,  0.03009249,\n",
      "       -0.01660462,  0.        ,  0.00129807, -0.05367428, -0.0015309 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.18441068465872384)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.18594158506057212\n",
      "DEBUG:shap:self.fx = 0.7971915584415586\n",
      "DEBUG:shap:self.link(self.fx) = 0.7971915584415586\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.11281822,  0.        , -0.00475813,  0.06901795,  0.00243855,\n",
      "        0.01771107, -0.00205189, -0.05664664,  0.00699321, -0.03009249,\n",
      "        0.01660462,  0.        , -0.00129807,  0.05367428,  0.0015309 ])\n",
      " 55%|█████▌    | 41/74 [01:08<00:54,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.11657497378097217)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1157672192217325\n",
      "DEBUG:shap:self.fx = 0.2729828073972811\n",
      "DEBUG:shap:self.link(self.fx) = 0.2729828073972811\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.00316133,  0.00510392, -0.00208396, -0.06002053,  0.00224211,\n",
      "       -0.01078361, -0.00673497,  0.06776299,  0.00481985, -0.00983692,\n",
      "       -0.00804539, -0.00574737, -0.00374733, -0.08634244,  0.00080775])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.11657497378097206)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.11576721922173239\n",
      "DEBUG:shap:self.fx = 0.7270171926027189\n",
      "DEBUG:shap:self.link(self.fx) = 0.7270171926027189\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.00316133, -0.00510392,  0.00208396,  0.06002053, -0.00224211,\n",
      "        0.01078361,  0.00673497, -0.06776299, -0.00481985,  0.00983692,\n",
      "        0.00804539,  0.00574737,  0.00374733,  0.08634244, -0.00080775])\n",
      " 57%|█████▋    | 42/74 [01:10<00:52,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.27819158712987885)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2922225957165827\n",
      "DEBUG:shap:self.fx = 0.0965274309024309\n",
      "DEBUG:shap:self.link(self.fx) = 0.0965274309024309\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.07581323,  0.01301799, -0.00803611, -0.04291417, -0.00211953,\n",
      "        0.00786023, -0.05282657, -0.00970026, -0.0226608 , -0.02341902,\n",
      "        0.00106896, -0.01576809,  0.00679041, -0.05367138, -0.01403101])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.27819158712987874)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2922225957165827\n",
      "DEBUG:shap:self.fx = 0.9034725690975692\n",
      "DEBUG:shap:self.link(self.fx) = 0.9034725690975692\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.07581323, -0.01301799,  0.00803611,  0.04291417,  0.00211953,\n",
      "       -0.00786023,  0.05282657,  0.00970026,  0.0226608 ,  0.02341902,\n",
      "       -0.00106896,  0.01576809, -0.00679041,  0.05367138,  0.01403101])\n",
      " 58%|█████▊    | 43/74 [01:12<00:50,  1.63s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.10383664212165106)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.11631911031309727\n",
      "DEBUG:shap:self.fx = 0.2724309163059163\n",
      "DEBUG:shap:self.link(self.fx) = 0.2724309163059163\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.01810926,  0.00741408,  0.00403995,  0.04619308, -0.00486368,\n",
      "        0.0145797 ,  0.00536603, -0.02146199, -0.04734225, -0.01347223,\n",
      "        0.00761104,  0.00101452,  0.0018097 , -0.08661534, -0.01248247])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.103836642121651)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.11631911031309716\n",
      "DEBUG:shap:self.fx = 0.7275690836940837\n",
      "DEBUG:shap:self.link(self.fx) = 0.7275690836940837\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.01810926, -0.00741408, -0.00403995, -0.04619308,  0.00486368,\n",
      "       -0.0145797 , -0.00536603,  0.02146199,  0.04734225,  0.01347223,\n",
      "       -0.00761104, -0.00101452, -0.0018097 ,  0.08661534,  0.01248247])\n",
      " 59%|█████▉    | 44/74 [01:13<00:48,  1.63s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3389207674267126)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3364702647142517\n",
      "DEBUG:shap:self.fx = 0.05227976190476191\n",
      "DEBUG:shap:self.link(self.fx) = 0.05227976190476191\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.08038266, -0.00095471,  0.0046806 , -0.06664474,  0.00185713,\n",
      "       -0.01709293, -0.04515513, -0.02836179, -0.02046694, -0.01223783,\n",
      "       -0.01718811, -0.00149422, -0.00017734, -0.05530206,  0.0024505 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.33892076742671245)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.33647026471425145\n",
      "DEBUG:shap:self.fx = 0.947720238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.947720238095238\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.08038266,  0.00095471, -0.0046806 ,  0.06664474, -0.00185713,\n",
      "        0.01709293,  0.04515513,  0.02836179,  0.02046694,  0.01223783,\n",
      "        0.01718811,  0.00149422,  0.00017734,  0.05530206, -0.0024505 ])\n",
      " 61%|██████    | 45/74 [01:15<00:48,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4471841575432154)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4373185159495292\n",
      "DEBUG:shap:self.fx = 0.8260685425685428\n",
      "DEBUG:shap:self.link(self.fx) = 0.8260685425685428\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.19471883,  0.01281594,  0.01067682,  0.04333215, -0.00290143,\n",
      "        0.00401113,  0.01686211,  0.06440339,  0.00493508,  0.01524186,\n",
      "       -0.0010347 ,  0.00940059, -0.01760402,  0.09232641, -0.00986564])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4471841575432154)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4373185159495291\n",
      "DEBUG:shap:self.fx = 0.1739314574314574\n",
      "DEBUG:shap:self.link(self.fx) = 0.1739314574314574\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.19471883, -0.01281594, -0.01067682, -0.04333215,  0.00290143,\n",
      "       -0.00401113, -0.01686211, -0.06440339, -0.00493508, -0.01524186,\n",
      "        0.0010347 , -0.00940059,  0.01760402, -0.09232641,  0.00986564])\n",
      " 62%|██████▏   | 46/74 [01:17<00:45,  1.63s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0430114554967481)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.06452973528574835\n",
      "DEBUG:shap:self.fx = 0.45327976190476194\n",
      "DEBUG:shap:self.link(self.fx) = 0.45327976190476194\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.13075712,  0.01453951, -0.00963037,  0.05000027, -0.0240454 ,\n",
      "       -0.0083868 ,  0.00827173, -0.02567756, -0.04793397, -0.00430072,\n",
      "       -0.00435289,  0.00692357, -0.00521434, -0.03793869,  0.02151828])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.0430114554967484)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.06452973528574857\n",
      "DEBUG:shap:self.fx = 0.546720238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.546720238095238\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.13075712, -0.01453951,  0.00963037, -0.05000027,  0.0240454 ,\n",
      "        0.0083868 , -0.00827173,  0.02567756,  0.04793397,  0.00430072,\n",
      "        0.00435289, -0.00692357,  0.00521434,  0.03793869, -0.02151828])\n",
      " 64%|██████▎   | 47/74 [01:18<00:44,  1.64s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2629883714423457)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.27359777609176306\n",
      "DEBUG:shap:self.fx = 0.11515225052725052\n",
      "DEBUG:shap:self.link(self.fx) = 0.11515225052725052\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.08115532,  0.01833015, -0.00729449, -0.03987646, -0.00268066,\n",
      "        0.0064992 , -0.04873182, -0.02778844, -0.01121038,  0.01590019,\n",
      "       -0.02320317, -0.01205209, -0.00451135, -0.04521374, -0.0106094 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2629883714423457)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.27359777609176306\n",
      "DEBUG:shap:self.fx = 0.8848477494727496\n",
      "DEBUG:shap:self.link(self.fx) = 0.8848477494727496\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.08115532, -0.01833015,  0.00729449,  0.03987646,  0.00268066,\n",
      "       -0.0064992 ,  0.04873182,  0.02778844,  0.01121038, -0.01590019,\n",
      "        0.02320317,  0.01205209,  0.00451135,  0.04521374,  0.0106094 ])\n",
      " 65%|██████▍   | 48/74 [01:20<00:42,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2676708734095905)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.25711757799859114\n",
      "DEBUG:shap:self.fx = 0.6458676046176047\n",
      "DEBUG:shap:self.link(self.fx) = 0.6458676046176047\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.20579447,  0.01021203, -0.01442252,  0.07245189, -0.00414953,\n",
      "       -0.00594842,  0.0156929 , -0.06057242, -0.00248034,  0.0051641 ,\n",
      "        0.01065725, -0.01601627,  0.00933855,  0.04194919, -0.0105533 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2676708734095905)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2571175779985912\n",
      "DEBUG:shap:self.fx = 0.3541323953823953\n",
      "DEBUG:shap:self.link(self.fx) = 0.3541323953823953\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.20579447, -0.01021203,  0.01442252, -0.07245189,  0.00414953,\n",
      "        0.00594842, -0.0156929 ,  0.06057242,  0.00248034, -0.0051641 ,\n",
      "       -0.01065725,  0.01601627, -0.00933855, -0.04194919,  0.0105533 ])\n",
      " 66%|██████▌   | 49/74 [01:22<00:41,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.18856714661436105)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.18284706846605533\n",
      "DEBUG:shap:self.fx = 0.20590295815295825\n",
      "DEBUG:shap:self.link(self.fx) = 0.20590295815295825\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.07779636,  0.00119577,  0.00562528,  0.00420623, -0.00711086,\n",
      "       -0.01213782, -0.02203895, -0.03386675, -0.01569331, -0.00843827,\n",
      "        0.00067344, -0.01409775, -0.00727328, -0.00181453,  0.00572008])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1885671466143608)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.18284706846605503\n",
      "DEBUG:shap:self.fx = 0.7940970418470416\n",
      "DEBUG:shap:self.link(self.fx) = 0.7940970418470416\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.07779636, -0.00119577, -0.00562528, -0.00420623,  0.00711086,\n",
      "        0.01213782,  0.02203895,  0.03386675,  0.01569331,  0.00843827,\n",
      "       -0.00067344,  0.01409775,  0.00727328,  0.00181453, -0.00572008])\n",
      " 68%|██████▊   | 50/74 [01:23<00:40,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2004797246403764)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1950200731433705\n",
      "DEBUG:shap:self.fx = 0.1937299534756431\n",
      "DEBUG:shap:self.link(self.fx) = 0.1937299534756431\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.09855834, -0.02835876,  0.00399698,  0.01429042,  0.02927847,\n",
      "       -0.01040315,  0.00600128, -0.02964175,  0.00937199, -0.01313608,\n",
      "        0.00113411, -0.00516328, -0.00384416, -0.07544745,  0.00545965])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2004797246403761)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.19502007314337022\n",
      "DEBUG:shap:self.fx = 0.8062700465243567\n",
      "DEBUG:shap:self.link(self.fx) = 0.8062700465243567\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.09855834,  0.02835876, -0.00399698, -0.01429042, -0.02927847,\n",
      "        0.01040315, -0.00600128,  0.02964175, -0.00937199,  0.01313608,\n",
      "       -0.00113411,  0.00516328,  0.00384416,  0.07544745, -0.00545965])\n",
      " 69%|██████▉   | 51/74 [01:25<00:39,  1.70s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4984843577623236)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4797341003651133\n",
      "DEBUG:shap:self.fx = 0.8684841269841269\n",
      "DEBUG:shap:self.link(self.fx) = 0.8684841269841269\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.21918576,  0.01246896,  0.00666008,  0.05353384,  0.        ,\n",
      "        0.0031396 ,  0.02217251,  0.10026551, -0.01867065, -0.00443152,\n",
      "        0.00850616,  0.00630824,  0.00354002,  0.08580585, -0.01875026])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4984843577623238)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.47973410036511355\n",
      "DEBUG:shap:self.fx = 0.13151587301587297\n",
      "DEBUG:shap:self.link(self.fx) = 0.13151587301587297\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.21918576, -0.01246896, -0.00666008, -0.05353384,  0.        ,\n",
      "       -0.0031396 , -0.02217251, -0.10026551,  0.01867065,  0.00443152,\n",
      "       -0.00850616, -0.00630824, -0.00354002, -0.08580585,  0.01875026])\n",
      " 70%|███████   | 52/74 [01:27<00:36,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2835825837692731)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.29004752225203556\n",
      "DEBUG:shap:self.fx = 0.09870250436697804\n",
      "DEBUG:shap:self.link(self.fx) = 0.09870250436697804\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10518599, -0.01045588,  0.00305625, -0.07215032,  0.00627468,\n",
      "        0.0159059 ,  0.0030837 , -0.0307889 , -0.00098388, -0.01269781,\n",
      "       -0.00977111, -0.00430925,  0.00189529, -0.06745525, -0.00646494])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.28358258376927326)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2900475222520358\n",
      "DEBUG:shap:self.fx = 0.9012974956330223\n",
      "DEBUG:shap:self.link(self.fx) = 0.9012974956330223\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10518599,  0.01045588, -0.00305625,  0.07215032, -0.00627468,\n",
      "       -0.0159059 , -0.0030837 ,  0.0307889 ,  0.00098388,  0.01269781,\n",
      "        0.00977111,  0.00430925, -0.00189529,  0.06745525,  0.00646494])\n",
      " 72%|███████▏  | 53/74 [01:28<00:35,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.30474182119764165)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.31142747643348945\n",
      "DEBUG:shap:self.fx = 0.700177503052503\n",
      "DEBUG:shap:self.link(self.fx) = 0.700177503052503\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.194471  ,  0.01942704, -0.00190935, -0.04875413,  0.01400853,\n",
      "        0.01704084,  0.0271071 , -0.01292548,  0.00949385, -0.00187613,\n",
      "       -0.01323383,  0.01740436,  0.0042088 ,  0.08027924,  0.00668566])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.30474182119764176)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.31142747643348956\n",
      "DEBUG:shap:self.fx = 0.29982249694749696\n",
      "DEBUG:shap:self.link(self.fx) = 0.29982249694749696\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.194471  , -0.01942704,  0.00190935,  0.04875413, -0.01400853,\n",
      "       -0.01704084, -0.0271071 ,  0.01292548, -0.00949385,  0.00187613,\n",
      "        0.01323383, -0.01740436, -0.0042088 , -0.08027924, -0.00668566])\n",
      " 73%|███████▎  | 54/74 [01:30<00:33,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.06647921870587176)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.016717017961004943\n",
      "DEBUG:shap:self.fx = 0.37203300865800865\n",
      "DEBUG:shap:self.link(self.fx) = 0.37203300865800865\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.09178363,  0.03715429, -0.00272417, -0.04290377,  0.0181562 ,\n",
      "       -0.01233026, -0.02975493, -0.02620378,  0.00629049, -0.00096137,\n",
      "       -0.00583161, -0.00987604,  0.00312453,  0.09116481,  0.0497622 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.06647921870587173)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.016717017961005\n",
      "DEBUG:shap:self.fx = 0.6279669913419915\n",
      "DEBUG:shap:self.link(self.fx) = 0.6279669913419915\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.09178363, -0.03715429,  0.00272417,  0.04290377, -0.0181562 ,\n",
      "        0.01233026,  0.02975493,  0.02620378, -0.00629049,  0.00096137,\n",
      "        0.00583161,  0.00987604, -0.00312453, -0.09116481, -0.0497622 ])\n",
      " 74%|███████▍  | 55/74 [01:32<00:31,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.38983663283029923)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4149225924286054\n",
      "DEBUG:shap:self.fx = 0.803672619047619\n",
      "DEBUG:shap:self.link(self.fx) = 0.803672619047619\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.18280862,  0.00991086,  0.00928909,  0.06733662,  0.01215658,\n",
      "        0.02139645,  0.01998421, -0.00769313, -0.02804205,  0.01302584,\n",
      "        0.00989675,  0.0059596 ,  0.00077109,  0.07303608,  0.02508596])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3898366328302994)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4149225924286055\n",
      "DEBUG:shap:self.fx = 0.19632738095238098\n",
      "DEBUG:shap:self.link(self.fx) = 0.19632738095238098\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.18280862, -0.00991086, -0.00928909, -0.06733662, -0.01215658,\n",
      "       -0.02139645, -0.01998421,  0.00769313,  0.02804205, -0.01302584,\n",
      "       -0.00989675, -0.0059596 , -0.00077109, -0.07303608, -0.02508596])\n",
      " 76%|███████▌  | 56/74 [01:33<00:29,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12992599730797832)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12684066047167364\n",
      "DEBUG:shap:self.fx = 0.5155906870906872\n",
      "DEBUG:shap:self.link(self.fx) = 0.5155906870906872\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.10023958,  0.01886029,  0.00508959,  0.0483061 , -0.02265622,\n",
      "        0.02365747,  0.01134186, -0.03672281, -0.00120406,  0.01449263,\n",
      "        0.00633259,  0.02388618,  0.00864743, -0.07034463, -0.00308534])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.12992599730797832)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1268406604716737\n",
      "DEBUG:shap:self.fx = 0.48440931290931283\n",
      "DEBUG:shap:self.link(self.fx) = 0.48440931290931283\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.10023958, -0.01886029, -0.00508959, -0.0483061 ,  0.02265622,\n",
      "       -0.02365747, -0.01134186,  0.03672281,  0.00120406, -0.01449263,\n",
      "       -0.00633259, -0.02388618, -0.00864743,  0.07034463,  0.00308534])\n",
      " 77%|███████▋  | 57/74 [01:35<00:28,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.16493650095985948)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.17974726263463192\n",
      "DEBUG:shap:self.fx = 0.20900276398438167\n",
      "DEBUG:shap:self.link(self.fx) = 0.20900276398438167\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.12560016,  0.00041961,  0.01024276, -0.03226313,  0.00680112,\n",
      "        0.01340389,  0.01175909, -0.03988826,  0.00352238, -0.02317526,\n",
      "       -0.01321315, -0.01005553,  0.00137787,  0.03173227, -0.01481076])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.16493650095985907)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1797472626346316\n",
      "DEBUG:shap:self.fx = 0.7909972360156181\n",
      "DEBUG:shap:self.link(self.fx) = 0.7909972360156181\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.12560016, -0.00041961, -0.01024276,  0.03226313, -0.00680112,\n",
      "       -0.01340389, -0.01175909,  0.03988826, -0.00352238,  0.02317526,\n",
      "        0.01321315,  0.01005553, -0.00137787, -0.03173227,  0.01481076])\n",
      " 78%|███████▊  | 58/74 [01:37<00:26,  1.67s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2876036309817329)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.28197660272490005\n",
      "DEBUG:shap:self.fx = 0.10677342389411354\n",
      "DEBUG:shap:self.link(self.fx) = 0.10677342389411354\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.11865118, -0.0082497 , -0.0011971 , -0.06457253, -0.0034333 ,\n",
      "       -0.02517196, -0.00793142, -0.04368102, -0.01660129,  0.02947552,\n",
      "       -0.01513408,  0.00354403, -0.00072438, -0.01527526,  0.00562703])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.28760363098173286)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2819766027249\n",
      "DEBUG:shap:self.fx = 0.8932265761058865\n",
      "DEBUG:shap:self.link(self.fx) = 0.8932265761058865\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.11865118,  0.0082497 ,  0.0011971 ,  0.06457253,  0.0034333 ,\n",
      "        0.02517196,  0.00793142,  0.04368102,  0.01660129, -0.02947552,\n",
      "        0.01513408, -0.00354403,  0.00072438,  0.01527526, -0.00562703])\n",
      " 80%|███████▉  | 59/74 [01:38<00:24,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.06340277420740117)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.05503339828941134\n",
      "DEBUG:shap:self.fx = 0.44378342490842493\n",
      "DEBUG:shap:self.link(self.fx) = 0.44378342490842493\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.13054476, -0.07137148,  0.00063539,  0.04447173,  0.01430261,\n",
      "       -0.00551502,  0.01141635,  0.11431032, -0.01917532, -0.0107735 ,\n",
      "       -0.00545697,  0.00323237, -0.00582168, -0.13739679, -0.00836938])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.06340277420740123)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.05503339828941134\n",
      "DEBUG:shap:self.fx = 0.5562165750915752\n",
      "DEBUG:shap:self.link(self.fx) = 0.5562165750915752\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.13054476,  0.07137148, -0.00063539, -0.04447173, -0.01430261,\n",
      "        0.00551502, -0.01141635, -0.11431032,  0.01917532,  0.0107735 ,\n",
      "        0.00545697, -0.00323237,  0.00582168,  0.13739679,  0.00836938])\n",
      " 81%|████████  | 60/74 [01:40<00:23,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.33182342949912225)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3496845504285374\n",
      "DEBUG:shap:self.fx = 0.03906547619047619\n",
      "DEBUG:shap:self.link(self.fx) = 0.03906547619047619\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.09334933,  0.00927705, -0.00371047, -0.05136281, -0.00387131,\n",
      "       -0.01015702, -0.04580804, -0.01781904, -0.00064913, -0.01033052,\n",
      "       -0.01755115, -0.01681973, -0.00562781, -0.06404413, -0.01786112])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3318234294991221)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3496845504285372\n",
      "DEBUG:shap:self.fx = 0.9609345238095237\n",
      "DEBUG:shap:self.link(self.fx) = 0.9609345238095237\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.09334933, -0.00927705,  0.00371047,  0.05136281,  0.00387131,\n",
      "        0.01015702,  0.04580804,  0.01781904,  0.00064913,  0.01033052,\n",
      "        0.01755115,  0.01681973,  0.00562781,  0.06404413,  0.01786112])\n",
      " 82%|████████▏ | 61/74 [01:42<00:21,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.31229327575980287)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3191463108902979\n",
      "DEBUG:shap:self.fx = 0.06960371572871574\n",
      "DEBUG:shap:self.link(self.fx) = 0.06960371572871574\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10854893,  0.00058753, -0.00082631, -0.05739853, -0.00045388,\n",
      "       -0.01738073,  0.        , -0.03296524, -0.00242563, -0.01628219,\n",
      "       -0.01177877,  0.0049132 ,  0.0005226 , -0.07025639, -0.00685304])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3122932757598026)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.31914631089029755\n",
      "DEBUG:shap:self.fx = 0.9303962842712841\n",
      "DEBUG:shap:self.link(self.fx) = 0.9303962842712841\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10854893, -0.00058753,  0.00082631,  0.05739853,  0.00045388,\n",
      "        0.01738073,  0.        ,  0.03296524,  0.00242563,  0.01628219,\n",
      "        0.01177877, -0.0049132 , -0.0005226 ,  0.07025639,  0.00685304])\n",
      " 84%|████████▍ | 62/74 [01:43<00:19,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19542722056602171)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.20859297533696225\n",
      "DEBUG:shap:self.fx = 0.18015705128205134\n",
      "DEBUG:shap:self.link(self.fx) = 0.18015705128205134\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.10112648,  0.00716719,  0.00588557, -0.04110939, -0.00967955,\n",
      "       -0.01396484, -0.05146119, -0.01970137, -0.03091968,  0.0196681 ,\n",
      "       -0.0003915 , -0.00479022,  0.00600959,  0.03898654, -0.01316575])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19542722056602171)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2085929753369623\n",
      "DEBUG:shap:self.fx = 0.8198429487179488\n",
      "DEBUG:shap:self.link(self.fx) = 0.8198429487179488\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.10112648, -0.00716719, -0.00588557,  0.04110939,  0.00967955,\n",
      "        0.01396484,  0.05146119,  0.01970137,  0.03091968, -0.0196681 ,\n",
      "        0.0003915 ,  0.00479022, -0.00600959, -0.03898654,  0.01316575])\n",
      " 85%|████████▌ | 63/74 [01:45<00:18,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.18553403966404852)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13913644575543269\n",
      "DEBUG:shap:self.fx = 0.2496135808635809\n",
      "DEBUG:shap:self.link(self.fx) = 0.2496135808635809\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.08776929,  0.00794474, -0.00262596, -0.06084735,  0.01185998,\n",
      "       -0.00562009, -0.06556355,  0.09338578,  0.00068497, -0.00938831,\n",
      "       -0.02454478, -0.01538459,  0.00903899, -0.03670458,  0.04639759])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1855340396640485)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1391364457554327\n",
      "DEBUG:shap:self.fx = 0.7503864191364192\n",
      "DEBUG:shap:self.link(self.fx) = 0.7503864191364192\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.08776929, -0.00794474,  0.00262596,  0.06084735, -0.01185998,\n",
      "        0.00562009,  0.06556355, -0.09338578, -0.00068497,  0.00938831,\n",
      "        0.02454478,  0.01538459, -0.00903899,  0.03670458, -0.04639759])\n",
      " 86%|████████▋ | 64/74 [01:47<00:16,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.07293401947212699)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08346072564221257\n",
      "DEBUG:shap:self.fx = 0.305289300976801\n",
      "DEBUG:shap:self.link(self.fx) = 0.305289300976801\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.01782229, -0.0242754 ,  0.00248173, -0.06629605,  0.00376133,\n",
      "        0.03655849,  0.00450552, -0.04245322, -0.00451884, -0.0070334 ,\n",
      "       -0.01648868,  0.00150979, -0.00258105,  0.05971804, -0.01052671])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.07293401947212677)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.0834607256422123\n",
      "DEBUG:shap:self.fx = 0.6947106990231988\n",
      "DEBUG:shap:self.link(self.fx) = 0.6947106990231988\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.01782229,  0.0242754 , -0.00248173,  0.06629605, -0.00376133,\n",
      "       -0.03655849, -0.00450552,  0.04245322,  0.00451884,  0.0070334 ,\n",
      "        0.01648868, -0.00150979,  0.00258105, -0.05971804,  0.01052671])\n",
      " 88%|████████▊ | 65/74 [01:48<00:14,  1.65s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20570631387797483)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.20470736788885488\n",
      "DEBUG:shap:self.fx = 0.1840426587301587\n",
      "DEBUG:shap:self.link(self.fx) = 0.1840426587301587\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.13702941, -0.00179768, -0.0032439 , -0.03749909,  0.00900317,\n",
      "        0.01458066, -0.01678465, -0.01971694, -0.00617561,  0.00628103,\n",
      "       -0.01394552,  0.00382235, -0.00298716, -0.00021358,  0.00099895])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20570631387797472)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2047073678888548\n",
      "DEBUG:shap:self.fx = 0.8159573412698413\n",
      "DEBUG:shap:self.link(self.fx) = 0.8159573412698413\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.13702941,  0.00179768,  0.0032439 ,  0.03749909, -0.00900317,\n",
      "       -0.01458066,  0.01678465,  0.01971694,  0.00617561, -0.00628103,\n",
      "        0.01394552, -0.00382235,  0.00298716,  0.00021358, -0.00099895])\n",
      " 89%|████████▉ | 66/74 [01:50<00:13,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.014010732087060385)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.0026340453780323014\n",
      "DEBUG:shap:self.fx = 0.3861159812409813\n",
      "DEBUG:shap:self.link(self.fx) = 0.3861159812409813\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.11993773,  0.01295766, -0.01188146,  0.04243783, -0.01148124,\n",
      "        0.01802294,  0.00423679, -0.03092928, -0.01516069,  0.        ,\n",
      "        0.00203178, -0.03942007,  0.00573869, -0.1105014 ,  0.01137669])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.014010732087060149)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.002634045378032024\n",
      "DEBUG:shap:self.fx = 0.6138840187590185\n",
      "DEBUG:shap:self.link(self.fx) = 0.6138840187590185\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.11993773, -0.01295766,  0.01188146, -0.04243783,  0.01148124,\n",
      "       -0.01802294, -0.00423679,  0.03092928,  0.01516069,  0.        ,\n",
      "       -0.00203178,  0.03942007, -0.00573869,  0.1105014 , -0.01137669])\n",
      " 91%|█████████ | 67/74 [01:52<00:11,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.08511255178987985)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.05949096849698138\n",
      "DEBUG:shap:self.fx = 0.44824099511599497\n",
      "DEBUG:shap:self.link(self.fx) = 0.44824099511599497\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.06666743,  0.00027538, -0.00384314,  0.0567037 , -0.00905601,\n",
      "        0.00691178,  0.00999601,  0.02555342,  0.00723299,  0.02470173,\n",
      "       -0.00417673,  0.00456311,  0.00536586, -0.10578298, -0.02562158])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.08511255178987999)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.059490968496981544\n",
      "DEBUG:shap:self.fx = 0.551759004884005\n",
      "DEBUG:shap:self.link(self.fx) = 0.551759004884005\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.06666743, -0.00027538,  0.00384314, -0.0567037 ,  0.00905601,\n",
      "       -0.00691178, -0.00999601, -0.02555342, -0.00723299, -0.02470173,\n",
      "        0.00417673, -0.00456311, -0.00536586,  0.10578298,  0.02562158])\n",
      " 92%|█████████▏| 68/74 [01:53<00:10,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.16777228474523637)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13868586855485548\n",
      "DEBUG:shap:self.fx = 0.2500641580641581\n",
      "DEBUG:shap:self.link(self.fx) = 0.2500641580641581\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.10261326, -0.01495426, -0.00325698,  0.0015475 ,  0.00061481,\n",
      "       -0.00927256, -0.038214  , -0.03825652, -0.01916041, -0.00941577,\n",
      "        0.00366781, -0.00550871, -0.00875116, -0.12942529,  0.02908642])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1677722847452362)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.13868586855485532\n",
      "DEBUG:shap:self.fx = 0.7499358419358418\n",
      "DEBUG:shap:self.link(self.fx) = 0.7499358419358418\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.10261326,  0.01495426,  0.00325698, -0.0015475 , -0.00061481,\n",
      "        0.00927256,  0.038214  ,  0.03825652,  0.01916041,  0.00941577,\n",
      "       -0.00366781,  0.00550871,  0.00875116,  0.12942529, -0.02908642])\n",
      " 93%|█████████▎| 69/74 [01:55<00:08,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.059179816296691674)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.05465494114892816\n",
      "DEBUG:shap:self.fx = 0.33409508547008543\n",
      "DEBUG:shap:self.link(self.fx) = 0.33409508547008543\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.1374253 ,  0.0109501 ,  0.00712266, -0.05533999,  0.00576124,\n",
      "       -0.00549544,  0.01804169,  0.10396605,  0.00346298, -0.00475835,\n",
      "        0.00469653,  0.00019447, -0.00329322, -0.00706325,  0.00452488])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.059179816296691404)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.05465494114892788\n",
      "DEBUG:shap:self.fx = 0.6659049145299144\n",
      "DEBUG:shap:self.link(self.fx) = 0.6659049145299144\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.1374253 , -0.0109501 , -0.00712266,  0.05533999, -0.00576124,\n",
      "        0.00549544, -0.01804169, -0.10396605, -0.00346298,  0.00475835,\n",
      "       -0.00469653, -0.00019447,  0.00329322,  0.00706325, -0.00452488])\n",
      " 95%|█████████▍| 70/74 [01:57<00:06,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22442619850220719)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2082174503484634\n",
      "DEBUG:shap:self.fx = 0.596967476967477\n",
      "DEBUG:shap:self.link(self.fx) = 0.596967476967477\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.18971296,  0.01320275, -0.00593675,  0.06281746,  0.02437085,\n",
      "       -0.01615366,  0.0119059 , -0.03956066, -0.04940088, -0.00924163,\n",
      "       -0.00960098,  0.02326982,  0.00270733,  0.0263337 , -0.01620875])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2244261985022073)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2082174503484635\n",
      "DEBUG:shap:self.fx = 0.403032523032523\n",
      "DEBUG:shap:self.link(self.fx) = 0.403032523032523\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.18971296, -0.01320275,  0.00593675, -0.06281746, -0.02437085,\n",
      "        0.01615366, -0.0119059 ,  0.03956066,  0.04940088,  0.00924163,\n",
      "        0.00960098, -0.02326982, -0.00270733, -0.0263337 ,  0.01620875])\n",
      " 96%|█████████▌| 71/74 [01:59<00:05,  1.70s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.11930521108277546)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13145533519932218\n",
      "DEBUG:shap:self.fx = 0.2572946914196914\n",
      "DEBUG:shap:self.link(self.fx) = 0.2572946914196914\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([-0.11210031,  0.00995708,  0.00322982, -0.02310192,  0.0095339 ,\n",
      "        0.01667265, -0.01498598, -0.02067081, -0.01028987,  0.03802442,\n",
      "       -0.00845897, -0.01666046, -0.00394476,  0.01349001, -0.01215012])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.11930521108277536)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.13145533519932218\n",
      "DEBUG:shap:self.fx = 0.7427053085803087\n",
      "DEBUG:shap:self.link(self.fx) = 0.7427053085803087\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([ 0.11210031, -0.00995708, -0.00322982,  0.02310192, -0.0095339 ,\n",
      "       -0.01667265,  0.01498598,  0.02067081,  0.01028987, -0.03802442,\n",
      "        0.00845897,  0.01666046,  0.00394476, -0.01349001,  0.01215012])\n",
      " 97%|█████████▋| 72/74 [02:00<00:03,  1.67s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20719081195126965)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.22933741371842675\n",
      "DEBUG:shap:self.fx = 0.6180874403374403\n",
      "DEBUG:shap:self.link(self.fx) = 0.6180874403374403\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.15134237,  0.01547573,  0.00668955,  0.06698761,  0.00150773,\n",
      "        0.02417875,  0.01160662, -0.00804117,  0.00960278,  0.02375007,\n",
      "       -0.00159867,  0.00417564,  0.03054002, -0.12902621,  0.0221466 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20719081195126973)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2293374137184268\n",
      "DEBUG:shap:self.fx = 0.3819125596625597\n",
      "DEBUG:shap:self.link(self.fx) = 0.3819125596625597\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.15134237, -0.01547573, -0.00668955, -0.06698761, -0.00150773,\n",
      "       -0.02417875, -0.01160662,  0.00804117, -0.00960278, -0.02375007,\n",
      "        0.00159867, -0.00417564, -0.03054002,  0.12902621, -0.0221466 ])\n",
      " 99%|█████████▊| 73/74 [02:02<00:01,  1.70s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.29170939104198834)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.31654849430450716\n",
      "DEBUG:shap:self.fx = 0.7052985209235207\n",
      "DEBUG:shap:self.link(self.fx) = 0.7052985209235207\n",
      "DEBUG:shap:self.fnull = 0.3887500266190136\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3887500266190136\n",
      "INFO:shap:phi = array([ 0.17866445, -0.0090458 , -0.01316276,  0.07318511, -0.02260881,\n",
      "        0.0222096 ,  0.01570815, -0.00923042, -0.0020316 ,  0.01007408,\n",
      "        0.0072396 , -0.00302005,  0.0082152 ,  0.03551263,  0.0248391 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.29170939104198845)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3165484943045075\n",
      "DEBUG:shap:self.fx = 0.29470147907647903\n",
      "DEBUG:shap:self.link(self.fx) = 0.29470147907647903\n",
      "DEBUG:shap:self.fnull = 0.6112499733809865\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6112499733809865\n",
      "INFO:shap:phi = array([-0.17866445,  0.0090458 ,  0.01316276, -0.07318511,  0.02260881,\n",
      "       -0.0222096 , -0.01570815,  0.00923042,  0.0020316 , -0.01007408,\n",
      "       -0.0072396 ,  0.00302005, -0.0082152 , -0.03551263, -0.0248391 ])\n",
      "100%|██████████| 74/74 [02:04<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8020833333333333,\n",
      "                0.8397435897435898,\n",
      "                0.7131410256410257,\n",
      "                0.6145833333333333,\n",
      "                0.5737179487179487,\n",
      "                0.5817307692307693,\n",
      "                0.5825320512820513,\n",
      "                0.6145833333333334,\n",
      "                0.6386217948717948,\n",
      "                0.6810897435897435,\n",
      "                0.6602564102564104,\n",
      "                0.6518429487179487,\n",
      "                0.7471955128205128,\n",
      "                0.6947115384615384,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5333619228350892,\n",
      "                0.5854290017917382,\n",
      "                0.7117184396839162,\n",
      "                0.7458745657755351,\n",
      "                0.7882211683938165,\n",
      "                0.81629281154797,\n",
      "                0.8518784974388885,\n",
      "                0.8782272567565552,\n",
      "                0.8603662885864408,\n",
      "                0.8846268030968748,\n",
      "                0.9209466010297434,\n",
      "                0.9438895036052928,\n",
      "                0.9230942930370424,\n",
      "                0.942150054860188,\n",
      "                0.9272027411818561\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17575241929729749,\n",
      "                0.1986929523104957,\n",
      "                0.2597070037610788,\n",
      "                0.27604349501841946,\n",
      "                0.2965766383981693,\n",
      "                0.3094726358791318,\n",
      "                0.3252681944157605,\n",
      "                0.3367758697199785,\n",
      "                0.3291563975002879,\n",
      "                0.3395284163415068,\n",
      "                0.354542866188551,\n",
      "                0.3641007792104075,\n",
      "                0.3560428205920232,\n",
      "                0.3635532888116729,\n",
      "                0.3581441230715909\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6597222222222222,\n",
      "            \"cross_entropy\": 0.82088532997473,\n",
      "            \"brier\": 0.3095571933677581\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8565705128205129,\n",
      "                0.8325320512820513,\n",
      "                0.8445512820512819,\n",
      "                0.8878205128205128,\n",
      "                0.8782051282051282,\n",
      "                0.8838141025641025,\n",
      "                0.8878205128205129,\n",
      "                0.8838141025641025,\n",
      "                0.8822115384615383,\n",
      "                0.8766025641025641,\n",
      "                0.875,\n",
      "                0.875801282051282,\n",
      "                0.8701923076923077,\n",
      "                0.875801282051282,\n",
      "                0.8782051282051282\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5577995700528187,\n",
      "                0.5201346733885938,\n",
      "                0.4655374628351458,\n",
      "                0.4380237734852441,\n",
      "                0.43838018080987795,\n",
      "                0.4360449867580237,\n",
      "                0.42697233630539444,\n",
      "                0.4353986306482422,\n",
      "                0.4363295317869158,\n",
      "                0.4388482578823135,\n",
      "                0.44277956858477674,\n",
      "                0.4479181639936016,\n",
      "                0.4411853843562204,\n",
      "                0.43669113234623613,\n",
      "                0.43130759728033224\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18281475287193621,\n",
      "                0.16834113484809304,\n",
      "                0.145363733060362,\n",
      "                0.13537964233817612,\n",
      "                0.13578212969515902,\n",
      "                0.1345341998682114,\n",
      "                0.1312264121027697,\n",
      "                0.1356495060143545,\n",
      "                0.1352525686591906,\n",
      "                0.13748507467713983,\n",
      "                0.13884812722942685,\n",
      "                0.14046081786348746,\n",
      "                0.13793953188590014,\n",
      "                0.13646746105293178,\n",
      "                0.13441740529050694\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.872596153846154,\n",
      "            \"cross_entropy\": 0.4528900833675824,\n",
      "            \"brier\": 0.14199749983050972\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/74 [00:00<?, ?it/s]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.27678796843625)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2756445436944241\n",
      "DEBUG:shap:self.fx = 0.6749630926444653\n",
      "DEBUG:shap:self.link(self.fx) = 0.6749630926444653\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.2017999 ,  0.0271786 , -0.00033244,  0.09964273,  0.00637291,\n",
      "       -0.01298279,  0.02917157, -0.02738782, -0.00783265, -0.00173201,\n",
      "        0.00196725,  0.01117128,  0.02924102, -0.07948959, -0.00114342])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2767879684362497)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.27564454369442387\n",
      "DEBUG:shap:self.fx = 0.32503690735553487\n",
      "DEBUG:shap:self.link(self.fx) = 0.32503690735553487\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.2017999 , -0.0271786 ,  0.00033244, -0.09964273, -0.00637291,\n",
      "        0.01298279, -0.02917157,  0.02738782,  0.00783265,  0.00173201,\n",
      "       -0.00196725, -0.01117128, -0.02924102,  0.07948959,  0.00114342])\n",
      "  1%|▏         | 1/74 [00:02<02:45,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22974861923562265)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2373706104454989\n",
      "DEBUG:shap:self.fx = 0.1619479385045423\n",
      "DEBUG:shap:self.link(self.fx) = 0.1619479385045423\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.1560494 ,  0.05130451,  0.01028373, -0.06063561, -0.00555516,\n",
      "       -0.01586947, -0.01900141, -0.02634468,  0.00042112, -0.00885417,\n",
      "       -0.02186089, -0.00740835, -0.00347823,  0.03329938, -0.00762199])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22974861923562284)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.237370610445499\n",
      "DEBUG:shap:self.fx = 0.8380520614954577\n",
      "DEBUG:shap:self.link(self.fx) = 0.8380520614954577\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.1560494 , -0.05130451, -0.01028373,  0.06063561,  0.00555516,\n",
      "        0.01586947,  0.01900141,  0.02634468, -0.00042112,  0.00885417,\n",
      "        0.02186089,  0.00740835,  0.00347823, -0.03329938,  0.00762199])\n",
      "  3%|▎         | 2/74 [00:04<02:40,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.08656965909312911)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08844081801570658\n",
      "DEBUG:shap:self.fx = 0.31087773093433463\n",
      "DEBUG:shap:self.link(self.fx) = 0.31087773093433463\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.16372654,  0.00125026,  0.01026172, -0.05362372,  0.00247549,\n",
      "       -0.01985236,  0.0291535 ,  0.03863178, -0.00267566,  0.03658878,\n",
      "       -0.00560807, -0.00048366, -0.01246481,  0.05350362, -0.00187116])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.08656965909312897)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08844081801570647\n",
      "DEBUG:shap:self.fx = 0.6891222690656652\n",
      "DEBUG:shap:self.link(self.fx) = 0.6891222690656652\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.16372654, -0.00125026, -0.01026172,  0.05362372, -0.00247549,\n",
      "        0.01985236, -0.0291535 , -0.03863178,  0.00267566, -0.03658878,\n",
      "        0.00560807,  0.00048366,  0.01246481, -0.05350362,  0.00187116])\n",
      "  4%|▍         | 3/74 [00:06<02:36,  2.21s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3124188559198798)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3189241040992156\n",
      "DEBUG:shap:self.fx = 0.7182426530492568\n",
      "DEBUG:shap:self.link(self.fx) = 0.7182426530492568\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.23661822,  0.02083283, -0.00227873, -0.02244465, -0.00630095,\n",
      "        0.01868008,  0.04059353,  0.01109673,  0.00482572, -0.00030264,\n",
      "       -0.00417193,  0.01622315, -0.02170387,  0.02075136,  0.00650525])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.31241885591987956)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3189241040992155\n",
      "DEBUG:shap:self.fx = 0.2817573469507432\n",
      "DEBUG:shap:self.link(self.fx) = 0.2817573469507432\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.23661822, -0.02083283,  0.00227873,  0.02244465,  0.00630095,\n",
      "       -0.01868008, -0.04059353, -0.01109673, -0.00482572,  0.00030264,\n",
      "        0.00417193, -0.01622315,  0.02170387, -0.02075136, -0.00650525])\n",
      "  5%|▌         | 4/74 [00:08<02:35,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1228259866755429)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.11995346958496172\n",
      "DEBUG:shap:self.fx = 0.2793650793650795\n",
      "DEBUG:shap:self.link(self.fx) = 0.2793650793650795\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.03525158, -0.04229583,  0.00344969, -0.04907609,  0.01366168,\n",
      "        0.07048535,  0.00740564, -0.05015137, -0.01780168, -0.00826769,\n",
      "       -0.03064862,  0.00514499, -0.01766778,  0.0281873 ,  0.00287252])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12282598667554281)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.11995346958496167\n",
      "DEBUG:shap:self.fx = 0.7206349206349204\n",
      "DEBUG:shap:self.link(self.fx) = 0.7206349206349204\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.03525158,  0.04229583, -0.00344969,  0.04907609, -0.01366168,\n",
      "       -0.07048535, -0.00740564,  0.05015137,  0.01780168,  0.00826769,\n",
      "        0.03064862, -0.00514499,  0.01766778, -0.0281873 , -0.00287252])\n",
      "  7%|▋         | 5/74 [00:11<02:31,  2.20s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17469777862096944)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2140995806164981\n",
      "DEBUG:shap:self.fx = 0.18521896833354312\n",
      "DEBUG:shap:self.link(self.fx) = 0.18521896833354312\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.10882362,  0.01573118,  0.012081  , -0.04666538,  0.        ,\n",
      "       -0.01830181, -0.04257631, -0.01746365,  0.        , -0.00107144,\n",
      "        0.02415658,  0.00472724, -0.00934204,  0.01285046, -0.0394018 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1746977786209695)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21409958061649814\n",
      "DEBUG:shap:self.fx = 0.8147810316664569\n",
      "DEBUG:shap:self.link(self.fx) = 0.8147810316664569\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.10882362, -0.01573118, -0.012081  ,  0.04666538,  0.        ,\n",
      "        0.01830181,  0.04257631,  0.01746365,  0.        ,  0.00107144,\n",
      "       -0.02415658, -0.00472724,  0.00934204, -0.01285046,  0.0394018 ])\n",
      "  8%|▊         | 6/74 [00:13<02:30,  2.21s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.28331027911950996)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2926814570063455\n",
      "DEBUG:shap:self.fx = 0.10663709194369572\n",
      "DEBUG:shap:self.link(self.fx) = 0.10663709194369572\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.16074567,  0.00909135, -0.00112331, -0.0677367 ,  0.01495482,\n",
      "       -0.01621414, -0.03339971,  0.00121717,  0.00218612, -0.00397124,\n",
      "        0.01095465, -0.00210404, -0.00702569, -0.02939388, -0.00937118])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.28331027911951007)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2926814570063455\n",
      "DEBUG:shap:self.fx = 0.8933629080563043\n",
      "DEBUG:shap:self.link(self.fx) = 0.8933629080563043\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.16074567, -0.00909135,  0.00112331,  0.0677367 , -0.01495482,\n",
      "        0.01621414,  0.03339971, -0.00121717, -0.00218612,  0.00397124,\n",
      "       -0.01095465,  0.00210404,  0.00702569,  0.02939388,  0.00937118])\n",
      "  9%|▉         | 7/74 [00:15<02:27,  2.21s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24534037381740414)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2547130245489236\n",
      "DEBUG:shap:self.fx = 0.6540315734989648\n",
      "DEBUG:shap:self.link(self.fx) = 0.6540315734989648\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.21860209,  0.01454259,  0.01498225,  0.00722165, -0.00277991,\n",
      "        0.02012229,  0.02218124, -0.02226128,  0.00136807, -0.00032133,\n",
      "        0.01309284, -0.00706447,  0.01878406, -0.05312971,  0.00937265])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2453403738174041)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2547130245489236\n",
      "DEBUG:shap:self.fx = 0.34596842650103515\n",
      "DEBUG:shap:self.link(self.fx) = 0.34596842650103515\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.21860209, -0.01454259, -0.01498225, -0.00722165,  0.00277991,\n",
      "       -0.02012229, -0.02218124,  0.02226128, -0.00136807,  0.00032133,\n",
      "       -0.01309284,  0.00706447, -0.01878406,  0.05312971, -0.00937265])\n",
      " 11%|█         | 8/74 [00:17<02:27,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.31319915983597724)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3344230795813014\n",
      "DEBUG:shap:self.fx = 0.06489546936873981\n",
      "DEBUG:shap:self.link(self.fx) = 0.06489546936873981\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.1542381 ,  0.00154209, -0.002648  , -0.07338332, -0.01146974,\n",
      "       -0.03051099, -0.04128147,  0.00125908,  0.00523371,  0.01490743,\n",
      "        0.00569624, -0.00135849, -0.0165838 , -0.0103638 , -0.02122392])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3131991598359776)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3344230795813017\n",
      "DEBUG:shap:self.fx = 0.9351045306312604\n",
      "DEBUG:shap:self.link(self.fx) = 0.9351045306312604\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.1542381 , -0.00154209,  0.002648  ,  0.07338332,  0.01146974,\n",
      "        0.03051099,  0.04128147, -0.00125908, -0.00523371, -0.01490743,\n",
      "       -0.00569624,  0.00135849,  0.0165838 ,  0.0103638 ,  0.02122392])\n",
      " 12%|█▏        | 9/74 [00:20<02:25,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.21648131012957295)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21513556835039396\n",
      "DEBUG:shap:self.fx = 0.18418298059964724\n",
      "DEBUG:shap:self.link(self.fx) = 0.18418298059964724\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.11923592, -0.03362855,  0.00322279,  0.01276078,  0.03320215,\n",
      "       -0.01440904, -0.00420464, -0.02584971,  0.00316524, -0.0105282 ,\n",
      "        0.00906773,  0.00406131, -0.02237136, -0.05173388,  0.00134574])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.21648131012957286)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2151355683503937\n",
      "DEBUG:shap:self.fx = 0.8158170194003525\n",
      "DEBUG:shap:self.link(self.fx) = 0.8158170194003525\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.11923592,  0.03362855, -0.00322279, -0.01276078, -0.03320215,\n",
      "        0.01440904,  0.00420464,  0.02584971, -0.00316524,  0.0105282 ,\n",
      "       -0.00906773, -0.00406131,  0.02237136,  0.05173388, -0.00134574])\n",
      " 14%|█▎        | 10/74 [00:22<02:24,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.285297753157668)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.28734018120868904\n",
      "DEBUG:shap:self.fx = 0.6866587301587302\n",
      "DEBUG:shap:self.link(self.fx) = 0.6866587301587302\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.20297962, -0.09150793, -0.01740207,  0.08340043,  0.00516075,\n",
      "        0.00654642,  0.0166982 ,  0.03887922, -0.01109756,  0.00897191,\n",
      "        0.00734604, -0.00127839, -0.0280096 ,  0.06461072,  0.00204243])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.28529775315766787)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2873401812086888\n",
      "DEBUG:shap:self.fx = 0.3133412698412699\n",
      "DEBUG:shap:self.link(self.fx) = 0.3133412698412699\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.20297962,  0.09150793,  0.01740207, -0.08340043, -0.00516075,\n",
      "       -0.00654642, -0.0166982 , -0.03887922,  0.01109756, -0.00897191,\n",
      "       -0.00734604,  0.00127839,  0.0280096 , -0.06461072, -0.00204243])\n",
      " 15%|█▍        | 11/74 [00:24<02:19,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24185052761526485)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2486157944843022\n",
      "DEBUG:shap:self.fx = 0.6479343434343434\n",
      "DEBUG:shap:self.link(self.fx) = 0.6479343434343434\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.17890127,  0.01103737, -0.00538841,  0.08741894, -0.00952002,\n",
      "        0.02796451, -0.01570936, -0.01773775, -0.00363921, -0.00697813,\n",
      "        0.01739542, -0.04747034,  0.00407939,  0.02149687,  0.00676527])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.24185052761526474)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2486157944843022\n",
      "DEBUG:shap:self.fx = 0.3520656565656565\n",
      "DEBUG:shap:self.link(self.fx) = 0.3520656565656565\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.17890127, -0.01103737,  0.00538841, -0.08741894,  0.00952002,\n",
      "       -0.02796451,  0.01570936,  0.01773775,  0.00363921,  0.00697813,\n",
      "       -0.01739542,  0.04747034, -0.00407939, -0.02149687, -0.00676527])\n",
      " 16%|█▌        | 12/74 [00:26<02:18,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4342152636018026)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.38302668914519694\n",
      "DEBUG:shap:self.fx = 0.7823452380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.7823452380952381\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.19622845,  0.0126738 ,  0.00910075,  0.10237877, -0.00350615,\n",
      "       -0.02508773,  0.02056579,  0.0419387 , -0.00403671,  0.01543243,\n",
      "        0.00108491,  0.00263677,  0.00859828,  0.0562072 , -0.05118857])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4342152636018026)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3830266891451968\n",
      "DEBUG:shap:self.fx = 0.21765476190476193\n",
      "DEBUG:shap:self.link(self.fx) = 0.21765476190476193\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.19622845, -0.0126738 , -0.00910075, -0.10237877,  0.00350615,\n",
      "        0.02508773, -0.02056579, -0.0419387 ,  0.00403671, -0.01543243,\n",
      "       -0.00108491, -0.00263677, -0.00859828, -0.0562072 ,  0.05118857])\n",
      " 18%|█▊        | 13/74 [00:28<02:15,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19615816174798675)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.20959777605821567\n",
      "DEBUG:shap:self.fx = 0.18972077289182554\n",
      "DEBUG:shap:self.link(self.fx) = 0.18972077289182554\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.11797672,  0.04156793,  0.00890288, -0.05637928,  0.01483119,\n",
      "       -0.00975041, -0.02374274, -0.02827919,  0.00682675, -0.01390853,\n",
      "       -0.01952299,  0.00257925,  0.00523131, -0.00653762, -0.01343961])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19615816174798664)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2095977760582156\n",
      "DEBUG:shap:self.fx = 0.8102792271081743\n",
      "DEBUG:shap:self.link(self.fx) = 0.8102792271081743\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.11797672, -0.04156793, -0.00890288,  0.05637928, -0.01483119,\n",
      "        0.00975041,  0.02374274,  0.02827919, -0.00682675,  0.01390853,\n",
      "        0.01952299, -0.00257925, -0.00523131,  0.00653762,  0.01343961])\n",
      " 19%|█▉        | 14/74 [00:31<02:13,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.0263351631967872)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.027654629536121744\n",
      "DEBUG:shap:self.fx = 0.37166391941391946\n",
      "DEBUG:shap:self.link(self.fx) = 0.37166391941391946\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.13805202,  0.01740489,  0.01098563,  0.09515314,  0.00243365,\n",
      "        0.05843967, -0.03502832, -0.02157908,  0.00047758, -0.00461842,\n",
      "       -0.00590175, -0.00641748,  0.00211325, -0.0017459 , -0.00131947])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.026335163196787307)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.027654629536121855\n",
      "DEBUG:shap:self.fx = 0.6283360805860806\n",
      "DEBUG:shap:self.link(self.fx) = 0.6283360805860806\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.13805202, -0.01740489, -0.01098563, -0.09515314, -0.00243365,\n",
      "       -0.05843967,  0.03502832,  0.02157908, -0.00047758,  0.00461842,\n",
      "        0.00590175,  0.00641748, -0.00211325,  0.0017459 ,  0.00131947])\n",
      " 20%|██        | 15/74 [00:33<02:13,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3012673283918976)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.30846669709818936\n",
      "DEBUG:shap:self.fx = 0.09085185185185186\n",
      "DEBUG:shap:self.link(self.fx) = 0.09085185185185186\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.11603512,  0.00196522, -0.00633794, -0.05651237, -0.00455161,\n",
      "        0.0084279 , -0.01932278, -0.02535548, -0.02518704, -0.01294019,\n",
      "       -0.00650322, -0.00256976, -0.01056457, -0.02578036, -0.00719937])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3012673283918978)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3084666970981895\n",
      "DEBUG:shap:self.fx = 0.9091481481481483\n",
      "DEBUG:shap:self.link(self.fx) = 0.9091481481481483\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.11603512, -0.00196522,  0.00633794,  0.05651237,  0.00455161,\n",
      "       -0.0084279 ,  0.01932278,  0.02535548,  0.02518704,  0.01294019,\n",
      "        0.00650322,  0.00256976,  0.01056457,  0.02578036,  0.00719937])\n",
      " 22%|██▏       | 16/74 [00:35<02:08,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.33672040669275594)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3087846256531332\n",
      "DEBUG:shap:self.fx = 0.7081031746031744\n",
      "DEBUG:shap:self.link(self.fx) = 0.7081031746031744\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.18722473, -0.08878707, -0.02042939,  0.07044894, -0.00493115,\n",
      "        0.03061269,  0.01414012,  0.07012925, -0.01077892,  0.01067212,\n",
      "        0.00082627,  0.01588553,  0.00799774,  0.05370954, -0.02793578])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3367204066927562)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3087846256531333\n",
      "DEBUG:shap:self.fx = 0.29189682539682543\n",
      "DEBUG:shap:self.link(self.fx) = 0.29189682539682543\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.18722473,  0.08878707,  0.02042939, -0.07044894,  0.00493115,\n",
      "       -0.03061269, -0.01414012, -0.07012925,  0.01077892, -0.01067212,\n",
      "       -0.00082627, -0.01588553, -0.00799774, -0.05370954,  0.02793578])\n",
      " 23%|██▎       | 17/74 [00:37<02:05,  2.19s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2300312187104887)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24595922882773663\n",
      "DEBUG:shap:self.fx = 0.6452777777777778\n",
      "DEBUG:shap:self.link(self.fx) = 0.6452777777777778\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.17635041, -0.03423233, -0.01741424,  0.01915286,  0.0042732 ,\n",
      "       -0.01240763,  0.03491068,  0.07228232,  0.00717785, -0.00565918,\n",
      "       -0.02634798,  0.01765028, -0.0240743 ,  0.01836928,  0.01592801])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23003121871048865)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.24595922882773652\n",
      "DEBUG:shap:self.fx = 0.3547222222222222\n",
      "DEBUG:shap:self.link(self.fx) = 0.3547222222222222\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.17635041,  0.03423233,  0.01741424, -0.01915286, -0.0042732 ,\n",
      "        0.01240763, -0.03491068, -0.07228232, -0.00717785,  0.00565918,\n",
      "        0.02634798, -0.01765028,  0.0240743 , -0.01836928, -0.01592801])\n",
      " 24%|██▍       | 18/74 [00:39<02:01,  2.17s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.49551949024800196)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5075889602074681\n",
      "DEBUG:shap:self.fx = 0.9069075091575093\n",
      "DEBUG:shap:self.link(self.fx) = 0.9069075091575093\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.20796668,  0.02612372,  0.00557317,  0.07980426, -0.01266303,\n",
      "        0.04810855,  0.02579609,  0.05323809, -0.00050067, -0.00149847,\n",
      "       -0.00915453,  0.00375338,  0.01644211,  0.05253015,  0.01206947])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.495519490248002)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5075889602074679\n",
      "DEBUG:shap:self.fx = 0.09309249084249084\n",
      "DEBUG:shap:self.link(self.fx) = 0.09309249084249084\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.20796668, -0.02612372, -0.00557317, -0.07980426,  0.01266303,\n",
      "       -0.04810855, -0.02579609, -0.05323809,  0.00050067,  0.00149847,\n",
      "        0.00915453, -0.00375338, -0.01644211, -0.05253015, -0.01206947])\n",
      " 26%|██▌       | 19/74 [00:42<01:58,  2.16s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.058721292184113316)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.05477778043600223\n",
      "DEBUG:shap:self.fx = 0.344540768514039\n",
      "DEBUG:shap:self.link(self.fx) = 0.344540768514039\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.19023001,  0.01012693, -0.00373409, -0.05757103,  0.        ,\n",
      "       -0.02811222, -0.02877667, -0.02210854,  0.00110153, -0.00408415,\n",
      "       -0.00026591, -0.0137504 , -0.02660974, -0.075167  ,  0.00394351])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.05872129218411355)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.054777780436002343\n",
      "DEBUG:shap:self.fx = 0.6554592314859611\n",
      "DEBUG:shap:self.link(self.fx) = 0.6554592314859611\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.19023001, -0.01012693,  0.00373409,  0.05757103,  0.        ,\n",
      "        0.02811222,  0.02877667,  0.02210854, -0.00110153,  0.00408415,\n",
      "        0.00026591,  0.0137504 ,  0.02660974,  0.075167  , -0.00394351])\n",
      " 27%|██▋       | 20/74 [00:44<01:56,  2.16s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.27922105053794466)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.288160237485126\n",
      "DEBUG:shap:self.fx = 0.11115831146491525\n",
      "DEBUG:shap:self.link(self.fx) = 0.11115831146491525\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.11349794,  0.04923115, -0.01100165, -0.04936306, -0.00867273,\n",
      "       -0.0355058 , -0.03962021, -0.01678852,  0.00084953, -0.01205038,\n",
      "        0.01027285, -0.00524271, -0.00726296, -0.04056861, -0.00893919])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.27922105053794494)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2881602374851262\n",
      "DEBUG:shap:self.fx = 0.8888416885350849\n",
      "DEBUG:shap:self.link(self.fx) = 0.8888416885350849\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.11349794, -0.04923115,  0.01100165,  0.04936306,  0.00867273,\n",
      "        0.0355058 ,  0.03962021,  0.01678852, -0.00084953,  0.01205038,\n",
      "       -0.01027285,  0.00524271,  0.00726296,  0.04056861,  0.00893919])\n",
      " 28%|██▊       | 21/74 [00:46<01:55,  2.17s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.25221853916513043)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.26769172182493534\n",
      "DEBUG:shap:self.fx = 0.6670102707749765\n",
      "DEBUG:shap:self.link(self.fx) = 0.6670102707749765\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.19559065, -0.08565738,  0.0161184 ,  0.07382494,  0.00917473,\n",
      "        0.01295441,  0.01919516, -0.02291404,  0.00663135, -0.00088062,\n",
      "        0.00973823,  0.00148537, -0.03825494,  0.05521228,  0.01547318])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2522185391651306)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2676917218249355\n",
      "DEBUG:shap:self.fx = 0.33298972922502323\n",
      "DEBUG:shap:self.link(self.fx) = 0.33298972922502323\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.19559065,  0.08565738, -0.0161184 , -0.07382494, -0.00917473,\n",
      "       -0.01295441, -0.01919516,  0.02291404, -0.00663135,  0.00088062,\n",
      "       -0.00973823, -0.00148537,  0.03825494, -0.05521228, -0.01547318])\n",
      " 30%|██▉       | 22/74 [00:48<01:54,  2.21s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3651545633384782)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3710284254932511\n",
      "DEBUG:shap:self.fx = 0.02829012345679013\n",
      "DEBUG:shap:self.link(self.fx) = 0.02829012345679013\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14154249, -0.00196169, -0.0005177 , -0.06563371, -0.00409182,\n",
      "       -0.02619517, -0.01354238, -0.02935764, -0.00146852, -0.01083802,\n",
      "       -0.01640386,  0.        , -0.01700112, -0.03660045, -0.00587386])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.36515456333847823)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3710284254932511\n",
      "DEBUG:shap:self.fx = 0.9717098765432098\n",
      "DEBUG:shap:self.link(self.fx) = 0.9717098765432098\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([0.14154249, 0.00196169, 0.0005177 , 0.06563371, 0.00409182,\n",
      "       0.02619517, 0.01354238, 0.02935764, 0.00146852, 0.01083802,\n",
      "       0.01640386, 0.        , 0.01700112, 0.03660045, 0.00587386])\n",
      " 31%|███       | 23/74 [00:50<01:50,  2.17s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4164666784629632)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.42394335581186354\n",
      "DEBUG:shap:self.fx = 0.8232619047619048\n",
      "DEBUG:shap:self.link(self.fx) = 0.8232619047619048\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.21759206,  0.01394141,  0.01219377,  0.08402092,  0.00670567,\n",
      "       -0.02472736,  0.03162766,  0.09883622, -0.02351588, -0.0076438 ,\n",
      "        0.01503349,  0.00038836, -0.03632667,  0.02834081,  0.00747668])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.41646667846296315)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4239433558118635\n",
      "DEBUG:shap:self.fx = 0.17673809523809528\n",
      "DEBUG:shap:self.link(self.fx) = 0.17673809523809528\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.21759206, -0.01394141, -0.01219377, -0.08402092, -0.00670567,\n",
      "        0.02472736, -0.03162766, -0.09883622,  0.02351588,  0.0076438 ,\n",
      "       -0.01503349, -0.00038836,  0.03632667, -0.02834081, -0.00747668])\n",
      " 32%|███▏      | 24/74 [00:53<01:51,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.26504669933557845)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2721240889746939\n",
      "DEBUG:shap:self.fx = 0.6714426379247351\n",
      "DEBUG:shap:self.link(self.fx) = 0.6714426379247351\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.21006182, -0.02087969,  0.00930629,  0.07031549,  0.01010338,\n",
      "       -0.01040101,  0.01908109, -0.04626163, -0.00062627, -0.00207169,\n",
      "       -0.01704902,  0.00208024, -0.03047048,  0.07185818,  0.00707739])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.26504669933557845)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2721240889746939\n",
      "DEBUG:shap:self.fx = 0.3285573620752648\n",
      "DEBUG:shap:self.link(self.fx) = 0.3285573620752648\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.21006182,  0.02087969, -0.00930629, -0.07031549, -0.01010338,\n",
      "        0.01040101, -0.01908109,  0.04626163,  0.00062627,  0.00207169,\n",
      "        0.01704902, -0.00208024,  0.03047048, -0.07185818, -0.00707739])\n",
      " 34%|███▍      | 25/74 [00:55<01:49,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.11817577976501215)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12318145104995876\n",
      "DEBUG:shap:self.fx = 0.5225\n",
      "DEBUG:shap:self.link(self.fx) = 0.5225\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.16913228, -0.01795084,  0.00156513,  0.06060971, -0.00489628,\n",
      "        0.04299446, -0.0070499 ,  0.02556689, -0.05683356, -0.00074764,\n",
      "        0.0171473 , -0.00145988, -0.0128922 , -0.0970097 ,  0.00500567])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.11817577976501213)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.12318145104995865\n",
      "DEBUG:shap:self.fx = 0.4775000000000001\n",
      "DEBUG:shap:self.link(self.fx) = 0.4775000000000001\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.16913228,  0.01795084, -0.00156513, -0.06060971,  0.00489628,\n",
      "       -0.04299446,  0.0070499 , -0.02556689,  0.05683356,  0.00074764,\n",
      "       -0.0171473 ,  0.00145988,  0.0128922 ,  0.0970097 , -0.00500567])\n",
      " 35%|███▌      | 26/74 [00:57<01:47,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2655125509701229)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.28349098081586926\n",
      "DEBUG:shap:self.fx = 0.11582756813417193\n",
      "DEBUG:shap:self.link(self.fx) = 0.11582756813417193\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14501604, -0.00247668, -0.00216823, -0.0548003 , -0.01131455,\n",
      "        0.01019486, -0.03256888, -0.02848892, -0.00120547,  0.0100916 ,\n",
      "        0.01886028,  0.01738077, -0.01878959, -0.02521139, -0.01797843])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.26551255097012333)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.28349098081586954\n",
      "DEBUG:shap:self.fx = 0.8841724318658283\n",
      "DEBUG:shap:self.link(self.fx) = 0.8841724318658283\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.14501604,  0.00247668,  0.00216823,  0.0548003 ,  0.01131455,\n",
      "       -0.01019486,  0.03256888,  0.02848892,  0.00120547, -0.0100916 ,\n",
      "       -0.01886028, -0.01738077,  0.01878959,  0.02521139,  0.01797843])\n",
      " 36%|███▋      | 27/74 [00:59<01:44,  2.21s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1643694003710993)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1674852156167078\n",
      "DEBUG:shap:self.fx = 0.23183333333333342\n",
      "DEBUG:shap:self.link(self.fx) = 0.23183333333333342\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.11540455, -0.0498512 , -0.00963817,  0.03549337, -0.00119664,\n",
      "       -0.02803725, -0.02028446, -0.0150125 ,  0.00322344,  0.01739577,\n",
      "       -0.00485401,  0.03495639,  0.01315284, -0.02431243, -0.00311582])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.16436940037109954)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16748521561670804\n",
      "DEBUG:shap:self.fx = 0.7681666666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.7681666666666668\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.11540455,  0.0498512 ,  0.00963817, -0.03549337,  0.00119664,\n",
      "        0.02803725,  0.02028446,  0.0150125 , -0.00322344, -0.01739577,\n",
      "        0.00485401, -0.03495639, -0.01315284,  0.02431243,  0.00311582])\n",
      " 38%|███▊      | 28/74 [01:01<01:41,  2.20s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2985390766107573)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.27252393615542847\n",
      "DEBUG:shap:self.fx = 0.12679461279461277\n",
      "DEBUG:shap:self.link(self.fx) = 0.12679461279461277\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.15637744,  0.00287318,  0.0047264 , -0.0649693 ,  0.00148689,\n",
      "        0.01299082, -0.00782552, -0.0121395 , -0.00368345, -0.00625946,\n",
      "       -0.02099704, -0.01201865,  0.01166271, -0.04800871,  0.02601514])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2985390766107571)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.27252393615542836\n",
      "DEBUG:shap:self.fx = 0.8732053872053871\n",
      "DEBUG:shap:self.link(self.fx) = 0.8732053872053871\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.15637744, -0.00287318, -0.0047264 ,  0.0649693 , -0.00148689,\n",
      "       -0.01299082,  0.00782552,  0.0121395 ,  0.00368345,  0.00625946,\n",
      "        0.02099704,  0.01201865, -0.01166271,  0.04800871, -0.02601514])\n",
      " 39%|███▉      | 29/74 [01:04<01:41,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.36029971503034663)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3634830383515461\n",
      "DEBUG:shap:self.fx = 0.7628015873015873\n",
      "DEBUG:shap:self.link(self.fx) = 0.7628015873015873\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.2027074 ,  0.02482925, -0.000406  ,  0.08896296, -0.02295126,\n",
      "        0.01266388,  0.01375975,  0.07922692,  0.00874619, -0.00270058,\n",
      "       -0.01188659,  0.00173421, -0.05751897,  0.02313256,  0.00318332])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3602997150303468)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.36348303835154605\n",
      "DEBUG:shap:self.fx = 0.2371984126984127\n",
      "DEBUG:shap:self.link(self.fx) = 0.2371984126984127\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.2027074 , -0.02482925,  0.000406  , -0.08896296,  0.02295126,\n",
      "       -0.01266388, -0.01375975, -0.07922692, -0.00874619,  0.00270058,\n",
      "        0.01188659, -0.00173421,  0.05751897, -0.02313256, -0.00318332])\n",
      " 41%|████      | 30/74 [01:06<01:39,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3949074235707314)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.40229256216106984\n",
      "DEBUG:shap:self.fx = 0.801611111111111\n",
      "DEBUG:shap:self.link(self.fx) = 0.801611111111111\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.1899577 ,  0.00957145, -0.02171758,  0.09703413,  0.00446499,\n",
      "        0.04614857,  0.02302539,  0.07079308, -0.01855492, -0.00611465,\n",
      "        0.00067489,  0.02034162,  0.02008555, -0.04080278,  0.00738514])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3949074235707316)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.40229256216106984\n",
      "DEBUG:shap:self.fx = 0.1983888888888889\n",
      "DEBUG:shap:self.link(self.fx) = 0.1983888888888889\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.1899577 , -0.00957145,  0.02171758, -0.09703413, -0.00446499,\n",
      "       -0.04614857, -0.02302539, -0.07079308,  0.01855492,  0.00611465,\n",
      "       -0.00067489, -0.02034162, -0.02008555,  0.04080278, -0.00738514])\n",
      " 42%|████▏     | 31/74 [01:08<01:36,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.056724225724094954)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.05808621295472077\n",
      "DEBUG:shap:self.fx = 0.457404761904762\n",
      "DEBUG:shap:self.link(self.fx) = 0.457404761904762\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.15003452,  0.01469944,  0.00154961,  0.05155409, -0.01066932,\n",
      "        0.04899391,  0.01580159, -0.04053424, -0.04181868,  0.00999896,\n",
      "       -0.0046093 ,  0.00689021, -0.07624843, -0.06891815,  0.00136199])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.056724225724094815)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.05808621295472072\n",
      "DEBUG:shap:self.fx = 0.542595238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.542595238095238\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.15003452, -0.01469944, -0.00154961, -0.05155409,  0.01066932,\n",
      "       -0.04899391, -0.01580159,  0.04053424,  0.04181868, -0.00999896,\n",
      "        0.0046093 , -0.00689021,  0.07624843,  0.06891815, -0.00136199])\n",
      " 43%|████▎     | 32/74 [01:10<01:33,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17349936413428962)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.15383224470075246\n",
      "DEBUG:shap:self.fx = 0.5531507936507937\n",
      "DEBUG:shap:self.link(self.fx) = 0.5531507936507937\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.17866134,  0.01755439,  0.00109506,  0.08525573, -0.00117451,\n",
      "       -0.01378952,  0.01039201, -0.03258171, -0.04361406,  0.00094455,\n",
      "        0.00802303, -0.00437244,  0.02090279, -0.05379729, -0.01966712])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17349936413428974)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.15383224470075257\n",
      "DEBUG:shap:self.fx = 0.44684920634920616\n",
      "DEBUG:shap:self.link(self.fx) = 0.44684920634920616\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.17866134, -0.01755439, -0.00109506, -0.08525573,  0.00117451,\n",
      "        0.01378952, -0.01039201,  0.03258171,  0.04361406, -0.00094455,\n",
      "       -0.00802303,  0.00437244, -0.02090279,  0.05379729,  0.01966712])\n",
      " 45%|████▍     | 33/74 [01:13<01:32,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0004051528026526169)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.014908689994589053\n",
      "DEBUG:shap:self.fx = 0.41422723894463026\n",
      "DEBUG:shap:self.link(self.fx) = 0.41422723894463026\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.11538258, -0.0612235 ,  0.0140727 , -0.03824051,  0.00275904,\n",
      "        0.01201848,  0.01816607, -0.0164492 , -0.00210076, -0.00269864,\n",
      "       -0.02598404, -0.00240164, -0.04341482,  0.03051941,  0.01450354])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.00040515280265249545)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.014908689994588942\n",
      "DEBUG:shap:self.fx = 0.5857727610553698\n",
      "DEBUG:shap:self.link(self.fx) = 0.5857727610553698\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.11538258,  0.0612235 , -0.0140727 ,  0.03824051, -0.00275904,\n",
      "       -0.01201848, -0.01816607,  0.0164492 ,  0.00210076,  0.00269864,\n",
      "        0.02598404,  0.00240164,  0.04341482, -0.03051941, -0.01450354])\n",
      " 46%|████▌     | 34/74 [01:15<01:30,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.32736500429956067)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3266939513254436\n",
      "DEBUG:shap:self.fx = 0.07262459762459762\n",
      "DEBUG:shap:self.link(self.fx) = 0.07262459762459762\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.15546322,  0.00048503, -0.00025507, -0.06848776, -0.00039394,\n",
      "       -0.02063737, -0.01565863, -0.02800541,  0.00259486, -0.00317212,\n",
      "       -0.00337062, -0.00428447,  0.00577138, -0.03648767,  0.00067105])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3273650042995607)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.32669395132544365\n",
      "DEBUG:shap:self.fx = 0.9273754023754024\n",
      "DEBUG:shap:self.link(self.fx) = 0.9273754023754024\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.15546322, -0.00048503,  0.00025507,  0.06848776,  0.00039394,\n",
      "        0.02063737,  0.01565863,  0.02800541, -0.00259486,  0.00317212,\n",
      "        0.00337062,  0.00428447, -0.00577138,  0.03648767, -0.00067105])\n",
      " 47%|████▋     | 35/74 [01:17<01:27,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.03944064076920711)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.0429375965690888\n",
      "DEBUG:shap:self.fx = 0.3563809523809524\n",
      "DEBUG:shap:self.link(self.fx) = 0.3563809523809524\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14402538,  0.0591714 ,  0.0071813 , -0.03905311,  0.014616  ,\n",
      "        0.06745313, -0.04739855,  0.01568214,  0.00828181,  0.03589285,\n",
      "       -0.00847626,  0.        , -0.00597964, -0.00278634, -0.00349696])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03944064076920737)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.04293759656908902\n",
      "DEBUG:shap:self.fx = 0.6436190476190478\n",
      "DEBUG:shap:self.link(self.fx) = 0.6436190476190478\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.14402538, -0.0591714 , -0.0071813 ,  0.03905311, -0.014616  ,\n",
      "       -0.06745313,  0.04739855, -0.01568214, -0.00828181, -0.03589285,\n",
      "        0.00847626,  0.        ,  0.00597964,  0.00278634,  0.00349696])\n",
      " 49%|████▊     | 36/74 [01:19<01:25,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20387456591575603)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21511879440835474\n",
      "DEBUG:shap:self.fx = 0.614437343358396\n",
      "DEBUG:shap:self.link(self.fx) = 0.614437343358396\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.19771155,  0.0041865 ,  0.00492749, -0.02376635,  0.00556599,\n",
      "        0.0612495 , -0.06262168,  0.04402901,  0.00493038, -0.00795295,\n",
      "        0.01146501,  0.00364478,  0.01455784, -0.05405251,  0.01124423])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20387456591575603)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21511879440835474\n",
      "DEBUG:shap:self.fx = 0.385562656641604\n",
      "DEBUG:shap:self.link(self.fx) = 0.385562656641604\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.19771155, -0.0041865 , -0.00492749,  0.02376635, -0.00556599,\n",
      "       -0.0612495 ,  0.06262168, -0.04402901, -0.00493038,  0.00795295,\n",
      "       -0.01146501, -0.00364478, -0.01455784,  0.05405251, -0.01124423])\n",
      " 50%|█████     | 37/74 [01:22<01:21,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.340494445844992)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3347766891451969\n",
      "DEBUG:shap:self.fx = 0.7340952380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.7340952380952381\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.1884619 ,  0.01992528,  0.00504573,  0.073442  , -0.00131202,\n",
      "        0.04559255,  0.02949244, -0.01313044, -0.06065774, -0.00592125,\n",
      "       -0.00127121,  0.01602852,  0.0220164 ,  0.02278228, -0.00571776])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.340494445844992)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.33477668914519676\n",
      "DEBUG:shap:self.fx = 0.265904761904762\n",
      "DEBUG:shap:self.link(self.fx) = 0.265904761904762\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.1884619 , -0.01992528, -0.00504573, -0.073442  ,  0.00131202,\n",
      "       -0.04559255, -0.02949244,  0.01313044,  0.06065774,  0.00592125,\n",
      "        0.00127121, -0.01602852, -0.0220164 , -0.02278228,  0.00571776])\n",
      " 51%|█████▏    | 38/74 [01:24<01:20,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.13160438518649265)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.0756029213924817\n",
      "DEBUG:shap:self.fx = 0.4749214703425229\n",
      "DEBUG:shap:self.link(self.fx) = 0.4749214703425229\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.13695878,  0.01159184, -0.00726486, -0.06257521,  0.01176506,\n",
      "        0.06948124, -0.01156757, -0.01755223, -0.00686676, -0.0120383 ,\n",
      "       -0.0208515 , -0.00217071,  0.01055758,  0.03213703, -0.05600146])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.13160438518649265)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.07560292139248181\n",
      "DEBUG:shap:self.fx = 0.5250785296574769\n",
      "DEBUG:shap:self.link(self.fx) = 0.5250785296574769\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.13695878, -0.01159184,  0.00726486,  0.06257521, -0.01176506,\n",
      "       -0.06948124,  0.01156757,  0.01755223,  0.00686676,  0.0120383 ,\n",
      "        0.0208515 ,  0.00217071, -0.01055758, -0.03213703,  0.05600146])\n",
      " 53%|█████▎    | 39/74 [01:26<01:17,  2.21s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20843873579282995)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21056044074402488\n",
      "DEBUG:shap:self.fx = 0.18875810820601632\n",
      "DEBUG:shap:self.link(self.fx) = 0.18875810820601632\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14012667,  0.04751925,  0.00977969, -0.06368589, -0.00497511,\n",
      "       -0.04061593,  0.02636405,  0.00928467, -0.00879655, -0.00359351,\n",
      "       -0.00112028, -0.00689535, -0.0008071 , -0.03077002, -0.0021217 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20843873579283015)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21056044074402502\n",
      "DEBUG:shap:self.fx = 0.8112418917939838\n",
      "DEBUG:shap:self.link(self.fx) = 0.8112418917939838\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.14012667, -0.04751925, -0.00977969,  0.06368589,  0.00497511,\n",
      "        0.04061593, -0.02636405, -0.00928467,  0.00879655,  0.00359351,\n",
      "        0.00112028,  0.00689535,  0.0008071 ,  0.03077002,  0.0021217 ])\n",
      " 54%|█████▍    | 40/74 [01:28<01:16,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2313087760094359)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.23977886641035867\n",
      "DEBUG:shap:self.fx = 0.15953968253968254\n",
      "DEBUG:shap:self.link(self.fx) = 0.15953968253968254\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.12526807, -0.01203776,  0.00529431,  0.01071484,  0.01104393,\n",
      "        0.02558101,  0.01402596, -0.02473052, -0.0015864 , -0.01414592,\n",
      "       -0.02218854, -0.00766668, -0.03931674, -0.05102818, -0.00847009])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23130877600943606)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.23977886641035884\n",
      "DEBUG:shap:self.fx = 0.8404603174603176\n",
      "DEBUG:shap:self.link(self.fx) = 0.8404603174603176\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.12526807,  0.01203776, -0.00529431, -0.01071484, -0.01104393,\n",
      "       -0.02558101, -0.01402596,  0.02473052,  0.0015864 ,  0.01414592,\n",
      "        0.02218854,  0.00766668,  0.03931674,  0.05102818,  0.00847009])\n",
      " 55%|█████▌    | 41/74 [01:31<01:14,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.18127184203604088)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2047371134773014\n",
      "DEBUG:shap:self.fx = 0.19458143547273982\n",
      "DEBUG:shap:self.link(self.fx) = 0.19458143547273982\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.108777  ,  0.0263981 ,  0.0028059 , -0.06064636,  0.00891479,\n",
      "       -0.01443147, -0.03328208, -0.02017193,  0.00846492, -0.01036529,\n",
      "       -0.01269099, -0.01698071,  0.00873149,  0.04075881, -0.02346527])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.18127184203604083)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2047371134773014\n",
      "DEBUG:shap:self.fx = 0.8054185645272601\n",
      "DEBUG:shap:self.link(self.fx) = 0.8054185645272601\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.108777  , -0.0263981 , -0.0028059 ,  0.06064636, -0.00891479,\n",
      "        0.01443147,  0.03328208,  0.02017193, -0.00846492,  0.01036529,\n",
      "        0.01269099,  0.01698071, -0.00873149, -0.04075881,  0.02346527])\n",
      " 57%|█████▋    | 42/74 [01:33<01:11,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5122483019777984)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.47718938755789536\n",
      "DEBUG:shap:self.fx = 0.8765079365079366\n",
      "DEBUG:shap:self.link(self.fx) = 0.8765079365079366\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.22526303,  0.0179241 ,  0.00371048,  0.08002793, -0.00229128,\n",
      "        0.00147627,  0.03883159,  0.07574759, -0.00556722, -0.00253444,\n",
      "        0.01506476,  0.00571112,  0.00955204,  0.04933234, -0.03505891])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5122483019777982)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.47718938755789525\n",
      "DEBUG:shap:self.fx = 0.12349206349206349\n",
      "DEBUG:shap:self.link(self.fx) = 0.12349206349206349\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.22526303, -0.0179241 , -0.00371048, -0.08002793,  0.00229128,\n",
      "       -0.00147627, -0.03883159, -0.07574759,  0.00556722,  0.00253444,\n",
      "       -0.01506476, -0.00571112, -0.00955204, -0.04933234,  0.03505891])\n",
      " 58%|█████▊    | 43/74 [01:35<01:08,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.10490697276055137)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.10634907398056631\n",
      "DEBUG:shap:self.fx = 0.2929694749694749\n",
      "DEBUG:shap:self.link(self.fx) = 0.2929694749694749\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.00347996,  0.0142728 , -0.00367423,  0.08622052,  0.00488737,\n",
      "       -0.01694625,  0.01235893, -0.0330136 , -0.04333033,  0.00280669,\n",
      "       -0.00395525,  0.01678769, -0.05947709, -0.07836428, -0.0014421 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1049069727605513)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.10634907398056626\n",
      "DEBUG:shap:self.fx = 0.707030525030525\n",
      "DEBUG:shap:self.link(self.fx) = 0.707030525030525\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.00347996, -0.0142728 ,  0.00367423, -0.08622052, -0.00488737,\n",
      "        0.01694625, -0.01235893,  0.0330136 ,  0.04333033, -0.00280669,\n",
      "        0.00395525, -0.01678769,  0.05947709,  0.07836428,  0.0014421 ])\n",
      " 59%|█████▉    | 44/74 [01:37<01:07,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.11880232731607654)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12298029109879888\n",
      "DEBUG:shap:self.fx = 0.5222988400488401\n",
      "DEBUG:shap:self.link(self.fx) = 0.5222988400488401\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.11678841,  0.01859234, -0.01289392,  0.08814439,  0.0040024 ,\n",
      "        0.01614734, -0.00198002, -0.02578325, -0.0643876 ,  0.00963358,\n",
      "        0.00344559,  0.01803734, -0.07020858,  0.01926429,  0.00417796])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.11880232731607648)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.12298029109879877\n",
      "DEBUG:shap:self.fx = 0.47770115995115997\n",
      "DEBUG:shap:self.link(self.fx) = 0.47770115995115997\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.11678841, -0.01859234,  0.01289392, -0.08814439, -0.0040024 ,\n",
      "       -0.01614734,  0.00198002,  0.02578325,  0.0643876 , -0.00963358,\n",
      "       -0.00344559, -0.01803734,  0.07020858, -0.01926429, -0.00417796])\n",
      " 61%|██████    | 45/74 [01:40<01:04,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.18132382010951326)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.183295340199176\n",
      "DEBUG:shap:self.fx = 0.2160232087508652\n",
      "DEBUG:shap:self.link(self.fx) = 0.2160232087508652\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.03368189,  0.00251917,  0.00730245, -0.07054307, -0.00318441,\n",
      "       -0.01073853, -0.03365379, -0.03629542,  0.00214991, -0.00496679,\n",
      "       -0.01059448, -0.00209487,  0.00519961,  0.0072583 , -0.00197152])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.18132382010951345)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.18329534019917615\n",
      "DEBUG:shap:self.fx = 0.7839767912491349\n",
      "DEBUG:shap:self.link(self.fx) = 0.7839767912491349\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.03368189, -0.00251917, -0.00730245,  0.07054307,  0.00318441,\n",
      "        0.01073853,  0.03365379,  0.03629542, -0.00214991,  0.00496679,\n",
      "        0.01059448,  0.00209487, -0.00519961, -0.0072583 ,  0.00197152])\n",
      " 62%|██████▏   | 46/74 [01:42<01:03,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.26053813750323757)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.24878066335555182\n",
      "DEBUG:shap:self.fx = 0.15053788559448938\n",
      "DEBUG:shap:self.link(self.fx) = 0.15053788559448938\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14105382,  0.00452692, -0.00316582, -0.06565867, -0.00302045,\n",
      "       -0.01391639, -0.04185751,  0.05646475,  0.00288177, -0.01324996,\n",
      "       -0.00671966, -0.01111248, -0.01591327, -0.00874356,  0.01175747])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.26053813750323757)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24878066335555182\n",
      "DEBUG:shap:self.fx = 0.8494621144055106\n",
      "DEBUG:shap:self.link(self.fx) = 0.8494621144055106\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.14105382, -0.00452692,  0.00316582,  0.06565867,  0.00302045,\n",
      "        0.01391639,  0.04185751, -0.05646475, -0.00288177,  0.01324996,\n",
      "        0.00671966,  0.01111248,  0.01591327,  0.00874356, -0.01175747])\n",
      " 64%|██████▎   | 47/74 [01:44<00:59,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22901014009646753)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.20421584258435005\n",
      "DEBUG:shap:self.fx = 0.6035343915343913\n",
      "DEBUG:shap:self.link(self.fx) = 0.6035343915343913\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.17527156, -0.05015878,  0.0043303 ,  0.09114993,  0.00791025,\n",
      "        0.039682  ,  0.02008662,  0.02123295, -0.0061774 , -0.00434503,\n",
      "        0.00907128, -0.00903361,  0.01287928, -0.08288918, -0.0247943 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22901014009646764)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.20421584258435027\n",
      "DEBUG:shap:self.fx = 0.39646560846560847\n",
      "DEBUG:shap:self.link(self.fx) = 0.39646560846560847\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.17527156,  0.05015878, -0.0043303 , -0.09114993, -0.00791025,\n",
      "       -0.039682  , -0.02008662, -0.02123295,  0.0061774 ,  0.00434503,\n",
      "       -0.00907128,  0.00903361, -0.01287928,  0.08288918,  0.0247943 ])\n",
      " 65%|██████▍   | 48/74 [01:46<00:57,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09146031089479942)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09244970483119702\n",
      "DEBUG:shap:self.fx = 0.3068688441188442\n",
      "DEBUG:shap:self.link(self.fx) = 0.3068688441188442\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.13481505,  0.06348936,  0.00125118, -0.03693321,  0.00704054,\n",
      "        0.07436646, -0.02527166, -0.0251959 ,  0.00554875, -0.00865513,\n",
      "        0.00974543, -0.00250417, -0.01172447, -0.00780243, -0.00098939])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0914603108947995)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09244970483119719\n",
      "DEBUG:shap:self.fx = 0.6931311558811559\n",
      "DEBUG:shap:self.link(self.fx) = 0.6931311558811559\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.13481505, -0.06348936, -0.00125118,  0.03693321, -0.00704054,\n",
      "       -0.07436646,  0.02527166,  0.0251959 , -0.00554875,  0.00865513,\n",
      "       -0.00974543,  0.00250417,  0.01172447,  0.00780243,  0.00098939])\n",
      " 66%|██████▌   | 49/74 [01:48<00:55,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.24165651072617428)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2503582314897238\n",
      "DEBUG:shap:self.fx = 0.14896031746031743\n",
      "DEBUG:shap:self.link(self.fx) = 0.14896031746031743\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.1150638 , -0.00114626,  0.00366035, -0.04274431,  0.00823324,\n",
      "        0.06641729, -0.02672631, -0.02030593, -0.00623651, -0.01763801,\n",
      "       -0.02914414, -0.00813558, -0.02156116, -0.03126537, -0.00870172])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24165651072617428)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2503582314897237\n",
      "DEBUG:shap:self.fx = 0.8510396825396824\n",
      "DEBUG:shap:self.link(self.fx) = 0.8510396825396824\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.1150638 ,  0.00114626, -0.00366035,  0.04274431, -0.00823324,\n",
      "       -0.06641729,  0.02672631,  0.02030593,  0.00623651,  0.01763801,\n",
      "        0.02914414,  0.00813558,  0.02156116,  0.03126537,  0.00870172])\n",
      " 68%|██████▊   | 50/74 [01:51<00:53,  2.21s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2556300362758998)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.25413317506961963\n",
      "DEBUG:shap:self.fx = 0.14518537388042158\n",
      "DEBUG:shap:self.link(self.fx) = 0.14518537388042158\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.13133715, -0.00323807, -0.00032046, -0.07525174, -0.00595082,\n",
      "        0.01167218, -0.02444369,  0.00483223,  0.00434717, -0.01664659,\n",
      "        0.00906206, -0.00418875,  0.00501436, -0.02918075,  0.00149686])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2556300362758999)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.25413317506961963\n",
      "DEBUG:shap:self.fx = 0.8548146261195784\n",
      "DEBUG:shap:self.link(self.fx) = 0.8548146261195784\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.13133715,  0.00323807,  0.00032046,  0.07525174,  0.00595082,\n",
      "       -0.01167218,  0.02444369, -0.00483223, -0.00434717,  0.01664659,\n",
      "       -0.00906206,  0.00418875, -0.00501436,  0.02918075, -0.00149686])\n",
      " 69%|██████▉   | 51/74 [01:53<00:51,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0652984917361902)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.07262589549440318\n",
      "DEBUG:shap:self.fx = 0.4719444444444444\n",
      "DEBUG:shap:self.link(self.fx) = 0.4719444444444444\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.09359633,  0.02567638, -0.01025166,  0.02038242, -0.0011921 ,\n",
      "       -0.01682251,  0.02201974, -0.02861267, -0.04356249,  0.022553  ,\n",
      "       -0.00656471,  0.02947026,  0.01779322, -0.05918673,  0.0073274 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.0652984917361902)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.07262589549440324\n",
      "DEBUG:shap:self.fx = 0.5280555555555555\n",
      "DEBUG:shap:self.link(self.fx) = 0.5280555555555555\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.09359633, -0.02567638,  0.01025166, -0.02038242,  0.0011921 ,\n",
      "        0.01682251, -0.02201974,  0.02861267,  0.04356249, -0.022553  ,\n",
      "        0.00656471, -0.02947026, -0.01779322,  0.05918673, -0.0073274 ])\n",
      " 70%|███████   | 52/74 [01:55<00:49,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1507362643289087)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1646260163364559\n",
      "DEBUG:shap:self.fx = 0.2346925326135853\n",
      "DEBUG:shap:self.link(self.fx) = 0.2346925326135853\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14879094,  0.02109707,  0.00371404, -0.05615041, -0.00229242,\n",
      "       -0.00919436,  0.02594556,  0.06988569, -0.03026234, -0.006842  ,\n",
      "       -0.02652298, -0.0028316 ,  0.01031956,  0.00118885, -0.01388975])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.15073626432890894)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16462601633645624\n",
      "DEBUG:shap:self.fx = 0.765307467386415\n",
      "DEBUG:shap:self.link(self.fx) = 0.765307467386415\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.14879094, -0.02109707, -0.00371404,  0.05615041,  0.00229242,\n",
      "        0.00919436, -0.02594556, -0.06988569,  0.03026234,  0.006842  ,\n",
      "        0.02652298,  0.0028316 , -0.01031956, -0.00118885,  0.01388975])\n",
      " 72%|███████▏  | 53/74 [01:57<00:47,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.24911120718853044)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.25991731438213994\n",
      "DEBUG:shap:self.fx = 0.13940123456790124\n",
      "DEBUG:shap:self.link(self.fx) = 0.13940123456790124\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14605216,  0.00577588, -0.00545216, -0.06478171,  0.00314323,\n",
      "       -0.00987493,  0.02548264, -0.01394557,  0.00045794, -0.01354655,\n",
      "       -0.01220789, -0.004669  ,  0.00700091, -0.02044184, -0.01080611])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2491112071885307)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2599173143821403\n",
      "DEBUG:shap:self.fx = 0.860598765432099\n",
      "DEBUG:shap:self.link(self.fx) = 0.860598765432099\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.14605216, -0.00577588,  0.00545216,  0.06478171, -0.00314323,\n",
      "        0.00987493, -0.02548264,  0.01394557, -0.00045794,  0.01354655,\n",
      "        0.01220789,  0.004669  , -0.00700091,  0.02044184,  0.01080611])\n",
      " 73%|███████▎  | 54/74 [02:00<00:44,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23032645424834328)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21085568773718003\n",
      "DEBUG:shap:self.fx = 0.18846286121286118\n",
      "DEBUG:shap:self.link(self.fx) = 0.18846286121286118\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.11225888,  0.04066294,  0.00643626, -0.04258679, -0.00105401,\n",
      "       -0.03287123, -0.02948393, -0.01611664, -0.03700064, -0.00759566,\n",
      "       -0.0036065 , -0.00344321,  0.04042033, -0.0318285 ,  0.01947077])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23032645424834336)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2108556877371801\n",
      "DEBUG:shap:self.fx = 0.8115371387871388\n",
      "DEBUG:shap:self.link(self.fx) = 0.8115371387871388\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.11225888, -0.04066294, -0.00643626,  0.04258679,  0.00105401,\n",
      "        0.03287123,  0.02948393,  0.01611664,  0.03700064,  0.00759566,\n",
      "        0.0036065 ,  0.00344321, -0.04042033,  0.0318285 , -0.01947077])\n",
      " 74%|███████▍  | 55/74 [02:02<00:42,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2285615881292928)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.23641995988478545\n",
      "DEBUG:shap:self.fx = 0.16289858906525576\n",
      "DEBUG:shap:self.link(self.fx) = 0.16289858906525576\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14731429, -0.02545429, -0.0010968 , -0.05253252, -0.00906546,\n",
      "       -0.01170848, -0.02410581,  0.00071182,  0.00639394,  0.01103494,\n",
      "        0.00473615, -0.00435877,  0.00639326,  0.01780472, -0.00785837])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22856158812929264)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.23641995988478526\n",
      "DEBUG:shap:self.fx = 0.837101410934744\n",
      "DEBUG:shap:self.link(self.fx) = 0.837101410934744\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.14731429,  0.02545429,  0.0010968 ,  0.05253252,  0.00906546,\n",
      "        0.01170848,  0.02410581, -0.00071182, -0.00639394, -0.01103494,\n",
      "       -0.00473615,  0.00435877, -0.00639326, -0.01780472,  0.00785837])\n",
      " 76%|███████▌  | 56/74 [02:04<00:40,  2.27s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3966763345123598)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.41129256216106974\n",
      "DEBUG:shap:self.fx = 0.810611111111111\n",
      "DEBUG:shap:self.link(self.fx) = 0.810611111111111\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 2.35613989e-01,  2.36887693e-02,  1.03246211e-02,  3.01979369e-02,\n",
      "        6.91905819e-03,  1.32598484e-02,  1.55949900e-02,  2.02187058e-02,\n",
      "        1.40514542e-04, -2.05923534e-03, -3.23507198e-02,  6.06122066e-03,\n",
      "        8.58424603e-03,  6.04823896e-02,  1.46162276e-02])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3966763345123599)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4112925621610698\n",
      "DEBUG:shap:self.fx = 0.1893888888888889\n",
      "DEBUG:shap:self.link(self.fx) = 0.1893888888888889\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-2.35613989e-01, -2.36887693e-02, -1.03246211e-02, -3.01979369e-02,\n",
      "       -6.91905819e-03, -1.32598484e-02, -1.55949900e-02, -2.02187058e-02,\n",
      "       -1.40514542e-04,  2.05923534e-03,  3.23507198e-02, -6.06122066e-03,\n",
      "       -8.58424603e-03, -6.04823896e-02, -1.46162276e-02])\n",
      " 77%|███████▋  | 57/74 [02:06<00:38,  2.27s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.022572750389237957)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.0039512923198000705\n",
      "DEBUG:shap:self.fx = 0.4032698412698413\n",
      "DEBUG:shap:self.link(self.fx) = 0.4032698412698413\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.15520483, -0.00870671,  0.00950091,  0.08689035,  0.00690004,\n",
      "        0.01646351,  0.01880892, -0.02168261,  0.00654059,  0.02840967,\n",
      "        0.00905102, -0.00797456,  0.0138819 ,  0.01969456, -0.01862146])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.022572750389238137)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.0039512923198001815\n",
      "DEBUG:shap:self.fx = 0.5967301587301586\n",
      "DEBUG:shap:self.link(self.fx) = 0.5967301587301586\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.15520483,  0.00870671, -0.00950091, -0.08689035, -0.00690004,\n",
      "       -0.01646351, -0.01880892,  0.02168261, -0.00654059, -0.02840967,\n",
      "       -0.00905102,  0.00797456, -0.0138819 , -0.01969456,  0.01862146])\n",
      " 78%|███████▊  | 58/74 [02:09<00:36,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.07645574911341421)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.06157018293696942\n",
      "DEBUG:shap:self.fx = 0.3377483660130718\n",
      "DEBUG:shap:self.link(self.fx) = 0.3377483660130718\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.16986013, -0.02289955, -0.01183035,  0.01731687,  0.00420981,\n",
      "       -0.00921703, -0.04374796, -0.03916137, -0.03698335, -0.00202934,\n",
      "        0.01077177, -0.00158469, -0.04039929, -0.07076141,  0.01488557])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.07645574911341416)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.061570182936969364\n",
      "DEBUG:shap:self.fx = 0.6622516339869281\n",
      "DEBUG:shap:self.link(self.fx) = 0.6622516339869281\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.16986013,  0.02289955,  0.01183035, -0.01731687, -0.00420981,\n",
      "        0.00921703,  0.04374796,  0.03916137,  0.03698335,  0.00202934,\n",
      "       -0.01077177,  0.00158469,  0.04039929,  0.07076141, -0.01488557])\n",
      " 80%|███████▉  | 59/74 [02:11<00:34,  2.27s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2840266455022025)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2871893875578953\n",
      "DEBUG:shap:self.fx = 0.6865079365079365\n",
      "DEBUG:shap:self.link(self.fx) = 0.6865079365079365\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.20014546, -0.12814708,  0.0032976 ,  0.1008971 ,  0.00275068,\n",
      "        0.01428519,  0.00283053,  0.04187039,  0.00678484,  0.00381918,\n",
      "        0.        ,  0.00280898,  0.01829928,  0.01438449,  0.00316274])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2840266455022025)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2871893875578953\n",
      "DEBUG:shap:self.fx = 0.31349206349206343\n",
      "DEBUG:shap:self.link(self.fx) = 0.31349206349206343\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.20014546,  0.12814708, -0.0032976 , -0.1008971 , -0.00275068,\n",
      "       -0.01428519, -0.00283053, -0.04187039, -0.00678484, -0.00381918,\n",
      "        0.        , -0.00280898, -0.01829928, -0.01438449, -0.00316274])\n",
      " 81%|████████  | 60/74 [02:13<00:31,  2.27s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2627347415660743)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2698560542245619\n",
      "DEBUG:shap:self.fx = 0.6691746031746031\n",
      "DEBUG:shap:self.link(self.fx) = 0.6691746031746031\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.18467954,  0.02325908,  0.00400906,  0.0819091 ,  0.0008196 ,\n",
      "        0.05729332,  0.01299846, -0.06148458, -0.00223041,  0.        ,\n",
      "        0.00325575, -0.0045354 ,  0.01848118, -0.05571996,  0.00712131])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2627347415660743)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.26985605422456194\n",
      "DEBUG:shap:self.fx = 0.3308253968253968\n",
      "DEBUG:shap:self.link(self.fx) = 0.3308253968253968\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.18467954, -0.02325908, -0.00400906, -0.0819091 , -0.0008196 ,\n",
      "       -0.05729332, -0.01299846,  0.06148458,  0.00223041,  0.        ,\n",
      "       -0.00325575,  0.0045354 , -0.01848118,  0.05571996, -0.00712131])\n",
      " 82%|████████▏ | 61/74 [02:15<00:29,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.25068911363641694)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2521202380017302\n",
      "DEBUG:shap:self.fx = 0.14719831094831096\n",
      "DEBUG:shap:self.link(self.fx) = 0.14719831094831096\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.12585594,  0.04650341,  0.0081434 , -0.03852479, -0.00819184,\n",
      "       -0.02302529, -0.01192396, -0.02268636, -0.01252504, -0.01030068,\n",
      "       -0.00027437, -0.005845  , -0.01173804, -0.03444463, -0.00143112])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.25068911363641705)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.25212023800173033\n",
      "DEBUG:shap:self.fx = 0.8528016890516891\n",
      "DEBUG:shap:self.link(self.fx) = 0.8528016890516891\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.12585594, -0.04650341, -0.0081434 ,  0.03852479,  0.00819184,\n",
      "        0.02302529,  0.01192396,  0.02268636,  0.01252504,  0.01030068,\n",
      "        0.00027437,  0.005845  ,  0.01173804,  0.03444463,  0.00143112])\n",
      " 84%|████████▍ | 62/74 [02:18<00:27,  2.28s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.32634942075090473)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3409574378389301\n",
      "DEBUG:shap:self.fx = 0.05836111111111111\n",
      "DEBUG:shap:self.link(self.fx) = 0.05836111111111111\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.13015239,  0.00961231, -0.00773601, -0.06080939, -0.00953595,\n",
      "       -0.014452  , -0.04348495, -0.01563407, -0.02491168,  0.03248362,\n",
      "       -0.01092224, -0.01443717,  0.00047901, -0.03684851, -0.01460802])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3263494207509047)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3409574378389302\n",
      "DEBUG:shap:self.fx = 0.9416388888888889\n",
      "DEBUG:shap:self.link(self.fx) = 0.9416388888888889\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.13015239, -0.00961231,  0.00773601,  0.06080939,  0.00953595,\n",
      "        0.014452  ,  0.04348495,  0.01563407,  0.02491168, -0.03248362,\n",
      "        0.01092224,  0.01443717, -0.00047901,  0.03684851,  0.01460802])\n",
      " 85%|████████▌ | 63/74 [02:20<00:24,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.008889055069429122)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.019427482795990714\n",
      "DEBUG:shap:self.fx = 0.4187460317460319\n",
      "DEBUG:shap:self.link(self.fx) = 0.4187460317460319\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.16783178, -0.04239898,  0.00230432,  0.07621603,  0.00093146,\n",
      "        0.0114716 ,  0.01410912, -0.07542387, -0.04509762, -0.00302275,\n",
      "       -0.00760953, -0.00308073, -0.01557743, -0.07176434,  0.01053843])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.008889055069428914)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.01942748279599049\n",
      "DEBUG:shap:self.fx = 0.5812539682539682\n",
      "DEBUG:shap:self.link(self.fx) = 0.5812539682539682\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.16783178,  0.04239898, -0.00230432, -0.07621603, -0.00093146,\n",
      "       -0.0114716 , -0.01410912,  0.07542387,  0.04509762,  0.00302275,\n",
      "        0.00760953,  0.00308073,  0.01557743,  0.07176434, -0.01053843])\n",
      " 86%|████████▋ | 64/74 [02:22<00:22,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.0787066478892773)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.07989822966076116\n",
      "DEBUG:shap:self.fx = 0.31942031928928005\n",
      "DEBUG:shap:self.link(self.fx) = 0.31942031928928005\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.15669128,  0.0247582 ,  0.01019302, -0.05396371, -0.00747004,\n",
      "       -0.00397713,  0.03624622,  0.0675106 ,  0.00396964, -0.0028324 ,\n",
      "        0.01075765, -0.00104988, -0.00124348, -0.00491407, -0.00119158])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.07870664788927724)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.0798982296607611\n",
      "DEBUG:shap:self.fx = 0.6805796807107198\n",
      "DEBUG:shap:self.link(self.fx) = 0.6805796807107198\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.15669128, -0.0247582 , -0.01019302,  0.05396371,  0.00747004,\n",
      "        0.00397713, -0.03624622, -0.0675106 , -0.00396964,  0.0028324 ,\n",
      "       -0.01075765,  0.00104988,  0.00124348,  0.00491407,  0.00119158])\n",
      " 88%|████████▊ | 65/74 [02:25<00:20,  2.30s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.09162098533891427)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.0861258954944033\n",
      "DEBUG:shap:self.fx = 0.4854444444444445\n",
      "DEBUG:shap:self.link(self.fx) = 0.4854444444444445\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.02057598, -0.03583007, -0.00513626,  0.09659565,  0.00541876,\n",
      "        0.05033047,  0.01183035, -0.02766925,  0.00103299,  0.02763893,\n",
      "       -0.01955343, -0.01421329,  0.01217836,  0.00957375, -0.00549509])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09162098533891408)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08612589549440319\n",
      "DEBUG:shap:self.fx = 0.5145555555555555\n",
      "DEBUG:shap:self.link(self.fx) = 0.5145555555555555\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.02057598,  0.03583007,  0.00513626, -0.09659565, -0.00541876,\n",
      "       -0.05033047, -0.01183035,  0.02766925, -0.00103299, -0.02763893,\n",
      "        0.01955343,  0.01421329, -0.01217836, -0.00957375,  0.00549509])\n",
      " 89%|████████▉ | 66/74 [02:27<00:18,  2.32s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2780386308644945)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2342216273531196\n",
      "DEBUG:shap:self.fx = 0.1650969215969216\n",
      "DEBUG:shap:self.link(self.fx) = 0.1650969215969216\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.14493088, -0.01313007,  0.01216605, -0.05400525, -0.00088761,\n",
      "       -0.01602776, -0.00839807, -0.03766652,  0.00429182,  0.00223812,\n",
      "        0.00619502, -0.00673878,  0.00654515, -0.02768986,  0.043817  ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2780386308644944)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2342216273531197\n",
      "DEBUG:shap:self.fx = 0.8349030784030784\n",
      "DEBUG:shap:self.link(self.fx) = 0.8349030784030784\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.14493088,  0.01313007, -0.01216605,  0.05400525,  0.00088761,\n",
      "        0.01602776,  0.00839807,  0.03766652, -0.00429182, -0.00223812,\n",
      "       -0.00619502,  0.00673878, -0.00654515,  0.02768986, -0.043817  ])\n",
      " 91%|█████████ | 67/74 [02:29<00:16,  2.34s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20890126948674057)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.17894817857967082\n",
      "DEBUG:shap:self.fx = 0.22037037037037038\n",
      "DEBUG:shap:self.link(self.fx) = 0.22037037037037038\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.15731356, -0.01953828, -0.00321094, -0.06704791,  0.0017043 ,\n",
      "       -0.01537679, -0.01625013,  0.09403588,  0.005388  , -0.01177566,\n",
      "       -0.00400857, -0.00484919,  0.00833105, -0.01898946,  0.02995309])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20890126948674076)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.17894817857967094\n",
      "DEBUG:shap:self.fx = 0.7796296296296297\n",
      "DEBUG:shap:self.link(self.fx) = 0.7796296296296297\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.15731356,  0.01953828,  0.00321094,  0.06704791, -0.0017043 ,\n",
      "        0.01537679,  0.01625013, -0.09403588, -0.005388  ,  0.01177566,\n",
      "        0.00400857,  0.00484919, -0.00833105,  0.01898946, -0.02995309])\n",
      " 92%|█████████▏| 68/74 [02:32<00:13,  2.31s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.39866410193024754)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.36970922882773655\n",
      "DEBUG:shap:self.fx = 0.7690277777777778\n",
      "DEBUG:shap:self.link(self.fx) = 0.7690277777777778\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.20290636,  0.01819936,  0.00172752,  0.08793225, -0.00348413,\n",
      "        0.01289745,  0.02487206,  0.05685748, -0.00492692, -0.01340457,\n",
      "       -0.01342051,  0.00118323, -0.03890819,  0.06623271, -0.02895487])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3986641019302475)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3697092288277365\n",
      "DEBUG:shap:self.fx = 0.23097222222222225\n",
      "DEBUG:shap:self.link(self.fx) = 0.23097222222222225\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.20290636, -0.01819936, -0.00172752, -0.08793225,  0.00348413,\n",
      "       -0.01289745, -0.02487206, -0.05685748,  0.00492692,  0.01340457,\n",
      "        0.01342051, -0.00118323,  0.03890819, -0.06623271,  0.02895487])\n",
      " 93%|█████████▎| 69/74 [02:34<00:11,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4142065474096112)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.42568541930392706\n",
      "DEBUG:shap:self.fx = 0.8250039682539683\n",
      "DEBUG:shap:self.link(self.fx) = 0.8250039682539683\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.20192365,  0.02171294, -0.01160366,  0.03013878, -0.00255842,\n",
      "        0.05375977,  0.03781757,  0.02884154, -0.00472803,  0.00646646,\n",
      "        0.01545521,  0.01764582,  0.00123509,  0.01809982,  0.01147887])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.41420654740961116)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.42568541930392695\n",
      "DEBUG:shap:self.fx = 0.1749960317460318\n",
      "DEBUG:shap:self.link(self.fx) = 0.1749960317460318\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.20192365, -0.02171294,  0.01160366, -0.03013878,  0.00255842,\n",
      "       -0.05375977, -0.03781757, -0.02884154,  0.00472803, -0.00646646,\n",
      "       -0.01545521, -0.01764582, -0.00123509, -0.01809982, -0.01147887])\n",
      " 95%|█████████▍| 70/74 [02:36<00:08,  2.25s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24268076261699023)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24744335581186377\n",
      "DEBUG:shap:self.fx = 0.646761904761905\n",
      "DEBUG:shap:self.link(self.fx) = 0.646761904761905\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.172025  ,  0.00565447,  0.00224042,  0.07842584,  0.00357285,\n",
      "        0.01834863,  0.02957429,  0.06171971, -0.05746936,  0.00551485,\n",
      "       -0.01968096, -0.00249771,  0.01841508, -0.07316234,  0.00476259])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.24268076261698976)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.24744335581186333\n",
      "DEBUG:shap:self.fx = 0.3532380952380954\n",
      "DEBUG:shap:self.link(self.fx) = 0.3532380952380954\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.172025  , -0.00565447, -0.00224042, -0.07842584, -0.00357285,\n",
      "       -0.01834863, -0.02957429, -0.06171971,  0.05746936, -0.00551485,\n",
      "        0.01968096,  0.00249771, -0.01841508,  0.07316234, -0.00476259])\n",
      " 96%|█████████▌| 71/74 [02:38<00:06,  2.24s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4573000742751856)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4634314510499586\n",
      "DEBUG:shap:self.fx = 0.8627499999999998\n",
      "DEBUG:shap:self.link(self.fx) = 0.8627499999999998\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([ 0.20693692,  0.01965528,  0.00241431,  0.09835098, -0.00981923,\n",
      "        0.01604274,  0.03810212,  0.06798934,  0.00586934,  0.00103938,\n",
      "        0.01441729,  0.01989226,  0.00690224, -0.03049289,  0.00613138])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.45730007427518593)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.46343145104995875\n",
      "DEBUG:shap:self.fx = 0.13724999999999998\n",
      "DEBUG:shap:self.link(self.fx) = 0.13724999999999998\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([-0.20693692, -0.01965528, -0.00241431, -0.09835098,  0.00981923,\n",
      "       -0.01604274, -0.03810212, -0.06798934, -0.00586934, -0.00103938,\n",
      "       -0.01441729, -0.01989226, -0.00690224,  0.03049289, -0.00613138])\n",
      " 97%|█████████▋| 72/74 [02:40<00:04,  2.23s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3089904930581165)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.323616269747762\n",
      "DEBUG:shap:self.fx = 0.07570227920227922\n",
      "DEBUG:shap:self.link(self.fx) = 0.07570227920227922\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.16488178, -0.02669943,  0.00703334, -0.04519847,  0.00266391,\n",
      "       -0.01130859, -0.02497439, -0.02391315, -0.01992771, -0.01235762,\n",
      "        0.        ,  0.00408699,  0.00648641,  0.        , -0.01462578])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.30899049305811643)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.32361626974776203\n",
      "DEBUG:shap:self.fx = 0.9242977207977208\n",
      "DEBUG:shap:self.link(self.fx) = 0.9242977207977208\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.16488178,  0.02669943, -0.00703334,  0.04519847, -0.00266391,\n",
      "        0.01130859,  0.02497439,  0.02391315,  0.01992771,  0.01235762,\n",
      "        0.        , -0.00408699, -0.00648641,  0.        ,  0.01462578])\n",
      " 99%|█████████▊| 73/74 [02:43<00:02,  2.22s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2569603684157078)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2723014549329472\n",
      "DEBUG:shap:self.fx = 0.12701709401709402\n",
      "DEBUG:shap:self.link(self.fx) = 0.12701709401709402\n",
      "DEBUG:shap:self.fnull = 0.3993185489500412\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3993185489500412\n",
      "INFO:shap:phi = array([-0.13069068,  0.00173339, -0.01214048, -0.05679102,  0.00158771,\n",
      "        0.01088723, -0.04028745, -0.01921966, -0.00413405, -0.00811139,\n",
      "        0.00768213, -0.02255409,  0.04108347, -0.02600548, -0.01534109])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2569603684157079)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.27230145493294744\n",
      "DEBUG:shap:self.fx = 0.8729829059829062\n",
      "DEBUG:shap:self.link(self.fx) = 0.8729829059829062\n",
      "DEBUG:shap:self.fnull = 0.6006814510499587\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6006814510499587\n",
      "INFO:shap:phi = array([ 0.13069068, -0.00173339,  0.01214048,  0.05679102, -0.00158771,\n",
      "       -0.01088723,  0.04028745,  0.01921966,  0.00413405,  0.00811139,\n",
      "       -0.00768213,  0.02255409, -0.04108347,  0.02600548,  0.01534109])\n",
      "100%|██████████| 74/74 [02:45<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7875,\n",
      "                0.7458333333333332,\n",
      "                0.6608333333333333,\n",
      "                0.56,\n",
      "                0.6216666666666666,\n",
      "                0.6291666666666667,\n",
      "                0.5275000000000001,\n",
      "                0.5741666666666667,\n",
      "                0.5783333333333334,\n",
      "                0.6258333333333334,\n",
      "                0.5991666666666667,\n",
      "                0.6058333333333333,\n",
      "                0.5204166666666666,\n",
      "                0.5454166666666667,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5893880935369175,\n",
      "                0.6939687843745195,\n",
      "                0.7861497864710774,\n",
      "                0.8458936405573276,\n",
      "                0.8828703216757898,\n",
      "                0.9095310509334874,\n",
      "                0.9373059843816347,\n",
      "                0.8598579037819417,\n",
      "                0.8939732945679326,\n",
      "                0.8995061653339594,\n",
      "                0.9145578564540002,\n",
      "                0.896320847839611,\n",
      "                0.9219070985617821,\n",
      "                0.9268913809609458,\n",
      "                0.9404186671352546\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.20014143968821002,\n",
      "                0.25060080888344277,\n",
      "                0.29290152701464217,\n",
      "                0.3204676327258146,\n",
      "                0.33733786946181604,\n",
      "                0.34798900723300935,\n",
      "                0.36022320636546296,\n",
      "                0.32889035475869166,\n",
      "                0.3442630343753096,\n",
      "                0.3469030473976222,\n",
      "                0.35334002172356127,\n",
      "                0.34556837299259124,\n",
      "                0.35703636063854377,\n",
      "                0.3591017801705773,\n",
      "                0.3649649438114703\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6054444444444443,\n",
      "            \"cross_entropy\": 0.859902725104412,\n",
      "            \"brier\": 0.32731529381605096\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7708333333333334,\n",
      "                0.7929166666666666,\n",
      "                0.8433333333333333,\n",
      "                0.8591666666666667,\n",
      "                0.845,\n",
      "                0.835,\n",
      "                0.8333333333333334,\n",
      "                0.8108333333333333,\n",
      "                0.8108333333333333,\n",
      "                0.8116666666666666,\n",
      "                0.8116666666666666,\n",
      "                0.8116666666666665,\n",
      "                0.8275,\n",
      "                0.8400000000000001,\n",
      "                0.8291666666666667\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.6613720387481131,\n",
      "                0.5813672929279904,\n",
      "                0.5108789761289761,\n",
      "                0.4728810069891966,\n",
      "                0.48131751388641597,\n",
      "                0.4882776563809955,\n",
      "                0.4842780747559211,\n",
      "                0.5228003413035268,\n",
      "                0.5075128233163185,\n",
      "                0.5094612179574532,\n",
      "                0.5042806321029312,\n",
      "                0.5050633476645214,\n",
      "                0.49699225583757406,\n",
      "                0.4902744787977843,\n",
      "                0.4891898601283233\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.22809981569093526,\n",
      "                0.19605940381276157,\n",
      "                0.16857600403574025,\n",
      "                0.15332288574781724,\n",
      "                0.15633375593993196,\n",
      "                0.15930476736063756,\n",
      "                0.15613386367060075,\n",
      "                0.16939742395066504,\n",
      "                0.1646962467012852,\n",
      "                0.1639675945631498,\n",
      "                0.16366221928609567,\n",
      "                0.16480046604569373,\n",
      "                0.16180537509758922,\n",
      "                0.15947555799223034,\n",
      "                0.15935898123209713\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8221944444444446,\n",
      "            \"cross_entropy\": 0.513729834461736,\n",
      "            \"brier\": 0.16833295740848203\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/74 [00:00<?, ?it/s]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.27893225204108973)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2820994472269981\n",
      "DEBUG:shap:self.fx = 0.08578769841269838\n",
      "DEBUG:shap:self.link(self.fx) = 0.08578769841269838\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10464954, -0.03099638, -0.00373699, -0.00566534,  0.        ,\n",
      "        0.01819693,  0.01472868, -0.05484793, -0.00828634, -0.01505646,\n",
      "       -0.00785655, -0.00808084, -0.00992054, -0.06276097, -0.0031672 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.27893225204108996)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2820994472269984\n",
      "DEBUG:shap:self.fx = 0.9142123015873017\n",
      "DEBUG:shap:self.link(self.fx) = 0.9142123015873017\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10464954,  0.03099638,  0.00373699,  0.00566534,  0.        ,\n",
      "       -0.01819693, -0.01472868,  0.05484793,  0.00828634,  0.01505646,\n",
      "        0.00785655,  0.00808084,  0.00992054,  0.06276097,  0.0031672 ])\n",
      "  1%|▏         | 1/74 [00:01<02:05,  1.71s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.14951464068588588)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.16172047897302982\n",
      "DEBUG:shap:self.fx = 0.20616666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.20616666666666666\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.09407001, -0.02789031,  0.00721369, -0.09098891,  0.00991532,\n",
      "       -0.01443961,  0.02375899,  0.01888117, -0.00563258, -0.00943991,\n",
      "       -0.01392286,  0.00544979, -0.00153922,  0.0431898 , -0.01220584])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.14951464068588605)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16172047897303\n",
      "DEBUG:shap:self.fx = 0.7938333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.7938333333333333\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.09407001,  0.02789031, -0.00721369,  0.09098891, -0.00991532,\n",
      "        0.01443961, -0.02375899, -0.01888117,  0.00563258,  0.00943991,\n",
      "        0.01392286, -0.00544979,  0.00153922, -0.0431898 ,  0.01220584])\n",
      "  3%|▎         | 2/74 [00:03<02:05,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1800047717738268)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1942561932587441\n",
      "DEBUG:shap:self.fx = 0.17363095238095239\n",
      "DEBUG:shap:self.link(self.fx) = 0.17363095238095239\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.13768565,  0.00140882,  0.00604483, -0.05700054,  0.00999813,\n",
      "       -0.01177587,  0.02066737, -0.03455398, -0.00512354,  0.00039735,\n",
      "        0.00413226, -0.00376015,  0.01012721,  0.01711898, -0.01425142])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.18000477177382682)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.19425619325874421\n",
      "DEBUG:shap:self.fx = 0.8263690476190475\n",
      "DEBUG:shap:self.link(self.fx) = 0.8263690476190475\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.13768565, -0.00140882, -0.00604483,  0.05700054, -0.00999813,\n",
      "        0.01177587, -0.02066737,  0.03455398,  0.00512354, -0.00039735,\n",
      "       -0.00413226,  0.00376015, -0.01012721, -0.01711898,  0.01425142])\n",
      "  4%|▍         | 3/74 [00:05<02:05,  1.76s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.16878127638384632)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.18769071706826798\n",
      "DEBUG:shap:self.fx = 0.1801964285714285\n",
      "DEBUG:shap:self.link(self.fx) = 0.1801964285714285\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.11920414, -0.00197464,  0.02267357, -0.05379741,  0.01497643,\n",
      "        0.02470693,  0.02172841, -0.05633103,  0.00828875, -0.00992557,\n",
      "       -0.00849397, -0.01528625, -0.01337929,  0.01723692, -0.01890944])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.16878127638384682)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.18769071706826845\n",
      "DEBUG:shap:self.fx = 0.8198035714285717\n",
      "DEBUG:shap:self.link(self.fx) = 0.8198035714285717\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.11920414,  0.00197464, -0.02267357,  0.05379741, -0.01497643,\n",
      "       -0.02470693, -0.02172841,  0.05633103, -0.00828875,  0.00992557,\n",
      "        0.00849397,  0.01528625,  0.01337929, -0.01723692,  0.01890944])\n",
      "  5%|▌         | 4/74 [00:06<02:02,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2564735704915268)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.23862920913175997\n",
      "DEBUG:shap:self.fx = 0.12925793650793652\n",
      "DEBUG:shap:self.link(self.fx) = 0.12925793650793652\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10396352,  0.0048131 , -0.00646425, -0.05180378, -0.00215684,\n",
      "       -0.01909761,  0.01052384, -0.04400835, -0.01490284, -0.00858428,\n",
      "       -0.00583711,  0.0296075 ,  0.00321133, -0.04781078,  0.01784436])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2564735704915271)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.23862920913176022\n",
      "DEBUG:shap:self.fx = 0.8707420634920635\n",
      "DEBUG:shap:self.link(self.fx) = 0.8707420634920635\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10396352, -0.0048131 ,  0.00646425,  0.05180378,  0.00215684,\n",
      "        0.01909761, -0.01052384,  0.04400835,  0.01490284,  0.00858428,\n",
      "        0.00583711, -0.0296075 , -0.00321133,  0.04781078, -0.01784436])\n",
      "  7%|▋         | 5/74 [00:08<01:59,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.14416783223872034)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.14228547340792275\n",
      "DEBUG:shap:self.fx = 0.5101726190476192\n",
      "DEBUG:shap:self.link(self.fx) = 0.5101726190476192\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.1668957 ,  0.00843667, -0.01253959,  0.08292631, -0.01279907,\n",
      "        0.0169681 ,  0.01389027, -0.05272207, -0.00461122, -0.00571517,\n",
      "        0.01938641, -0.00250864,  0.00573878, -0.07917867, -0.00188236])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.14416783223871998)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.14228547340792236\n",
      "DEBUG:shap:self.fx = 0.48982738095238093\n",
      "DEBUG:shap:self.link(self.fx) = 0.48982738095238093\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.1668957 , -0.00843667,  0.01253959, -0.08292631,  0.01279907,\n",
      "       -0.0169681 , -0.01389027,  0.05272207,  0.00461122,  0.00571517,\n",
      "       -0.01938641,  0.00250864, -0.00573878,  0.07917867,  0.00188236])\n",
      "  8%|▊         | 6/74 [00:10<01:57,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12272073505596713)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.10468031467776379\n",
      "DEBUG:shap:self.fx = 0.4725674603174603\n",
      "DEBUG:shap:self.link(self.fx) = 0.4725674603174603\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.02924968, -0.00400783, -0.01091529,  0.0819059 , -0.00961842,\n",
      "        0.0130999 ,  0.02184527,  0.04152172,  0.00815859,  0.0028393 ,\n",
      "        0.00927847,  0.00081016,  0.02206382, -0.08351053, -0.01804042])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.12272073505596706)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.10468031467776362\n",
      "DEBUG:shap:self.fx = 0.5274325396825397\n",
      "DEBUG:shap:self.link(self.fx) = 0.5274325396825397\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.02924968,  0.00400783,  0.01091529, -0.0819059 ,  0.00961842,\n",
      "       -0.0130999 , -0.02184527, -0.04152172, -0.00815859, -0.0028393 ,\n",
      "       -0.00927847, -0.00081016, -0.02206382,  0.08351053,  0.01804042])\n",
      "  9%|▉         | 7/74 [00:12<01:55,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.07969614611223871)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.062047859925410676\n",
      "DEBUG:shap:self.fx = 0.3058392857142858\n",
      "DEBUG:shap:self.link(self.fx) = 0.3058392857142858\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.12449235,  0.01869005,  0.01496947, -0.05998419, -0.00303503,\n",
      "       -0.0150538 , -0.03104821,  0.05761776,  0.0100457 ,  0.01549442,\n",
      "        0.02625231, -0.00536721,  0.01553161,  0.00068332,  0.01764829])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0796961461122392)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.062047859925411175\n",
      "DEBUG:shap:self.fx = 0.6941607142857145\n",
      "DEBUG:shap:self.link(self.fx) = 0.6941607142857145\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.12449235, -0.01869005, -0.01496947,  0.05998419,  0.00303503,\n",
      "        0.0150538 ,  0.03104821, -0.05761776, -0.0100457 , -0.01549442,\n",
      "       -0.02625231,  0.00536721, -0.01553161, -0.00068332, -0.01764829])\n",
      " 11%|█         | 8/74 [00:13<01:54,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03222434488180047)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.031521584519033696\n",
      "DEBUG:shap:self.fx = 0.3994087301587302\n",
      "DEBUG:shap:self.link(self.fx) = 0.3994087301587302\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.14624752,  0.00518383,  0.0136619 ,  0.08930681,  0.0093166 ,\n",
      "       -0.01757835,  0.00430893, -0.05174929, -0.041542  , -0.00545235,\n",
      "        0.00768505, -0.02136368, -0.01612055, -0.08968006, -0.00070276])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.032224344881800426)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.03152158451903364\n",
      "DEBUG:shap:self.fx = 0.6005912698412696\n",
      "DEBUG:shap:self.link(self.fx) = 0.6005912698412696\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.14624752, -0.00518383, -0.0136619 , -0.08930681, -0.0093166 ,\n",
      "        0.01757835, -0.00430893,  0.05174929,  0.041542  ,  0.00545235,\n",
      "       -0.00768505,  0.02136368,  0.01612055,  0.08968006,  0.00070276])\n",
      " 12%|█▏        | 9/74 [00:15<01:52,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.28342618714859047)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2791371456396965\n",
      "DEBUG:shap:self.fx = 0.08875\n",
      "DEBUG:shap:self.link(self.fx) = 0.08875\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10262297, -0.02185337,  0.00411207, -0.03426993,  0.00472685,\n",
      "       -0.02851994, -0.01558465, -0.02474885,  0.00804454, -0.01024631,\n",
      "        0.0070383 , -0.00132052,  0.0014571 , -0.06963849,  0.00428904])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2834261871485908)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2791371456396967\n",
      "DEBUG:shap:self.fx = 0.91125\n",
      "DEBUG:shap:self.link(self.fx) = 0.91125\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10262297,  0.02185337, -0.00411207,  0.03426993, -0.00472685,\n",
      "        0.02851994,  0.01558465,  0.02474885, -0.00804454,  0.01024631,\n",
      "       -0.0070383 ,  0.00132052, -0.0014571 ,  0.06963849, -0.00428904])\n",
      " 14%|█▎        | 10/74 [00:17<01:48,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20391198976194966)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1828930980206489\n",
      "DEBUG:shap:self.fx = 0.18499404761904759\n",
      "DEBUG:shap:self.link(self.fx) = 0.18499404761904759\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10638836,  0.0029214 ,  0.        , -0.06776368, -0.00483936,\n",
      "       -0.01290357, -0.04659036,  0.0698955 , -0.0049463 , -0.01279228,\n",
      "        0.00417167, -0.02128033,  0.        , -0.00339632,  0.02101889])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20391198976195013)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.18289309802064924\n",
      "DEBUG:shap:self.fx = 0.8150059523809525\n",
      "DEBUG:shap:self.link(self.fx) = 0.8150059523809525\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10638836, -0.0029214 ,  0.        ,  0.06776368,  0.00483936,\n",
      "        0.01290357,  0.04659036, -0.0698955 ,  0.0049463 ,  0.01279228,\n",
      "       -0.00417167,  0.02128033,  0.        ,  0.00339632, -0.02101889])\n",
      " 15%|█▍        | 11/74 [00:18<01:45,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.199463144367651)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21364905040160126\n",
      "DEBUG:shap:self.fx = 0.15423809523809523\n",
      "DEBUG:shap:self.link(self.fx) = 0.15423809523809523\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.13054531, -0.00170465,  0.00835263, -0.06559588, -0.004969  ,\n",
      "        0.00767904, -0.02021706, -0.03298808,  0.00808312, -0.01529937,\n",
      "        0.00340977,  0.000713  , -0.00443467,  0.04805332, -0.01418591])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19946314436765142)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21364905040160165\n",
      "DEBUG:shap:self.fx = 0.8457619047619049\n",
      "DEBUG:shap:self.link(self.fx) = 0.8457619047619049\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.13054531,  0.00170465, -0.00835263,  0.06559588,  0.004969  ,\n",
      "       -0.00767904,  0.02021706,  0.03298808, -0.00808312,  0.01529937,\n",
      "       -0.00340977, -0.000713  ,  0.00443467, -0.04805332,  0.01418591])\n",
      " 16%|█▌        | 12/74 [00:20<01:43,  1.66s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.47493480009617534)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.48495015594760527\n",
      "DEBUG:shap:self.fx = 0.8528373015873018\n",
      "DEBUG:shap:self.link(self.fx) = 0.8528373015873018\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.17800832,  0.00922416, -0.01148486,  0.09490497,  0.00369753,\n",
      "        0.01794904,  0.03542761,  0.08446255, -0.00705957,  0.00595449,\n",
      "        0.00541709,  0.00712059,  0.03497146,  0.0163414 ,  0.01001536])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.47493480009617495)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4849501559476049\n",
      "DEBUG:shap:self.fx = 0.1471626984126984\n",
      "DEBUG:shap:self.link(self.fx) = 0.1471626984126984\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.17800832, -0.00922416,  0.01148486, -0.09490497, -0.00369753,\n",
      "       -0.01794904, -0.03542761, -0.08446255,  0.00705957, -0.00595449,\n",
      "       -0.00541709, -0.00712059, -0.03497146, -0.0163414 , -0.01001536])\n",
      " 18%|█▊        | 13/74 [00:22<01:42,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2356587705519333)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2650776218301727\n",
      "DEBUG:shap:self.fx = 0.1028095238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.1028095238095238\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.09487027,  0.01075905, -0.01090683, -0.0452584 ,  0.01927031,\n",
      "       -0.01448726, -0.0442361 , -0.02061047, -0.01687102, -0.00375186,\n",
      "       -0.01089801, -0.03833129, -0.00039162,  0.03492501, -0.02941885])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2356587705519335)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.265077621830173\n",
      "DEBUG:shap:self.fx = 0.8971904761904763\n",
      "DEBUG:shap:self.link(self.fx) = 0.8971904761904763\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.09487027, -0.01075905,  0.01090683,  0.0452584 , -0.01927031,\n",
      "        0.01448726,  0.0442361 ,  0.02061047,  0.01687102,  0.00375186,\n",
      "        0.01089801,  0.03833129,  0.00039162, -0.03492501,  0.02941885])\n",
      " 19%|█▉        | 14/74 [00:23<01:40,  1.68s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.031135069732888057)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.02250619325874409\n",
      "DEBUG:shap:self.fx = 0.3453809523809524\n",
      "DEBUG:shap:self.link(self.fx) = 0.3453809523809524\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.11228008,  0.02012495,  0.01108167, -0.04750117, -0.00633716,\n",
      "       -0.00549914,  0.0424084 ,  0.07527934,  0.01129899,  0.01688376,\n",
      "        0.00230317, -0.00369623, -0.00374533, -0.03145622,  0.00862888])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03113506973288839)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.022506193258744478\n",
      "DEBUG:shap:self.fx = 0.6546190476190478\n",
      "DEBUG:shap:self.link(self.fx) = 0.6546190476190478\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.11228008, -0.02012495, -0.01108167,  0.04750117,  0.00633716,\n",
      "        0.00549914, -0.0424084 , -0.07527934, -0.01129899, -0.01688376,\n",
      "       -0.00230317,  0.00369623,  0.00374533,  0.03145622, -0.00862888])\n",
      " 20%|██        | 15/74 [00:25<01:40,  1.70s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.003056763867631585)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.008553812306363207\n",
      "DEBUG:shap:self.fx = 0.3593333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.3593333333333333\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.09038708, -0.03068715,  0.00323558, -0.02192769,  0.00778547,\n",
      "        0.03457992,  0.02386431,  0.11060297, -0.02206778,  0.01274573,\n",
      "       -0.00815441, -0.0005019 ,  0.00109731, -0.02324205, -0.00549705])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0030567638676316233)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.008553812306363318\n",
      "DEBUG:shap:self.fx = 0.6406666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.6406666666666666\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.09038708,  0.03068715, -0.00323558,  0.02192769, -0.00778547,\n",
      "       -0.03457992, -0.02386431, -0.11060297,  0.02206778, -0.01274573,\n",
      "        0.00815441,  0.0005019 , -0.00109731,  0.02324205,  0.00549705])\n",
      " 22%|██▏       | 16/74 [00:27<01:40,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.27051595353132685)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2635572988047481\n",
      "DEBUG:shap:self.fx = 0.6314444444444446\n",
      "DEBUG:shap:self.link(self.fx) = 0.6314444444444446\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.19019727,  0.01493422, -0.00567087,  0.08161531,  0.00366523,\n",
      "        0.0164943 ,  0.0106667 , -0.06036419, -0.0054599 , -0.0042712 ,\n",
      "       -0.01424656, -0.015286  ,  0.00703068,  0.05121096, -0.00695865])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.27051595353132646)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.26355729880474765\n",
      "DEBUG:shap:self.fx = 0.36855555555555564\n",
      "DEBUG:shap:self.link(self.fx) = 0.36855555555555564\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.19019727, -0.01493422,  0.00567087, -0.08161531, -0.00366523,\n",
      "       -0.0164943 , -0.0106667 ,  0.06036419,  0.0054599 ,  0.0042712 ,\n",
      "        0.01424656,  0.015286  , -0.00703068, -0.05121096,  0.00695865])\n",
      " 23%|██▎       | 17/74 [00:29<01:38,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.07463614427768589)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08333952659207744\n",
      "DEBUG:shap:self.fx = 0.28454761904761905\n",
      "DEBUG:shap:self.link(self.fx) = 0.28454761904761905\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.06966907,  0.00960204,  0.00604295, -0.03991837,  0.00980371,\n",
      "        0.041316  , -0.04052133,  0.04718002,  0.00584538, -0.01550225,\n",
      "        0.02064583,  0.00416519,  0.00437763, -0.05800388, -0.00870338])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0746361442776862)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08333952659207777\n",
      "DEBUG:shap:self.fx = 0.7154523809523811\n",
      "DEBUG:shap:self.link(self.fx) = 0.7154523809523811\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.06966907, -0.00960204, -0.00604295,  0.03991837, -0.00980371,\n",
      "       -0.041316  ,  0.04052133, -0.04718002, -0.00584538,  0.01550225,\n",
      "       -0.02064583, -0.00416519, -0.00437763,  0.05800388,  0.00870338])\n",
      " 24%|██▍       | 18/74 [00:30<01:36,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1390949252482795)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09795262183017267\n",
      "DEBUG:shap:self.fx = 0.2699345238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.2699345238095238\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.12556093, -0.00392268, -0.01270673, -0.06089006,  0.00765141,\n",
      "       -0.00726758,  0.01454995,  0.02289777,  0.00722409,  0.00522903,\n",
      "       -0.00972782,  0.00525996, -0.00787558,  0.02604424,  0.0411423 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1390949252482799)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09795262183017306\n",
      "DEBUG:shap:self.fx = 0.7300654761904763\n",
      "DEBUG:shap:self.link(self.fx) = 0.7300654761904763\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.12556093,  0.00392268,  0.01270673,  0.06089006, -0.00765141,\n",
      "        0.00726758, -0.01454995, -0.02289777, -0.00722409, -0.00522903,\n",
      "        0.00972782, -0.00525996,  0.00787558, -0.02604424, -0.0411423 ])\n",
      " 26%|██▌       | 19/74 [00:32<01:34,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.04066766535317735)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.03169801919546844\n",
      "DEBUG:shap:self.fx = 0.39958516483516493\n",
      "DEBUG:shap:self.link(self.fx) = 0.39958516483516493\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.05903536, -0.01978   ,  0.01415616,  0.07480337, -0.00175973,\n",
      "        0.02899391,  0.0088535 , -0.02623076,  0.00830651,  0.01297439,\n",
      "        0.00641789, -0.01661522,  0.00247898,  0.00710401, -0.00896965])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.04066766535317718)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.03169801919546822\n",
      "DEBUG:shap:self.fx = 0.6004148351648351\n",
      "DEBUG:shap:self.link(self.fx) = 0.6004148351648351\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.05903536,  0.01978   , -0.01415616, -0.07480337,  0.00175973,\n",
      "       -0.02899391, -0.0088535 ,  0.02623076, -0.00830651, -0.01297439,\n",
      "       -0.00641789,  0.01661522, -0.00247898, -0.00710401,  0.00896965])\n",
      " 27%|██▋       | 20/74 [00:34<01:32,  1.71s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.13999178721513225)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.14346254246509332\n",
      "DEBUG:shap:self.fx = 0.22442460317460317\n",
      "DEBUG:shap:self.link(self.fx) = 0.22442460317460317\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10111532, -0.00030639,  0.00930932, -0.07780466,  0.00594032,\n",
      "        0.0389046 , -0.05971766,  0.01684923,  0.00221314, -0.00663749,\n",
      "        0.01105845, -0.00730699,  0.03066417, -0.00204252, -0.00347076])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1399917872151322)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.14346254246509327\n",
      "DEBUG:shap:self.fx = 0.7755753968253966\n",
      "DEBUG:shap:self.link(self.fx) = 0.7755753968253966\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10111532,  0.00030639, -0.00930932,  0.07780466, -0.00594032,\n",
      "       -0.0389046 ,  0.05971766, -0.01684923, -0.00221314,  0.00663749,\n",
      "       -0.01105845,  0.00730699, -0.03066417,  0.00204252,  0.00347076])\n",
      " 28%|██▊       | 21/74 [00:35<01:30,  1.71s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2916092302064902)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2568692884968394\n",
      "DEBUG:shap:self.fx = 0.11101785714285713\n",
      "DEBUG:shap:self.link(self.fx) = 0.11101785714285713\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.08889506,  0.00205289,  0.00664781, -0.04949254,  0.00196626,\n",
      "       -0.01307361, -0.03152562, -0.01677548, -0.00964314, -0.00147635,\n",
      "        0.00231066, -0.01317561, -0.00957937, -0.07095007,  0.03473994])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2916092302064902)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.25686928849683943\n",
      "DEBUG:shap:self.fx = 0.8889821428571427\n",
      "DEBUG:shap:self.link(self.fx) = 0.8889821428571427\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.08889506, -0.00205289, -0.00664781,  0.04949254, -0.00196626,\n",
      "        0.01307361,  0.03152562,  0.01677548,  0.00964314,  0.00147635,\n",
      "       -0.00231066,  0.01317561,  0.00957937,  0.07095007, -0.03473994])\n",
      " 30%|██▉       | 22/74 [00:37<01:28,  1.69s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.25493939774980057)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2586783305507798\n",
      "DEBUG:shap:self.fx = 0.6265654761904763\n",
      "DEBUG:shap:self.link(self.fx) = 0.6265654761904763\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.15358559,  0.02130475,  0.00222841, -0.01530963,  0.00662838,\n",
      "       -0.00346042,  0.03307221,  0.13932893,  0.0136812 , -0.0073316 ,\n",
      "        0.0001774 ,  0.01327524,  0.00228357, -0.10452462,  0.00373893])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2549393977498003)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2586783305507796\n",
      "DEBUG:shap:self.fx = 0.3734345238095237\n",
      "DEBUG:shap:self.link(self.fx) = 0.3734345238095237\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.15358559, -0.02130475, -0.00222841,  0.01530963, -0.00662838,\n",
      "        0.00346042, -0.03307221, -0.13932893, -0.0136812 ,  0.0073316 ,\n",
      "       -0.0001774 , -0.01327524, -0.00228357,  0.10452462, -0.00373893])\n",
      " 31%|███       | 23/74 [00:39<01:27,  1.71s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.07550846813400508)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09529142578887506\n",
      "DEBUG:shap:self.fx = 0.46317857142857155\n",
      "DEBUG:shap:self.link(self.fx) = 0.46317857142857155\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.1352233 , -0.0394241 , -0.02501368,  0.01035671, -0.00132423,\n",
      "       -0.00054084,  0.02553357,  0.03437469,  0.00434298, -0.00823544,\n",
      "        0.00277523,  0.03056141,  0.01961544, -0.11273656,  0.01978296])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.07550846813400475)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09529142578887484\n",
      "DEBUG:shap:self.fx = 0.5368214285714284\n",
      "DEBUG:shap:self.link(self.fx) = 0.5368214285714284\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.1352233 ,  0.0394241 ,  0.02501368, -0.01035671,  0.00132423,\n",
      "        0.00054084, -0.02553357, -0.03437469, -0.00434298,  0.00823544,\n",
      "       -0.00277523, -0.03056141, -0.01961544,  0.11273656, -0.01978296])\n",
      " 32%|███▏      | 24/74 [00:41<01:26,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2823130207389406)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3104407170682679\n",
      "DEBUG:shap:self.fx = 0.05744642857142858\n",
      "DEBUG:shap:self.link(self.fx) = 0.05744642857142858\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.08100053,  0.00883477, -0.0094718 , -0.07268196, -0.00035007,\n",
      "       -0.01423004, -0.04119383, -0.03955216,  0.00330789, -0.00655112,\n",
      "        0.01414885, -0.03562582, -0.00647476, -0.00147244, -0.0281277 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2823130207389409)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.31044071706826826\n",
      "DEBUG:shap:self.fx = 0.9425535714285715\n",
      "DEBUG:shap:self.link(self.fx) = 0.9425535714285715\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.08100053, -0.00883477,  0.0094718 ,  0.07268196,  0.00035007,\n",
      "        0.01423004,  0.04119383,  0.03955216, -0.00330789,  0.00655112,\n",
      "       -0.01414885,  0.03562582,  0.00647476,  0.00147244,  0.0281277 ])\n",
      " 34%|███▍      | 25/74 [00:42<01:24,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.24536802460269777)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.25697643135398224\n",
      "DEBUG:shap:self.fx = 0.11091071428571427\n",
      "DEBUG:shap:self.link(self.fx) = 0.11091071428571427\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.11186666,  0.00918771, -0.00106158, -0.07063751, -0.01068065,\n",
      "       -0.01987861, -0.03248062,  0.02550417,  0.00945555, -0.00167087,\n",
      "        0.01347462, -0.00124614, -0.00567991, -0.04778752, -0.01160841])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24536802460269802)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2569764313539825\n",
      "DEBUG:shap:self.fx = 0.8890892857142858\n",
      "DEBUG:shap:self.link(self.fx) = 0.8890892857142858\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.11186666, -0.00918771,  0.00106158,  0.07063751,  0.01068065,\n",
      "        0.01987861,  0.03248062, -0.02550417, -0.00945555,  0.00167087,\n",
      "       -0.01347462,  0.00124614,  0.00567991,  0.04778752,  0.01160841])\n",
      " 35%|███▌      | 26/74 [00:44<01:22,  1.71s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.02283981510944675)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.0027800027825536366\n",
      "DEBUG:shap:self.fx = 0.36510714285714285\n",
      "DEBUG:shap:self.link(self.fx) = 0.36510714285714285\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.04234487,  0.0246071 , -0.02357009,  0.0792964 ,  0.0050859 ,\n",
      "       -0.01307056,  0.01289609, -0.03409187,  0.01165792, -0.00156645,\n",
      "        0.01338776,  0.02795242, -0.00579122, -0.07728836,  0.02005981])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.02283981510944693)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.0027800027825538587\n",
      "DEBUG:shap:self.fx = 0.6348928571428571\n",
      "DEBUG:shap:self.link(self.fx) = 0.6348928571428571\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.04234487, -0.0246071 ,  0.02357009, -0.0792964 , -0.0050859 ,\n",
      "        0.01307056, -0.01289609,  0.03409187, -0.01165792,  0.00156645,\n",
      "       -0.01338776, -0.02795242,  0.00579122,  0.07728836, -0.02005981])\n",
      " 36%|███▋      | 27/74 [00:46<01:21,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2194637806151783)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2111371456396965\n",
      "DEBUG:shap:self.fx = 0.15675\n",
      "DEBUG:shap:self.link(self.fx) = 0.15675\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.09096114, -0.01372607, -0.00216159, -0.03041457,  0.00563434,\n",
      "        0.01341642, -0.01852401, -0.0262307 , -0.01803071,  0.0080624 ,\n",
      "        0.00349935, -0.00634228, -0.00324325, -0.04044197,  0.00832663])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.21946378061517857)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21113714563969688\n",
      "DEBUG:shap:self.fx = 0.8432500000000002\n",
      "DEBUG:shap:self.link(self.fx) = 0.8432500000000002\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.09096114,  0.01372607,  0.00216159,  0.03041457, -0.00563434,\n",
      "       -0.01341642,  0.01852401,  0.0262307 ,  0.01803071, -0.0080624 ,\n",
      "       -0.00349935,  0.00634228,  0.00324325,  0.04044197, -0.00832663])\n",
      " 38%|███▊      | 28/74 [00:48<01:19,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19468195893036644)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.18765650515395416\n",
      "DEBUG:shap:self.fx = 0.5555436507936506\n",
      "DEBUG:shap:self.link(self.fx) = 0.5555436507936506\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.18507664,  0.00767014,  0.00952289, -0.03235243,  0.00563619,\n",
      "       -0.02733213, -0.04277508,  0.10459261, -0.02837606, -0.0107612 ,\n",
      "       -0.00297907,  0.0044121 ,  0.00598585,  0.0163615 , -0.00702545])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19468195893036647)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.18765650515395405\n",
      "DEBUG:shap:self.fx = 0.44445634920634924\n",
      "DEBUG:shap:self.link(self.fx) = 0.44445634920634924\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.18507664, -0.00767014, -0.00952289,  0.03235243, -0.00563619,\n",
      "        0.02733213,  0.04277508, -0.10459261,  0.02837606,  0.0107612 ,\n",
      "        0.00297907, -0.0044121 , -0.00598585, -0.0163615 ,  0.00702545])\n",
      " 39%|███▉      | 29/74 [00:49<01:17,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.49678252818206925)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5038985686460178\n",
      "DEBUG:shap:self.fx = 0.8717857142857143\n",
      "DEBUG:shap:self.link(self.fx) = 0.8717857142857143\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.19476725,  0.01646234, -0.00326438,  0.09244422,  0.00816033,\n",
      "       -0.01372907,  0.02901032,  0.07247118, -0.00359252,  0.00150022,\n",
      "       -0.0148578 ,  0.02579145,  0.02392261,  0.06769638,  0.00711604])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.496782528182069)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5038985686460176\n",
      "DEBUG:shap:self.fx = 0.1282142857142857\n",
      "DEBUG:shap:self.link(self.fx) = 0.1282142857142857\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.19476725, -0.01646234,  0.00326438, -0.09244422, -0.00816033,\n",
      "        0.01372907, -0.02901032, -0.07247118,  0.00359252, -0.00150022,\n",
      "        0.0148578 , -0.02579145, -0.02392261, -0.06769638, -0.00711604])\n",
      " 41%|████      | 30/74 [00:51<01:16,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.31077006460875645)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2852795210269704\n",
      "DEBUG:shap:self.fx = 0.6531666666666669\n",
      "DEBUG:shap:self.link(self.fx) = 0.6531666666666669\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.17552864,  0.00921912,  0.01196185,  0.10259237,  0.00782617,\n",
      "       -0.00503919,  0.02381212, -0.07629124, -0.00286506, -0.00611457,\n",
      "        0.01132298, -0.0072192 ,  0.02928877,  0.03674732, -0.02549054])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3107700646087559)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2852795210269699\n",
      "DEBUG:shap:self.fx = 0.3468333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.3468333333333334\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.17552864, -0.00921912, -0.01196185, -0.10259237, -0.00782617,\n",
      "        0.00503919, -0.02381212,  0.07629124,  0.00286506,  0.00611457,\n",
      "       -0.01132298,  0.0072192 , -0.02928877, -0.03674732,  0.02549054])\n",
      " 42%|████▏     | 31/74 [00:53<01:14,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3623219030282451)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.36665452102697027\n",
      "DEBUG:shap:self.fx = 0.7345416666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.7345416666666668\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.15239732,  0.02140511,  0.00682296,  0.08054608, -0.02015054,\n",
      "        0.00633968,  0.03123182,  0.06465597, -0.0105529 , -0.0006887 ,\n",
      "        0.00422039,  0.00293556,  0.00668376,  0.01647538,  0.00433262])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3623219030282447)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.36665452102697\n",
      "DEBUG:shap:self.fx = 0.2654583333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.2654583333333333\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.15239732, -0.02140511, -0.00682296, -0.08054608,  0.02015054,\n",
      "       -0.00633968, -0.03123182, -0.06465597,  0.0105529 ,  0.0006887 ,\n",
      "       -0.00422039, -0.00293556, -0.00668376, -0.01647538, -0.00433262])\n",
      " 43%|████▎     | 32/74 [00:55<01:13,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17570931261284378)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.19363666388411305\n",
      "DEBUG:shap:self.fx = 0.5615238095238095\n",
      "DEBUG:shap:self.link(self.fx) = 0.5615238095238095\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.18074749,  0.01620669,  0.01582575, -0.10895439,  0.        ,\n",
      "       -0.01398086,  0.03370138, -0.03680846,  0.00729301,  0.0044426 ,\n",
      "        0.0063399 ,  0.00569354, -0.00047413,  0.06567679,  0.01792735])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1757093126128435)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.19363666388411271\n",
      "DEBUG:shap:self.fx = 0.4384761904761906\n",
      "DEBUG:shap:self.link(self.fx) = 0.4384761904761906\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.18074749, -0.01620669, -0.01582575,  0.10895439,  0.        ,\n",
      "        0.01398086, -0.03370138,  0.03680846, -0.00729301, -0.0044426 ,\n",
      "       -0.0063399 , -0.00569354,  0.00047413, -0.06567679, -0.01792735])\n",
      " 45%|████▍     | 33/74 [00:56<01:11,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.101055697328056)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.10172047897302977\n",
      "DEBUG:shap:self.fx = 0.2661666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.2661666666666667\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.08455068,  0.04590644,  0.01955333, -0.07034258, -0.01260605,\n",
      "       -0.03416565,  0.02710616,  0.05230028, -0.01058849,  0.00123159,\n",
      "        0.0122106 , -0.00828324,  0.01517861, -0.05400602, -0.00066478])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.10105569732805636)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.10172047897303016\n",
      "DEBUG:shap:self.fx = 0.7338333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.7338333333333334\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.08455068, -0.04590644, -0.01955333,  0.07034258,  0.01260605,\n",
      "        0.03416565, -0.02710616, -0.05230028,  0.01058849, -0.00123159,\n",
      "       -0.0122106 ,  0.00828324, -0.01517861,  0.05400602,  0.00066478])\n",
      " 46%|████▌     | 34/74 [00:58<01:09,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23458315032885707)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.25931571706826795\n",
      "DEBUG:shap:self.fx = 0.10857142857142855\n",
      "DEBUG:shap:self.link(self.fx) = 0.10857142857142855\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.07252398,  0.01815588, -0.01303672, -0.06504785,  0.        ,\n",
      "       -0.01765274, -0.05381097, -0.019842  ,  0.00558632,  0.00504911,\n",
      "        0.02020849, -0.03514631, -0.00702901,  0.00050665, -0.02473257])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23458315032885743)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2593157170682683\n",
      "DEBUG:shap:self.fx = 0.8914285714285716\n",
      "DEBUG:shap:self.link(self.fx) = 0.8914285714285716\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.07252398, -0.01815588,  0.01303672,  0.06504785,  0.        ,\n",
      "        0.01765274,  0.05381097,  0.019842  , -0.00558632, -0.00504911,\n",
      "       -0.02020849,  0.03514631,  0.00702901, -0.00050665,  0.02473257])\n",
      " 47%|████▋     | 35/74 [01:00<01:07,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.486832355520392)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4976366638841131\n",
      "DEBUG:shap:self.fx = 0.8655238095238096\n",
      "DEBUG:shap:self.link(self.fx) = 0.8655238095238096\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.20228749,  0.00984006,  0.02487963,  0.08477939,  0.00696568,\n",
      "       -0.00800813,  0.03628746,  0.10133578, -0.02627092,  0.00067188,\n",
      "        0.00978518,  0.00669982, -0.01047482,  0.04805384,  0.01080431])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4868323555203916)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4976366638841128\n",
      "DEBUG:shap:self.fx = 0.13447619047619047\n",
      "DEBUG:shap:self.link(self.fx) = 0.13447619047619047\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.20228749, -0.00984006, -0.02487963, -0.08477939, -0.00696568,\n",
      "        0.00800813, -0.03628746, -0.10133578,  0.02627092, -0.00067188,\n",
      "       -0.00978518, -0.00669982,  0.01047482, -0.04805384, -0.01080431])\n",
      " 49%|████▊     | 36/74 [01:01<01:05,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4871331951451177)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4932140448364941\n",
      "DEBUG:shap:self.fx = 0.8611011904761906\n",
      "DEBUG:shap:self.link(self.fx) = 0.8611011904761906\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.18758151,  0.01074127, -0.03453785,  0.09362335,  0.00724784,\n",
      "       -0.00489385,  0.02394316,  0.07268981,  0.0148509 ,  0.00159869,\n",
      "        0.00548586,  0.03254501,  0.01287295,  0.06338455,  0.00608085])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4871331951451173)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4932140448364938\n",
      "DEBUG:shap:self.fx = 0.13889880952380954\n",
      "DEBUG:shap:self.link(self.fx) = 0.13889880952380954\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.18758151, -0.01074127,  0.03453785, -0.09362335, -0.00724784,\n",
      "        0.00489385, -0.02394316, -0.07268981, -0.0148509 , -0.00159869,\n",
      "       -0.00548586, -0.03254501, -0.01287295, -0.06338455, -0.00608085])\n",
      " 50%|█████     | 37/74 [01:03<01:03,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22665558772663358)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.24614905040160126\n",
      "DEBUG:shap:self.fx = 0.12173809523809523\n",
      "DEBUG:shap:self.link(self.fx) = 0.12173809523809523\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.1059248 ,  0.01543001, -0.00582616, -0.06315488,  0.0138106 ,\n",
      "       -0.00427335, -0.06414989,  0.00816219,  0.00450832,  0.00698644,\n",
      "       -0.01218633, -0.00625844,  0.01026372, -0.02404301, -0.01949346])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22665558772663347)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24614905040160118\n",
      "DEBUG:shap:self.fx = 0.8782619047619045\n",
      "DEBUG:shap:self.link(self.fx) = 0.8782619047619045\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.1059248 , -0.01543001,  0.00582616,  0.06315488, -0.0138106 ,\n",
      "        0.00427335,  0.06414989, -0.00816219, -0.00450832, -0.00698644,\n",
      "        0.01218633,  0.00625844, -0.01026372,  0.02404301,  0.01949346])\n",
      " 51%|█████▏    | 38/74 [01:05<01:02,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000007)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4559767881995639)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4542378543603036\n",
      "DEBUG:shap:self.fx = 0.8221250000000001\n",
      "DEBUG:shap:self.link(self.fx) = 0.8221250000000001\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.19221403,  0.0160732 ,  0.01622743,  0.09578567,  0.00206272,\n",
      "       -0.01844641,  0.03893579,  0.03880377, -0.00973578,  0.00182984,\n",
      "        0.00399223,  0.00359447, -0.00268393,  0.07732376, -0.00173893])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000007)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4559767881995636)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4542378543603033\n",
      "DEBUG:shap:self.fx = 0.177875\n",
      "DEBUG:shap:self.link(self.fx) = 0.177875\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.19221403, -0.0160732 , -0.01622743, -0.09578567, -0.00206272,\n",
      "        0.01844641, -0.03893579, -0.03880377,  0.00973578, -0.00182984,\n",
      "       -0.00399223, -0.00359447,  0.00268393, -0.07732376,  0.00173893])\n",
      " 53%|█████▎    | 39/74 [01:07<01:01,  1.76s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2777062999166183)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2954104734079226\n",
      "DEBUG:shap:self.fx = 0.6632976190476191\n",
      "DEBUG:shap:self.link(self.fx) = 0.6632976190476191\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.153073  , -0.04131393, -0.00868358,  0.0849879 , -0.02516474,\n",
      "       -0.00105412,  0.02373363,  0.06288849,  0.02138333,  0.00343962,\n",
      "        0.00789022,  0.01115621,  0.00168095, -0.01631069,  0.01770417])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.27770629991661816)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.29541047340792226\n",
      "DEBUG:shap:self.fx = 0.33670238095238103\n",
      "DEBUG:shap:self.link(self.fx) = 0.33670238095238103\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.153073  ,  0.04131393,  0.00868358, -0.0849879 ,  0.02516474,\n",
      "        0.00105412, -0.02373363, -0.06288849, -0.02138333, -0.00343962,\n",
      "       -0.00789022, -0.01115621, -0.00168095,  0.01631069, -0.01770417])\n",
      " 54%|█████▍    | 40/74 [01:08<00:59,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4648782187559663)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4674997591222083\n",
      "DEBUG:shap:self.fx = 0.8353869047619048\n",
      "DEBUG:shap:self.link(self.fx) = 0.8353869047619048\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.1734571 ,  0.01243357, -0.03352806,  0.09012951,  0.00493712,\n",
      "        0.01615321,  0.02409087,  0.08187064, -0.01131948, -0.00243468,\n",
      "        0.00178314,  0.03465606,  0.02135881,  0.05129039,  0.00262154])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.46487821875596613)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4674997591222081\n",
      "DEBUG:shap:self.fx = 0.16461309523809523\n",
      "DEBUG:shap:self.link(self.fx) = 0.16461309523809523\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.1734571 , -0.01243357,  0.03352806, -0.09012951, -0.00493712,\n",
      "       -0.01615321, -0.02409087, -0.08187064,  0.01131948,  0.00243468,\n",
      "       -0.00178314, -0.03465606, -0.02135881, -0.05129039, -0.00262154])\n",
      " 55%|█████▌    | 41/74 [01:10<00:57,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.39377346316715284)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4284819019793512\n",
      "DEBUG:shap:self.fx = 0.7963690476190477\n",
      "DEBUG:shap:self.link(self.fx) = 0.7963690476190477\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.20718121,  0.01079525,  0.00407351,  0.08830408,  0.00788465,\n",
      "        0.01376408,  0.02184573, -0.04430424,  0.01308879,  0.00232572,\n",
      "       -0.01925429,  0.0055536 ,  0.0060766 ,  0.07643878,  0.03470844])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.39377346316715256)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4284819019793509\n",
      "DEBUG:shap:self.fx = 0.20363095238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.20363095238095238\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.20718121, -0.01079525, -0.00407351, -0.08830408, -0.00788465,\n",
      "       -0.01376408, -0.02184573,  0.04430424, -0.01308879, -0.00232572,\n",
      "        0.01925429, -0.0055536 , -0.0060766 , -0.07643878, -0.03470844])\n",
      " 57%|█████▋    | 42/74 [01:12<00:55,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5397894846923253)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5562676162650655\n",
      "DEBUG:shap:self.fx = 0.924154761904762\n",
      "DEBUG:shap:self.link(self.fx) = 0.924154761904762\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.20508536,  0.01776534,  0.01284212,  0.0987821 , -0.00240847,\n",
      "        0.0227173 ,  0.0350306 ,  0.04388297,  0.0140865 ,  0.00321349,\n",
      "       -0.00823922,  0.00880351,  0.01562882,  0.07259905,  0.01647813])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5397894846923253)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5562676162650652\n",
      "DEBUG:shap:self.fx = 0.0758452380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.0758452380952381\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.20508536, -0.01776534, -0.01284212, -0.0987821 ,  0.00240847,\n",
      "       -0.0227173 , -0.0350306 , -0.04388297, -0.0140865 , -0.00321349,\n",
      "        0.00823922, -0.00880351, -0.01562882, -0.07259905, -0.01647813])\n",
      " 58%|█████▊    | 43/74 [01:14<00:53,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.28730207096586036)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2808811932587441\n",
      "DEBUG:shap:self.fx = 0.08700595238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.08700595238095238\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.12379055, -0.00546666,  0.00861356, -0.04655858,  0.00414453,\n",
      "        0.00453688,  0.01853252, -0.03779694,  0.0043202 , -0.01540061,\n",
      "       -0.01213125, -0.00991954, -0.01184642, -0.06453922,  0.00642088])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2873020709658605)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2808811932587443\n",
      "DEBUG:shap:self.fx = 0.9129940476190476\n",
      "DEBUG:shap:self.link(self.fx) = 0.9129940476190476\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.12379055,  0.00546666, -0.00861356,  0.04655858, -0.00414453,\n",
      "       -0.00453688, -0.01853252,  0.03779694, -0.0043202 ,  0.01540061,\n",
      "        0.01213125,  0.00991954,  0.01184642,  0.06453922, -0.00642088])\n",
      " 59%|█████▉    | 44/74 [01:15<00:52,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2264023870533315)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1875776218301727\n",
      "DEBUG:shap:self.fx = 0.18030952380952378\n",
      "DEBUG:shap:self.link(self.fx) = 0.18030952380952378\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.12616552,  0.00821041, -0.00915217, -0.04919011,  0.00069031,\n",
      "       -0.00852121,  0.0056    , -0.0227107 , -0.01836361,  0.00266963,\n",
      "       -0.00197132, -0.00699344, -0.00765297,  0.00714831,  0.03882477])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22640238705333166)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1875776218301729\n",
      "DEBUG:shap:self.fx = 0.8196904761904762\n",
      "DEBUG:shap:self.link(self.fx) = 0.8196904761904762\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.12616552, -0.00821041,  0.00915217,  0.04919011, -0.00069031,\n",
      "        0.00852121, -0.0056    ,  0.0227107 ,  0.01836361, -0.00266963,\n",
      "        0.00197132,  0.00699344,  0.00765297, -0.00714831, -0.03882477])\n",
      " 61%|██████    | 45/74 [01:17<00:50,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3148333575530665)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3178038123063631\n",
      "DEBUG:shap:self.fx = 0.05008333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.05008333333333334\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10222801,  0.00207688,  0.00163129, -0.06890556, -0.00871935,\n",
      "       -0.02045019, -0.00821106, -0.03500566,  0.00211606, -0.00965749,\n",
      "       -0.00632252,  0.00260396, -0.00797242, -0.0557893 , -0.00297045])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.31483335755306674)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.31780381230636345\n",
      "DEBUG:shap:self.fx = 0.9499166666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.9499166666666667\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10222801, -0.00207688, -0.00163129,  0.06890556,  0.00871935,\n",
      "        0.02045019,  0.00821106,  0.03500566, -0.00211606,  0.00965749,\n",
      "        0.00632252, -0.00260396,  0.00797242,  0.0557893 ,  0.00297045])\n",
      " 62%|██████▏   | 46/74 [01:19<00:48,  1.72s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3672182247085901)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.38798587023331943\n",
      "DEBUG:shap:self.fx = 0.7558730158730159\n",
      "DEBUG:shap:self.link(self.fx) = 0.7558730158730159\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.19070364,  0.01128982, -0.01422734, -0.03075834,  0.00260238,\n",
      "        0.03133879,  0.021534  ,  0.02647321,  0.01096191,  0.01007757,\n",
      "        0.00921408,  0.03828224, -0.00908969,  0.06881597,  0.02076765])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3672182247085899)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3879858702333192\n",
      "DEBUG:shap:self.fx = 0.24412698412698408\n",
      "DEBUG:shap:self.link(self.fx) = 0.24412698412698408\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.19070364, -0.01128982,  0.01422734,  0.03075834, -0.00260238,\n",
      "       -0.03133879, -0.021534  , -0.02647321, -0.01096191, -0.01007757,\n",
      "       -0.00921408, -0.03828224,  0.00908969, -0.06881597, -0.02076765])\n",
      " 64%|██████▎   | 47/74 [01:21<00:46,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3468864587811225)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.33167833055077967\n",
      "DEBUG:shap:self.fx = 0.6995654761904762\n",
      "DEBUG:shap:self.link(self.fx) = 0.6995654761904762\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.1662543 , -0.05167708, -0.03891129,  0.06868877,  0.        ,\n",
      "        0.00510924,  0.01937804,  0.07796577, -0.00729796,  0.0037393 ,\n",
      "        0.005812  ,  0.02728871,  0.00882688,  0.06170977, -0.01520813])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3468864587811225)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.33167833055077955\n",
      "DEBUG:shap:self.fx = 0.30043452380952373\n",
      "DEBUG:shap:self.link(self.fx) = 0.30043452380952373\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.1662543 ,  0.05167708,  0.03891129, -0.06868877,  0.        ,\n",
      "       -0.00510924, -0.01937804, -0.07796577,  0.00729796, -0.0037393 ,\n",
      "       -0.005812  , -0.02728871, -0.00882688, -0.06170977,  0.01520813])\n",
      " 65%|██████▍   | 48/74 [01:22<00:45,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2503975156888809)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.26470857421112504\n",
      "DEBUG:shap:self.fx = 0.10317857142857143\n",
      "DEBUG:shap:self.link(self.fx) = 0.10317857142857143\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.09771884,  0.00305572, -0.00528471, -0.07726119,  0.00202166,\n",
      "        0.01158422, -0.06923174,  0.04371853,  0.00571654, -0.01377076,\n",
      "       -0.00496338, -0.01865226,  0.02148595, -0.05109725, -0.01431106])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.25039751568888124)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.26470857421112537\n",
      "DEBUG:shap:self.fx = 0.8968214285714287\n",
      "DEBUG:shap:self.link(self.fx) = 0.8968214285714287\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.09771884, -0.00305572,  0.00528471,  0.07726119, -0.00202166,\n",
      "       -0.01158422,  0.06923174, -0.04371853, -0.00571654,  0.01377076,\n",
      "        0.00496338,  0.01865226, -0.02148595,  0.05109725,  0.01431106])\n",
      " 66%|██████▌   | 49/74 [01:24<00:42,  1.70s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.06204108086627051)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.05603595516350596\n",
      "DEBUG:shap:self.fx = 0.31185119047619053\n",
      "DEBUG:shap:self.link(self.fx) = 0.31185119047619053\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.15494834,  0.00636295,  0.00504705, -0.0473423 , -0.0024522 ,\n",
      "       -0.01966667, -0.00173201,  0.08439721,  0.01221197,  0.0051638 ,\n",
      "        0.02959074, -0.00560722,  0.00213309,  0.02480085,  0.00600513])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.06204108086627096)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.056035955163506346\n",
      "DEBUG:shap:self.fx = 0.6881488095238096\n",
      "DEBUG:shap:self.link(self.fx) = 0.6881488095238096\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.15494834, -0.00636295, -0.00504705,  0.0473423 ,  0.0024522 ,\n",
      "        0.01966667,  0.00173201, -0.08439721, -0.01221197, -0.0051638 ,\n",
      "       -0.02959074,  0.00560722, -0.00213309, -0.02480085, -0.00600513])\n",
      " 68%|██████▊   | 50/74 [01:26<00:41,  1.73s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4846249022223824)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.48799777499522423\n",
      "DEBUG:shap:self.fx = 0.8558849206349207\n",
      "DEBUG:shap:self.link(self.fx) = 0.8558849206349207\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.19142085,  0.02190415, -0.00132074,  0.08444358,  0.01007405,\n",
      "        0.02231396,  0.03571175,  0.07563531, -0.0133989 ,  0.01307622,\n",
      "       -0.00977932,  0.01051884,  0.01322249,  0.03080267,  0.00337287])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.48462490222238186)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4879977749952239\n",
      "DEBUG:shap:self.fx = 0.14411507936507936\n",
      "DEBUG:shap:self.link(self.fx) = 0.14411507936507936\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.19142085, -0.02190415,  0.00132074, -0.08444358, -0.01007405,\n",
      "       -0.02231396, -0.03571175, -0.07563531,  0.0133989 , -0.01307622,\n",
      "        0.00977932, -0.01051884, -0.01322249, -0.03080267, -0.00337287])\n",
      " 69%|██████▉   | 51/74 [01:27<00:40,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.0517574913615158)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.05992285992541069\n",
      "DEBUG:shap:self.fx = 0.3079642857142858\n",
      "DEBUG:shap:self.link(self.fx) = 0.3079642857142858\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.11504081,  0.01719816,  0.00562074, -0.06594433,  0.00708371,\n",
      "        0.00212938,  0.0253449 ,  0.09597397, -0.02469178,  0.00508648,\n",
      "       -0.00627008, -0.00199407,  0.0021137 ,  0.00163254, -0.00816537])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.051757491361516014)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.05992285992541102\n",
      "DEBUG:shap:self.fx = 0.6920357142857143\n",
      "DEBUG:shap:self.link(self.fx) = 0.6920357142857143\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.11504081, -0.01719816, -0.00562074,  0.06594433, -0.00708371,\n",
      "       -0.00212938, -0.0253449 , -0.09597397,  0.02469178, -0.00508648,\n",
      "        0.00627008,  0.00199407, -0.0021137 , -0.00163254,  0.00816537])\n",
      " 70%|███████   | 52/74 [01:29<00:38,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.39397527304085617)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4196247591222082\n",
      "DEBUG:shap:self.fx = 0.7875119047619047\n",
      "DEBUG:shap:self.link(self.fx) = 0.7875119047619047\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.18006279,  0.01377639,  0.01985804, -0.03245105,  0.00826301,\n",
      "        0.01226132,  0.03282642,  0.07811503,  0.01287098,  0.0047902 ,\n",
      "        0.01298865, -0.0020051 , -0.01155078,  0.06416938,  0.02564949])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.39397527304085606)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4196247591222081\n",
      "DEBUG:shap:self.fx = 0.2124880952380952\n",
      "DEBUG:shap:self.link(self.fx) = 0.2124880952380952\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.18006279, -0.01377639, -0.01985804,  0.03245105, -0.00826301,\n",
      "       -0.01226132, -0.03282642, -0.07811503, -0.01287098, -0.0047902 ,\n",
      "       -0.01298865,  0.0020051 ,  0.01155078, -0.06416938, -0.02564949])\n",
      " 72%|███████▏  | 53/74 [01:31<00:36,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5000078253731433)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5060017432491927\n",
      "DEBUG:shap:self.fx = 0.8738888888888892\n",
      "DEBUG:shap:self.link(self.fx) = 0.8738888888888892\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.17891976,  0.01189752,  0.00126908,  0.11635778,  0.004384  ,\n",
      "        0.01382482,  0.02981495,  0.07193564,  0.0188272 , -0.00410587,\n",
      "       -0.00210938,  0.02926831,  0.00986577,  0.01985827,  0.00599392])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5000078253731429)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5060017432491921\n",
      "DEBUG:shap:self.fx = 0.12611111111111112\n",
      "DEBUG:shap:self.link(self.fx) = 0.12611111111111112\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.17891976, -0.01189752, -0.00126908, -0.11635778, -0.004384  ,\n",
      "       -0.01382482, -0.02981495, -0.07193564, -0.0188272 ,  0.00410587,\n",
      "        0.00210938, -0.02926831, -0.00986577, -0.01985827, -0.00599392])\n",
      " 73%|███████▎  | 54/74 [01:34<00:41,  2.09s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23020015139619832)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2174283305507797\n",
      "DEBUG:shap:self.fx = 0.5853154761904762\n",
      "DEBUG:shap:self.link(self.fx) = 0.5853154761904762\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.18885722,  0.0158783 , -0.0222231 ,  0.08464473,  0.01106592,\n",
      "       -0.01558564,  0.01927422, -0.04702872, -0.04389703, -0.00220144,\n",
      "       -0.01843238,  0.0342712 ,  0.00368367,  0.02189321, -0.01277182])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23020015139619798)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21742833055077948\n",
      "DEBUG:shap:self.fx = 0.4146845238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.4146845238095238\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.18885722, -0.0158783 ,  0.0222231 , -0.08464473, -0.01106592,\n",
      "        0.01558564, -0.01927422,  0.04702872,  0.04389703,  0.00220144,\n",
      "        0.01843238, -0.0342712 , -0.00368367, -0.02189321,  0.01277182])\n",
      " 74%|███████▍  | 55/74 [01:36<00:39,  2.09s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1957929195453293)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.19706174881429964\n",
      "DEBUG:shap:self.fx = 0.17082539682539685\n",
      "DEBUG:shap:self.link(self.fx) = 0.17082539682539685\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10221494,  0.0036547 ,  0.01220025,  0.00583252,  0.00109315,\n",
      "       -0.02135839, -0.05410726,  0.03021913,  0.00265414,  0.01816883,\n",
      "        0.00492149, -0.0270524 , -0.00160627, -0.06819788, -0.00126883])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19579291954532962)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.19706174881429994\n",
      "DEBUG:shap:self.fx = 0.8291746031746032\n",
      "DEBUG:shap:self.link(self.fx) = 0.8291746031746032\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10221494, -0.0036547 , -0.01220025, -0.00583252, -0.00109315,\n",
      "        0.02135839,  0.05410726, -0.03021913, -0.00265414, -0.01816883,\n",
      "       -0.00492149,  0.0270524 ,  0.00160627,  0.06819788,  0.00126883])\n",
      " 76%|███████▌  | 56/74 [01:38<00:36,  2.01s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.293283915218599)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3064228599254108\n",
      "DEBUG:shap:self.fx = 0.061464285714285714\n",
      "DEBUG:shap:self.link(self.fx) = 0.061464285714285714\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.13114421, -0.02092949, -0.00019554, -0.07637045, -0.00728334,\n",
      "       -0.02420569,  0.01475665, -0.0331115 ,  0.00622906, -0.00159515,\n",
      "       -0.00472795, -0.00710852, -0.00545118, -0.00214661, -0.01313894])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.29328391521859914)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.30642285992541096\n",
      "DEBUG:shap:self.fx = 0.9385357142857143\n",
      "DEBUG:shap:self.link(self.fx) = 0.9385357142857143\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.13114421,  0.02092949,  0.00019554,  0.07637045,  0.00728334,\n",
      "        0.02420569, -0.01475665,  0.0331115 , -0.00622906,  0.00159515,\n",
      "        0.00472795,  0.00710852,  0.00545118,  0.00214661,  0.01313894])\n",
      " 77%|███████▋  | 57/74 [01:40<00:33,  1.99s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2696949110322158)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2787621456396965\n",
      "DEBUG:shap:self.fx = 0.08912500000000001\n",
      "DEBUG:shap:self.link(self.fx) = 0.08912500000000001\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.0990622 ,  0.00723436,  0.        , -0.04552349, -0.00377688,\n",
      "       -0.01599639, -0.05493628,  0.0179881 ,  0.00475994, -0.00158027,\n",
      "       -0.00303996, -0.02336371,  0.0080065 , -0.06040462, -0.00906723])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.26969491103221593)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2787621456396966\n",
      "DEBUG:shap:self.fx = 0.9108749999999999\n",
      "DEBUG:shap:self.link(self.fx) = 0.9108749999999999\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.0990622 , -0.00723436,  0.        ,  0.04552349,  0.00377688,\n",
      "        0.01599639,  0.05493628, -0.0179881 , -0.00475994,  0.00158027,\n",
      "        0.00303996,  0.02336371, -0.0080065 ,  0.06040462,  0.00906723])\n",
      " 78%|███████▊  | 58/74 [01:42<00:31,  1.96s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.14294750063140838)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.14500619325874411\n",
      "DEBUG:shap:self.fx = 0.22288095238095237\n",
      "DEBUG:shap:self.link(self.fx) = 0.22288095238095237\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.07087873, -0.001474  ,  0.00155728, -0.05911285,  0.00641241,\n",
      "        0.02020053,  0.03093094,  0.03997741, -0.01269803, -0.01315927,\n",
      "       -0.00800228, -0.01119219,  0.01468067, -0.08018939, -0.00205869])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1429475006314087)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.14500619325874442\n",
      "DEBUG:shap:self.fx = 0.7771190476190477\n",
      "DEBUG:shap:self.link(self.fx) = 0.7771190476190477\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.07087873,  0.001474  , -0.00155728,  0.05911285, -0.00641241,\n",
      "       -0.02020053, -0.03093094, -0.03997741,  0.01269803,  0.01315927,\n",
      "        0.00800228,  0.01119219, -0.01468067,  0.08018939,  0.00205869])\n",
      " 80%|███████▉  | 59/74 [01:43<00:28,  1.92s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17474796937378664)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.06027952102697026\n",
      "DEBUG:shap:self.fx = 0.42816666666666675\n",
      "DEBUG:shap:self.link(self.fx) = 0.42816666666666675\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.12062897, -0.00831372, -0.00316732,  0.04888024, -0.00722293,\n",
      "        0.01361785,  0.01070513,  0.03940605, -0.04486501,  0.00330341,\n",
      "        0.01598061, -0.00387976, -0.01032556, -0.11446845,  0.        ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17474796937378653)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.060279521026970095\n",
      "DEBUG:shap:self.fx = 0.5718333333333332\n",
      "DEBUG:shap:self.link(self.fx) = 0.5718333333333332\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.12062897,  0.00831372,  0.00316732, -0.04888024,  0.00722293,\n",
      "       -0.01361785, -0.01070513, -0.03940605,  0.04486501, -0.00330341,\n",
      "       -0.01598061,  0.00387976,  0.01032556,  0.11446845,  0.        ])\n",
      " 81%|████████  | 60/74 [01:45<00:26,  1.87s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5705771939984109)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5947795210269702\n",
      "DEBUG:shap:self.fx = 0.9626666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.9626666666666667\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.1962219 ,  0.01116404,  0.00790555,  0.09692793,  0.00674464,\n",
      "       -0.01201198,  0.03619564,  0.09368614,  0.01012337,  0.00229658,\n",
      "        0.01240207,  0.00940975,  0.03029419,  0.06921736,  0.02420233])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5705771939984108)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.59477952102697\n",
      "DEBUG:shap:self.fx = 0.037333333333333336\n",
      "DEBUG:shap:self.link(self.fx) = 0.037333333333333336\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.1962219 , -0.01116404, -0.00790555, -0.09692793, -0.00674464,\n",
      "        0.01201198, -0.03619564, -0.09368614, -0.01012337, -0.00229658,\n",
      "       -0.01240207, -0.00940975, -0.03029419, -0.06921736, -0.02420233])\n",
      " 82%|████████▏ | 61/74 [01:47<00:24,  1.87s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.02885765951868168)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.03285738373493452\n",
      "DEBUG:shap:self.fx = 0.33502976190476197\n",
      "DEBUG:shap:self.link(self.fx) = 0.33502976190476197\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.12061624,  0.06756382,  0.00588227, -0.05642622, -0.01983103,\n",
      "        0.02042601, -0.03182611,  0.02307555,  0.01164234,  0.02083947,\n",
      "        0.002294  ,  0.00608744,  0.02270644,  0.0193246 , -0.00399972])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.028857659518682167)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.032857383734934964\n",
      "DEBUG:shap:self.fx = 0.6649702380952383\n",
      "DEBUG:shap:self.link(self.fx) = 0.6649702380952383\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.12061624, -0.06756382, -0.00588227,  0.05642622,  0.01983103,\n",
      "       -0.02042601,  0.03182611, -0.02307555, -0.01164234, -0.02083947,\n",
      "       -0.002294  , -0.00608744, -0.02270644, -0.0193246 ,  0.00399972])\n",
      " 84%|████████▍ | 62/74 [01:49<00:22,  1.87s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.25317244787957094)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.26011333611588694\n",
      "DEBUG:shap:self.fx = 0.10777380952380952\n",
      "DEBUG:shap:self.link(self.fx) = 0.10777380952380952\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10870154, -0.0010631 ,  0.00598117, -0.06939858,  0.00377824,\n",
      "        0.01083111, -0.02495222, -0.02387097, -0.00233593, -0.0123719 ,\n",
      "        0.00762541, -0.00415313, -0.0079312 , -0.02660982, -0.00694089])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.253172447879571)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.26011333611588705\n",
      "DEBUG:shap:self.fx = 0.8922261904761903\n",
      "DEBUG:shap:self.link(self.fx) = 0.8922261904761903\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10870154,  0.0010631 , -0.00598117,  0.06939858, -0.00377824,\n",
      "       -0.01083111,  0.02495222,  0.02387097,  0.00233593,  0.0123719 ,\n",
      "       -0.00762541,  0.00415313,  0.0079312 ,  0.02660982,  0.00694089])\n",
      " 85%|████████▌ | 63/74 [01:51<00:20,  1.87s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.21854141095923935)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.17992881230636315\n",
      "DEBUG:shap:self.fx = 0.18795833333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.18795833333333334\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.09697995,  0.00671481,  0.00409711, -0.07138303, -0.00356781,\n",
      "       -0.00740073, -0.05834379,  0.05884585,  0.0019849 , -0.00802403,\n",
      "       -0.01802739, -0.0245271 ,  0.02328493, -0.02521518,  0.0386126 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.21854141095923976)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.17992881230636348\n",
      "DEBUG:shap:self.fx = 0.8120416666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.8120416666666668\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.09697995, -0.00671481, -0.00409711,  0.07138303,  0.00356781,\n",
      "        0.00740073,  0.05834379, -0.05884585, -0.0019849 ,  0.00802403,\n",
      "        0.01802739,  0.0245271 , -0.02328493,  0.02521518, -0.0386126 ])\n",
      " 86%|████████▋ | 64/74 [01:53<00:18,  1.83s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1874620902292916)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.20812524087779172\n",
      "DEBUG:shap:self.fx = 0.15976190476190477\n",
      "DEBUG:shap:self.link(self.fx) = 0.15976190476190477\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.07746434,  0.00694397, -0.01600907, -0.06049668,  0.01446416,\n",
      "        0.03769256,  0.00118786,  0.01106221, -0.00770649, -0.0157009 ,\n",
      "       -0.0078782 , -0.0430041 ,  0.02631324, -0.0568663 , -0.02066315])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.18746209022929186)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.20812524087779205\n",
      "DEBUG:shap:self.fx = 0.8402380952380953\n",
      "DEBUG:shap:self.link(self.fx) = 0.8402380952380953\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.07746434, -0.00694397,  0.01600907,  0.06049668, -0.01446416,\n",
      "       -0.03769256, -0.00118786, -0.01106221,  0.00770649,  0.0157009 ,\n",
      "        0.0078782 ,  0.0430041 , -0.02631324,  0.0568663 ,  0.02066315])\n",
      " 88%|████████▊ | 65/74 [01:54<00:16,  1.83s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2690938133041107)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2704823837349346\n",
      "DEBUG:shap:self.fx = 0.09740476190476191\n",
      "DEBUG:shap:self.link(self.fx) = 0.09740476190476191\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.09524745,  0.03523457,  0.00572241, -0.05738641, -0.01305745,\n",
      "       -0.00988409, -0.00352766, -0.03078213, -0.00456065, -0.01195111,\n",
      "       -0.01315816, -0.00919335, -0.00888334, -0.052419  , -0.00138857])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.26909381330411064)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2704823837349346\n",
      "DEBUG:shap:self.fx = 0.9025952380952379\n",
      "DEBUG:shap:self.link(self.fx) = 0.9025952380952379\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.09524745, -0.03523457, -0.00572241,  0.05738641,  0.01305745,\n",
      "        0.00988409,  0.00352766,  0.03078213,  0.00456065,  0.01195111,\n",
      "        0.01315816,  0.00919335,  0.00888334,  0.052419  ,  0.00138857])\n",
      " 89%|████████▉ | 66/74 [01:56<00:14,  1.82s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2418840378554108)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2433871456396965\n",
      "DEBUG:shap:self.fx = 0.1245\n",
      "DEBUG:shap:self.link(self.fx) = 0.1245\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.10913653, -0.01277941,  0.00656694, -0.04393236, -0.00389719,\n",
      "        0.01215014,  0.00683113, -0.02427728,  0.00553242, -0.0098554 ,\n",
      "       -0.00403536,  0.        , -0.00243217, -0.06261895, -0.00150311])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24188403785541093)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24338714563969666\n",
      "DEBUG:shap:self.fx = 0.8755\n",
      "DEBUG:shap:self.link(self.fx) = 0.8755\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.10913653,  0.01277941, -0.00656694,  0.04393236,  0.00389719,\n",
      "       -0.01215014, -0.00683113,  0.02427728, -0.00553242,  0.0098554 ,\n",
      "        0.00403536,  0.        ,  0.00243217,  0.06261895,  0.00150311])\n",
      " 91%|█████████ | 67/74 [01:58<00:12,  1.80s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20055610582032785)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21337524087779178\n",
      "DEBUG:shap:self.fx = 0.1545119047619047\n",
      "DEBUG:shap:self.link(self.fx) = 0.1545119047619047\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.07088115,  0.0190218 , -0.00280194, -0.05300059,  0.        ,\n",
      "        0.00824801, -0.0515807 ,  0.01566639, -0.01158077, -0.00687297,\n",
      "        0.01308305, -0.02089596, -0.00765498, -0.0313063 , -0.01281914])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20055610582032796)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21337524087779192\n",
      "DEBUG:shap:self.fx = 0.8454880952380952\n",
      "DEBUG:shap:self.link(self.fx) = 0.8454880952380952\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.07088115, -0.0190218 ,  0.00280194,  0.05300059,  0.        ,\n",
      "       -0.00824801,  0.0515807 , -0.01566639,  0.01158077,  0.00687297,\n",
      "       -0.01308305,  0.02089596,  0.00765498,  0.0313063 ,  0.01281914])\n",
      " 92%|█████████▏| 68/74 [02:00<00:10,  1.81s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.190827163711882)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.20233159008414092\n",
      "DEBUG:shap:self.fx = 0.16555555555555557\n",
      "DEBUG:shap:self.link(self.fx) = 0.16555555555555557\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.12756431,  0.0200487 ,  0.00496467, -0.05772061, -0.00081302,\n",
      "       -0.02099593, -0.06532205,  0.01581881,  0.00889848, -0.00119457,\n",
      "       -0.02415904,  0.03661191, -0.00695697,  0.02755677, -0.01150443])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1908271637118821)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.20233159008414103\n",
      "DEBUG:shap:self.fx = 0.8344444444444443\n",
      "DEBUG:shap:self.link(self.fx) = 0.8344444444444443\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.12756431, -0.0200487 , -0.00496467,  0.05772061,  0.00081302,\n",
      "        0.02099593,  0.06532205, -0.01581881, -0.00889848,  0.00119457,\n",
      "        0.02415904, -0.03661191,  0.00695697, -0.02755677,  0.01150443])\n",
      " 93%|█████████▎| 69/74 [02:02<00:09,  1.81s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2730628266442426)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.25522047897302985\n",
      "DEBUG:shap:self.fx = 0.11266666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.11266666666666665\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([-0.08749137,  0.02906351,  0.00553593, -0.05215298,  0.00070938,\n",
      "       -0.02495706, -0.03381998, -0.01870248, -0.01772658, -0.00882765,\n",
      "       -0.0131893 , -0.02095894,  0.01585403, -0.04639933,  0.01784235])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.27306282664424253)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2552204789730299\n",
      "DEBUG:shap:self.fx = 0.8873333333333332\n",
      "DEBUG:shap:self.link(self.fx) = 0.8873333333333332\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([ 0.08749137, -0.02906351, -0.00553593,  0.05215298, -0.00070938,\n",
      "        0.02495706,  0.03381998,  0.01870248,  0.01772658,  0.00882765,\n",
      "        0.0131893 ,  0.02095894, -0.01585403,  0.04639933, -0.01784235])\n",
      " 95%|█████████▍| 70/74 [02:03<00:07,  1.81s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3657410496055957)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3707973781698273\n",
      "DEBUG:shap:self.fx = 0.7386845238095238\n",
      "DEBUG:shap:self.link(self.fx) = 0.7386845238095238\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.15919139,  0.01944641, -0.01753382, -0.00246565, -0.00646043,\n",
      "        0.02125209,  0.02499897,  0.05073974, -0.00279691,  0.00393671,\n",
      "        0.01494359,  0.02499783,  0.02150295,  0.05398817,  0.00505633])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3657410496055956)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.37079737816982716\n",
      "DEBUG:shap:self.fx = 0.2613154761904761\n",
      "DEBUG:shap:self.link(self.fx) = 0.2613154761904761\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.15919139, -0.01944641,  0.01753382,  0.00246565,  0.00646043,\n",
      "       -0.02125209, -0.02499897, -0.05073974,  0.00279691, -0.00393671,\n",
      "       -0.01494359, -0.02499783, -0.02150295, -0.05398817, -0.00505633])\n",
      " 96%|█████████▌| 71/74 [02:05<00:05,  1.84s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5892584868069595)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5775533305507797\n",
      "DEBUG:shap:self.fx = 0.9454404761904762\n",
      "DEBUG:shap:self.link(self.fx) = 0.9454404761904762\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.20130892,  0.01268957,  0.00890214,  0.11094766,  0.00375937,\n",
      "        0.02509101,  0.03891993,  0.08572619,  0.01439903,  0.00070218,\n",
      "        0.0198462 ,  0.01148575,  0.00430736,  0.05117316, -0.01170516])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5892584868069591)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5775533305507795\n",
      "DEBUG:shap:self.fx = 0.05455952380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.05455952380952381\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.20130892, -0.01268957, -0.00890214, -0.11094766, -0.00375937,\n",
      "       -0.02509101, -0.03891993, -0.08572619, -0.01439903, -0.00070218,\n",
      "       -0.0198462 , -0.01148575, -0.00430736, -0.05117316,  0.01170516])\n",
      " 97%|█████████▋| 72/74 [02:07<00:03,  1.92s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0697083899535073)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.07726761626506545\n",
      "DEBUG:shap:self.fx = 0.44515476190476194\n",
      "DEBUG:shap:self.link(self.fx) = 0.44515476190476194\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.14197781,  0.00301533,  0.02306403,  0.08050626, -0.00179389,\n",
      "        0.00344875,  0.00867066, -0.0444417 , -0.0407534 ,  0.01226936,\n",
      "        0.00845389, -0.00366726, -0.01986195, -0.10117949,  0.00755923])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.06970838995350705)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.07726761626506518\n",
      "DEBUG:shap:self.fx = 0.5548452380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.5548452380952381\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.14197781, -0.00301533, -0.02306403, -0.08050626,  0.00179389,\n",
      "       -0.00344875, -0.00867066,  0.0444417 ,  0.0407534 , -0.01226936,\n",
      "       -0.00845389,  0.00366726,  0.01986195,  0.10117949, -0.00755923])\n",
      " 99%|█████████▊| 73/74 [02:09<00:01,  1.89s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.04455293952131627)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.035100949598398656\n",
      "DEBUG:shap:self.fx = 0.40298809523809515\n",
      "DEBUG:shap:self.link(self.fx) = 0.40298809523809515\n",
      "DEBUG:shap:self.fnull = 0.3678871456396965\n",
      "DEBUG:shap:self.link(self.fnull) = 0.3678871456396965\n",
      "INFO:shap:phi = array([ 0.14827449,  0.00504334,  0.00028469,  0.06441217, -0.0032201 ,\n",
      "       -0.01382358,  0.012368  , -0.04133082, -0.04449579, -0.00178417,\n",
      "        0.00930893, -0.00028105,  0.00085748, -0.09106064, -0.00945199])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.04455293952131631)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.0351009495983986\n",
      "DEBUG:shap:self.fx = 0.5970119047619047\n",
      "DEBUG:shap:self.link(self.fx) = 0.5970119047619047\n",
      "DEBUG:shap:self.fnull = 0.6321128543603033\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6321128543603033\n",
      "INFO:shap:phi = array([-0.14827449, -0.00504334, -0.00028469, -0.06441217,  0.0032201 ,\n",
      "        0.01382358, -0.012368  ,  0.04133082,  0.04449579,  0.00178417,\n",
      "       -0.00930893,  0.00028105, -0.00085748,  0.09106064,  0.00945199])\n",
      "100%|██████████| 74/74 [02:11<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8387096774193548,\n",
      "                0.7741935483870968,\n",
      "                0.7599399849962492,\n",
      "                0.7351837959489873,\n",
      "                0.6781695423855963,\n",
      "                0.6834208552138036,\n",
      "                0.5858964741185296,\n",
      "                0.5596399099774944,\n",
      "                0.5558889722430608,\n",
      "                0.4951237809452363,\n",
      "                0.4028507126781695,\n",
      "                0.46174043510877716,\n",
      "                0.4246061515378845,\n",
      "                0.41747936984246065,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5193068224943925,\n",
      "                0.5884276777641769,\n",
      "                0.606017463133041,\n",
      "                0.6769923018390795,\n",
      "                0.713251049802941,\n",
      "                0.777170066168812,\n",
      "                0.8097615528760742,\n",
      "                0.8325013104183201,\n",
      "                0.8454462470235794,\n",
      "                0.880687022675766,\n",
      "                0.8618255137513322,\n",
      "                0.8627240321533328,\n",
      "                0.8789419861761316,\n",
      "                0.8881107626199484,\n",
      "                0.8937715432763311\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.16720830628118008,\n",
      "                0.20064877500497325,\n",
      "                0.20862298219047065,\n",
      "                0.24276897776608453,\n",
      "                0.26001066333595496,\n",
      "                0.28937136524704976,\n",
      "                0.3037600035015351,\n",
      "                0.3140788994549396,\n",
      "                0.31916146808575163,\n",
      "                0.334362746881767,\n",
      "                0.3272903945763365,\n",
      "                0.32787975107537387,\n",
      "                0.3345552101040773,\n",
      "                0.33825577726387107,\n",
      "                0.3406323110321205\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.59152288072018,\n",
      "            \"cross_entropy\": 0.7756623568115507,\n",
      "            \"brier\": 0.2872405087867657\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8945986496624156,\n",
      "                0.8807201800450112,\n",
      "                0.9024756189047263,\n",
      "                0.9167291822955739,\n",
      "                0.9047261815453863,\n",
      "                0.9069767441860466,\n",
      "                0.9182295573893473,\n",
      "                0.9092273068267066,\n",
      "                0.8994748687171792,\n",
      "                0.9024756189047262,\n",
      "                0.9009752438109526,\n",
      "                0.891972993248312,\n",
      "                0.8942235558889722,\n",
      "                0.8987246811702926,\n",
      "                0.8994748687171792\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5339335987660522,\n",
      "                0.4644702556151713,\n",
      "                0.42012108956571426,\n",
      "                0.38370294811830236,\n",
      "                0.38350528284408963,\n",
      "                0.38379002741618,\n",
      "                0.3739531897443354,\n",
      "                0.37935897981210503,\n",
      "                0.38579319122015177,\n",
      "                0.39109098435741246,\n",
      "                0.39038645629215213,\n",
      "                0.4059026829970491,\n",
      "                0.40390593142719505,\n",
      "                0.4041106260777957,\n",
      "                0.40118807518577815\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17395977258876588,\n",
      "                0.14233368561447618,\n",
      "                0.1271685787310535,\n",
      "                0.11529523911652789,\n",
      "                0.1162465477795363,\n",
      "                0.11600668857275998,\n",
      "                0.11253308562957226,\n",
      "                0.11440429261501137,\n",
      "                0.11511658703687726,\n",
      "                0.11738495698531191,\n",
      "                0.11733943412805545,\n",
      "                0.1209865031782178,\n",
      "                0.12115912697505885,\n",
      "                0.12118795043758877,\n",
      "                0.11986653926437998\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.901400350087522,\n",
      "            \"cross_entropy\": 0.40701422129596565,\n",
      "            \"brier\": 0.12339926591021291\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/74 [00:00<?, ?it/s]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.042006284900791294)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08728100214417595\n",
      "DEBUG:shap:self.fx = 0.33379761904761907\n",
      "DEBUG:shap:self.link(self.fx) = 0.33379761904761907\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.11683146, -0.05823946,  0.00143906,  0.06335488, -0.00252588,\n",
      "        0.01271716,  0.02425497, -0.00115818,  0.01124938,  0.00172614,\n",
      "       -0.0072631 ,  0.00700997,  0.04579216, -0.02353192, -0.04527472])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.042006284900791536)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08728100214417622\n",
      "DEBUG:shap:self.fx = 0.666202380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.666202380952381\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.11683146,  0.05823946, -0.00143906, -0.06335488,  0.00252588,\n",
      "       -0.01271716, -0.02425497,  0.00115818, -0.01124938, -0.00172614,\n",
      "        0.0072631 , -0.00700997, -0.04579216,  0.02353192,  0.04527472])\n",
      "  1%|▏         | 1/74 [00:01<02:07,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17930704551875587)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.17249528785846174\n",
      "DEBUG:shap:self.fx = 0.24858333333333327\n",
      "DEBUG:shap:self.link(self.fx) = 0.24858333333333327\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.16096407,  0.06952013,  0.00596314, -0.07060762, -0.02080829,\n",
      "       -0.03354617, -0.00650694,  0.00679437,  0.00110779,  0.019595  ,\n",
      "       -0.02012026,  0.01133982,  0.00439875,  0.0145273 ,  0.00681176])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17930704551875593)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1724952878584618\n",
      "DEBUG:shap:self.fx = 0.7514166666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.7514166666666666\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.16096407, -0.06952013, -0.00596314,  0.07060762,  0.02080829,\n",
      "        0.03354617,  0.00650694, -0.00679437, -0.00110779, -0.019595  ,\n",
      "        0.02012026, -0.01133982, -0.00439875, -0.0145273 , -0.00681176])\n",
      "  3%|▎         | 2/74 [00:03<02:05,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17675112058596457)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.10571304547487165\n",
      "DEBUG:shap:self.fx = 0.5267916666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.5267916666666667\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.13114847,  0.00112956, -0.00344364,  0.07216041, -0.01242404,\n",
      "        0.01102873,  0.03701753, -0.0389457 ,  0.0085898 , -0.00976128,\n",
      "       -0.00210452, -0.01512283, -0.00060567, -0.00191568, -0.07103808])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17675112058596432)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.10571304547487148\n",
      "DEBUG:shap:self.fx = 0.47320833333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.47320833333333334\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.13114847, -0.00112956,  0.00344364, -0.07216041,  0.01242404,\n",
      "       -0.01102873, -0.03701753,  0.0389457 , -0.0085898 ,  0.00976128,\n",
      "        0.00210452,  0.01512283,  0.00060567,  0.00191568,  0.07103808])\n",
      "  4%|▍         | 3/74 [00:05<02:04,  1.75s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3217262176104461)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.36523523750385717\n",
      "DEBUG:shap:self.fx = 0.7863138586956522\n",
      "DEBUG:shap:self.link(self.fx) = 0.7863138586956522\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.17141308,  0.00720122,  0.01010406,  0.05687273,  0.00055691,\n",
      "        0.01180484, -0.02843057, -0.03793618,  0.00772817,  0.01564143,\n",
      "        0.0092746 ,  0.00357381,  0.01116419,  0.08275792,  0.04350902])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.32172621761044595)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.365235237503857\n",
      "DEBUG:shap:self.fx = 0.21368614130434782\n",
      "DEBUG:shap:self.link(self.fx) = 0.21368614130434782\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.17141308, -0.00720122, -0.01010406, -0.05687273, -0.00055691,\n",
      "       -0.01180484,  0.02843057,  0.03793618, -0.00772817, -0.01564143,\n",
      "       -0.0092746 , -0.00357381, -0.01116419, -0.08275792, -0.04350902])\n",
      "  5%|▌         | 4/74 [00:06<02:01,  1.74s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.27897473989693705)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2754833830965569\n",
      "DEBUG:shap:self.fx = 0.1455952380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.1455952380952381\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.13271103,  0.05161686,  0.00556872, -0.05065891,  0.00439418,\n",
      "       -0.00823598,  0.00076362, -0.03162368, -0.03604621, -0.00529991,\n",
      "       -0.01518018, -0.01198577,  0.01597823, -0.06555469,  0.00349136])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.27897473989693705)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.27548338309655696\n",
      "DEBUG:shap:self.fx = 0.8544047619047618\n",
      "DEBUG:shap:self.link(self.fx) = 0.8544047619047618\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.13271103, -0.05161686, -0.00556872,  0.05065891, -0.00439418,\n",
      "        0.00823598, -0.00076362,  0.03162368,  0.03604621,  0.00529991,\n",
      "        0.01518018,  0.01198577, -0.01597823,  0.06555469, -0.00349136])\n",
      "  7%|▋         | 5/74 [00:08<02:02,  1.77s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1930045167277554)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1841545140489378\n",
      "DEBUG:shap:self.fx = 0.23692410714285722\n",
      "DEBUG:shap:self.link(self.fx) = 0.23692410714285722\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.09889992,  0.062859  ,  0.00082185, -0.04022744, -0.02035722,\n",
      "       -0.02160141, -0.06307047, -0.02053113, -0.00535337,  0.01228619,\n",
      "       -0.01626052,  0.00416726,  0.00512397,  0.00803869,  0.00885   ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19300451672775557)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.184154514048938\n",
      "DEBUG:shap:self.fx = 0.7630758928571428\n",
      "DEBUG:shap:self.link(self.fx) = 0.7630758928571428\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.09889992, -0.062859  , -0.00082185,  0.04022744,  0.02035722,\n",
      "        0.02160141,  0.06307047,  0.02053113,  0.00535337, -0.01228619,\n",
      "        0.01626052, -0.00416726, -0.00512397, -0.00803869, -0.00885   ])\n",
      "  8%|▊         | 6/74 [00:10<02:08,  1.89s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.28622869823101815)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.32383010928703315\n",
      "DEBUG:shap:self.fx = 0.09724851190476189\n",
      "DEBUG:shap:self.link(self.fx) = 0.09724851190476189\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.13970959, -0.00880064, -0.00121791, -0.05019748, -0.01327698,\n",
      "        0.00250551, -0.04513387, -0.03487562, -0.00124687,  0.02300895,\n",
      "        0.01513167,  0.00588674, -0.00109964, -0.03720298, -0.03760141])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.28622869823101815)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.32383010928703326\n",
      "DEBUG:shap:self.fx = 0.9027514880952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.9027514880952381\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.13970959,  0.00880064,  0.00121791,  0.05019748,  0.01327698,\n",
      "       -0.00250551,  0.04513387,  0.03487562,  0.00124687, -0.02300895,\n",
      "       -0.01513167, -0.00588674,  0.00109964,  0.03720298,  0.03760141])\n",
      "  9%|▉         | 7/74 [00:12<02:08,  1.92s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19636240902713548)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13414112119179505\n",
      "DEBUG:shap:self.fx = 0.28693749999999996\n",
      "DEBUG:shap:self.link(self.fx) = 0.28693749999999996\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.14667499,  0.02006982, -0.00788852, -0.04327511, -0.00195262,\n",
      "       -0.0107396 ,  0.01294415, -0.03137801, -0.02902791,  0.00596687,\n",
      "        0.00855728,  0.01578989,  0.00901209,  0.00223425,  0.06222129])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1963624090271355)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1341411211917951\n",
      "DEBUG:shap:self.fx = 0.7130624999999999\n",
      "DEBUG:shap:self.link(self.fx) = 0.7130624999999999\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.14667499, -0.02006982,  0.00788852,  0.04327511,  0.00195262,\n",
      "        0.0107396 , -0.01294415,  0.03137801,  0.02902791, -0.00596687,\n",
      "       -0.00855728, -0.01578989, -0.00901209, -0.00223425, -0.06222129])\n",
      " 11%|█         | 8/74 [00:14<02:05,  1.90s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2626121605421772)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2558643354775093\n",
      "DEBUG:shap:self.fx = 0.16521428571428573\n",
      "DEBUG:shap:self.link(self.fx) = 0.16521428571428573\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.13055667, -0.00468673, -0.00690398, -0.08500871,  0.0020847 ,\n",
      "        0.01171007,  0.03377339,  0.00219474,  0.        , -0.00466661,\n",
      "       -0.01036219, -0.01772391,  0.00294575, -0.05541201,  0.00674783])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.26261216054217723)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2558643354775094\n",
      "DEBUG:shap:self.fx = 0.8347857142857142\n",
      "DEBUG:shap:self.link(self.fx) = 0.8347857142857142\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.13055667,  0.00468673,  0.00690398,  0.08500871, -0.0020847 ,\n",
      "       -0.01171007, -0.03377339, -0.00219474,  0.        ,  0.00466661,\n",
      "        0.01036219,  0.01772391, -0.00294575,  0.05541201, -0.00674783])\n",
      " 12%|█▏        | 9/74 [00:16<01:58,  1.82s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.08659168457306265)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.11709945452512832\n",
      "DEBUG:shap:self.fx = 0.3039791666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.3039791666666667\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.1438444 , -0.00214844, -0.00564389, -0.0429493 ,  0.00376693,\n",
      "        0.02110194,  0.02703589, -0.03550706, -0.02135405,  0.02915324,\n",
      "        0.00317708,  0.00523968,  0.01206103,  0.06331966, -0.03050777])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.08659168457306274)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.11709945452512849\n",
      "DEBUG:shap:self.fx = 0.6960208333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.6960208333333333\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.1438444 ,  0.00214844,  0.00564389,  0.0429493 , -0.00376693,\n",
      "       -0.02110194, -0.02703589,  0.03550706,  0.02135405, -0.02915324,\n",
      "       -0.00317708, -0.00523968, -0.01206103, -0.06331966,  0.03050777])\n",
      " 14%|█▎        | 10/74 [00:18<01:53,  1.77s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4058228485390034)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.40933804547487157\n",
      "DEBUG:shap:self.fx = 0.8304166666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.8304166666666666\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.19968176,  0.02036103,  0.00291673,  0.07726562,  0.00083778,\n",
      "       -0.01688952,  0.0053944 ,  0.09114633,  0.00571092,  0.00834487,\n",
      "       -0.02611078,  0.00612741,  0.01723211,  0.0138042 ,  0.0035152 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.40582284853900336)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.40933804547487146\n",
      "DEBUG:shap:self.fx = 0.16958333333333336\n",
      "DEBUG:shap:self.link(self.fx) = 0.16958333333333336\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.19968176, -0.02036103, -0.00291673, -0.07726562, -0.00083778,\n",
      "        0.01688952, -0.0053944 , -0.09114633, -0.00571092, -0.00834487,\n",
      "        0.02611078, -0.00612741, -0.01723211, -0.0138042 , -0.0035152 ])\n",
      " 15%|█▍        | 11/74 [00:19<01:52,  1.79s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23675397295150444)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.16423338309655688\n",
      "DEBUG:shap:self.fx = 0.2568452380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.2568452380952381\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.14098089,  0.01555547,  0.00406925, -0.04804892, -0.00232582,\n",
      "       -0.01100032, -0.03117065, -0.03849078,  0.00120524,  0.00378804,\n",
      "        0.00676626,  0.00108383,  0.01421637, -0.01142106,  0.07252059])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23675397295150447)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16423338309655688\n",
      "DEBUG:shap:self.fx = 0.7431547619047617\n",
      "DEBUG:shap:self.link(self.fx) = 0.7431547619047617\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.14098089, -0.01555547, -0.00406925,  0.04804892,  0.00232582,\n",
      "        0.01100032,  0.03117065,  0.03849078, -0.00120524, -0.00378804,\n",
      "       -0.00676626, -0.00108383, -0.01421637,  0.01142106, -0.07252059])\n",
      " 16%|█▌        | 12/74 [00:21<01:50,  1.78s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.04398290995061981)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.05381374023941404\n",
      "DEBUG:shap:self.fx = 0.36726488095238097\n",
      "DEBUG:shap:self.link(self.fx) = 0.36726488095238097\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.10000159,  0.01037869, -0.00349672,  0.07422328, -0.00228085,\n",
      "        0.00963601,  0.03440521, -0.00149429, -0.04555502, -0.00253773,\n",
      "        0.01631907,  0.00507341,  0.01093843, -0.04959079, -0.00983083])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.04398290995062011)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.05381374023941432\n",
      "DEBUG:shap:self.fx = 0.6327351190476191\n",
      "DEBUG:shap:self.link(self.fx) = 0.6327351190476191\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.10000159, -0.01037869,  0.00349672, -0.07422328,  0.00228085,\n",
      "       -0.00963601, -0.03440521,  0.00149429,  0.04555502,  0.00253773,\n",
      "       -0.01631907, -0.00507341, -0.01093843,  0.04959079,  0.00983083])\n",
      " 18%|█▊        | 13/74 [00:23<01:48,  1.77s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.527364593453495)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5487547121415384\n",
      "DEBUG:shap:self.fx = 0.9698333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.9698333333333333\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.19379387,  0.02114315,  0.01116354,  0.07074096,  0.00894846,\n",
      "        0.00681141,  0.05173948,  0.0722043 , -0.00428377, -0.0064055 ,\n",
      "        0.00588367,  0.01189622,  0.00871011,  0.07501869,  0.02139012])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5273645934534948)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5487547121415381\n",
      "DEBUG:shap:self.fx = 0.030166666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.030166666666666665\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.19379387, -0.02114315, -0.01116354, -0.07074096, -0.00894846,\n",
      "       -0.00681141, -0.05173948, -0.0722043 ,  0.00428377,  0.0064055 ,\n",
      "       -0.00588367, -0.01189622, -0.00871011, -0.07501869, -0.02139012])\n",
      " 19%|█▉        | 14/74 [00:25<01:50,  1.85s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.42449232038130885)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4354516818385081\n",
      "DEBUG:shap:self.fx = 0.8565303030303031\n",
      "DEBUG:shap:self.link(self.fx) = 0.8565303030303031\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.20264604,  0.0220788 ,  0.00592637,  0.05665375,  0.01316099,\n",
      "       -0.00524779,  0.04559626,  0.10055836, -0.03385693, -0.00485793,\n",
      "        0.01329952, -0.01019179,  0.00312331,  0.01560336,  0.01095936])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.42449232038130874)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.43545168183850785\n",
      "DEBUG:shap:self.fx = 0.14346969696969697\n",
      "DEBUG:shap:self.link(self.fx) = 0.14346969696969697\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.20264604, -0.0220788 , -0.00592637, -0.05665375, -0.01316099,\n",
      "        0.00524779, -0.04559626, -0.10055836,  0.03385693,  0.00485793,\n",
      "       -0.01329952,  0.01019179, -0.00312331, -0.01560336, -0.01095936])\n",
      " 20%|██        | 15/74 [00:27<01:54,  1.95s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.24007653069856183)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.286373134649352\n",
      "DEBUG:shap:self.fx = 0.13470548654244305\n",
      "DEBUG:shap:self.link(self.fx) = 0.13470548654244305\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.13632708,  0.03851048, -0.00395688, -0.06401009,  0.01216499,\n",
      "       -0.01079084, -0.05433711, -0.00505682, -0.00160008,  0.0139786 ,\n",
      "        0.00460422, -0.01141393, -0.00137986, -0.02046213, -0.0462966 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24007653069856189)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2863731346493521\n",
      "DEBUG:shap:self.fx = 0.8652945134575569\n",
      "DEBUG:shap:self.link(self.fx) = 0.8652945134575569\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.13632708, -0.03851048,  0.00395688,  0.06401009, -0.01216499,\n",
      "        0.01079084,  0.05433711,  0.00505682,  0.00160008, -0.0139786 ,\n",
      "       -0.00460422,  0.01141393,  0.00137986,  0.02046213,  0.0462966 ])\n",
      " 22%|██▏       | 16/74 [00:29<02:00,  2.08s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.48189954907699345)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.41817137880820493\n",
      "DEBUG:shap:self.fx = 0.8392499999999999\n",
      "DEBUG:shap:self.link(self.fx) = 0.8392499999999999\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.19783551,  0.02273942,  0.00810735,  0.07158033,  0.00823977,\n",
      "       -0.01351892,  0.04841635,  0.04268516,  0.00401523,  0.01037573,\n",
      "        0.00398367,  0.00320583,  0.01023456,  0.06399955, -0.06372817])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4818995490769933)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.41817137880820476\n",
      "DEBUG:shap:self.fx = 0.16075000000000003\n",
      "DEBUG:shap:self.link(self.fx) = 0.16075000000000003\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.19783551, -0.02273942, -0.00810735, -0.07158033, -0.00823977,\n",
      "        0.01351892, -0.04841635, -0.04268516, -0.00401523, -0.01037573,\n",
      "       -0.00398367, -0.00320583, -0.01023456, -0.06399955,  0.06372817])\n",
      " 23%|██▎       | 17/74 [00:32<02:02,  2.15s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.07477205028641969)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.017292906906080818\n",
      "DEBUG:shap:self.fx = 0.4037857142857142\n",
      "DEBUG:shap:self.link(self.fx) = 0.4037857142857142\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.15041842,  0.02754323,  0.0003324 , -0.05279498,  0.0099133 ,\n",
      "        0.00955015,  0.032874  ,  0.0621254 ,  0.00267561, -0.00810151,\n",
      "        0.01006315,  0.0283764 ,  0.0153057 , -0.06221649,  0.05747914])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.07477205028641998)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.017292906906080985\n",
      "DEBUG:shap:self.fx = 0.5962142857142858\n",
      "DEBUG:shap:self.link(self.fx) = 0.5962142857142858\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.15041842, -0.02754323, -0.0003324 ,  0.05279498, -0.0099133 ,\n",
      "       -0.00955015, -0.032874  , -0.0621254 , -0.00267561,  0.00810151,\n",
      "       -0.01006315, -0.0283764 , -0.0153057 ,  0.06221649, -0.05747914])\n",
      " 24%|██▍       | 18/74 [00:34<02:02,  2.19s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.29836358496876225)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.31378732083719046\n",
      "DEBUG:shap:self.fx = 0.7348659420289855\n",
      "DEBUG:shap:self.link(self.fx) = 0.7348659420289855\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.18502286,  0.03076925, -0.00906492,  0.05767767, -0.00899085,\n",
      "        0.01493908,  0.03135818, -0.00989734, -0.02836805, -0.01420567,\n",
      "       -0.005035  , -0.00746585,  0.01310959,  0.04851465,  0.01542374])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2983635849687621)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.31378732083719035\n",
      "DEBUG:shap:self.fx = 0.26513405797101447\n",
      "DEBUG:shap:self.link(self.fx) = 0.26513405797101447\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.18502286, -0.03076925,  0.00906492, -0.05767767,  0.00899085,\n",
      "       -0.01493908, -0.03135818,  0.00989734,  0.02836805,  0.01420567,\n",
      "        0.005035  ,  0.00746585, -0.01310959, -0.04851465, -0.01542374])\n",
      " 26%|██▌       | 19/74 [00:36<02:04,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.25980630496884344)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21218874023941403\n",
      "DEBUG:shap:self.fx = 0.20888988095238098\n",
      "DEBUG:shap:self.link(self.fx) = 0.20888988095238098\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.11428129, -0.06533883, -0.00614862,  0.00824766, -0.00205185,\n",
      "       -0.00940416,  0.00670837, -0.06450328,  0.00281796,  0.02172407,\n",
      "       -0.00400049,  0.00228672, -0.00711854, -0.02874402,  0.04761756])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.25980630496884377)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21218874023941425\n",
      "DEBUG:shap:self.fx = 0.7911101190476191\n",
      "DEBUG:shap:self.link(self.fx) = 0.7911101190476191\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.11428129,  0.06533883,  0.00614862, -0.00824766,  0.00205185,\n",
      "        0.00940416, -0.00670837,  0.06450328, -0.00281796, -0.02172407,\n",
      "        0.00400049, -0.00228672,  0.00711854,  0.02874402, -0.04761756])\n",
      " 27%|██▋       | 20/74 [00:39<02:03,  2.30s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2663120483913403)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2719952878584616\n",
      "DEBUG:shap:self.fx = 0.14908333333333337\n",
      "DEBUG:shap:self.link(self.fx) = 0.14908333333333337\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.15093697, -0.00761291,  0.00178869, -0.05469906, -0.00466332,\n",
      "       -0.01353889,  0.02839671, -0.0382057 , -0.01745102,  0.02357597,\n",
      "        0.01403144,  0.00935708,  0.00408148, -0.06043556, -0.00568324])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.26631204839134076)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.27199528785846205\n",
      "DEBUG:shap:self.fx = 0.8509166666666669\n",
      "DEBUG:shap:self.link(self.fx) = 0.8509166666666669\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.15093697,  0.00761291, -0.00178869,  0.05469906,  0.00466332,\n",
      "        0.01353889, -0.02839671,  0.0382057 ,  0.01745102, -0.02357597,\n",
      "       -0.01403144, -0.00935708, -0.00408148,  0.06043556,  0.00568324])\n",
      " 28%|██▊       | 21/74 [00:41<02:03,  2.32s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2279024326761549)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2165880454748716\n",
      "DEBUG:shap:self.fx = 0.6376666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.6376666666666666\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.18943569,  0.02721153, -0.00855701,  0.05777076,  0.00861218,\n",
      "       -0.01512262,  0.04055907, -0.04369099, -0.05108823,  0.00376642,\n",
      "       -0.00954738,  0.01013264,  0.01197918,  0.00644119, -0.01131439])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22790243267615465)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21658804547487148\n",
      "DEBUG:shap:self.fx = 0.36233333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.36233333333333334\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.18943569, -0.02721153,  0.00855701, -0.05777076, -0.00861218,\n",
      "        0.01512262, -0.04055907,  0.04369099,  0.05108823, -0.00376642,\n",
      "        0.00954738, -0.01013264, -0.01197918, -0.00644119,  0.01131439])\n",
      " 30%|██▉       | 22/74 [00:44<02:01,  2.33s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.44671226367374756)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4566297121415383\n",
      "DEBUG:shap:self.fx = 0.8777083333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.8777083333333333\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.17761589,  0.01946737, -0.0171291 ,  0.05883485,  0.01621438,\n",
      "        0.00705037,  0.04594846,  0.07396106, -0.02992283, -0.0021531 ,\n",
      "       -0.00666321,  0.00850973,  0.02509342,  0.06988498,  0.00991745])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.44671226367374745)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.45662971214153814\n",
      "DEBUG:shap:self.fx = 0.12229166666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.12229166666666667\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.17761589, -0.01946737,  0.0171291 , -0.05883485, -0.01621438,\n",
      "       -0.00705037, -0.04594846, -0.07396106,  0.02992283,  0.0021531 ,\n",
      "        0.00666321, -0.00850973, -0.02509342, -0.06988498, -0.00991745])\n",
      " 31%|███       | 23/74 [00:46<01:58,  2.33s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.13139339893890542)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13915600214417595\n",
      "DEBUG:shap:self.fx = 0.28192261904761906\n",
      "DEBUG:shap:self.link(self.fx) = 0.28192261904761906\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.11250918,  0.01721925, -0.00841276,  0.04684757,  0.0024478 ,\n",
      "       -0.0022794 ,  0.02547966, -0.03540223, -0.01621301,  0.02336475,\n",
      "       -0.02372323, -0.01992295, -0.01284286, -0.01544679, -0.0077626 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.13139339893890575)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.13915600214417623\n",
      "DEBUG:shap:self.fx = 0.718077380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.718077380952381\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.11250918, -0.01721925,  0.00841276, -0.04684757, -0.0024478 ,\n",
      "        0.0022794 , -0.02547966,  0.03540223,  0.01621301, -0.02336475,\n",
      "        0.02372323,  0.01992295,  0.01284286,  0.01544679,  0.0077626 ])\n",
      " 32%|███▏      | 24/74 [00:48<01:57,  2.35s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17959543644225592)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.17806315958177926\n",
      "DEBUG:shap:self.fx = 0.5991417807735743\n",
      "DEBUG:shap:self.link(self.fx) = 0.5991417807735743\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 1.88904138e-01,  3.34714129e-03,  5.43192297e-04, -3.58513895e-03,\n",
      "        1.83491216e-04,  1.09604349e-02,  3.47616493e-02, -4.12263893e-02,\n",
      "        1.16230240e-02,  1.19131474e-02,  1.07133787e-02, -1.66811895e-02,\n",
      "        1.22538398e-02, -4.41152829e-02, -1.53227686e-03])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17959543644225578)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.17806315958177904\n",
      "DEBUG:shap:self.fx = 0.4008582192264258\n",
      "DEBUG:shap:self.link(self.fx) = 0.4008582192264258\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-1.88904138e-01, -3.34714129e-03, -5.43192297e-04,  3.58513895e-03,\n",
      "       -1.83491216e-04, -1.09604349e-02, -3.47616493e-02,  4.12263893e-02,\n",
      "       -1.16230240e-02, -1.19131474e-02, -1.07133787e-02,  1.66811895e-02,\n",
      "       -1.22538398e-02,  4.41152829e-02,  1.53227686e-03])\n",
      " 34%|███▍      | 25/74 [00:51<01:54,  2.35s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23026705635645336)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.27728695452512836\n",
      "DEBUG:shap:self.fx = 0.14379166666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.14379166666666665\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.08812444,  0.04306767, -0.01124302, -0.07223436,  0.00972052,\n",
      "        0.00381232, -0.06675474,  0.00233505, -0.02460644,  0.00155773,\n",
      "        0.01198738, -0.01731176,  0.00257468, -0.02504765, -0.0470199 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23026705635645334)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2772869545251284\n",
      "DEBUG:shap:self.fx = 0.8562083333333332\n",
      "DEBUG:shap:self.link(self.fx) = 0.8562083333333332\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.08812444, -0.04306767,  0.01124302,  0.07223436, -0.00972052,\n",
      "       -0.00381232,  0.06675474, -0.00233505,  0.02460644, -0.00155773,\n",
      "       -0.01198738,  0.01731176, -0.00257468,  0.02504765,  0.0470199 ])\n",
      " 35%|███▌      | 26/74 [00:53<01:52,  2.34s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.035121969158656785)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.07837028785846173\n",
      "DEBUG:shap:self.fx = 0.3427083333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.3427083333333333\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.14622904,  0.01143541,  0.        ,  0.06853816,  0.00373755,\n",
      "       -0.00686302,  0.03076875, -0.04147482,  0.00327173,  0.0065826 ,\n",
      "       -0.00827962, -0.01743129,  0.01066133,  0.05016028, -0.04324832])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03512196915865689)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.07837028785846178\n",
      "DEBUG:shap:self.fx = 0.6572916666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.6572916666666666\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.14622904, -0.01143541,  0.        , -0.06853816, -0.00373755,\n",
      "        0.00686302, -0.03076875,  0.04147482, -0.00327173, -0.0065826 ,\n",
      "        0.00827962,  0.01743129, -0.01066133, -0.05016028,  0.04324832])\n",
      " 36%|███▋      | 27/74 [00:55<01:46,  2.26s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1222244680884382)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08646498482815868\n",
      "DEBUG:shap:self.fx = 0.33461363636363634\n",
      "DEBUG:shap:self.link(self.fx) = 0.33461363636363634\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.12561845, -0.01806174, -0.00553573,  0.0172619 ,  0.00206397,\n",
      "       -0.00613108, -0.06385919, -0.04072928, -0.02409853, -0.00181564,\n",
      "        0.01249965, -0.00638113, -0.01761515, -0.09544097,  0.03575948])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12222446808843834)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08646498482815879\n",
      "DEBUG:shap:self.fx = 0.6653863636363636\n",
      "DEBUG:shap:self.link(self.fx) = 0.6653863636363636\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.12561845,  0.01806174,  0.00553573, -0.0172619 , -0.00206397,\n",
      "        0.00613108,  0.06385919,  0.04072928,  0.02409853,  0.00181564,\n",
      "       -0.01249965,  0.00638113,  0.01761515,  0.09544097, -0.03575948])\n",
      " 38%|███▊      | 28/74 [00:57<01:45,  2.30s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.11826171680860752)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1440280259536998\n",
      "DEBUG:shap:self.fx = 0.2770505952380952\n",
      "DEBUG:shap:self.link(self.fx) = 0.2770505952380952\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.08372057,  0.00286965,  0.00449694,  0.0587573 ,  0.00158836,\n",
      "       -0.00900857,  0.02169126, -0.05077541, -0.01629297, -0.00042561,\n",
      "        0.00925026, -0.01608263,  0.00794329, -0.04855302, -0.02576631])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.11826171680860782)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.14402802595370012\n",
      "DEBUG:shap:self.fx = 0.722949404761905\n",
      "DEBUG:shap:self.link(self.fx) = 0.722949404761905\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.08372057, -0.00286965, -0.00449694, -0.0587573 , -0.00158836,\n",
      "        0.00900857, -0.02169126,  0.05077541,  0.01629297,  0.00042561,\n",
      "       -0.00925026,  0.01608263, -0.00794329,  0.04855302,  0.02576631])\n",
      " 39%|███▉      | 29/74 [01:00<01:43,  2.31s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3676363921070047)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.36567137880820494\n",
      "DEBUG:shap:self.fx = 0.78675\n",
      "DEBUG:shap:self.link(self.fx) = 0.78675\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.20039071, -0.07947514, -0.01151029,  0.05840315,  0.00633095,\n",
      "       -0.00286925,  0.04009368,  0.0408563 ,  0.00184161,  0.01358499,\n",
      "        0.00898334,  0.00656581, -0.00222646,  0.086667  , -0.00196501])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.36763639210700455)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3656713788082048\n",
      "DEBUG:shap:self.fx = 0.21325000000000005\n",
      "DEBUG:shap:self.link(self.fx) = 0.21325000000000005\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.20039071,  0.07947514,  0.01151029, -0.05840315, -0.00633095,\n",
      "        0.00286925, -0.04009368, -0.0408563 , -0.00184161, -0.01358499,\n",
      "       -0.00898334, -0.00656581,  0.00222646, -0.086667  ,  0.00196501])\n",
      " 41%|████      | 30/74 [01:02<01:42,  2.33s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17052421327912198)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.16366195452512833\n",
      "DEBUG:shap:self.fx = 0.2574166666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.2574166666666667\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.10554506, -0.00128048,  0.00652721,  0.02484388,  0.0024343 ,\n",
      "       -0.00638984, -0.02914536, -0.03712619, -0.01193508, -0.01362173,\n",
      "        0.0032482 , -0.01177296, -0.00151943,  0.0107583 ,  0.00686226])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17052421327912234)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16366195452512877\n",
      "DEBUG:shap:self.fx = 0.7425833333333336\n",
      "DEBUG:shap:self.link(self.fx) = 0.7425833333333336\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.10554506,  0.00128048, -0.00652721, -0.02484388, -0.0024343 ,\n",
      "        0.00638984,  0.02914536,  0.03712619,  0.01193508,  0.01362173,\n",
      "       -0.0032482 ,  0.01177296,  0.00151943, -0.0107583 , -0.00686226])\n",
      " 42%|████▏     | 31/74 [01:05<01:41,  2.35s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20482501741273657)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.24084052595369979\n",
      "DEBUG:shap:self.fx = 0.18023809523809523\n",
      "DEBUG:shap:self.link(self.fx) = 0.18023809523809523\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.12093498,  0.02617696, -0.0106884 , -0.05047572,  0.02420045,\n",
      "       -0.00739149, -0.04907117, -0.01794389, -0.01425025,  0.00391283,\n",
      "       -0.00909544, -0.01255526, -0.00332535,  0.0366167 , -0.03601551])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20482501741273687)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2408405259537001\n",
      "DEBUG:shap:self.fx = 0.8197619047619049\n",
      "DEBUG:shap:self.link(self.fx) = 0.8197619047619049\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.12093498, -0.02617696,  0.0106884 ,  0.05047572, -0.02420045,\n",
      "        0.00739149,  0.04907117,  0.01794389,  0.01425025, -0.00391283,\n",
      "        0.00909544,  0.01255526,  0.00332535, -0.0366167 ,  0.03601551])\n",
      " 43%|████▎     | 32/74 [01:07<01:40,  2.39s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.24710080719794789)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2553820632207805\n",
      "DEBUG:shap:self.fx = 0.1656965579710145\n",
      "DEBUG:shap:self.link(self.fx) = 0.1656965579710145\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.14831966, -0.01133082,  0.00310921, -0.05290393,  0.01868848,\n",
      "        0.00848596,  0.03418009, -0.03742745, -0.02928029, -0.0200204 ,\n",
      "        0.00652314, -0.00094577, -0.01340832, -0.00445105, -0.00828126])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24710080719794802)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2553820632207807\n",
      "DEBUG:shap:self.fx = 0.8343034420289855\n",
      "DEBUG:shap:self.link(self.fx) = 0.8343034420289855\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.14831966,  0.01133082, -0.00310921,  0.05290393, -0.01868848,\n",
      "       -0.00848596, -0.03418009,  0.03742745,  0.02928029,  0.0200204 ,\n",
      "       -0.00652314,  0.00094577,  0.01340832,  0.00445105,  0.00828126])\n",
      " 45%|████▍     | 33/74 [01:10<01:38,  2.41s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19709069015712066)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1480880454748717\n",
      "DEBUG:shap:self.fx = 0.5691666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.5691666666666667\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.15743356, -0.06001993,  0.0103098 ,  0.03878561, -0.00851538,\n",
      "        0.01444163,  0.02429813, -0.03950558, -0.03652537,  0.02627872,\n",
      "       -0.00418955,  0.00596562, -0.00608006,  0.07441348, -0.04900264])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19709069015712055)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1480880454748716\n",
      "DEBUG:shap:self.fx = 0.43083333333333323\n",
      "DEBUG:shap:self.link(self.fx) = 0.43083333333333323\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.15743356,  0.06001993, -0.0103098 , -0.03878561,  0.00851538,\n",
      "       -0.01444163, -0.02429813,  0.03950558,  0.03652537, -0.02627872,\n",
      "        0.00418955, -0.00596562,  0.00608006, -0.07441348,  0.04900264])\n",
      " 46%|████▌     | 34/74 [01:12<01:34,  2.37s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20928798811565355)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13694469262036646\n",
      "DEBUG:shap:self.fx = 0.28413392857142855\n",
      "DEBUG:shap:self.link(self.fx) = 0.28413392857142855\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.15049363,  0.02557217, -0.00310877, -0.04223792,  0.00570533,\n",
      "       -0.00906752,  0.02106315, -0.03314731, -0.03549289,  0.00283443,\n",
      "        0.00241214,  0.01152566, -0.00853515,  0.00368231,  0.0723433 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20928798811565347)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.13694469262036635\n",
      "DEBUG:shap:self.fx = 0.7158660714285712\n",
      "DEBUG:shap:self.link(self.fx) = 0.7158660714285712\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.15049363, -0.02557217,  0.00310877,  0.04223792, -0.00570533,\n",
      "        0.00906752, -0.02106315,  0.03314731,  0.03549289, -0.00283443,\n",
      "       -0.00241214, -0.01152566,  0.00853515, -0.00368231, -0.0723433 ])\n",
      " 47%|████▋     | 35/74 [01:14<01:32,  2.38s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.28556036289550946)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.25607862119179503\n",
      "DEBUG:shap:self.fx = 0.165\n",
      "DEBUG:shap:self.link(self.fx) = 0.165\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.10575748,  0.04636035, -0.00174555, -0.04902906, -0.00824076,\n",
      "       -0.01668377, -0.04436838, -0.02408277, -0.03193326, -0.00904201,\n",
      "       -0.00903352, -0.0088917 ,  0.0226306 , -0.04574304,  0.02948174])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.28556036289550946)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.25607862119179503\n",
      "DEBUG:shap:self.fx = 0.8349999999999999\n",
      "DEBUG:shap:self.link(self.fx) = 0.8349999999999999\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.10575748, -0.04636035,  0.00174555,  0.04902906,  0.00824076,\n",
      "        0.01668377,  0.04436838,  0.02408277,  0.03193326,  0.00904201,\n",
      "        0.00903352,  0.0088917 , -0.0226306 ,  0.04574304, -0.02948174])\n",
      " 49%|████▊     | 36/74 [01:17<01:31,  2.41s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.08109773423829111)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08417137880820486\n",
      "DEBUG:shap:self.fx = 0.5052499999999999\n",
      "DEBUG:shap:self.link(self.fx) = 0.5052499999999999\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.14442727,  0.00222168,  0.01022265,  0.04593088,  0.00151811,\n",
      "        0.01293117,  0.03002836, -0.04382318, -0.03608097,  0.02373212,\n",
      "       -0.00093976,  0.00612647, -0.03519895, -0.07999811,  0.00307364])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.08109773423829102)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08417137880820474\n",
      "DEBUG:shap:self.fx = 0.4947500000000001\n",
      "DEBUG:shap:self.link(self.fx) = 0.4947500000000001\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.14442727, -0.00222168, -0.01022265, -0.04593088, -0.00151811,\n",
      "       -0.01293117, -0.03002836,  0.04382318,  0.03608097, -0.02373212,\n",
      "        0.00093976, -0.00612647,  0.03519895,  0.07999811, -0.00307364])\n",
      " 50%|█████     | 37/74 [01:19<01:29,  2.42s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2749084822452301)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.26474528785846163\n",
      "DEBUG:shap:self.fx = 0.15633333333333335\n",
      "DEBUG:shap:self.link(self.fx) = 0.15633333333333335\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.10058158, -0.03075956, -0.00253741, -0.05375281, -0.00241019,\n",
      "       -0.00070683,  0.0166858 , -0.03260811, -0.01190255,  0.01158561,\n",
      "       -0.00326178,  0.00249455, -0.0232909 , -0.04386272,  0.01016319])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2749084822452305)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2647452878584621\n",
      "DEBUG:shap:self.fx = 0.8436666666666669\n",
      "DEBUG:shap:self.link(self.fx) = 0.8436666666666669\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.10058158,  0.03075956,  0.00253741,  0.05375281,  0.00241019,\n",
      "        0.00070683, -0.0166858 ,  0.03260811,  0.01190255, -0.01158561,\n",
      "        0.00326178, -0.00249455,  0.0232909 ,  0.04386272, -0.01016319])\n",
      " 51%|█████▏    | 38/74 [01:21<01:26,  2.40s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2236361845228112)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.24993278785846168\n",
      "DEBUG:shap:self.fx = 0.17114583333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.17114583333333333\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.15909398, -0.00401532,  0.00231984, -0.07018964, -0.00549122,\n",
      "       -0.00662286, -0.08473701,  0.0455076 ,  0.0174655 ,  0.0240599 ,\n",
      "        0.00633047,  0.0026031 ,  0.00207508,  0.00615234, -0.0262966 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2236361845228111)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24993278785846174\n",
      "DEBUG:shap:self.fx = 0.8288541666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.8288541666666666\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.15909398,  0.00401532, -0.00231984,  0.07018964,  0.00549122,\n",
      "        0.00662286,  0.08473701, -0.0455076 , -0.0174655 , -0.0240599 ,\n",
      "       -0.00633047, -0.0026031 , -0.00207508, -0.00615234,  0.0262966 ])\n",
      " 53%|█████▎    | 39/74 [01:24<01:23,  2.40s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2645634021770023)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1693062997632236\n",
      "DEBUG:shap:self.fx = 0.2517723214285714\n",
      "DEBUG:shap:self.link(self.fx) = 0.2517723214285714\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.12837341, -0.01714496,  0.0069171 , -0.04550071,  0.00391519,\n",
      "       -0.01175861, -0.01343039, -0.04468695,  0.00182946,  0.00659219,\n",
      "        0.        ,  0.00124942,  0.00866226, -0.03283399,  0.0952571 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2645634021770026)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16930629976322387\n",
      "DEBUG:shap:self.fx = 0.7482276785714287\n",
      "DEBUG:shap:self.link(self.fx) = 0.7482276785714287\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.12837341,  0.01714496, -0.0069171 ,  0.04550071, -0.00391519,\n",
      "        0.01175861,  0.01343039,  0.04468695, -0.00182946, -0.00659219,\n",
      "        0.        , -0.00124942, -0.00866226,  0.03283399, -0.0952571 ])\n",
      " 54%|█████▍    | 40/74 [01:26<01:21,  2.38s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09299847181322311)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.06993278785846174\n",
      "DEBUG:shap:self.fx = 0.35114583333333327\n",
      "DEBUG:shap:self.link(self.fx) = 0.35114583333333327\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.12208928, -0.05111367,  0.00513184,  0.05645628,  0.00642835,\n",
      "        0.0098168 ,  0.02466745, -0.04153373, -0.02583009,  0.00610195,\n",
      "        0.0061367 ,  0.00080838,  0.00721548,  0.02480505,  0.02306568])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.09299847181322324)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.0699327878584618\n",
      "DEBUG:shap:self.fx = 0.6488541666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.6488541666666666\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.12208928,  0.05111367, -0.00513184, -0.05645628, -0.00642835,\n",
      "       -0.0098168 , -0.02466745,  0.04153373,  0.02583009, -0.00610195,\n",
      "       -0.0061367 , -0.00080838, -0.00721548, -0.02480505, -0.02306568])\n",
      " 55%|█████▌    | 41/74 [01:29<01:19,  2.41s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.21726761509673076)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.18626612119179498\n",
      "DEBUG:shap:self.fx = 0.23481250000000004\n",
      "DEBUG:shap:self.link(self.fx) = 0.23481250000000004\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.12676551, -0.05527133, -0.00705625, -0.04443699,  0.00124166,\n",
      "       -0.01255437,  0.01685555, -0.04204149, -0.01400314, -0.00895097,\n",
      "        0.00160065,  0.01336118, -0.00777362,  0.06852703,  0.03100149])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.21726761509673093)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1862661211917952\n",
      "DEBUG:shap:self.fx = 0.7651875\n",
      "DEBUG:shap:self.link(self.fx) = 0.7651875\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.12676551,  0.05527133,  0.00705625,  0.04443699, -0.00124166,\n",
      "        0.01255437, -0.01685555,  0.04204149,  0.01400314,  0.00895097,\n",
      "       -0.00160065, -0.01336118,  0.00777362, -0.06852703, -0.03100149])\n",
      " 57%|█████▋    | 42/74 [01:31<01:16,  2.39s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.25586557759777523)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2773076584588757\n",
      "DEBUG:shap:self.fx = 0.14377096273291926\n",
      "DEBUG:shap:self.link(self.fx) = 0.14377096273291926\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.1142858 ,  0.02347027, -0.0088652 , -0.03256262, -0.00301678,\n",
      "       -0.00981223, -0.05225726,  0.00245766, -0.0051333 , -0.00168737,\n",
      "        0.00306805, -0.01240043,  0.01462875, -0.05946932, -0.02144208])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2558655775977755)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.27730765845887595\n",
      "DEBUG:shap:self.fx = 0.8562290372670808\n",
      "DEBUG:shap:self.link(self.fx) = 0.8562290372670808\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.1142858 , -0.02347027,  0.0088652 ,  0.03256262,  0.00301678,\n",
      "        0.00981223,  0.05225726, -0.00245766,  0.0051333 ,  0.00168737,\n",
      "       -0.00306805,  0.01240043, -0.01462875,  0.05946932,  0.02144208])\n",
      " 58%|█████▊    | 43/74 [01:33<01:14,  2.40s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.14439158487948198)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.128828621191795\n",
      "DEBUG:shap:self.fx = 0.29225\n",
      "DEBUG:shap:self.link(self.fx) = 0.29225\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.11998915,  0.0059485 ,  0.00353736,  0.06804437,  0.00169758,\n",
      "        0.00640225, -0.05120804, -0.0490497 , -0.01574664, -0.00155255,\n",
      "       -0.01141871,  0.00520851,  0.00669964,  0.00703501,  0.01556296])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.14439158487948214)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12882862119179528\n",
      "DEBUG:shap:self.fx = 0.7077500000000001\n",
      "DEBUG:shap:self.link(self.fx) = 0.7077500000000001\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.11998915, -0.0059485 , -0.00353736, -0.06804437, -0.00169758,\n",
      "       -0.00640225,  0.05120804,  0.0490497 ,  0.01574664,  0.00155255,\n",
      "        0.01141871, -0.00520851, -0.00669964, -0.00703501, -0.01556296])\n",
      " 59%|█████▉    | 44/74 [01:36<01:12,  2.41s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2052113133752696)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.24768278785846165\n",
      "DEBUG:shap:self.fx = 0.17339583333333336\n",
      "DEBUG:shap:self.link(self.fx) = 0.17339583333333336\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.11262646, -0.05810203,  0.00702993, -0.07365695,  0.01361223,\n",
      "       -0.00439806,  0.02318728,  0.00255198, -0.02290371, -0.00159071,\n",
      "       -0.02141721,  0.0037982 , -0.00810021,  0.04740441, -0.04247147])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2052113133752698)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24768278785846176\n",
      "DEBUG:shap:self.fx = 0.8266041666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.8266041666666666\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.11262646,  0.05810203, -0.00702993,  0.07365695, -0.01361223,\n",
      "        0.00439806, -0.02318728, -0.00255198,  0.02290371,  0.00159071,\n",
      "        0.02141721, -0.0037982 ,  0.00810021, -0.04740441,  0.04247147])\n",
      " 61%|██████    | 45/74 [01:38<01:09,  2.38s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1412710137883428)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.15068576404893785\n",
      "DEBUG:shap:self.fx = 0.27039285714285716\n",
      "DEBUG:shap:self.link(self.fx) = 0.27039285714285716\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.10721288,  0.03034026,  0.00862349, -0.05496762, -0.01978831,\n",
      "       -0.02532153, -0.06208413, -0.01895463,  0.00485184,  0.02460102,\n",
      "        0.0065961 ,  0.00570301,  0.        ,  0.06634238, -0.00941475])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1412710137883431)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1506857640489382\n",
      "DEBUG:shap:self.fx = 0.729607142857143\n",
      "DEBUG:shap:self.link(self.fx) = 0.729607142857143\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.10721288, -0.03034026, -0.00862349,  0.05496762,  0.01978831,\n",
      "        0.02532153,  0.06208413,  0.01895463, -0.00485184, -0.02460102,\n",
      "       -0.0065961 , -0.00570301,  0.        , -0.06634238,  0.00941475])\n",
      " 62%|██████▏   | 46/74 [01:41<01:07,  2.40s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3257217040432876)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.34541195452512835\n",
      "DEBUG:shap:self.fx = 0.07566666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.07566666666666667\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.12014994,  0.02221676, -0.00470413, -0.05529688, -0.01112698,\n",
      "       -0.01200925, -0.05848492, -0.0220628 , -0.02730633,  0.02403814,\n",
      "       -0.00425281, -0.01006952,  0.00195966, -0.0484727 , -0.01969025])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.32572170404328754)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3454119545251284\n",
      "DEBUG:shap:self.fx = 0.9243333333333332\n",
      "DEBUG:shap:self.link(self.fx) = 0.9243333333333332\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.12014994, -0.02221676,  0.00470413,  0.05529688,  0.01112698,\n",
      "        0.01200925,  0.05848492,  0.0220628 ,  0.02730633, -0.02403814,\n",
      "        0.00425281,  0.01006952, -0.00195966,  0.0484727 ,  0.01969025])\n",
      " 64%|██████▎   | 47/74 [01:43<01:04,  2.40s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1715695824852885)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1801708830965569\n",
      "DEBUG:shap:self.fx = 0.2409077380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.2409077380952381\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.14131681,  0.00704188,  0.00860291, -0.04692716, -0.00533539,\n",
      "       -0.01277389, -0.06843758,  0.06757256, -0.01479333,  0.01913819,\n",
      "       -0.00698333,  0.00763588, -0.0032398 ,  0.01824629, -0.0086013 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17156958248528872)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.18017088309655704\n",
      "DEBUG:shap:self.fx = 0.7590922619047619\n",
      "DEBUG:shap:self.link(self.fx) = 0.7590922619047619\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.14131681, -0.00704188, -0.00860291,  0.04692716,  0.00533539,\n",
      "        0.01277389,  0.06843758, -0.06757256,  0.01479333, -0.01913819,\n",
      "        0.00698333, -0.00763588,  0.0032398 , -0.01824629,  0.0086013 ])\n",
      " 65%|██████▍   | 48/74 [01:45<01:01,  2.38s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999995)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.15785749799400056)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.19774528785846163\n",
      "DEBUG:shap:self.fx = 0.22333333333333338\n",
      "DEBUG:shap:self.link(self.fx) = 0.22333333333333338\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.15346661,  0.01186587,  0.00433209, -0.05757507, -0.00798355,\n",
      "       -0.01648039, -0.04939428,  0.07457094,  0.01422249,  0.02568431,\n",
      "        0.01179668, -0.01429112,  0.01390336, -0.01504222, -0.03988779])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999995)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.15785749799400078)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1977452878584618\n",
      "DEBUG:shap:self.fx = 0.7766666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.7766666666666666\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.15346661, -0.01186587, -0.00433209,  0.05757507,  0.00798355,\n",
      "        0.01648039,  0.04939428, -0.07457094, -0.01422249, -0.02568431,\n",
      "       -0.01179668,  0.01429112, -0.01390336,  0.01504222,  0.03988779])\n",
      " 66%|██████▌   | 49/74 [01:48<00:59,  2.39s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.29513666642795455)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.31827789655411387\n",
      "DEBUG:shap:self.fx = 0.10280072463768114\n",
      "DEBUG:shap:self.link(self.fx) = 0.10280072463768114\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.11933255,  0.04497293, -0.01227964, -0.05820897, -0.01157   ,\n",
      "       -0.01705002, -0.0645244 , -0.02535242, -0.00855469,  0.01888858,\n",
      "       -0.00412221, -0.01389308,  0.00914406, -0.03325426, -0.02314123])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2951366664279548)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.318277896554114\n",
      "DEBUG:shap:self.fx = 0.8971992753623188\n",
      "DEBUG:shap:self.link(self.fx) = 0.8971992753623188\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.11933255, -0.04497293,  0.01227964,  0.05820897,  0.01157   ,\n",
      "        0.01705002,  0.0645244 ,  0.02535242,  0.00855469, -0.01888858,\n",
      "        0.00412221,  0.01389308, -0.00914406,  0.03325426,  0.02314123])\n",
      " 68%|██████▊   | 50/74 [01:50<00:57,  2.40s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1691189291005844)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12448523750385715\n",
      "DEBUG:shap:self.fx = 0.5455638586956522\n",
      "DEBUG:shap:self.link(self.fx) = 0.5455638586956522\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.1948517 ,  0.03509284,  0.0096208 , -0.07165656,  0.00898101,\n",
      "       -0.02105322,  0.00883841, -0.03291511,  0.01284105, -0.0070733 ,\n",
      "        0.00340195, -0.00884837, -0.00633554,  0.04337328, -0.04463369])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.16911892910058435)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.12448523750385698\n",
      "DEBUG:shap:self.fx = 0.45443614130434784\n",
      "DEBUG:shap:self.link(self.fx) = 0.45443614130434784\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.1948517 , -0.03509284, -0.0096208 ,  0.07165656, -0.00898101,\n",
      "        0.02105322, -0.00883841,  0.03291511, -0.01284105,  0.0070733 ,\n",
      "       -0.00340195,  0.00884837,  0.00633554, -0.04337328,  0.04463369])\n",
      " 69%|██████▉   | 51/74 [01:53<00:55,  2.39s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19785384523247007)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21418576404893788\n",
      "DEBUG:shap:self.fx = 0.20689285714285713\n",
      "DEBUG:shap:self.link(self.fx) = 0.20689285714285713\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.12381664, -0.00239591,  0.00399277, -0.07181328, -0.01121268,\n",
      "       -0.00817486, -0.033549  , -0.0356311 ,  0.00859421,  0.01644831,\n",
      "        0.00180383, -0.01203107,  0.0101431 ,  0.05978848, -0.01633192])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19785384523247043)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2141857640489383\n",
      "DEBUG:shap:self.fx = 0.7931071428571431\n",
      "DEBUG:shap:self.link(self.fx) = 0.7931071428571431\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.12381664,  0.00239591, -0.00399277,  0.07181328,  0.01121268,\n",
      "        0.00817486,  0.033549  ,  0.0356311 , -0.00859421, -0.01644831,\n",
      "       -0.00180383,  0.01203107, -0.0101431 , -0.05978848,  0.01633192])\n",
      " 70%|███████   | 52/74 [01:55<00:52,  2.38s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.21687220092251785)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2348807045251283\n",
      "DEBUG:shap:self.fx = 0.1861979166666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.1861979166666667\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.06187488,  0.03849071, -0.00929286, -0.0489767 , -0.01637701,\n",
      "       -0.01169797, -0.06025399, -0.0163523 , -0.00553908,  0.02233078,\n",
      "       -0.00293741, -0.00698248, -0.00178344, -0.03562556, -0.0180085 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.216872200922518)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.23488070452512844\n",
      "DEBUG:shap:self.fx = 0.8138020833333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.8138020833333333\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.06187488, -0.03849071,  0.00929286,  0.0489767 ,  0.01637701,\n",
      "        0.01169797,  0.06025399,  0.0163523 ,  0.00553908, -0.02233078,\n",
      "        0.00293741,  0.00698248,  0.00178344,  0.03562556,  0.0180085 ])\n",
      " 72%|███████▏  | 53/74 [01:57<00:49,  2.36s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3048901462645083)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3338762402394141\n",
      "DEBUG:shap:self.fx = 0.08720238095238093\n",
      "DEBUG:shap:self.link(self.fx) = 0.08720238095238093\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.1290616 ,  0.01229773, -0.00567723, -0.0583322 ,  0.00950677,\n",
      "       -0.00284523, -0.04646903, -0.02023035,  0.01326166, -0.0193359 ,\n",
      "       -0.01917699, -0.00851135, -0.00639905, -0.02391737, -0.02898609])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3048901462645085)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3338762402394143\n",
      "DEBUG:shap:self.fx = 0.9127976190476191\n",
      "DEBUG:shap:self.link(self.fx) = 0.9127976190476191\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.1290616 , -0.01229773,  0.00567723,  0.0583322 , -0.00950677,\n",
      "        0.00284523,  0.04646903,  0.02023035, -0.01326166,  0.0193359 ,\n",
      "        0.01917699,  0.00851135,  0.00639905,  0.02391737,  0.02898609])\n",
      " 73%|███████▎  | 54/74 [02:00<00:47,  2.35s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5209979022521382)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5455880454748716\n",
      "DEBUG:shap:self.fx = 0.9666666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.9666666666666667\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.1905747 ,  0.01362229, -0.00304826,  0.07299384,  0.00665422,\n",
      "        0.01172902,  0.04637125,  0.05919498,  0.00769819,  0.00358494,\n",
      "        0.01451779,  0.0214793 , -0.00464463,  0.08027027,  0.02459014])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.520997902252138)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5455880454748715\n",
      "DEBUG:shap:self.fx = 0.03333333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.03333333333333333\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.1905747 , -0.01362229,  0.00304826, -0.07299384, -0.00665422,\n",
      "       -0.01172902, -0.04637125, -0.05919498, -0.00769819, -0.00358494,\n",
      "       -0.01451779, -0.0214793 ,  0.00464463, -0.08027027, -0.02459014])\n",
      " 74%|███████▍  | 55/74 [02:02<00:44,  2.34s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22667515831686322)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.26581820452512833\n",
      "DEBUG:shap:self.fx = 0.15526041666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.15526041666666668\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.13692706, -0.00767334,  0.01002305, -0.05686512,  0.0087705 ,\n",
      "        0.00801785,  0.02153636, -0.04626341,  0.01067323, -0.02033007,\n",
      "       -0.00669886, -0.01774848, -0.00285258,  0.00966276, -0.03914305])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22667515831686358)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2658182045251286\n",
      "DEBUG:shap:self.fx = 0.8447395833333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.8447395833333334\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.13692706,  0.00767334, -0.01002305,  0.05686512, -0.0087705 ,\n",
      "       -0.00801785, -0.02153636,  0.04626341, -0.01067323,  0.02033007,\n",
      "        0.00669886,  0.01774848,  0.00285258, -0.00966276,  0.03914305])\n",
      " 76%|███████▌  | 56/74 [02:04<00:42,  2.34s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12182949167709806)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.06367137880820495\n",
      "DEBUG:shap:self.fx = 0.48474999999999996\n",
      "DEBUG:shap:self.link(self.fx) = 0.48474999999999996\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.01691166,  0.00110192,  0.00104909,  0.06206681, -0.00302724,\n",
      "        0.00256397,  0.03280939,  0.04708364, -0.00832332, -0.00250377,\n",
      "        0.00579192,  0.00968484,  0.0116241 , -0.05500353, -0.05815811])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.12182949167709778)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.06367137880820473\n",
      "DEBUG:shap:self.fx = 0.5152500000000001\n",
      "DEBUG:shap:self.link(self.fx) = 0.5152500000000001\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.01691166, -0.00110192, -0.00104909, -0.06206681,  0.00302724,\n",
      "       -0.00256397, -0.03280939, -0.04708364,  0.00832332,  0.00250377,\n",
      "       -0.00579192, -0.00968484, -0.0116241 ,  0.05500353,  0.05815811])\n",
      " 77%|███████▋  | 57/74 [02:07<00:40,  2.36s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.25969236797774026)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2961112298874472\n",
      "DEBUG:shap:self.fx = 0.12496739130434782\n",
      "DEBUG:shap:self.link(self.fx) = 0.12496739130434782\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.09679531,  0.        , -0.00337705, -0.05993786,  0.00232334,\n",
      "       -0.01707072, -0.02989944, -0.02834243,  0.00876841, -0.01119456,\n",
      "        0.01016236, -0.01668688,  0.00497474, -0.02261697, -0.03641886])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.25969236797774037)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2961112298874474\n",
      "DEBUG:shap:self.fx = 0.8750326086956522\n",
      "DEBUG:shap:self.link(self.fx) = 0.8750326086956522\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.09679531,  0.        ,  0.00337705,  0.05993786, -0.00232334,\n",
      "        0.01707072,  0.02989944,  0.02834243, -0.00876841,  0.01119456,\n",
      "       -0.01016236,  0.01668688, -0.00497474,  0.02261697,  0.03641886])\n",
      " 78%|███████▊  | 58/74 [02:09<00:37,  2.35s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24907943158869947)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2598380454748717\n",
      "DEBUG:shap:self.fx = 0.6809166666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.6809166666666667\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.17765441, -0.08199414,  0.00780353,  0.06628537,  0.0030599 ,\n",
      "       -0.00293433,  0.04759287,  0.06729437, -0.05436977, -0.00735192,\n",
      "        0.00084736,  0.00611989,  0.00869266,  0.01037925,  0.01075861])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.24907943158869922)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.25983804547487144\n",
      "DEBUG:shap:self.fx = 0.3190833333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.3190833333333334\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.17765441,  0.08199414, -0.00780353, -0.06628537, -0.0030599 ,\n",
      "        0.00293433, -0.04759287, -0.06729437,  0.05436977,  0.00735192,\n",
      "       -0.00084736, -0.00611989, -0.00869266, -0.01037925, -0.01075861])\n",
      " 80%|███████▉  | 59/74 [02:11<00:35,  2.39s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.13882031987598553)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1724327424445687\n",
      "DEBUG:shap:self.fx = 0.5935113636363637\n",
      "DEBUG:shap:self.link(self.fx) = 0.5935113636363637\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.1272182 ,  0.01159455, -0.00970378,  0.05322514,  0.00332586,\n",
      "        0.02089437,  0.02088596, -0.04090994, -0.07274938, -0.01277543,\n",
      "        0.01239979,  0.00123621,  0.01027093,  0.01390784,  0.03361242])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.13882031987598528)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.17243274244456847\n",
      "DEBUG:shap:self.fx = 0.40648863636363636\n",
      "DEBUG:shap:self.link(self.fx) = 0.40648863636363636\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.1272182 , -0.01159455,  0.00970378, -0.05322514, -0.00332586,\n",
      "       -0.02089437, -0.02088596,  0.04090994,  0.07274938,  0.01277543,\n",
      "       -0.01239979, -0.00123621, -0.01027093, -0.01390784, -0.03361242])\n",
      " 81%|████████  | 60/74 [02:14<00:33,  2.40s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0956568051608874)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1363706541705238\n",
      "DEBUG:shap:self.fx = 0.5574492753623188\n",
      "DEBUG:shap:self.link(self.fx) = 0.5574492753623188\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.13818829,  0.03514716, -0.01072906,  0.03216537,  0.00433954,\n",
      "       -0.0137087 ,  0.03549892, -0.03808007, -0.01219307, -0.00644597,\n",
      "       -0.01194456,  0.00117144,  0.01922576, -0.07697824,  0.04071385])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09565680516088726)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13637065417052358\n",
      "DEBUG:shap:self.fx = 0.44255072463768125\n",
      "DEBUG:shap:self.link(self.fx) = 0.44255072463768125\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.13818829, -0.03514716,  0.01072906, -0.03216537, -0.00433954,\n",
      "        0.0137087 , -0.03549892,  0.03808007,  0.01219307,  0.00644597,\n",
      "        0.01194456, -0.00117144, -0.01922576,  0.07697824, -0.04071385])\n",
      " 82%|████████▏ | 61/74 [02:16<00:31,  2.39s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.25974581185246204)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21712971214153848\n",
      "DEBUG:shap:self.fx = 0.6382083333333335\n",
      "DEBUG:shap:self.link(self.fx) = 0.6382083333333335\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.15997333, -0.09477741, -0.01959948,  0.03805736, -0.00288147,\n",
      "       -0.00340111,  0.03022415,  0.07316523, -0.03364116,  0.01403948,\n",
      "        0.0070462 ,  0.01219055,  0.00193422,  0.07741592, -0.0426161 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.25974581185246187)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2171297121415383\n",
      "DEBUG:shap:self.fx = 0.3617916666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.3617916666666665\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.15997333,  0.09477741,  0.01959948, -0.03805736,  0.00288147,\n",
      "        0.00340111, -0.03022415, -0.07316523,  0.03364116, -0.01403948,\n",
      "       -0.0070462 , -0.01219055, -0.00193422, -0.07741592,  0.0426161 ])\n",
      " 84%|████████▍ | 62/74 [02:19<00:28,  2.36s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.34472370816709114)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3654267060779234\n",
      "DEBUG:shap:self.fx = 0.05565191511387165\n",
      "DEBUG:shap:self.link(self.fx) = 0.05565191511387165\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.15581449, -0.00201446,  0.00391802, -0.06977135, -0.00673515,\n",
      "       -0.02259192, -0.04451563, -0.04516698,  0.00249676,  0.0155989 ,\n",
      "       -0.00603674, -0.0029798 ,  0.00615468, -0.01726554, -0.020703  ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3447237081670912)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3654267060779236\n",
      "DEBUG:shap:self.fx = 0.9443480848861284\n",
      "DEBUG:shap:self.link(self.fx) = 0.9443480848861284\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.15581449,  0.00201446, -0.00391802,  0.06977135,  0.00673515,\n",
      "        0.02259192,  0.04451563,  0.04516698, -0.00249676, -0.0155989 ,\n",
      "        0.00603674,  0.0029798 , -0.00615468,  0.01726554,  0.020703  ])\n",
      " 85%|████████▌ | 63/74 [02:21<00:26,  2.40s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.09486888641052099)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09095168183850794\n",
      "DEBUG:shap:self.fx = 0.512030303030303\n",
      "DEBUG:shap:self.link(self.fx) = 0.512030303030303\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.15984541,  0.00357814, -0.00827796, -0.03653672,  0.0007879 ,\n",
      "        0.02456308,  0.03189389, -0.03821676, -0.02063794, -0.01634535,\n",
      "       -0.01564606,  0.01227793, -0.00840942,  0.00599273, -0.0039172 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09486888641052092)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09095168183850777\n",
      "DEBUG:shap:self.fx = 0.48796969696969705\n",
      "DEBUG:shap:self.link(self.fx) = 0.48796969696969705\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.15984541, -0.00357814,  0.00827796,  0.03653672, -0.0007879 ,\n",
      "       -0.02456308, -0.03189389,  0.03821676,  0.02063794,  0.01634535,\n",
      "        0.01564606, -0.01227793,  0.00840942, -0.00599273,  0.0039172 ])\n",
      " 86%|████████▋ | 64/74 [02:24<00:24,  2.43s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22924208556421893)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.19123040690608076\n",
      "DEBUG:shap:self.fx = 0.22984821428571425\n",
      "DEBUG:shap:self.link(self.fx) = 0.22984821428571425\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.16285568, -0.01385192,  0.01171528, -0.06008421, -0.00330482,\n",
      "       -0.01140225,  0.01825796, -0.03383781,  0.00869392, -0.00605765,\n",
      "        0.02018027, -0.01053574, -0.01439169,  0.02823224,  0.03801168])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22924208556421935)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.19123040690608106\n",
      "DEBUG:shap:self.fx = 0.7701517857142859\n",
      "DEBUG:shap:self.link(self.fx) = 0.7701517857142859\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.16285568,  0.01385192, -0.01171528,  0.06008421,  0.00330482,\n",
      "        0.01140225, -0.01825796,  0.03383781, -0.00869392,  0.00605765,\n",
      "       -0.02018027,  0.01053574,  0.01439169, -0.02823224, -0.03801168])\n",
      " 88%|████████▊ | 65/74 [02:26<00:22,  2.45s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5308970858668443)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4897547121415384\n",
      "DEBUG:shap:self.fx = 0.9108333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.9108333333333334\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.21112761,  0.01960984,  0.00524135,  0.08015596,  0.01120903,\n",
      "        0.01145137,  0.04981226,  0.07904685,  0.0028118 ,  0.00495289,\n",
      "        0.01273742,  0.01723595,  0.00534641,  0.02015833, -0.04114237])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5308970858668441)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.48975471214153815\n",
      "DEBUG:shap:self.fx = 0.08916666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.08916666666666667\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.21112761, -0.01960984, -0.00524135, -0.08015596, -0.01120903,\n",
      "       -0.01145137, -0.04981226, -0.07904685, -0.0028118 , -0.00495289,\n",
      "       -0.01273742, -0.01723595, -0.00534641, -0.02015833,  0.04114237])\n",
      " 89%|████████▉ | 66/74 [02:28<00:19,  2.42s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.25041974177161863)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.29298622988744716\n",
      "DEBUG:shap:self.fx = 0.12809239130434782\n",
      "DEBUG:shap:self.link(self.fx) = 0.12809239130434782\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.10379254,  0.04016252, -0.01666697, -0.06039809,  0.00217262,\n",
      "        0.00302998, -0.04394156, -0.00150538, -0.02130481, -0.00888905,\n",
      "        0.00159723, -0.02288398, -0.0016178 , -0.0163819 , -0.04256649])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2504197417716188)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.29298622988744727\n",
      "DEBUG:shap:self.fx = 0.8719076086956521\n",
      "DEBUG:shap:self.link(self.fx) = 0.8719076086956521\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.10379254, -0.04016252,  0.01666697,  0.06039809, -0.00217262,\n",
      "       -0.00302998,  0.04394156,  0.00150538,  0.02130481,  0.00888905,\n",
      "       -0.00159723,  0.02288398,  0.0016178 ,  0.0163819 ,  0.04256649])\n",
      " 91%|█████████ | 67/74 [02:31<00:16,  2.35s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.44073411963068543)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.44661834850517484\n",
      "DEBUG:shap:self.fx = 0.8676969696969699\n",
      "DEBUG:shap:self.link(self.fx) = 0.8676969696969699\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.1829006 ,  0.01513046, -0.00142574,  0.0807123 ,  0.00069541,\n",
      "        0.01063106,  0.05546016,  0.07491254,  0.01113446,  0.01066833,\n",
      "        0.02026852,  0.00961223,  0.00036804, -0.03033425,  0.00588423])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4407341196306852)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.44661834850517457\n",
      "DEBUG:shap:self.fx = 0.13230303030303028\n",
      "DEBUG:shap:self.link(self.fx) = 0.13230303030303028\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.1829006 , -0.01513046,  0.00142574, -0.0807123 , -0.00069541,\n",
      "       -0.01063106, -0.05546016, -0.07491254, -0.01113446, -0.01066833,\n",
      "       -0.02026852, -0.00961223, -0.00036804,  0.03033425, -0.00588423])\n",
      " 92%|█████████▏| 68/74 [02:33<00:14,  2.38s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3486784837953292)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3807868251255424\n",
      "DEBUG:shap:self.fx = 0.04029179606625259\n",
      "DEBUG:shap:self.link(self.fx) = 0.04029179606625259\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.1353502 , -0.02204416,  0.00228558, -0.06112411, -0.00676546,\n",
      "       -0.01321759, -0.04048352, -0.03741569, -0.00595998,  0.014375  ,\n",
      "        0.        , -0.00199363,  0.        , -0.04098473, -0.03210834])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.34867848379532934)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3807868251255425\n",
      "DEBUG:shap:self.fx = 0.9597082039337473\n",
      "DEBUG:shap:self.link(self.fx) = 0.9597082039337473\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.1353502 ,  0.02204416, -0.00228558,  0.06112411,  0.00676546,\n",
      "        0.01321759,  0.04048352,  0.03741569,  0.00595998, -0.014375  ,\n",
      "        0.        ,  0.00199363,  0.        ,  0.04098473,  0.03210834])\n",
      " 93%|█████████▎| 69/74 [02:35<00:11,  2.35s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999995)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.30922010557576324)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2550324902394141\n",
      "DEBUG:shap:self.fx = 0.16604613095238094\n",
      "DEBUG:shap:self.link(self.fx) = 0.16604613095238094\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.12560523, -0.04455879, -0.00804119, -0.03905616,  0.00274784,\n",
      "       -0.01250164,  0.01417613, -0.06461539,  0.00718587, -0.00292463,\n",
      "       -0.00095797, -0.00270492, -0.00355586, -0.02880818,  0.05418762])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999995)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3092201055757632)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2550324902394141\n",
      "DEBUG:shap:self.fx = 0.8339538690476189\n",
      "DEBUG:shap:self.link(self.fx) = 0.8339538690476189\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.12560523,  0.04455879,  0.00804119,  0.03905616, -0.00274784,\n",
      "        0.01250164, -0.01417613,  0.06461539, -0.00718587,  0.00292463,\n",
      "        0.00095797,  0.00270492,  0.00355586,  0.02880818, -0.05418762])\n",
      " 95%|█████████▍| 70/74 [02:38<00:09,  2.41s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4819226110672185)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4850404264272528\n",
      "DEBUG:shap:self.fx = 0.9061190476190478\n",
      "DEBUG:shap:self.link(self.fx) = 0.9061190476190478\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.22225001,  0.02835606,  0.01127516,  0.08848213,  0.00839292,\n",
      "       -0.00550657,  0.05007335,  0.0283999 ,  0.00855854,  0.00678684,\n",
      "        0.00101269,  0.00943761,  0.01263064,  0.01177332,  0.00311782])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.48192261106721834)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4850404264272524\n",
      "DEBUG:shap:self.fx = 0.09388095238095237\n",
      "DEBUG:shap:self.link(self.fx) = 0.09388095238095237\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.22225001, -0.02835606, -0.01127516, -0.08848213, -0.00839292,\n",
      "        0.00550657, -0.05007335, -0.0283999 , -0.00855854, -0.00678684,\n",
      "       -0.00101269, -0.00943761, -0.01263064, -0.01177332, -0.00311782])\n",
      " 96%|█████████▌| 71/74 [02:40<00:07,  2.36s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0624966263926665)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.06855774244456853\n",
      "DEBUG:shap:self.fx = 0.48963636363636354\n",
      "DEBUG:shap:self.link(self.fx) = 0.48963636363636354\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([ 0.15884419,  0.02265267,  0.0063541 ,  0.04674976,  0.00081012,\n",
      "       -0.00515538, -0.07171301, -0.05473271, -0.0279015 , -0.00922355,\n",
      "        0.00821887, -0.02017443,  0.0077675 ,  0.00606112,  0.        ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.062496626392666496)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.06855774244456836\n",
      "DEBUG:shap:self.fx = 0.5103636363636365\n",
      "DEBUG:shap:self.link(self.fx) = 0.5103636363636365\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([-0.15884419, -0.02265267, -0.0063541 , -0.04674976, -0.00081012,\n",
      "        0.00515538,  0.07171301,  0.05473271,  0.0279015 ,  0.00922355,\n",
      "       -0.00821887,  0.02017443, -0.0077675 , -0.00606112,  0.        ])\n",
      " 97%|█████████▋| 72/74 [02:42<00:04,  2.37s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.11917144032080104)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.169578621191795\n",
      "DEBUG:shap:self.fx = 0.2515\n",
      "DEBUG:shap:self.link(self.fx) = 0.2515\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.11297218,  0.05680642,  0.00622099, -0.04236977,  0.01030549,\n",
      "       -0.01689657, -0.06677336, -0.02166317, -0.00725989,  0.02293374,\n",
      "        0.02073671,  0.00433594, -0.00149927,  0.02892349, -0.05040718])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1191714403208011)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16957862119179512\n",
      "DEBUG:shap:self.fx = 0.7484999999999999\n",
      "DEBUG:shap:self.link(self.fx) = 0.7484999999999999\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.11297218, -0.05680642, -0.00622099,  0.04236977, -0.01030549,\n",
      "        0.01689657,  0.06677336,  0.02166317,  0.00725989, -0.02293374,\n",
      "       -0.02073671, -0.00433594,  0.00149927, -0.02892349,  0.05040718])\n",
      " 99%|█████████▊| 73/74 [02:45<00:02,  2.34s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.06610812987582126)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.017084573572747397\n",
      "DEBUG:shap:self.fx = 0.4039940476190476\n",
      "DEBUG:shap:self.link(self.fx) = 0.4039940476190476\n",
      "DEBUG:shap:self.fnull = 0.421078621191795\n",
      "DEBUG:shap:self.link(self.fnull) = 0.421078621191795\n",
      "INFO:shap:phi = array([-0.16027944,  0.01205257, -0.00892861,  0.01778473,  0.0130019 ,\n",
      "       -0.01134201,  0.0129392 , -0.07219635,  0.00658652,  0.00413246,\n",
      "        0.01104935,  0.01426865,  0.01506392,  0.07975897,  0.04902356])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.06610812987582157)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.01708457357274773\n",
      "DEBUG:shap:self.fx = 0.5960059523809526\n",
      "DEBUG:shap:self.link(self.fx) = 0.5960059523809526\n",
      "DEBUG:shap:self.fnull = 0.5789213788082048\n",
      "DEBUG:shap:self.link(self.fnull) = 0.5789213788082048\n",
      "INFO:shap:phi = array([ 0.16027944, -0.01205257,  0.00892861, -0.01778473, -0.0130019 ,\n",
      "        0.01134201, -0.0129392 ,  0.07219635, -0.00658652, -0.00413246,\n",
      "       -0.01104935, -0.01426865, -0.01506392, -0.07975897, -0.04902356])\n",
      "100%|██████████| 74/74 [02:47<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8286445012787723,\n",
      "                0.7468030690537085,\n",
      "                0.7178175618073316,\n",
      "                0.6317135549872123,\n",
      "                0.5524296675191817,\n",
      "                0.6086956521739131,\n",
      "                0.6325660699062234,\n",
      "                0.6982097186700768,\n",
      "                0.711849957374254,\n",
      "                0.6368286445012787,\n",
      "                0.5592497868712702,\n",
      "                0.5196078431372548,\n",
      "                0.48763853367433935,\n",
      "                0.550298380221654,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5247611733780392,\n",
      "                0.5992980891784528,\n",
      "                0.6364483622529632,\n",
      "                0.7030805887135134,\n",
      "                0.764792833477202,\n",
      "                0.7780820786677748,\n",
      "                0.7962646706446573,\n",
      "                0.8106359100631979,\n",
      "                0.8076533497670039,\n",
      "                0.853825796631459,\n",
      "                0.8787514646182164,\n",
      "                0.8711167992531359,\n",
      "                0.8791571272222569,\n",
      "                0.842185806284067,\n",
      "                0.8697720218315294\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17191309223617363,\n",
      "                0.20559231482901733,\n",
      "                0.22279499813175022,\n",
      "                0.2545604943132168,\n",
      "                0.2847126378229196,\n",
      "                0.2913512652958653,\n",
      "                0.3000969222074143,\n",
      "                0.30701958898035975,\n",
      "                0.30565095216923893,\n",
      "                0.3266958740886581,\n",
      "                0.33818781347887356,\n",
      "                0.33490890991635586,\n",
      "                0.33843748071383184,\n",
      "                0.32205690043346263,\n",
      "                0.3348469112139148\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6254901960784314,\n",
      "            \"cross_entropy\": 0.774388404798898,\n",
      "            \"brier\": 0.28925507705540354\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8047740835464622,\n",
      "                0.8405797101449275,\n",
      "                0.8350383631713556,\n",
      "                0.8644501278772379,\n",
      "                0.8584825234441602,\n",
      "                0.8533674339300937,\n",
      "                0.8337595907928389,\n",
      "                0.8277919863597613,\n",
      "                0.8260869565217391,\n",
      "                0.8312020460358056,\n",
      "                0.8380221653878944,\n",
      "                0.8473998294970163,\n",
      "                0.8533674339300937,\n",
      "                0.8550724637681159,\n",
      "                0.8533674339300937\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.6304875596901828,\n",
      "                0.5231308843317846,\n",
      "                0.49239532464583374,\n",
      "                0.45061291867255465,\n",
      "                0.4401524189059828,\n",
      "                0.44338652637942283,\n",
      "                0.4593776936160279,\n",
      "                0.4696961164785607,\n",
      "                0.4750169900067638,\n",
      "                0.4644041914235581,\n",
      "                0.4605469896397578,\n",
      "                0.4587796723398221,\n",
      "                0.4584951335150209,\n",
      "                0.45552697280724835,\n",
      "                0.45297774690534315\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.21120993032259455,\n",
      "                0.1662162563773505,\n",
      "                0.15263013176691798,\n",
      "                0.13865086965929263,\n",
      "                0.1341011290204091,\n",
      "                0.13534384534591934,\n",
      "                0.14268394260144285,\n",
      "                0.14585743977563176,\n",
      "                0.1484783540859465,\n",
      "                0.1443902529909404,\n",
      "                0.1437225696035937,\n",
      "                0.14301879153988858,\n",
      "                0.14238037453950478,\n",
      "                0.14122245896534602,\n",
      "                0.14064052329750873\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8415174765558397,\n",
      "            \"cross_entropy\": 0.47566580929052427,\n",
      "            \"brier\": 0.14870312465948582\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/74 [00:00<?, ?it/s]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17894642139490638)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1660816326530612\n",
      "DEBUG:shap:self.fx = 0.20566666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.20566666666666666\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11385852,  0.01430519,  0.00254306, -0.07051476,  0.        ,\n",
      "       -0.00504029, -0.04330775, -0.0354833 , -0.02110535,  0.02492751,\n",
      "       -0.00178847,  0.        ,  0.00604721,  0.06432906,  0.01286479])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.17894642139490619)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16608163265306097\n",
      "DEBUG:shap:self.fx = 0.7943333333333332\n",
      "DEBUG:shap:self.link(self.fx) = 0.7943333333333332\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11385852, -0.01430519, -0.00254306,  0.07051476,  0.        ,\n",
      "        0.00504029,  0.04330775,  0.0354833 ,  0.02110535, -0.02492751,\n",
      "        0.00178847,  0.        , -0.00604721, -0.06432906, -0.01286479])\n",
      "  1%|▏         | 1/74 [00:01<01:54,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.19719096421529775)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1939183673469388\n",
      "DEBUG:shap:self.fx = 0.5656666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.5656666666666667\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.11998376, -0.10323777,  0.00769699,  0.09711363, -0.00606974,\n",
      "        0.00949418,  0.02354199,  0.03569   ,  0.00702176, -0.02654364,\n",
      "        0.        ,  0.00632846,  0.03144277, -0.00527145, -0.0032726 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19719096421529794)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.19391836734693896\n",
      "DEBUG:shap:self.fx = 0.4343333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.4343333333333333\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.11998376,  0.10323777, -0.00769699, -0.09711363,  0.00606974,\n",
      "       -0.00949418, -0.02354199, -0.03569   , -0.00702176,  0.02654364,\n",
      "        0.        , -0.00632846, -0.03144277,  0.00527145,  0.0032726 ])\n",
      "  3%|▎         | 2/74 [00:03<01:55,  1.60s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.48793149403814523)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.4974183673469389\n",
      "DEBUG:shap:self.fx = 0.8691666666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.8691666666666668\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.1517085 ,  0.01898166,  0.        ,  0.10951409,  0.01533393,\n",
      "        0.01709268,  0.04659729,  0.08311176,  0.00199739, -0.01898863,\n",
      "        0.00041146,  0.02425186,  0.03124968,  0.00666982,  0.00948687])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4879314940381453)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4974183673469389\n",
      "DEBUG:shap:self.fx = 0.13083333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.13083333333333333\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.1517085 , -0.01898166,  0.        , -0.10951409, -0.01533393,\n",
      "       -0.01709268, -0.04659729, -0.08311176, -0.00199739,  0.01898863,\n",
      "       -0.00041146, -0.02425186, -0.03124968, -0.00666982, -0.00948687])\n",
      "  4%|▍         | 3/74 [00:04<01:51,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2745331617001855)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.28924829931972784\n",
      "DEBUG:shap:self.fx = 0.0825\n",
      "DEBUG:shap:self.link(self.fx) = 0.0825\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11699639,  0.00353936,  0.00255745, -0.05397552, -0.00233151,\n",
      "        0.00949851, -0.03901811, -0.03016358,  0.00689118, -0.00359308,\n",
      "        0.00817316, -0.02156694,  0.0069257 , -0.04447337, -0.01471514])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2745331617001854)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.28924829931972773\n",
      "DEBUG:shap:self.fx = 0.9175\n",
      "DEBUG:shap:self.link(self.fx) = 0.9175\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11699639, -0.00353936, -0.00255745,  0.05397552,  0.00233151,\n",
      "       -0.00949851,  0.03901811,  0.03016358, -0.00689118,  0.00359308,\n",
      "       -0.00817316,  0.02156694, -0.0069257 ,  0.04447337,  0.01471514])\n",
      "  5%|▌         | 4/74 [00:06<01:50,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0634156818324165)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.050085034013605534\n",
      "DEBUG:shap:self.fx = 0.4218333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.4218333333333334\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.14990634,  0.01045958, -0.00568065, -0.06199696,  0.01673906,\n",
      "       -0.03106693, -0.05245377,  0.07251409, -0.01688163,  0.        ,\n",
      "       -0.00664925, -0.00918523, -0.00106337, -0.00122561, -0.01333065])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.0634156818324166)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.050085034013605645\n",
      "DEBUG:shap:self.fx = 0.5781666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.5781666666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.14990634, -0.01045958,  0.00568065,  0.06199696, -0.01673906,\n",
      "        0.03106693,  0.05245377, -0.07251409,  0.01688163,  0.        ,\n",
      "        0.00664925,  0.00918523,  0.00106337,  0.00122561,  0.01333065])\n",
      "  7%|▋         | 5/74 [00:07<01:48,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.08322489550810187)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09313265306122448\n",
      "DEBUG:shap:self.fx = 0.46488095238095234\n",
      "DEBUG:shap:self.link(self.fx) = 0.46488095238095234\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.10714055,  0.003143  ,  0.01121951,  0.0578135 ,  0.00629299,\n",
      "       -0.01152771,  0.0262638 , -0.05124677, -0.02700265, -0.0139335 ,\n",
      "       -0.00523482,  0.01127178,  0.00528189, -0.0362567 ,  0.00990776])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.08322489550810193)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09313265306122454\n",
      "DEBUG:shap:self.fx = 0.5351190476190477\n",
      "DEBUG:shap:self.link(self.fx) = 0.5351190476190477\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.10714055, -0.003143  , -0.01121951, -0.0578135 , -0.00629299,\n",
      "        0.01152771, -0.0262638 ,  0.05124677,  0.02700265,  0.0139335 ,\n",
      "        0.00523482, -0.01127178, -0.00528189,  0.0362567 , -0.00990776])\n",
      "  8%|▊         | 6/74 [00:09<01:47,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3779155973780005)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3914183673469388\n",
      "DEBUG:shap:self.fx = 0.7631666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.7631666666666667\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.16102053,  0.03801767, -0.01434766, -0.03079805,  0.01463653,\n",
      "        0.0438996 ,  0.03333193,  0.0286876 , -0.00845662, -0.00879231,\n",
      "        0.0037793 ,  0.04570183,  0.00638891,  0.06484635,  0.01350277])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3779155973780007)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3914183673469389\n",
      "DEBUG:shap:self.fx = 0.23683333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.23683333333333334\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.16102053, -0.03801767,  0.01434766,  0.03079805, -0.01463653,\n",
      "       -0.0438996 , -0.03333193, -0.0286876 ,  0.00845662,  0.00879231,\n",
      "       -0.0037793 , -0.04570183, -0.00638891, -0.06484635, -0.01350277])\n",
      "  9%|▉         | 7/74 [00:11<01:45,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.4175864274160517)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.44908503401360544\n",
      "DEBUG:shap:self.fx = 0.8208333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.8208333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.17764375,  0.01252321,  0.        ,  0.01283651,  0.00118145,\n",
      "       -0.0041954 ,  0.04135077,  0.07949009,  0.00089082,  0.00482978,\n",
      "        0.00190925,  0.00667629, -0.00891563,  0.09136555,  0.03149861])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4175864274160517)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.44908503401360556\n",
      "DEBUG:shap:self.fx = 0.17916666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.17916666666666667\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.17764375, -0.01252321,  0.        , -0.01283651, -0.00118145,\n",
      "        0.0041954 , -0.04135077, -0.07949009, -0.00089082, -0.00482978,\n",
      "       -0.00190925, -0.00667629,  0.00891563, -0.09136555, -0.03149861])\n",
      " 11%|█         | 8/74 [00:12<01:46,  1.62s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1353677098631376)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1434149659863945\n",
      "DEBUG:shap:self.fx = 0.22833333333333336\n",
      "DEBUG:shap:self.link(self.fx) = 0.22833333333333336\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.06668187,  0.00966784,  0.00475418, -0.06736374,  0.00590436,\n",
      "        0.02926281, -0.06194591,  0.03321113, -0.00146587,  0.00391658,\n",
      "        0.01528454,  0.01487955, -0.00030076, -0.05449054, -0.00804726])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1353677098631375)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.14341496598639436\n",
      "DEBUG:shap:self.fx = 0.7716666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.7716666666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.06668187, -0.00966784, -0.00475418,  0.06736374, -0.00590436,\n",
      "       -0.02926281,  0.06194591, -0.03321113,  0.00146587, -0.00391658,\n",
      "       -0.01528454, -0.01487955,  0.00030076,  0.05449054,  0.00804726])\n",
      " 12%|█▏        | 9/74 [00:14<01:43,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.21216634421310276)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2184149659863945\n",
      "DEBUG:shap:self.fx = 0.15333333333333335\n",
      "DEBUG:shap:self.link(self.fx) = 0.15333333333333335\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.13185561, -0.00449072, -0.00090159, -0.05247922,  0.01727986,\n",
      "        0.00714653, -0.05030272, -0.01513821, -0.00139247,  0.0209575 ,\n",
      "       -0.00967312,  0.00894374,  0.00568991, -0.00595021, -0.00624862])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2121663442131026)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21841496598639432\n",
      "DEBUG:shap:self.fx = 0.8466666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.8466666666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.13185561,  0.00449072,  0.00090159,  0.05247922, -0.01727986,\n",
      "       -0.00714653,  0.05030272,  0.01513821,  0.00139247, -0.0209575 ,\n",
      "        0.00967312, -0.00894374, -0.00568991,  0.00595021,  0.00624862])\n",
      " 14%|█▎        | 10/74 [00:15<01:39,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1234106789797155)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.13458163265306117\n",
      "DEBUG:shap:self.fx = 0.2371666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.2371666666666667\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11900793,  0.00274052,  0.01709965, -0.03679797, -0.00999209,\n",
      "        0.01692206,  0.03222491, -0.03536488,  0.00406308, -0.00505224,\n",
      "       -0.00467947, -0.01231112, -0.00042075,  0.02716554, -0.01117095])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1234106789797153)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1345816326530611\n",
      "DEBUG:shap:self.fx = 0.7628333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.7628333333333334\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11900793, -0.00274052, -0.01709965,  0.03679797,  0.00999209,\n",
      "       -0.01692206, -0.03222491,  0.03536488, -0.00406308,  0.00505224,\n",
      "        0.00467947,  0.01231112,  0.00042075, -0.02716554,  0.01117095])\n",
      " 15%|█▍        | 11/74 [00:17<01:40,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.0028625997299634998)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.009414965986394519\n",
      "DEBUG:shap:self.fx = 0.36233333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.36233333333333334\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.08603604, -0.05124457,  0.00990767,  0.07376373,  0.00913474,\n",
      "        0.02036335, -0.02002458,  0.05902627, -0.00179333,  0.02373476,\n",
      "        0.00332512,  0.01283532, -0.00954817, -0.04630687, -0.00655237])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.0028625997299633055)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.009414965986394352\n",
      "DEBUG:shap:self.fx = 0.6376666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.6376666666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.08603604,  0.05124457, -0.00990767, -0.07376373, -0.00913474,\n",
      "       -0.02036335,  0.02002458, -0.05902627,  0.00179333, -0.02373476,\n",
      "       -0.00332512, -0.01283532,  0.00954817,  0.04630687,  0.00655237])\n",
      " 16%|█▌        | 12/74 [00:18<01:37,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22779201712058192)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.17391496598639455\n",
      "DEBUG:shap:self.fx = 0.1978333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.1978333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09540839,  0.        ,  0.00907969, -0.05097937,  0.00368249,\n",
      "        0.00177941, -0.02374504, -0.01191455,  0.01263993,  0.00161805,\n",
      "        0.00100336, -0.01798559,  0.0058507 , -0.06341271,  0.05387705])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22779201712058178)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.17391496598639444\n",
      "DEBUG:shap:self.fx = 0.8021666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.8021666666666667\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09540839,  0.        , -0.00907969,  0.05097937, -0.00368249,\n",
      "       -0.00177941,  0.02374504,  0.01191455, -0.01263993, -0.00161805,\n",
      "       -0.00100336,  0.01798559, -0.0058507 ,  0.06341271, -0.05387705])\n",
      " 18%|█▊        | 13/74 [00:20<01:34,  1.54s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.01907293754598581)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.017751700680272098\n",
      "DEBUG:shap:self.fx = 0.38949999999999996\n",
      "DEBUG:shap:self.link(self.fx) = 0.38949999999999996\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.03836451,  0.05552353,  0.01175661, -0.03718719, -0.00241512,\n",
      "       -0.01572175,  0.03165235, -0.06218858,  0.01082626,  0.01173784,\n",
      "        0.00617159,  0.01870186,  0.00740485, -0.01697067,  0.03682464])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.019072937545985595)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.01775170068027232\n",
      "DEBUG:shap:self.fx = 0.6104999999999999\n",
      "DEBUG:shap:self.link(self.fx) = 0.6104999999999999\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.03836451, -0.05552353, -0.01175661,  0.03718719,  0.00241512,\n",
      "        0.01572175, -0.03165235,  0.06218858, -0.01082626, -0.01173784,\n",
      "       -0.00617159, -0.01870186, -0.00740485,  0.01697067, -0.03682464])\n",
      " 19%|█▉        | 14/74 [00:21<01:31,  1.52s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19585954675415823)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2200816326530612\n",
      "DEBUG:shap:self.fx = 0.15166666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.15166666666666667\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11728919,  0.01346825,  0.00538514, -0.04385023, -0.00314027,\n",
      "       -0.0062512 , -0.06698593, -0.04001892,  0.0092888 , -0.00709338,\n",
      "       -0.00528465,  0.0092868 , -0.0026217 ,  0.05924692, -0.02422209])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1958595467541583)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.22008163265306113\n",
      "DEBUG:shap:self.fx = 0.8483333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.8483333333333334\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11728919, -0.01346825, -0.00538514,  0.04385023,  0.00314027,\n",
      "        0.0062512 ,  0.06698593,  0.04001892, -0.0092888 ,  0.00709338,\n",
      "        0.00528465, -0.0092868 ,  0.0026217 , -0.05924692,  0.02422209])\n",
      " 20%|██        | 15/74 [00:23<01:30,  1.53s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.07030659397567268)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09124829931972783\n",
      "DEBUG:shap:self.fx = 0.2805\n",
      "DEBUG:shap:self.link(self.fx) = 0.2805\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.07179206,  0.00146979,  0.00675405, -0.04836294,  0.00215466,\n",
      "       -0.00763944, -0.04561577,  0.00609679, -0.007299  ,  0.01227238,\n",
      "       -0.00459414,  0.01111831,  0.00198579,  0.07314497, -0.02094171])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.07030659397567267)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09124829931972778\n",
      "DEBUG:shap:self.fx = 0.7195\n",
      "DEBUG:shap:self.link(self.fx) = 0.7195\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.07179206, -0.00146979, -0.00675405,  0.04836294, -0.00215466,\n",
      "        0.00763944,  0.04561577, -0.00609679,  0.007299  , -0.01227238,\n",
      "        0.00459414, -0.01111831, -0.00198579, -0.07314497,  0.02094171])\n",
      " 22%|██▏       | 16/74 [00:25<01:29,  1.55s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09136204631983225)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.06570068027210879\n",
      "DEBUG:shap:self.fx = 0.30604761904761907\n",
      "DEBUG:shap:self.link(self.fx) = 0.30604761904761907\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09987893,  0.01834004,  0.00488345,  0.06120262, -0.00539841,\n",
      "       -0.00317591,  0.0326474 , -0.04828362, -0.02253236, -0.00676669,\n",
      "        0.00179794, -0.00239579, -0.01281017, -0.00899162,  0.02566137])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.09136204631983218)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.06570068027210874\n",
      "DEBUG:shap:self.fx = 0.693952380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.693952380952381\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09987893, -0.01834004, -0.00488345, -0.06120262,  0.00539841,\n",
      "        0.00317591, -0.0326474 ,  0.04828362,  0.02253236,  0.00676669,\n",
      "       -0.00179794,  0.00239579,  0.01281017,  0.00899162, -0.02566137])\n",
      " 23%|██▎       | 17/74 [00:26<01:28,  1.55s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.13555515953416006)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.14086734693877545\n",
      "DEBUG:shap:self.fx = 0.2308809523809524\n",
      "DEBUG:shap:self.link(self.fx) = 0.2308809523809524\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.07842573,  0.01055473,  0.05072122, -0.02117496,  0.        ,\n",
      "        0.00643351, -0.05640898, -0.02301514,  0.00722728,  0.00056098,\n",
      "        0.        , -0.00719307,  0.0054728 , -0.03030782, -0.00531219])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.13555515953416003)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.14086734693877545\n",
      "DEBUG:shap:self.fx = 0.7691190476190477\n",
      "DEBUG:shap:self.link(self.fx) = 0.7691190476190477\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.07842573, -0.01055473, -0.05072122,  0.02117496,  0.        ,\n",
      "       -0.00643351,  0.05640898,  0.02301514, -0.00722728, -0.00056098,\n",
      "        0.        ,  0.00719307, -0.0054728 ,  0.03030782,  0.00531219])\n",
      " 24%|██▍       | 18/74 [00:28<01:26,  1.54s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5201959351338656)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5447993197278911\n",
      "DEBUG:shap:self.fx = 0.9165476190476189\n",
      "DEBUG:shap:self.link(self.fx) = 0.9165476190476189\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.18009842,  0.01965786,  0.00027276,  0.10866598,  0.00720739,\n",
      "        0.01294265,  0.03504629, -0.01761941,  0.00559714,  0.0106921 ,\n",
      "        0.01058359,  0.02451364,  0.0016636 ,  0.12087392,  0.02460338])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5201959351338659)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5447993197278913\n",
      "DEBUG:shap:self.fx = 0.08345238095238094\n",
      "DEBUG:shap:self.link(self.fx) = 0.08345238095238094\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.18009842, -0.01965786, -0.00027276, -0.10866598, -0.00720739,\n",
      "       -0.01294265, -0.03504629,  0.01761941, -0.00559714, -0.0106921 ,\n",
      "       -0.01058359, -0.02451364, -0.0016636 , -0.12087392, -0.02460338])\n",
      " 26%|██▌       | 19/74 [00:29<01:25,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.26707276400981556)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2790816326530612\n",
      "DEBUG:shap:self.fx = 0.09266666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.09266666666666666\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11708746, -0.01394733, -0.01128806, -0.03648548,  0.00259539,\n",
      "        0.00335341,  0.03154906, -0.02992514,  0.00119192, -0.00511411,\n",
      "       -0.00457455, -0.03225602, -0.00390888, -0.05117551, -0.01200887])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2670727640098154)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2790816326530611\n",
      "DEBUG:shap:self.fx = 0.9073333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.9073333333333333\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11708746,  0.01394733,  0.01128806,  0.03648548, -0.00259539,\n",
      "       -0.00335341, -0.03154906,  0.02992514, -0.00119192,  0.00511411,\n",
      "        0.00457455,  0.03225602,  0.00390888,  0.05117551,  0.01200887])\n",
      " 27%|██▋       | 20/74 [00:31<01:23,  1.55s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3063528633834653)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3135850340136055\n",
      "DEBUG:shap:self.fx = 0.6853333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.6853333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.15575559,  0.01808418, -0.00346153,  0.08155099, -0.00706751,\n",
      "        0.0185956 ,  0.04110765, -0.02317519, -0.01687577,  0.00688081,\n",
      "       -0.01451555,  0.00902974,  0.010592  ,  0.02985185,  0.00723217])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.30635286338346546)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3135850340136056\n",
      "DEBUG:shap:self.fx = 0.31466666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.31466666666666665\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.15575559, -0.01808418,  0.00346153, -0.08155099,  0.00706751,\n",
      "       -0.0185956 , -0.04110765,  0.02317519,  0.01687577, -0.00688081,\n",
      "        0.01451555, -0.00902974, -0.010592  , -0.02985185, -0.00723217])\n",
      " 28%|██▊       | 21/74 [00:32<01:22,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.15122817577515654)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08974829931972789\n",
      "DEBUG:shap:self.fx = 0.282\n",
      "DEBUG:shap:self.link(self.fx) = 0.282\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09343917,  0.01166516, -0.0091298 , -0.05826838,  0.02087435,\n",
      "       -0.00146487, -0.04293046, -0.02911472,  0.00725146,  0.01688537,\n",
      "       -0.00023239, -0.03917219, -0.00120458,  0.06705203,  0.06147988])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1512281757751564)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08974829931972783\n",
      "DEBUG:shap:self.fx = 0.7180000000000001\n",
      "DEBUG:shap:self.link(self.fx) = 0.7180000000000001\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09343917, -0.01166516,  0.0091298 ,  0.05826838, -0.02087435,\n",
      "        0.00146487,  0.04293046,  0.02911472, -0.00725146, -0.01688537,\n",
      "        0.00023239,  0.03917219,  0.00120458, -0.06705203, -0.06147988])\n",
      " 30%|██▉       | 22/74 [00:34<01:19,  1.52s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2455838574367194)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2545816326530612\n",
      "DEBUG:shap:self.fx = 0.11716666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.11716666666666666\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11885325, -0.04752466, -0.0035902 , -0.06718088, -0.00453527,\n",
      "       -0.01778985,  0.00841598, -0.02248294, -0.00603286,  0.01073809,\n",
      "        0.        ,  0.        , -0.00013584,  0.02338782, -0.00899778])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.24558385743671915)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2545816326530609\n",
      "DEBUG:shap:self.fx = 0.8828333333333331\n",
      "DEBUG:shap:self.link(self.fx) = 0.8828333333333331\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11885325,  0.04752466,  0.0035902 ,  0.06718088,  0.00453527,\n",
      "        0.01778985, -0.00841598,  0.02248294,  0.00603286, -0.01073809,\n",
      "        0.        ,  0.        ,  0.00013584, -0.02338782,  0.00899778])\n",
      " 31%|███       | 23/74 [00:35<01:19,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.26345602115989386)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.27191496598639453\n",
      "DEBUG:shap:self.fx = 0.09983333333333336\n",
      "DEBUG:shap:self.link(self.fx) = 0.09983333333333336\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.03433486,  0.0218714 , -0.0092973 , -0.05723357,  0.00822767,\n",
      "       -0.01227147, -0.06750976, -0.02152541,  0.00741855, -0.01131239,\n",
      "       -0.00521417, -0.04390843,  0.00253016, -0.04089644, -0.00845894])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.26345602115989386)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.27191496598639453\n",
      "DEBUG:shap:self.fx = 0.9001666666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.9001666666666668\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.03433486, -0.0218714 ,  0.0092973 ,  0.05723357, -0.00822767,\n",
      "        0.01227147,  0.06750976,  0.02152541, -0.00741855,  0.01131239,\n",
      "        0.00521417,  0.04390843, -0.00253016,  0.04089644,  0.00845894])\n",
      " 32%|███▏      | 24/74 [00:37<01:17,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.14857576920211546)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1704149659863945\n",
      "DEBUG:shap:self.fx = 0.20133333333333336\n",
      "DEBUG:shap:self.link(self.fx) = 0.20133333333333336\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09005233,  0.00358624, -0.00506936, -0.04154194,  0.00216245,\n",
      "        0.00248943,  0.02502292, -0.02689826,  0.00847892, -0.01020913,\n",
      "       -0.00616195, -0.04373799,  0.00191762,  0.03143762, -0.0218392 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.14857576920211538)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.17041496598639438\n",
      "DEBUG:shap:self.fx = 0.7986666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.7986666666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09005233, -0.00358624,  0.00506936,  0.04154194, -0.00216245,\n",
      "       -0.00248943, -0.02502292,  0.02689826, -0.00847892,  0.01020913,\n",
      "        0.00616195,  0.04373799, -0.00191762, -0.03143762,  0.0218392 ])\n",
      " 34%|███▍      | 25/74 [00:39<01:16,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1322134843474819)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08991496598639453\n",
      "DEBUG:shap:self.fx = 0.2818333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.2818333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09750694, -0.02722721, -0.010495  , -0.0472232 ,  0.02636277,\n",
      "       -0.01199316,  0.01348349, -0.03954219, -0.03031337,  0.00223164,\n",
      "       -0.00049616,  0.00643304, -0.00302898,  0.0871018 ,  0.04229852])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.13221348434748162)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08991496598639426\n",
      "DEBUG:shap:self.fx = 0.7181666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.7181666666666665\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09750694,  0.02722721,  0.010495  ,  0.0472232 , -0.02636277,\n",
      "        0.01199316, -0.01348349,  0.03954219,  0.03031337, -0.00223164,\n",
      "        0.00049616, -0.00643304,  0.00302898, -0.0871018 , -0.04229852])\n",
      " 35%|███▌      | 26/74 [00:40<01:13,  1.53s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2885799441606462)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3129183673469388\n",
      "DEBUG:shap:self.fx = 0.6846666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.6846666666666666\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.13423834, -0.04036735, -0.01681409,  0.08990997, -0.00295196,\n",
      "        0.01888468,  0.0292638 ,  0.        ,  0.00397199, -0.00369582,\n",
      "        0.0024605 ,  0.00352224,  0.04133966,  0.02881798,  0.02433842])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2885799441606463)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3129183673469389\n",
      "DEBUG:shap:self.fx = 0.31533333333333335\n",
      "DEBUG:shap:self.link(self.fx) = 0.31533333333333335\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.13423834,  0.04036735,  0.01681409, -0.08990997,  0.00295196,\n",
      "       -0.01888468, -0.0292638 ,  0.        , -0.00397199,  0.00369582,\n",
      "       -0.0024605 , -0.00352224, -0.04133966, -0.02881798, -0.02433842])\n",
      " 36%|███▋      | 27/74 [00:42<01:13,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.12664471890951473)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.1217482993197278\n",
      "DEBUG:shap:self.fx = 0.25000000000000006\n",
      "DEBUG:shap:self.link(self.fx) = 0.25000000000000006\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.04814911, -0.03377092,  0.01207968, -0.05480828,  0.00108036,\n",
      "        0.02144919,  0.01859001, -0.01777812,  0.01587015, -0.00764263,\n",
      "       -0.00299708,  0.00927959, -0.00412468, -0.03572286,  0.00489642])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12664471890951462)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12174829931972775\n",
      "DEBUG:shap:self.fx = 0.75\n",
      "DEBUG:shap:self.link(self.fx) = 0.75\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.04814911,  0.03377092, -0.01207968,  0.05480828, -0.00108036,\n",
      "       -0.02144919, -0.01859001,  0.01777812, -0.01587015,  0.00764263,\n",
      "        0.00299708, -0.00927959,  0.00412468,  0.03572286, -0.00489642])\n",
      " 38%|███▊      | 28/74 [00:43<01:10,  1.52s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2211018161557584)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21175170068027216\n",
      "DEBUG:shap:self.fx = 0.5835\n",
      "DEBUG:shap:self.link(self.fx) = 0.5835\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.17929505,  0.00850604,  0.0038156 , -0.05272139,  0.00565324,\n",
      "        0.02302791, -0.05050367,  0.05854632, -0.00364274,  0.00047763,\n",
      "       -0.00246349,  0.00203097, -0.0031982 ,  0.05227856, -0.00935012])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22110181615575847)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21175170068027221\n",
      "DEBUG:shap:self.fx = 0.41650000000000004\n",
      "DEBUG:shap:self.link(self.fx) = 0.41650000000000004\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.17929505, -0.00850604, -0.0038156 ,  0.05272139, -0.00565324,\n",
      "       -0.02302791,  0.05050367, -0.05854632,  0.00364274, -0.00047763,\n",
      "        0.00246349, -0.00203097,  0.0031982 , -0.05227856,  0.00935012])\n",
      " 39%|███▉      | 29/74 [00:45<01:09,  1.54s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.29358292990927437)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.30608503401360543\n",
      "DEBUG:shap:self.fx = 0.6778333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.6778333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.13990353,  0.01018081,  0.00500294,  0.08446167, -0.00168559,\n",
      "        0.01598277,  0.04051385,  0.05946508,  0.00329758, -0.00729721,\n",
      "        0.00399395,  0.00297268,  0.00713281, -0.07034195,  0.0125021 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2935829299092745)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.30608503401360554\n",
      "DEBUG:shap:self.fx = 0.3221666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.3221666666666667\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.13990353, -0.01018081, -0.00500294, -0.08446167,  0.00168559,\n",
      "       -0.01598277, -0.04051385, -0.05946508, -0.00329758,  0.00729721,\n",
      "       -0.00399395, -0.00297268, -0.00713281,  0.07034195, -0.0125021 ])\n",
      " 41%|████      | 30/74 [00:46<01:09,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22314307446596493)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2300816326530612\n",
      "DEBUG:shap:self.fx = 0.14166666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.14166666666666666\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.0956545 ,  0.00932192,  0.01215306, -0.08508521, -0.00154379,\n",
      "       -0.01971262,  0.02402587, -0.0371302 ,  0.00746485,  0.0014365 ,\n",
      "        0.00166516,  0.00065648, -0.00592711, -0.03481348, -0.00693856])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22314307446596485)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.23008163265306114\n",
      "DEBUG:shap:self.fx = 0.8583333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.8583333333333334\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.0956545 , -0.00932192, -0.01215306,  0.08508521,  0.00154379,\n",
      "        0.01971262, -0.02402587,  0.0371302 , -0.00746485, -0.0014365 ,\n",
      "       -0.00166516, -0.00065648,  0.00592711,  0.03481348,  0.00693856])\n",
      " 42%|████▏     | 31/74 [00:48<01:09,  1.61s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23781775927307505)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2550816326530612\n",
      "DEBUG:shap:self.fx = 0.11666666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.11666666666666665\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.07172484,  0.01263325, -0.02025343, -0.04520544, -0.00429542,\n",
      "       -0.01384846, -0.06464923, -0.02505394,  0.01933714, -0.00055956,\n",
      "       -0.00120269, -0.02879552,  0.03396295, -0.02816257, -0.01726387])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23781775927307486)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.25508163265306105\n",
      "DEBUG:shap:self.fx = 0.8833333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.8833333333333333\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.07172484, -0.01263325,  0.02025343,  0.04520544,  0.00429542,\n",
      "        0.01384846,  0.06464923,  0.02505394, -0.01933714,  0.00055956,\n",
      "        0.00120269,  0.02879552, -0.03396295,  0.02816257,  0.01726387])\n",
      " 43%|████▎     | 32/74 [00:50<01:07,  1.61s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3461956953140066)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.37325170068027214\n",
      "DEBUG:shap:self.fx = 0.745\n",
      "DEBUG:shap:self.link(self.fx) = 0.745\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.15036366,  0.00977561,  0.00781177, -0.04800973,  0.00072869,\n",
      "       -0.01636474,  0.01038794,  0.10769422,  0.01077027,  0.00223347,\n",
      "       -0.01208534,  0.00617931,  0.00751652,  0.10919404,  0.02705601])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3461956953140067)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3732517006802722\n",
      "DEBUG:shap:self.fx = 0.25500000000000006\n",
      "DEBUG:shap:self.link(self.fx) = 0.25500000000000006\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.15036366, -0.00977561, -0.00781177,  0.04800973, -0.00072869,\n",
      "        0.01636474, -0.01038794, -0.10769422, -0.01077027, -0.00223347,\n",
      "        0.01208534, -0.00617931, -0.00751652, -0.10919404, -0.02705601])\n",
      " 45%|████▍     | 33/74 [00:51<01:04,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.14232692697980576)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.16641496598639452\n",
      "DEBUG:shap:self.fx = 0.20533333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.20533333333333334\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11610724,  0.01004985,  0.01178445, -0.04951427, -0.00301262,\n",
      "        0.00333485, -0.02022163, -0.0452226 ,  0.00298838,  0.00036024,\n",
      "        0.01394642,  0.00872355, -0.00022069,  0.04078439, -0.02408804])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1423269269798056)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16641496598639438\n",
      "DEBUG:shap:self.fx = 0.7946666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.7946666666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11610724, -0.01004985, -0.01178445,  0.04951427,  0.00301262,\n",
      "       -0.00333485,  0.02022163,  0.0452226 , -0.00298838, -0.00036024,\n",
      "       -0.01394642, -0.00872355,  0.00022069, -0.04078439,  0.02408804])\n",
      " 46%|████▌     | 34/74 [00:53<01:03,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.31209298889952347)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.30091496598639456\n",
      "DEBUG:shap:self.fx = 0.07083333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.07083333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09317254, -0.04509793,  0.01322575, -0.04996002, -0.0034409 ,\n",
      "       -0.01191426, -0.03160223, -0.02401186,  0.00773593, -0.00824648,\n",
      "       -0.00926695, -0.0002987 , -0.00173692, -0.05430588,  0.01117802])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3120929888995233)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.30091496598639444\n",
      "DEBUG:shap:self.fx = 0.9291666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.9291666666666667\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09317254,  0.04509793, -0.01322575,  0.04996002,  0.0034409 ,\n",
      "        0.01191426,  0.03160223,  0.02401186, -0.00773593,  0.00824648,\n",
      "        0.00926695,  0.0002987 ,  0.00173692,  0.05430588, -0.01117802])\n",
      " 47%|████▋     | 35/74 [00:54<01:01,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.021525101971173924)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.016835034013605477\n",
      "DEBUG:shap:self.fx = 0.38858333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.38858333333333334\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.10192637,  0.02527886,  0.00899208, -0.01543566, -0.00493224,\n",
      "        0.01710971, -0.02785973, -0.05497851, -0.00445173,  0.0318478 ,\n",
      "       -0.00939199,  0.01260268,  0.02629285, -0.08547538, -0.00469007])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.02152510197117409)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.016835034013605643\n",
      "DEBUG:shap:self.fx = 0.6114166666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.6114166666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.10192637, -0.02527886, -0.00899208,  0.01543566,  0.00493224,\n",
      "       -0.01710971,  0.02785973,  0.05497851,  0.00445173, -0.0318478 ,\n",
      "        0.00939199, -0.01260268, -0.02629285,  0.08547538,  0.00469007])\n",
      " 49%|████▊     | 36/74 [00:56<00:59,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.10011276320981208)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09558163265306124\n",
      "DEBUG:shap:self.fx = 0.2761666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.2761666666666666\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.08754141, -0.04662807,  0.00144615,  0.08261713,  0.0074758 ,\n",
      "        0.01144465,  0.01125674, -0.0555585 ,  0.00968723, -0.01573967,\n",
      "        0.00695832,  0.01428736, -0.00444728, -0.03537119,  0.00453113])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.10011276320981184)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09558163265306097\n",
      "DEBUG:shap:self.fx = 0.7238333333333332\n",
      "DEBUG:shap:self.link(self.fx) = 0.7238333333333332\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.08754141,  0.04662807, -0.00144615, -0.08261713, -0.0074758 ,\n",
      "       -0.01144465, -0.01125674,  0.0555585 , -0.00968723,  0.01573967,\n",
      "       -0.00695832, -0.01428736,  0.00444728,  0.03537119, -0.00453113])\n",
      " 50%|█████     | 37/74 [00:57<00:58,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.32561677437234965)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3355816326530612\n",
      "DEBUG:shap:self.fx = 0.036166666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.036166666666666666\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09439887,  0.00068138, -0.0017217 , -0.06444742,  0.00466266,\n",
      "       -0.00433041, -0.03458193, -0.03624964, -0.00935436, -0.00337801,\n",
      "       -0.00306116, -0.03923604,  0.00575364, -0.04595492, -0.00996486])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3256167743723496)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.33558163265306096\n",
      "DEBUG:shap:self.fx = 0.9638333333333332\n",
      "DEBUG:shap:self.link(self.fx) = 0.9638333333333332\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09439887, -0.00068138,  0.0017217 ,  0.06444742, -0.00466266,\n",
      "        0.00433041,  0.03458193,  0.03624964,  0.00935436,  0.00337801,\n",
      "        0.00306116,  0.03923604, -0.00575364,  0.04595492,  0.00996486])\n",
      " 51%|█████▏    | 38/74 [00:59<00:56,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.002805158194732142)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.003918367346938789\n",
      "DEBUG:shap:self.fx = 0.37566666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.37566666666666665\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.12184968, -0.08064635, -0.00662464,  0.03242424, -0.0190746 ,\n",
      "        0.00130413,  0.02943652, -0.03203231, -0.00555248, -0.0172555 ,\n",
      "       -0.00623785,  0.00940109, -0.00045286, -0.02373391,  0.00111321])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.002805158194732267)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.003918367346938845\n",
      "DEBUG:shap:self.fx = 0.6243333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.6243333333333334\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.12184968,  0.08064635,  0.00662464, -0.03242424,  0.0190746 ,\n",
      "       -0.00130413, -0.02943652,  0.03203231,  0.00555248,  0.0172555 ,\n",
      "        0.00623785, -0.00940109,  0.00045286,  0.02373391, -0.00111321])\n",
      " 53%|█████▎    | 39/74 [01:01<00:55,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.303124731716052)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2979183673469388\n",
      "DEBUG:shap:self.fx = 0.6696666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.6696666666666666\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.15344308,  0.01796938, -0.01534118,  0.06693753, -0.00330203,\n",
      "        0.00585347,  0.03425206,  0.02041249,  0.00942773,  0.02330193,\n",
      "       -0.00170744, -0.06024434, -0.02610491,  0.07822694, -0.00520636])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.30312473171605214)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.29791836734693894\n",
      "DEBUG:shap:self.fx = 0.3303333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.3303333333333333\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.15344308, -0.01796938,  0.01534118, -0.06693753,  0.00330203,\n",
      "       -0.00585347, -0.03425206, -0.02041249, -0.00942773, -0.02330193,\n",
      "        0.00170744,  0.06024434,  0.02610491, -0.07822694,  0.00520636])\n",
      " 54%|█████▍    | 40/74 [01:02<00:52,  1.54s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20359570576579625)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.21224829931972786\n",
      "DEBUG:shap:self.fx = 0.1595\n",
      "DEBUG:shap:self.link(self.fx) = 0.1595\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11580454, -0.00347705,  0.00435692,  0.06578613, -0.00516043,\n",
      "       -0.01056677, -0.05742093, -0.03285687, -0.00225562, -0.00434243,\n",
      "       -0.00289165, -0.05770075, -0.00237387,  0.02111215, -0.00865259])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2035957057657962)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.21224829931972777\n",
      "DEBUG:shap:self.fx = 0.8405\n",
      "DEBUG:shap:self.link(self.fx) = 0.8405\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11580454,  0.00347705, -0.00435692, -0.06578613,  0.00516043,\n",
      "        0.01056677,  0.05742093,  0.03285687,  0.00225562,  0.00434243,\n",
      "        0.00289165,  0.05770075,  0.00237387, -0.02111215,  0.00865259])\n",
      " 55%|█████▌    | 41/74 [01:04<00:51,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.23908285199445392)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2579149659863945\n",
      "DEBUG:shap:self.fx = 0.11383333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.11383333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09115651, -0.00370007, -0.0182177 , -0.04958034,  0.00704925,\n",
      "        0.05352608, -0.03515839, -0.01721345,  0.00538503, -0.0106183 ,\n",
      "       -0.00162352, -0.03987863,  0.00578115, -0.04367746, -0.01883211])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.23908285199445384)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.2579149659863943\n",
      "DEBUG:shap:self.fx = 0.8861666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.8861666666666665\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09115651,  0.00370007,  0.0182177 ,  0.04958034, -0.00704925,\n",
      "       -0.05352608,  0.03515839,  0.01721345, -0.00538503,  0.0106183 ,\n",
      "        0.00162352,  0.03987863, -0.00578115,  0.04367746,  0.01883211])\n",
      " 57%|█████▋    | 42/74 [01:05<00:49,  1.55s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.04485170256355146)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.03829931972789119\n",
      "DEBUG:shap:self.fx = 0.41004761904761905\n",
      "DEBUG:shap:self.link(self.fx) = 0.41004761904761905\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.10480366,  0.00927709,  0.01715181,  0.06829773,  0.        ,\n",
      "        0.00319974,  0.02814761, -0.04182373, -0.03934664,  0.03243696,\n",
      "        0.00155238,  0.00695246, -0.03949122, -0.10630613, -0.00655238])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.044851702563551615)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.03829931972789136\n",
      "DEBUG:shap:self.fx = 0.5899523809523809\n",
      "DEBUG:shap:self.link(self.fx) = 0.5899523809523809\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.10480366, -0.00927709, -0.01715181, -0.06829773,  0.        ,\n",
      "       -0.00319974, -0.02814761,  0.04182373,  0.03934664, -0.03243696,\n",
      "       -0.00155238, -0.00695246,  0.03949122,  0.10630613,  0.00655238])\n",
      " 58%|█████▊    | 43/74 [01:07<00:49,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.18284141290571532)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.17341496598639453\n",
      "DEBUG:shap:self.fx = 0.19833333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.19833333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.08049481,  0.00704081, -0.01295203,  0.04383964, -0.0008958 ,\n",
      "        0.01367274,  0.03602829, -0.02470212, -0.02024999, -0.01236695,\n",
      "       -0.00631596, -0.07690081, -0.00428001, -0.04426441,  0.00942645])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1828414129057153)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1734149659863945\n",
      "DEBUG:shap:self.fx = 0.8016666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.8016666666666667\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.08049481, -0.00704081,  0.01295203, -0.04383964,  0.0008958 ,\n",
      "       -0.01367274, -0.03602829,  0.02470212,  0.02024999,  0.01236695,\n",
      "        0.00631596,  0.07690081,  0.00428001,  0.04426441, -0.00942645])\n",
      " 59%|█████▉    | 44/74 [01:08<00:47,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.39794996491398565)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.41791836734693866\n",
      "DEBUG:shap:self.fx = 0.7896666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.7896666666666665\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.17093307,  0.01700972,  0.00917045,  0.06852474,  0.00648062,\n",
      "        0.02537013,  0.03913088,  0.01285106, -0.00913553, -0.02011753,\n",
      "        0.00495486,  0.00445642,  0.00633574,  0.06198535,  0.0199684 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.39794996491398593)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4179183673469389\n",
      "DEBUG:shap:self.fx = 0.21033333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.21033333333333334\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.17093307, -0.01700972, -0.00917045, -0.06852474, -0.00648062,\n",
      "       -0.02537013, -0.03913088, -0.01285106,  0.00913553,  0.02011753,\n",
      "       -0.00495486, -0.00445642, -0.00633574, -0.06198535, -0.0199684 ])\n",
      " 61%|██████    | 45/74 [01:10<00:45,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3417970833173726)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3500816326530612\n",
      "DEBUG:shap:self.fx = 0.021666666666666664\n",
      "DEBUG:shap:self.link(self.fx) = 0.021666666666666664\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.1212136 , -0.01761257, -0.00152657, -0.0701032 , -0.00391711,\n",
      "       -0.01096778, -0.04300141, -0.02790209, -0.01790188, -0.00414042,\n",
      "        0.00893578,  0.00281973, -0.00138791, -0.03387806, -0.00828455])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.34179708331737246)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.350081632653061\n",
      "DEBUG:shap:self.fx = 0.9783333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.9783333333333333\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.1212136 ,  0.01761257,  0.00152657,  0.0701032 ,  0.00391711,\n",
      "        0.01096778,  0.04300141,  0.02790209,  0.01790188,  0.00414042,\n",
      "       -0.00893578, -0.00281973,  0.00138791,  0.03387806,  0.00828455])\n",
      " 62%|██████▏   | 46/74 [01:12<00:45,  1.61s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.15656183188751233)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.14632312925170077\n",
      "DEBUG:shap:self.fx = 0.5180714285714286\n",
      "DEBUG:shap:self.link(self.fx) = 0.5180714285714286\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.14909909,  0.00966123,  0.00828076, -0.04329159, -0.00236916,\n",
      "       -0.03116619,  0.04715798,  0.04978387,  0.00484322, -0.00254661,\n",
      "        0.00326703, -0.00604431,  0.00493918, -0.03505267, -0.0102387 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.15656183188751244)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.14632312925170088\n",
      "DEBUG:shap:self.fx = 0.4819285714285714\n",
      "DEBUG:shap:self.link(self.fx) = 0.4819285714285714\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.14909909, -0.00966123, -0.00828076,  0.04329159,  0.00236916,\n",
      "        0.03116619, -0.04715798, -0.04978387, -0.00484322,  0.00254661,\n",
      "       -0.00326703,  0.00604431, -0.00493918,  0.03505267,  0.0102387 ])\n",
      " 64%|██████▎   | 47/74 [01:13<00:42,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.45707994517989353)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.47408503401360524\n",
      "DEBUG:shap:self.fx = 0.8458333333333331\n",
      "DEBUG:shap:self.link(self.fx) = 0.8458333333333331\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.15625524,  0.02154092,  0.00294267,  0.08277451, -0.01708655,\n",
      "        0.00753977,  0.03830574,  0.03587369, -0.00383908,  0.00258783,\n",
      "       -0.00485093,  0.02426216,  0.00678241,  0.10399156,  0.01700509])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.45707994517989387)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4740850340136056\n",
      "DEBUG:shap:self.fx = 0.15416666666666665\n",
      "DEBUG:shap:self.link(self.fx) = 0.15416666666666665\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.15625524, -0.02154092, -0.00294267, -0.08277451,  0.01708655,\n",
      "       -0.00753977, -0.03830574, -0.03587369,  0.00383908, -0.00258783,\n",
      "        0.00485093, -0.02426216, -0.00678241, -0.10399156, -0.01700509])\n",
      " 65%|██████▍   | 48/74 [01:15<00:40,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.10933235222234487)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.12741496598639449\n",
      "DEBUG:shap:self.fx = 0.24433333333333337\n",
      "DEBUG:shap:self.link(self.fx) = 0.24433333333333337\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09740048, -0.0545362 ,  0.00031001, -0.08256005, -0.00716733,\n",
      "       -0.00666258,  0.02332838,  0.00731871,  0.00498593,  0.01556013,\n",
      "       -0.00239758,  0.01917593,  0.        ,  0.07071278, -0.01808261])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(15.0)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.109332352222345)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12741496598639457\n",
      "DEBUG:shap:self.fx = 0.7556666666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.7556666666666668\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09740048,  0.0545362 , -0.00031001,  0.08256005,  0.00716733,\n",
      "        0.00666258, -0.02332838, -0.00731871, -0.00498593, -0.01556013,\n",
      "        0.00239758, -0.01917593,  0.        , -0.07071278,  0.01808261])\n",
      " 66%|██████▌   | 49/74 [01:16<00:39,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09497872408352047)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.07641496598639447\n",
      "DEBUG:shap:self.fx = 0.2953333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.2953333333333334\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.02655415,  0.0493529 ,  0.00480645, -0.03190666,  0.        ,\n",
      "       -0.02544346, -0.04899071, -0.02833533, -0.0133564 ,  0.00746104,\n",
      "       -0.00155972,  0.01291083,  0.00353276,  0.00310372,  0.01856376])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.09497872408352047)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.07641496598639452\n",
      "DEBUG:shap:self.fx = 0.7046666666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.7046666666666668\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.02655415, -0.0493529 , -0.00480645,  0.03190666,  0.        ,\n",
      "        0.02544346,  0.04899071,  0.02833533,  0.0133564 , -0.00746104,\n",
      "        0.00155972, -0.01291083, -0.00353276, -0.00310372, -0.01856376])\n",
      " 68%|██████▊   | 50/74 [01:18<00:38,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.10757686794715283)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.11674829931972791\n",
      "DEBUG:shap:self.fx = 0.25499999999999995\n",
      "DEBUG:shap:self.link(self.fx) = 0.25499999999999995\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.11591505,  0.00668199,  0.01323183, -0.04375233,  0.00160269,\n",
      "        0.0193698 ,  0.00885315,  0.03085374, -0.02869321, -0.00273951,\n",
      "        0.00093625,  0.01870531, -0.00489132, -0.0118202 , -0.00917143])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.10757686794715272)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.11674829931972774\n",
      "DEBUG:shap:self.fx = 0.745\n",
      "DEBUG:shap:self.link(self.fx) = 0.745\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.11591505, -0.00668199, -0.01323183,  0.04375233, -0.00160269,\n",
      "       -0.0193698 , -0.00885315, -0.03085374,  0.02869321,  0.00273951,\n",
      "       -0.00093625, -0.01870531,  0.00489132,  0.0118202 ,  0.00917143])\n",
      " 69%|██████▉   | 51/74 [01:20<00:36,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.47265699461208704)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.49832312925170064\n",
      "DEBUG:shap:self.fx = 0.8700714285714285\n",
      "DEBUG:shap:self.link(self.fx) = 0.8700714285714285\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.17710259,  0.01906431, -0.00181794,  0.07333722, -0.00058121,\n",
      "        0.01640646,  0.03352397, -0.00894458,  0.00726558, -0.01396734,\n",
      "        0.0096421 ,  0.03191026,  0.00942794,  0.12028762,  0.02566613])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4726569946120872)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4983231292517008\n",
      "DEBUG:shap:self.fx = 0.12992857142857145\n",
      "DEBUG:shap:self.link(self.fx) = 0.12992857142857145\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.17710259, -0.01906431,  0.00181794, -0.07333722,  0.00058121,\n",
      "       -0.01640646, -0.03352397,  0.00894458, -0.00726558,  0.01396734,\n",
      "       -0.0096421 , -0.03191026, -0.00942794, -0.12028762, -0.02566613])\n",
      " 70%|███████   | 52/74 [01:21<00:34,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.22050828379125773)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2408673469387755\n",
      "DEBUG:shap:self.fx = 0.13088095238095235\n",
      "DEBUG:shap:self.link(self.fx) = 0.13088095238095235\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.02927437,  0.03731584, -0.0114491 , -0.04268555, -0.00388492,\n",
      "        0.00411464, -0.07148773,  0.01130689, -0.03193508, -0.0007176 ,\n",
      "       -0.00122751, -0.05420366,  0.00976431, -0.03614444, -0.02035906])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.22050828379125761)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.24086734693877543\n",
      "DEBUG:shap:self.fx = 0.8691190476190477\n",
      "DEBUG:shap:self.link(self.fx) = 0.8691190476190477\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.02927437, -0.03731584,  0.0114491 ,  0.04268555,  0.00388492,\n",
      "       -0.00411464,  0.07148773, -0.01130689,  0.03193508,  0.0007176 ,\n",
      "        0.00122751,  0.05420366, -0.00976431,  0.03614444,  0.02035906])\n",
      " 72%|███████▏  | 53/74 [01:23<00:32,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.16600551450460493)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.152608843537415\n",
      "DEBUG:shap:self.fx = 0.5243571428571429\n",
      "DEBUG:shap:self.link(self.fx) = 0.5243571428571429\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.11794061, -0.06382482, -0.00859732,  0.07833154,  0.00166132,\n",
      "        0.01781099,  0.01637269,  0.02418206,  0.0090508 , -0.01005285,\n",
      "        0.00409265,  0.01151635,  0.05255974, -0.08503823, -0.01339667])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1660055145046051)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.15260884353741516\n",
      "DEBUG:shap:self.fx = 0.4756428571428571\n",
      "DEBUG:shap:self.link(self.fx) = 0.4756428571428571\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.11794061,  0.06382482,  0.00859732, -0.07833154, -0.00166132,\n",
      "       -0.01781099, -0.01637269, -0.02418206, -0.0090508 ,  0.01005285,\n",
      "       -0.00409265, -0.01151635, -0.05255974,  0.08503823,  0.01339667])\n",
      " 73%|███████▎  | 54/74 [01:24<00:31,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03869667106370884)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.03968027210884362\n",
      "DEBUG:shap:self.fx = 0.4114285714285715\n",
      "DEBUG:shap:self.link(self.fx) = 0.4114285714285715\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.10538691, -0.00428947, -0.01576907,  0.09194053, -0.00587336,\n",
      "       -0.01103237, -0.09146047,  0.0493213 , -0.0004569 ,  0.01372851,\n",
      "        0.0023    , -0.0619357 ,  0.01425872, -0.04742196,  0.0009836 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.03869667106370874)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.03968027210884362\n",
      "DEBUG:shap:self.fx = 0.5885714285714286\n",
      "DEBUG:shap:self.link(self.fx) = 0.5885714285714286\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.10538691,  0.00428947,  0.01576907, -0.09194053,  0.00587336,\n",
      "        0.01103237,  0.09146047, -0.0493213 ,  0.0004569 , -0.01372851,\n",
      "       -0.0023    ,  0.0619357 , -0.01425872,  0.04742196, -0.0009836 ])\n",
      " 74%|███████▍  | 55/74 [01:26<00:29,  1.55s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.2113542268149965)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.22674829931972787\n",
      "DEBUG:shap:self.fx = 0.145\n",
      "DEBUG:shap:self.link(self.fx) = 0.145\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.10128943,  0.02904215, -0.00385651, -0.03271691, -0.0037791 ,\n",
      "        0.03793275, -0.03568635, -0.02108145, -0.00346636,  0.008204  ,\n",
      "        0.        , -0.04213493, -0.00407302, -0.03844905, -0.01539407])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.2113542268149963)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.22674829931972773\n",
      "DEBUG:shap:self.fx = 0.855\n",
      "DEBUG:shap:self.link(self.fx) = 0.855\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.10128943, -0.02904215,  0.00385651,  0.03271691,  0.0037791 ,\n",
      "       -0.03793275,  0.03568635,  0.02108145,  0.00346636, -0.008204  ,\n",
      "        0.        ,  0.04213493,  0.00407302,  0.03844905,  0.01539407])\n",
      " 76%|███████▌  | 56/74 [01:27<00:28,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.3257134068929368)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.32508503401360567\n",
      "DEBUG:shap:self.fx = 0.6968333333333335\n",
      "DEBUG:shap:self.link(self.fx) = 0.6968333333333335\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.1392561 ,  0.01352148, -0.01183004,  0.1133532 , -0.00489172,\n",
      "       -0.0043735 ,  0.03567315,  0.04083854,  0.00598567,  0.0109639 ,\n",
      "        0.01471559,  0.00672702,  0.01819799, -0.05242398, -0.00062837])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.32571340689293676)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3250850340136056\n",
      "DEBUG:shap:self.fx = 0.30316666666666664\n",
      "DEBUG:shap:self.link(self.fx) = 0.30316666666666664\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.1392561 , -0.01352148,  0.01183004, -0.1133532 ,  0.00489172,\n",
      "        0.0043735 , -0.03567315, -0.04083854, -0.00598567, -0.0109639 ,\n",
      "       -0.01471559, -0.00672702, -0.01819799,  0.05242398,  0.00062837])\n",
      " 77%|███████▋  | 57/74 [01:29<00:26,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1939641831192978)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.16565646258503408\n",
      "DEBUG:shap:self.fx = 0.5374047619047619\n",
      "DEBUG:shap:self.link(self.fx) = 0.5374047619047619\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.14896201,  0.01654118, -0.00870659, -0.05614687, -0.00113952,\n",
      "        0.02258819, -0.00425598, -0.0196131 , -0.00129858, -0.00472896,\n",
      "        0.00867088,  0.00593152,  0.00451417,  0.08264584, -0.02830772])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19396418311929778)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.16565646258503414\n",
      "DEBUG:shap:self.fx = 0.4625952380952381\n",
      "DEBUG:shap:self.link(self.fx) = 0.4625952380952381\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.14896201, -0.01654118,  0.00870659,  0.05614687,  0.00113952,\n",
      "       -0.02258819,  0.00425598,  0.0196131 ,  0.00129858,  0.00472896,\n",
      "       -0.00867088, -0.00593152, -0.00451417, -0.08264584,  0.02830772])\n",
      " 78%|███████▊  | 58/74 [01:30<00:24,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.07425646741345723)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.08491496598639448\n",
      "DEBUG:shap:self.fx = 0.2868333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.2868333333333334\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.13934238,  0.0014165 ,  0.01551716, -0.05268427, -0.00574221,\n",
      "       -0.01134773,  0.02134887,  0.02630061, -0.00972008,  0.01596032,\n",
      "        0.0082011 , -0.0060214 , -0.00798135,  0.06983842, -0.0106585 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.07425646741345715)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.08491496598639436\n",
      "DEBUG:shap:self.fx = 0.7131666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.7131666666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.13934238, -0.0014165 , -0.01551716,  0.05268427,  0.00574221,\n",
      "        0.01134773, -0.02134887, -0.02630061,  0.00972008, -0.01596032,\n",
      "       -0.0082011 ,  0.0060214 ,  0.00798135, -0.06983842,  0.0106585 ])\n",
      " 80%|███████▉  | 59/74 [01:32<00:23,  1.54s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.43980763470388107)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.45708503401360556\n",
      "DEBUG:shap:self.fx = 0.8288333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.8288333333333334\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.16537643,  0.02905642,  0.00685094,  0.09659151, -0.01052096,\n",
      "        0.0190793 ,  0.04605745,  0.06023099, -0.0020559 , -0.01168478,\n",
      "       -0.00851901,  0.00776275,  0.01598647,  0.02559601,  0.0172774 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4398076347038812)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.45708503401360556\n",
      "DEBUG:shap:self.fx = 0.17116666666666666\n",
      "DEBUG:shap:self.link(self.fx) = 0.17116666666666666\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.16537643, -0.02905642, -0.00685094, -0.09659151,  0.01052096,\n",
      "       -0.0190793 , -0.04605745, -0.06023099,  0.0020559 ,  0.01168478,\n",
      "        0.00851901, -0.00776275, -0.01598647, -0.02559601, -0.0172774 ])\n",
      " 81%|████████  | 60/74 [01:34<00:21,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.5076630468658899)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.5232517006802722\n",
      "DEBUG:shap:self.fx = 0.895\n",
      "DEBUG:shap:self.link(self.fx) = 0.895\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.1698968 ,  0.01291026, -0.00712957,  0.07217566,  0.00369345,\n",
      "        0.01853678,  0.03821367,  0.0352207 ,  0.01094727,  0.00056979,\n",
      "        0.00145847,  0.03330597, -0.00495247,  0.12281628,  0.01558865])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.5076630468658898)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.5232517006802723\n",
      "DEBUG:shap:self.fx = 0.105\n",
      "DEBUG:shap:self.link(self.fx) = 0.105\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.1698968 , -0.01291026,  0.00712957, -0.07217566, -0.00369345,\n",
      "       -0.01853678, -0.03821367, -0.0352207 , -0.01094727, -0.00056979,\n",
      "       -0.00145847, -0.03330597,  0.00495247, -0.12281628, -0.01558865])\n",
      " 82%|████████▏ | 61/74 [01:35<00:20,  1.60s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.03940693154852383)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.03758163265306119\n",
      "DEBUG:shap:self.fx = 0.33416666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.33416666666666667\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.10735504,  0.00885959, -0.01175366,  0.04419427,  0.00386958,\n",
      "        0.00119179,  0.02437186, -0.02352394, -0.01705807,  0.02413196,\n",
      "       -0.01252811, -0.08555417, -0.02496406, -0.077999  ,  0.0018253 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03940693154852387)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.03758163265306114\n",
      "DEBUG:shap:self.fx = 0.6658333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.6658333333333334\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.10735504, -0.00885959,  0.01175366, -0.04419427, -0.00386958,\n",
      "       -0.00119179, -0.02437186,  0.02352394,  0.01705807, -0.02413196,\n",
      "        0.01252811,  0.08555417,  0.02496406,  0.077999  , -0.0018253 ])\n",
      " 84%|████████▍ | 62/74 [01:37<00:19,  1.62s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.44213736169820234)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.440251700680272\n",
      "DEBUG:shap:self.fx = 0.8119999999999998\n",
      "DEBUG:shap:self.link(self.fx) = 0.8119999999999998\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.18557271,  0.01812339,  0.01011246,  0.07867425, -0.00535983,\n",
      "        0.00820573,  0.0411042 ,  0.03726626,  0.00344447, -0.01849403,\n",
      "       -0.00314524,  0.01953911, -0.02867147,  0.09576536, -0.00188566])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.4421373616982027)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.4402517006802722\n",
      "DEBUG:shap:self.fx = 0.18800000000000006\n",
      "DEBUG:shap:self.link(self.fx) = 0.18800000000000006\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.18557271, -0.01812339, -0.01011246, -0.07867425,  0.00535983,\n",
      "       -0.00820573, -0.0411042 , -0.03726626, -0.00344447,  0.01849403,\n",
      "        0.00314524, -0.01953911,  0.02867147, -0.09576536,  0.00188566])\n",
      " 85%|████████▌ | 63/74 [01:38<00:17,  1.61s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.18922113145488595)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.18458163265306118\n",
      "DEBUG:shap:self.fx = 0.18716666666666668\n",
      "DEBUG:shap:self.link(self.fx) = 0.18716666666666668\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.09953044,  0.00228871,  0.01008263, -0.05912462, -0.00363736,\n",
      "        0.0096333 ,  0.02857258,  0.01623924,  0.00219598, -0.00596404,\n",
      "       -0.00817483, -0.0282082 ,  0.00073614, -0.05433023,  0.0046395 ])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.18922113145488587)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.18458163265306105\n",
      "DEBUG:shap:self.fx = 0.8128333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.8128333333333333\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.09953044, -0.00228871, -0.01008263,  0.05912462,  0.00363736,\n",
      "       -0.0096333 , -0.02857258, -0.01623924, -0.00219598,  0.00596404,\n",
      "        0.00817483,  0.0282082 , -0.00073614,  0.05433023, -0.0046395 ])\n",
      " 86%|████████▋ | 64/74 [01:40<00:16,  1.60s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09357020846330628)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.10874829931972785\n",
      "DEBUG:shap:self.fx = 0.263\n",
      "DEBUG:shap:self.link(self.fx) = 0.263\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.12656307,  0.03121911,  0.01131731, -0.04063832, -0.00086287,\n",
      "       -0.00883342, -0.0659353 ,  0.01817348,  0.00825284,  0.00300667,\n",
      "       -0.00536017,  0.02861919, -0.00366525,  0.05769959, -0.01517809])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.09357020846330626)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.10874829931972774\n",
      "DEBUG:shap:self.fx = 0.737\n",
      "DEBUG:shap:self.link(self.fx) = 0.737\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.12656307, -0.03121911, -0.01131731,  0.04063832,  0.00086287,\n",
      "        0.00883342,  0.0659353 , -0.01817348, -0.00825284, -0.00300667,\n",
      "        0.00536017, -0.02861919,  0.00366525, -0.05769959,  0.01517809])\n",
      " 88%|████████▊ | 65/74 [01:42<00:14,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.19712735101468962)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.2200816326530612\n",
      "DEBUG:shap:self.fx = 0.15166666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.15166666666666667\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.13585452,  0.01517657,  0.00423061, -0.06930392,  0.00028698,\n",
      "       -0.01051895, -0.02951174, -0.03461129,  0.01386745, -0.00422496,\n",
      "       -0.00565233, -0.0102866 , -0.0037622 ,  0.07303755, -0.02295428])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1971273510146896)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.22008163265306102\n",
      "DEBUG:shap:self.fx = 0.8483333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.8483333333333333\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.13585452, -0.01517657, -0.00423061,  0.06930392, -0.00028698,\n",
      "        0.01051895,  0.02951174,  0.03461129, -0.01386745,  0.00422496,\n",
      "        0.00565233,  0.0102866 ,  0.0037622 , -0.07303755,  0.02295428])\n",
      " 89%|████████▉ | 66/74 [01:43<00:12,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.17500425205391107)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.19224829931972787\n",
      "DEBUG:shap:self.fx = 0.1795\n",
      "DEBUG:shap:self.link(self.fx) = 0.1795\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.1346744 , -0.00459759,  0.00715264, -0.06036218, -0.00046258,\n",
      "        0.00646036, -0.03515662, -0.04073867,  0.00926438, -0.00583451,\n",
      "       -0.00104867,  0.01259522, -0.00041206,  0.07281043, -0.01724405])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.1750042520539109)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.19224829931972776\n",
      "DEBUG:shap:self.fx = 0.8205\n",
      "DEBUG:shap:self.link(self.fx) = 0.8205\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.1346744 ,  0.00459759, -0.00715264,  0.06036218,  0.00046258,\n",
      "       -0.00646036,  0.03515662,  0.04073867, -0.00926438,  0.00583451,\n",
      "        0.00104867, -0.01259522,  0.00041206, -0.07281043,  0.01724405])\n",
      " 91%|█████████ | 67/74 [01:45<00:11,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.30260931353370263)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.3384897959183675\n",
      "DEBUG:shap:self.fx = 0.7102380952380953\n",
      "DEBUG:shap:self.link(self.fx) = 0.7102380952380953\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.1558776 ,  0.00449304,  0.00861487,  0.05298183, -0.00692181,\n",
      "        0.01216346, -0.04469993, -0.01583784,  0.00381489, -0.01680049,\n",
      "        0.00094229,  0.01430321,  0.00608465,  0.12759354,  0.03588048])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.3026093135337027)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3384897959183675\n",
      "DEBUG:shap:self.fx = 0.2897619047619048\n",
      "DEBUG:shap:self.link(self.fx) = 0.2897619047619048\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.1558776 , -0.00449304, -0.00861487, -0.05298183,  0.00692181,\n",
      "       -0.01216346,  0.04469993,  0.01583784, -0.00381489,  0.01680049,\n",
      "       -0.00094229, -0.01430321, -0.00608465, -0.12759354, -0.03588048])\n",
      " 92%|█████████▏| 68/74 [01:46<00:09,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.36584077147789307)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.35848979591836727\n",
      "DEBUG:shap:self.fx = 0.7302380952380951\n",
      "DEBUG:shap:self.link(self.fx) = 0.7302380952380951\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.14440097,  0.01694243,  0.00343848,  0.0767321 , -0.00233266,\n",
      "        0.02175618,  0.01969431,  0.0281611 , -0.0061743 , -0.02709973,\n",
      "        0.00369776, -0.02208725,  0.00635624,  0.10235515, -0.00735098])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.36584077147789335)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.3584897959183675\n",
      "DEBUG:shap:self.fx = 0.26976190476190476\n",
      "DEBUG:shap:self.link(self.fx) = 0.26976190476190476\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.14440097, -0.01694243, -0.00343848, -0.0767321 ,  0.00233266,\n",
      "       -0.02175618, -0.01969431, -0.0281611 ,  0.0061743 ,  0.02709973,\n",
      "       -0.00369776,  0.02208725, -0.00635624, -0.10235515,  0.00735098])\n",
      " 93%|█████████▎| 69/74 [01:48<00:07,  1.56s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.03204905830104218)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.03641496598639454\n",
      "DEBUG:shap:self.fx = 0.3353333333333333\n",
      "DEBUG:shap:self.link(self.fx) = 0.3353333333333333\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.12795152,  0.00563542,  0.01117666, -0.04430619,  0.00456248,\n",
      "       -0.00877292, -0.05144495,  0.0775267 ,  0.01097635,  0.013057  ,\n",
      "       -0.00144576,  0.00842793,  0.00477653,  0.06573322, -0.00436591])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999998)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.03204905830104206)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.03641496598639449\n",
      "DEBUG:shap:self.fx = 0.6646666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.6646666666666667\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.12795152, -0.00563542, -0.01117666,  0.04430619, -0.00456248,\n",
      "        0.00877292,  0.05144495, -0.0775267 , -0.01097635, -0.013057  ,\n",
      "        0.00144576, -0.00842793, -0.00477653, -0.06573322,  0.00436591])\n",
      " 95%|█████████▍| 70/74 [01:49<00:06,  1.55s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.09971157625663746)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.09548979591836743\n",
      "DEBUG:shap:self.fx = 0.4672380952380953\n",
      "DEBUG:shap:self.link(self.fx) = 0.4672380952380953\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.16016034,  0.0063243 ,  0.01396979, -0.03894309, -0.00860143,\n",
      "        0.03106816,  0.04658127, -0.01394986,  0.        , -0.00675389,\n",
      "        0.00213388, -0.03313261,  0.00521697, -0.06436225, -0.00422178])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.09971157625663744)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.09548979591836748\n",
      "DEBUG:shap:self.fx = 0.5327619047619048\n",
      "DEBUG:shap:self.link(self.fx) = 0.5327619047619048\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.16016034, -0.0063243 , -0.01396979,  0.03894309,  0.00860143,\n",
      "       -0.03106816, -0.04658127,  0.01394986,  0.        ,  0.00675389,\n",
      "       -0.00213388,  0.03313261, -0.00521697,  0.06436225,  0.00422178])\n",
      " 96%|█████████▌| 71/74 [01:51<00:04,  1.58s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.12257506033781991)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.12325170068027208\n",
      "DEBUG:shap:self.fx = 0.49499999999999994\n",
      "DEBUG:shap:self.link(self.fx) = 0.49499999999999994\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([ 0.12248434, -0.06312843, -0.00091882,  0.10563473,  0.01262862,\n",
      "       -0.00480674,  0.02840784, -0.02670736, -0.00152498, -0.00688255,\n",
      "       -0.01315696,  0.01846133,  0.02697994, -0.07489591,  0.00067664])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000004)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.12257506033781992)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.12325170068027214\n",
      "DEBUG:shap:self.fx = 0.5050000000000001\n",
      "DEBUG:shap:self.link(self.fx) = 0.5050000000000001\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([-0.12248434,  0.06312843,  0.00091882, -0.10563473, -0.01262862,\n",
      "        0.00480674, -0.02840784,  0.02670736,  0.00152498,  0.00688255,\n",
      "        0.01315696, -0.01846133, -0.02697994,  0.07489591, -0.00067664])\n",
      " 97%|█████████▋| 72/74 [01:53<00:03,  1.57s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.20944763990374454)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.19708163265306117\n",
      "DEBUG:shap:self.fx = 0.1746666666666667\n",
      "DEBUG:shap:self.link(self.fx) = 0.1746666666666667\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.08223496,  0.05148186,  0.00507145, -0.06102913,  0.00204984,\n",
      "       -0.03672134, -0.03831818, -0.03748417,  0.00191734, -0.00061223,\n",
      "        0.01062147,  0.00913792,  0.00159728, -0.03492482,  0.01236601])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.20944763990374443)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1970816326530611\n",
      "DEBUG:shap:self.fx = 0.8253333333333334\n",
      "DEBUG:shap:self.link(self.fx) = 0.8253333333333334\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.08223496, -0.05148186, -0.00507145,  0.06102913, -0.00204984,\n",
      "        0.03672134,  0.03831818,  0.03748417, -0.00191734,  0.00061223,\n",
      "       -0.01062147, -0.00913792, -0.00159728,  0.03492482, -0.01236601])\n",
      " 99%|█████████▊| 73/74 [01:54<00:01,  1.59s/it]DEBUG:shap:weight_vector = array([0.32951193, 0.1774295 , 0.12814353, 0.1048447 , 0.09226334,\n",
      "       0.08542902, 0.08237798])\n",
      "DEBUG:shap:num_subset_sizes = 7\n",
      "DEBUG:shap:num_paired_subset_sizes = 7\n",
      "DEBUG:shap:self.M = 15\n",
      "DEBUG:shap:subset_size = 1\n",
      "DEBUG:shap:nsubsets = np.float64(30.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 684.7257865059703\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 22.824192883532344\n",
      "DEBUG:shap:subset_size = 2\n",
      "DEBUG:shap:nsubsets = np.float64(210.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 541.9568679014247\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 2.5807469900067845\n",
      "DEBUG:shap:subset_size = 3\n",
      "DEBUG:shap:nsubsets = np.float64(910.0)\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1] = 477.6872707634842\n",
      "DEBUG:shap:self.nsamples*weight_vector[subset_size-1]/nsubsets = 0.5249310667730596\n",
      "INFO:shap:num_full_subsets = 2\n",
      "DEBUG:shap:samples_left = 1838\n",
      "INFO:shap:remaining_weight_vector = array([0.25989514, 0.21264148, 0.1871245 , 0.17326343, 0.16707545])\n",
      "INFO:shap:num_paired_subset_sizes = 7\n",
      "INFO:shap:weight_left = np.float64(0.4930585722173909)\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(-0.1461798858660979)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = -0.15403401360544217\n",
      "DEBUG:shap:self.fx = 0.2177142857142857\n",
      "DEBUG:shap:self.link(self.fx) = 0.2177142857142857\n",
      "DEBUG:shap:self.fnull = 0.37174829931972786\n",
      "DEBUG:shap:self.link(self.fnull) = 0.37174829931972786\n",
      "INFO:shap:phi = array([-0.10490812,  0.01085939,  0.00327615,  0.07728705, -0.00707306,\n",
      "        0.02354997, -0.06878972, -0.03285433, -0.00186577, -0.00144521,\n",
      "       -0.01036584, -0.03657084,  0.01725304, -0.01453259, -0.00785413])\n",
      "DEBUG:shap:fraction_evaluated = 0.06341939815662577\n",
      "INFO:shap:np.sum(w_aug) = np.float64(14.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(1.0000000000000002)\n",
      "DEBUG:shap:etmp[:4, :] = array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.],\n",
      "       [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.]])\n",
      "DEBUG:shap:np.sum(w) = np.float64(0.14617988586609756)\n",
      "DEBUG:shap:self.link(self.fx) - self.link(self.fnull) = 0.1540340136054419\n",
      "DEBUG:shap:self.fx = 0.7822857142857141\n",
      "DEBUG:shap:self.link(self.fx) = 0.7822857142857141\n",
      "DEBUG:shap:self.fnull = 0.6282517006802723\n",
      "DEBUG:shap:self.link(self.fnull) = 0.6282517006802723\n",
      "INFO:shap:phi = array([ 0.10490812, -0.01085939, -0.00327615, -0.07728705,  0.00707306,\n",
      "       -0.02354997,  0.06878972,  0.03285433,  0.00186577,  0.00144521,\n",
      "        0.01036584,  0.03657084, -0.01725304,  0.01453259,  0.00785413])\n",
      "100%|██████████| 74/74 [01:56<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.77344336084021,\n",
      "                0.7531882970742686,\n",
      "                0.7381845461365341,\n",
      "                0.7464366091522882,\n",
      "                0.6459114778694673,\n",
      "                0.6504126031507876,\n",
      "                0.5746436609152288,\n",
      "                0.5333833458364591,\n",
      "                0.46999249812453114,\n",
      "                0.6204051012753188,\n",
      "                0.46924231057764443,\n",
      "                0.47261815453863465,\n",
      "                0.481245311327832,\n",
      "                0.5048762190547638,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5584202674130104,\n",
      "                0.6152823978620233,\n",
      "                0.659037108740996,\n",
      "                0.6816295750643078,\n",
      "                0.7385189827480575,\n",
      "                0.7741145693503552,\n",
      "                0.8500390166377951,\n",
      "                0.8641993400757866,\n",
      "                0.9009943646743731,\n",
      "                0.8691958201515381,\n",
      "                0.8613699932305556,\n",
      "                0.8813517850454523,\n",
      "                0.8777005361244103,\n",
      "                0.8623889178205392,\n",
      "                0.8770640441784052\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18761853207735799,\n",
      "                0.21349258921102227,\n",
      "                0.2352747003202182,\n",
      "                0.24601078231292514,\n",
      "                0.27172150430532577,\n",
      "                0.2878702796393332,\n",
      "                0.3205881073650181,\n",
      "                0.3263050304054054,\n",
      "                0.3417079947447447,\n",
      "                0.32967059496997,\n",
      "                0.32683535510510514,\n",
      "                0.3351458415915916,\n",
      "                0.334121,\n",
      "                0.3279449376876877,\n",
      "                0.3339753430930932\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.5955988997249313,\n",
      "            \"cross_entropy\": 0.7914204479411738,\n",
      "            \"brier\": 0.29455217285525326\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7996999249812454,\n",
      "                0.8435858964741185,\n",
      "                0.8522130532633159,\n",
      "                0.8439609902475619,\n",
      "                0.8499624906226556,\n",
      "                0.8529632408102025,\n",
      "                0.8439609902475619,\n",
      "                0.8312078019504877,\n",
      "                0.8477119279819955,\n",
      "                0.8469617404351087,\n",
      "                0.8342085521380345,\n",
      "                0.8375843960990248,\n",
      "                0.8184546136534134,\n",
      "                0.822205551387847,\n",
      "                0.8244561140285072\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5568416944948791,\n",
      "                0.4803972268976447,\n",
      "                0.4913084188236074,\n",
      "                0.48321531022432596,\n",
      "                0.4551934228785443,\n",
      "                0.4634261407490266,\n",
      "                0.4708180234038162,\n",
      "                0.4800239500330183,\n",
      "                0.4797757879311866,\n",
      "                0.48390886285873796,\n",
      "                0.48857339642599973,\n",
      "                0.48575438756350914,\n",
      "                0.5010832771791706,\n",
      "                0.4984998197265036,\n",
      "                0.49914526465592496\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18404619594594598,\n",
      "                0.1502662864114114,\n",
      "                0.15474233671171173,\n",
      "                0.15330450750750751,\n",
      "                0.14288727120679354,\n",
      "                0.14654385604928907,\n",
      "                0.14893739328039773,\n",
      "                0.1514153097325642,\n",
      "                0.15262029286365447,\n",
      "                0.15439245706356866,\n",
      "                0.1549040383457437,\n",
      "                0.15376700067031318,\n",
      "                0.15993943756703133,\n",
      "                0.15819850072202304,\n",
      "                0.15791030935718886\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8366091522880722,\n",
      "            \"cross_entropy\": 0.48786433225639303,\n",
      "            \"brier\": 0.15492501289567626\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 456, 789, 1010]\n",
    "\n",
    "X = X[[\"xylose\", \"xanthosine\", \"uracil\", \"ribulose/xylulose\", \"valylglutamine\", \"tryptophylglycine\", \"succinate\", \"valine betaine\", \"ursodeoxycholate sulfate (1)\", \"tricarballylate\",\"succinimide\", \"thymine\", \"syringic acid\", \"serotonin\", \"ribitol\" ]]\n",
    "\n",
    "y = df_encoded['Group']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X),columns=X.columns,index=X.index)\n",
    "\n",
    "all_scores = {\n",
    "    'deletion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    },\n",
    "    'insertion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    }\n",
    "}\n",
    "\n",
    "for i in seeds:\n",
    "    print(\"Training Random Forest model...\")\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 7],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, n_iter=50,\n",
    "            cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    model = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "    background_data = shap.kmeans(X_train, 100)\n",
    "    explainer = shap.KernelExplainer(model.predict_proba, background_data)\n",
    "\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    result = evaluate_global_shap_scores(model, X_test, y_test, shap_values)\n",
    "\n",
    "    for method in ['deletion', 'insertion']:\n",
    "        for metric in ['auroc', 'cross_entropy', 'brier']:\n",
    "            all_scores[method][metric].append(result[method][\"average_scores\"][metric])\n",
    "\n",
    "    import json\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.6155557286380419,\n",
      "            \"std\": 0.025009852723275047\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.8044518529261528,\n",
      "            \"std\": 0.032395437669372876\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.30158404917624626,\n",
      "            \"std\": 0.015052282006838936\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.8548635154444065,\n",
      "            \"std\": 0.02849115712478812\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.4674328561344403,\n",
      "            \"std\": 0.036029267580464895\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.14747157214087334,\n",
      "            \"std\": 0.014843916537739232\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "final_results = {\n",
    "    'deletion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['deletion'].items()\n",
    "    },\n",
    "    'insertion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['insertion'].items()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(json.dumps(final_results, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBS Causal SHAP Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xylose                          0.159926\n",
      "xanthosine                      0.005054\n",
      "uracil                          0.024651\n",
      "ribulose/xylulose               0.157096\n",
      "valylglutamine                  0.001092\n",
      "tryptophylglycine               0.001896\n",
      "succinate                       0.012208\n",
      "valine betaine                  0.034348\n",
      "ursodeoxycholate sulfate (1)    0.000260\n",
      "tricarballylate                 0.000698\n",
      "succinimide                     0.006417\n",
      "thymine                         0.016280\n",
      "syringic acid                   0.000676\n",
      "serotonin                       0.072681\n",
      "ribitol                         0.007174\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "file_paths = ['../../result/Real_World_IBS/Causal_SHAP_IBS_42.pkl', '../../result/Real_World_IBS/Causal_SHAP_IBS_123.pkl', '../../result/Real_World_IBS/Causal_SHAP_IBS_456.pkl', '../../result/Real_World_IBS/Causal_SHAP_IBS_789.pkl', '../../result/Real_World_IBS/Causal_SHAP_IBS_1010.pkl']\n",
    "\n",
    "def load_and_format_shap_values(file_path, feature_names):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    n_samples = len(data)\n",
    "    n_features = len(feature_names)\n",
    "    shap_array = np.zeros((n_samples, n_features))\n",
    "    \n",
    "    for i, instance in enumerate(data):\n",
    "        for j, feature in enumerate(feature_names):\n",
    "            shap_array[i, j] = instance.get(feature, 0)\n",
    "    \n",
    "    return shap_array\n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "causal_shap_values = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    formatted_values = load_and_format_shap_values(file_path, feature_names)\n",
    "    causal_shap_values.append(formatted_values)\n",
    "\n",
    "print(pd.Series(np.abs(causal_shap_values[0]).mean(axis=0), index=feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8020833333333333,\n",
      "                0.7131410256410257,\n",
      "                0.7131410256410257,\n",
      "                0.6145833333333333,\n",
      "                0.6185897435897436,\n",
      "                0.6233974358974359,\n",
      "                0.5817307692307693,\n",
      "                0.594551282051282,\n",
      "                0.5953525641025641,\n",
      "                0.6073717948717949,\n",
      "                0.5945512820512819,\n",
      "                0.6378205128205129,\n",
      "                0.6422275641025641,\n",
      "                0.4911858974358975,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5333619228350892,\n",
      "                0.6176319966059503,\n",
      "                0.7117184396839162,\n",
      "                0.7458745657755351,\n",
      "                0.7544846458433045,\n",
      "                0.7643038992941047,\n",
      "                0.821400464724071,\n",
      "                0.847067025492969,\n",
      "                0.8668130379941142,\n",
      "                0.8891361917078303,\n",
      "                0.9339429947820997,\n",
      "                0.924163630982221,\n",
      "                0.9035509841238791,\n",
      "                0.8925618058423742,\n",
      "                0.9272027411818561\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17575241929729749,\n",
      "                0.21478375157982196,\n",
      "                0.2597070037610788,\n",
      "                0.27604349501841946,\n",
      "                0.27991708339961313,\n",
      "                0.2844424229388321,\n",
      "                0.31193143333661116,\n",
      "                0.3233782880092635,\n",
      "                0.33203258800467644,\n",
      "                0.3413062780808007,\n",
      "                0.35965035941518275,\n",
      "                0.3559432155331778,\n",
      "                0.34736284251859567,\n",
      "                0.3432399848039314,\n",
      "                0.3581441230715909\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6219818376068376,\n",
      "            \"cross_entropy\": 0.8088809564579544,\n",
      "            \"brier\": 0.3042423525845929\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8565705128205129,\n",
      "                0.8497596153846154,\n",
      "                0.8445512820512819,\n",
      "                0.8878205128205128,\n",
      "                0.8910256410256411,\n",
      "                0.8878205128205129,\n",
      "                0.8774038461538461,\n",
      "                0.8822115384615384,\n",
      "                0.8774038461538461,\n",
      "                0.8798076923076924,\n",
      "                0.8806089743589745,\n",
      "                0.8838141025641025,\n",
      "                0.8782051282051282,\n",
      "                0.8846153846153846,\n",
      "                0.8782051282051282\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5577995700528187,\n",
      "                0.48561723474015095,\n",
      "                0.4655374628351458,\n",
      "                0.4380237734852441,\n",
      "                0.4442835781441994,\n",
      "                0.44640795836777464,\n",
      "                0.44765061538967194,\n",
      "                0.4426989729961006,\n",
      "                0.4452145470994406,\n",
      "                0.44550351090404394,\n",
      "                0.43598045275578146,\n",
      "                0.42746930445675824,\n",
      "                0.4283525816854086,\n",
      "                0.42277047467250956,\n",
      "                0.43130759728033224\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18281475287193621,\n",
      "                0.15138956546440746,\n",
      "                0.145363733060362,\n",
      "                0.13537964233817612,\n",
      "                0.13811109520936868,\n",
      "                0.13900521757066117,\n",
      "                0.13968135646795402,\n",
      "                0.13749926306716267,\n",
      "                0.13861799075393094,\n",
      "                0.13961429267355152,\n",
      "                0.1357247122086571,\n",
      "                0.13268623870064064,\n",
      "                0.1327547844285534,\n",
      "                0.13054367695291189,\n",
      "                0.13441740529050694\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8759882478632478,\n",
      "            \"cross_entropy\": 0.45097450899102526,\n",
      "            \"brier\": 0.14090691513725204\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7875,\n",
      "                0.7458333333333332,\n",
      "                0.6608333333333333,\n",
      "                0.56,\n",
      "                0.5341666666666667,\n",
      "                0.5449999999999999,\n",
      "                0.4741666666666666,\n",
      "                0.4916666666666667,\n",
      "                0.5083333333333333,\n",
      "                0.4925,\n",
      "                0.46333333333333326,\n",
      "                0.47583333333333333,\n",
      "                0.5475,\n",
      "                0.46916666666666673,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5893880935369175,\n",
      "                0.6939687843745195,\n",
      "                0.7861497864710774,\n",
      "                0.8458936405573276,\n",
      "                0.8563292153869034,\n",
      "                0.8614756871522624,\n",
      "                0.8846286320184191,\n",
      "                0.8939189794493904,\n",
      "                0.9521357012719036,\n",
      "                0.9957748941580877,\n",
      "                1.0225135070200213,\n",
      "                1.0346153137679555,\n",
      "                0.9121359840206228,\n",
      "                0.9619538315570729,\n",
      "                0.9404186671352546\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.20014143968821002,\n",
      "                0.25060080888344277,\n",
      "                0.29290152701464217,\n",
      "                0.3204676327258146,\n",
      "                0.3250657168676518,\n",
      "                0.32722921073518113,\n",
      "                0.3375658266482527,\n",
      "                0.34093980394650514,\n",
      "                0.36567267078231797,\n",
      "                0.3832999169260126,\n",
      "                0.39332163692886773,\n",
      "                0.3976958840847826,\n",
      "                0.3522985231076693,\n",
      "                0.3737091000733354,\n",
      "                0.3649649438114703\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.5503888888888888,\n",
      "            \"cross_entropy\": 0.8820867145251824,\n",
      "            \"brier\": 0.3350583094816104\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7708333333333334,\n",
      "                0.7929166666666666,\n",
      "                0.8433333333333333,\n",
      "                0.8591666666666667,\n",
      "                0.8625,\n",
      "                0.8658333333333333,\n",
      "                0.8641666666666666,\n",
      "                0.8633333333333333,\n",
      "                0.8475,\n",
      "                0.845,\n",
      "                0.8508333333333333,\n",
      "                0.8466666666666667,\n",
      "                0.8308333333333333,\n",
      "                0.8333333333333334,\n",
      "                0.8291666666666667\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.6613720387481131,\n",
      "                0.5813672929279904,\n",
      "                0.5108789761289761,\n",
      "                0.4728810069891966,\n",
      "                0.46816023951512614,\n",
      "                0.46518595588889494,\n",
      "                0.46072975332157917,\n",
      "                0.4577855507947911,\n",
      "                0.46962335931889193,\n",
      "                0.47351118242045903,\n",
      "                0.47416295924753366,\n",
      "                0.47002089754970217,\n",
      "                0.49733548742144135,\n",
      "                0.4871241976779984,\n",
      "                0.4891898601283233\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.22809981569093526,\n",
      "                0.19605940381276157,\n",
      "                0.16857600403574025,\n",
      "                0.15332288574781724,\n",
      "                0.15190677633547675,\n",
      "                0.15081303945342128,\n",
      "                0.14896174104169768,\n",
      "                0.14710402713458515,\n",
      "                0.1504874565246574,\n",
      "                0.15216776543777213,\n",
      "                0.15248019862232925,\n",
      "                0.15122474485640175,\n",
      "                0.16156096150094154,\n",
      "                0.15805205753032267,\n",
      "                0.15935898123209713\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8403611111111112,\n",
      "            \"cross_entropy\": 0.4959552505386011,\n",
      "            \"brier\": 0.1620117239304638\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8387096774193548,\n",
      "                0.7741935483870968,\n",
      "                0.7449362340585146,\n",
      "                0.7351837959489873,\n",
      "                0.7164291072768192,\n",
      "                0.7404351087771943,\n",
      "                0.695423855963991,\n",
      "                0.6969242310577645,\n",
      "                0.6879219804951238,\n",
      "                0.6271567891972993,\n",
      "                0.568642160540135,\n",
      "                0.632033008252063,\n",
      "                0.6219054763690922,\n",
      "                0.5626406601650413,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5193068224943925,\n",
      "                0.5884276777641769,\n",
      "                0.6528984636814126,\n",
      "                0.6769923018390795,\n",
      "                0.6828393719866309,\n",
      "                0.6789103549658556,\n",
      "                0.7261480090260554,\n",
      "                0.7375841733114205,\n",
      "                0.7462689942210788,\n",
      "                0.7821190731505933,\n",
      "                0.8683993068767332,\n",
      "                0.8760320874142727,\n",
      "                0.8815356593522089,\n",
      "                0.8507441265848273,\n",
      "                0.8937715432763311\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.16720830628118008,\n",
      "                0.20064877500497325,\n",
      "                0.23147481697693523,\n",
      "                0.24276897776608453,\n",
      "                0.24557780087687597,\n",
      "                0.24383818529408438,\n",
      "                0.26630388528749843,\n",
      "                0.27150835211641267,\n",
      "                0.2756389985298862,\n",
      "                0.2921601807702154,\n",
      "                0.3288839815908064,\n",
      "                0.3317336478636907,\n",
      "                0.33372936500829065,\n",
      "                0.3223428025595217,\n",
      "                0.3406323110321205\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6761690422605651,\n",
      "            \"cross_entropy\": 0.744131864396338,\n",
      "            \"brier\": 0.2729633591305717\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8945986496624156,\n",
      "                0.8807201800450112,\n",
      "                0.9017254313578394,\n",
      "                0.9167291822955739,\n",
      "                0.9144786196549137,\n",
      "                0.9009752438109527,\n",
      "                0.8829707426856714,\n",
      "                0.8784696174043511,\n",
      "                0.8844711177794449,\n",
      "                0.886721680420105,\n",
      "                0.8927231807951987,\n",
      "                0.8972243060765192,\n",
      "                0.8912228057014253,\n",
      "                0.8957239309827456,\n",
      "                0.8994748687171792\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5339335987660522,\n",
      "                0.4644702556151713,\n",
      "                0.41740777547848185,\n",
      "                0.38370294811830236,\n",
      "                0.3864523954295421,\n",
      "                0.3985990045824139,\n",
      "                0.40193552863054616,\n",
      "                0.4066080191823932,\n",
      "                0.40705156811768256,\n",
      "                0.4035936477584196,\n",
      "                0.4019949745622336,\n",
      "                0.39591901362547177,\n",
      "                0.400364212711417,\n",
      "                0.3989797570020913,\n",
      "                0.40118807518577815\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17395977258876588,\n",
      "                0.14233368561447618,\n",
      "                0.12648882895646923,\n",
      "                0.11529523911652789,\n",
      "                0.11639516830580525,\n",
      "                0.12023709020920365,\n",
      "                0.12201136849019512,\n",
      "                0.12159425470597084,\n",
      "                0.12245391893365515,\n",
      "                0.12090561827649288,\n",
      "                0.11986550681155662,\n",
      "                0.11772343355522369,\n",
      "                0.11923461935954412,\n",
      "                0.11867717145159401,\n",
      "                0.11986653926437998\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8945486371592898,\n",
      "            \"cross_entropy\": 0.41348005165106644,\n",
      "            \"brier\": 0.12513614770932405\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8286445012787723,\n",
      "                0.7468030690537085,\n",
      "                0.710997442455243,\n",
      "                0.6317135549872123,\n",
      "                0.6351236146632566,\n",
      "                0.5524296675191817,\n",
      "                0.4876385336743393,\n",
      "                0.5831202046035806,\n",
      "                0.5950554134697357,\n",
      "                0.5507246376811594,\n",
      "                0.463768115942029,\n",
      "                0.46675191815856787,\n",
      "                0.46078431372549017,\n",
      "                0.4671781756180733,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5247611733780392,\n",
      "                0.5992980891784528,\n",
      "                0.6592960329956608,\n",
      "                0.7030805887135134,\n",
      "                0.7123429769697089,\n",
      "                0.7792986083853992,\n",
      "                0.8037872866271865,\n",
      "                0.8157944287928084,\n",
      "                0.8312201302583456,\n",
      "                0.8499798908110113,\n",
      "                0.9004801982080393,\n",
      "                0.8711329850339488,\n",
      "                0.8567397830951963,\n",
      "                0.8482023882172938,\n",
      "                0.8697720218315294\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17191309223617363,\n",
      "                0.20559231482901733,\n",
      "                0.23306026497931379,\n",
      "                0.2545604943132168,\n",
      "                0.25885472716700286,\n",
      "                0.2916288575515612,\n",
      "                0.30362085631261115,\n",
      "                0.3093286612325834,\n",
      "                0.3165553167224293,\n",
      "                0.3251276681479757,\n",
      "                0.3473243173536318,\n",
      "                0.33486828613858943,\n",
      "                0.32836808345053226,\n",
      "                0.3246201718081623,\n",
      "                0.3348469112139148\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.5787155441886899,\n",
      "            \"cross_entropy\": 0.7750124388330756,\n",
      "            \"brier\": 0.2893513348971144\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8047740835464622,\n",
      "                0.8405797101449275,\n",
      "                0.8729752770673486,\n",
      "                0.8644501278772379,\n",
      "                0.8678601875532822,\n",
      "                0.8635976129582268,\n",
      "                0.8687127024722933,\n",
      "                0.8584825234441603,\n",
      "                0.8431372549019608,\n",
      "                0.8465473145780051,\n",
      "                0.845694799658994,\n",
      "                0.8482523444160273,\n",
      "                0.855072463768116,\n",
      "                0.8533674339300937,\n",
      "                0.8533674339300937\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.6304875596901828,\n",
      "                0.5231308843317846,\n",
      "                0.4637947978058688,\n",
      "                0.45061291867255465,\n",
      "                0.4464000778634561,\n",
      "                0.43741959341963843,\n",
      "                0.4343828088814684,\n",
      "                0.44095534195423597,\n",
      "                0.449821537239907,\n",
      "                0.4488176755567255,\n",
      "                0.44574551781082855,\n",
      "                0.4432763960927437,\n",
      "                0.4416409651042574,\n",
      "                0.44278392951614776,\n",
      "                0.45297774690534315\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.21120993032259455,\n",
      "                0.1662162563773505,\n",
      "                0.14575619665769501,\n",
      "                0.13865086965929263,\n",
      "                0.13745506200715107,\n",
      "                0.13346606119201282,\n",
      "                0.13267303433366406,\n",
      "                0.13544096246814463,\n",
      "                0.14009645039920346,\n",
      "                0.13952960336446998,\n",
      "                0.1379663286517446,\n",
      "                0.13606350263967296,\n",
      "                0.13568799279153657,\n",
      "                0.13671727850999613,\n",
      "                0.14064052329750873\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8524580846831484,\n",
      "            \"cross_entropy\": 0.4634831833896762,\n",
      "            \"brier\": 0.14450467017813587\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8274568642160541,\n",
      "                0.7531882970742686,\n",
      "                0.7381845461365341,\n",
      "                0.7464366091522882,\n",
      "                0.6459114778694673,\n",
      "                0.5697674418604651,\n",
      "                0.5836459114778695,\n",
      "                0.5656414103525882,\n",
      "                0.5468867216804201,\n",
      "                0.4553638409602401,\n",
      "                0.4343585896474118,\n",
      "                0.46061515378844714,\n",
      "                0.3683420855213803,\n",
      "                0.33908477119279823,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5110473030180641,\n",
      "                0.6152823978620233,\n",
      "                0.659037108740996,\n",
      "                0.6816295750643078,\n",
      "                0.7385189827480575,\n",
      "                0.8083555665781142,\n",
      "                0.809865226540508,\n",
      "                0.816834065043128,\n",
      "                0.8645194716902611,\n",
      "                0.9089021997755932,\n",
      "                0.9303423241854474,\n",
      "                0.9146826912239642,\n",
      "                0.8917415155132613,\n",
      "                0.9101248109726001,\n",
      "                0.8770640441784052\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.1613070374934884,\n",
      "                0.21349258921102227,\n",
      "                0.2352747003202182,\n",
      "                0.24601078231292514,\n",
      "                0.27172150430532577,\n",
      "                0.30185235940277017,\n",
      "                0.30259065412606484,\n",
      "                0.30583363363363364,\n",
      "                0.32696897560060056,\n",
      "                0.34533637950450446,\n",
      "                0.35349237499999997,\n",
      "                0.3474291144894895,\n",
      "                0.33930961148648653,\n",
      "                0.34657311711711714,\n",
      "                0.3339753430930932\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.5689922480620155,\n",
      "            \"cross_entropy\": 0.7958631522089822,\n",
      "            \"brier\": 0.2954112118064493\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8038259564891225,\n",
      "                0.8435858964741185,\n",
      "                0.8522130532633159,\n",
      "                0.8439609902475619,\n",
      "                0.8499624906226556,\n",
      "                0.8454613653413353,\n",
      "                0.8372093023255813,\n",
      "                0.8267066766691673,\n",
      "                0.8173293323330834,\n",
      "                0.8300825206301575,\n",
      "                0.8364591147786947,\n",
      "                0.837959489872468,\n",
      "                0.8304576144036009,\n",
      "                0.8259564891222806,\n",
      "                0.8244561140285072\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.6925534341410899,\n",
      "                0.4803972268976447,\n",
      "                0.4913084188236074,\n",
      "                0.48321531022432596,\n",
      "                0.4551934228785443,\n",
      "                0.4621389745448629,\n",
      "                0.4766297945078694,\n",
      "                0.4832814192871908,\n",
      "                0.49814563592381705,\n",
      "                0.4937059988487875,\n",
      "                0.49149806755161485,\n",
      "                0.48823035493208217,\n",
      "                0.492851668726223,\n",
      "                0.49383665145030414,\n",
      "                0.49914526465592496\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.249799322072072,\n",
      "                0.1502662864114114,\n",
      "                0.15474233671171173,\n",
      "                0.15330450750750751,\n",
      "                0.14288727120679354,\n",
      "                0.1451331718548906,\n",
      "                0.15032873661671875,\n",
      "                0.15207793787154503,\n",
      "                0.15736487452503525,\n",
      "                0.15784162801066373,\n",
      "                0.15690941367898512,\n",
      "                0.15577429668443954,\n",
      "                0.1557842093004995,\n",
      "                0.15585027074715022,\n",
      "                0.15791030935718886\n",
      "            ]\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8337084271067766,\n",
      "            \"cross_entropy\": 0.49880877622625935,\n",
      "            \"brier\": 0.15973163817044084\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 456, 789, 1010]\n",
    "\n",
    "X = X[[\"xylose\", \"xanthosine\", \"uracil\", \"ribulose/xylulose\", \"valylglutamine\", \"tryptophylglycine\", \"succinate\", \"valine betaine\", \"ursodeoxycholate sulfate (1)\", \"tricarballylate\",\"succinimide\", \"thymine\", \"syringic acid\", \"serotonin\", \"ribitol\" ]]\n",
    "\n",
    "y = df_encoded['Group']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X),columns=X.columns,index=X.index)\n",
    "\n",
    "all_scores = {\n",
    "    'deletion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    },\n",
    "    'insertion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    }\n",
    "}\n",
    "\n",
    "idx = 0\n",
    "for i in seeds:\n",
    "    print(\"Training Random Forest model...\")\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 7],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, n_iter=50,\n",
    "            cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    model = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "    result = evaluate_global_shap_scores(model, X_test, y_test, pd.Series(np.abs(causal_shap_values[idx]).mean(axis=0), index=feature_names), causal=True)\n",
    "\n",
    "    for method in ['deletion', 'insertion']:\n",
    "        for metric in ['auroc', 'cross_entropy', 'brier']:\n",
    "            all_scores[method][metric].append(result[method][\"average_scores\"][metric])\n",
    "\n",
    "    import json\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n",
    "\n",
    "    idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.5992495122013993,\n",
      "            \"std\": 0.04507300546645652\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.8011950252843064,\n",
      "            \"std\": 0.045984127610605406\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.2994053135800677,\n",
      "            \"std\": 0.02054626659289343\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.8594129015847148,\n",
      "            \"std\": 0.022721453409459143\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.46454035415932565,\n",
      "            \"std\": 0.0314754657562984\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.1464582190251233,\n",
      "            \"std\": 0.013471148605793222\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "final_results = {\n",
    "    'deletion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['deletion'].items()\n",
    "    },\n",
    "    'insertion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['insertion'].items()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(json.dumps(final_results, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Graph Plotting - MC Computational Complexity\n",
    "Num_samples: (IBS)     \n",
    "2: 25.7215    \n",
    "4: 47.5259    \n",
    "8: 92.2149      \n",
    "16: 184.0276, AUROC=0.5597      \n",
    "32: 366.1318, AUROC=0.5678      \n",
    "64: 736.3944, AUROC=0.5680         \n",
    "128: 1429.2009, AUROC=0.5651       \n",
    "256: 2824.8572, AUROC=0.5678        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "\n",
      "Final Results:\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.5597499999999999,\n",
      "            \"std\": 0.0\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.8762457657821152,\n",
      "            \"std\": 0.0\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.3325803879057119,\n",
      "            \"std\": 0.0\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.8407500000000002,\n",
      "            \"std\": 0.0\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.4965878644661133,\n",
      "            \"std\": 0.0\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.16225627998058723,\n",
      "            \"std\": 0.0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "file_paths = ['../../result/Real_World_IBS/Causal_SHAP_IBS_123_no_16.pkl']\n",
    "\n",
    "def load_and_format_shap_values(file_path, feature_names):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    n_samples = len(data)\n",
    "    n_features = len(feature_names)\n",
    "    shap_array = np.zeros((n_samples, n_features))\n",
    "    \n",
    "    for i, instance in enumerate(data):\n",
    "        for j, feature in enumerate(feature_names):\n",
    "            shap_array[i, j] = instance.get(feature, 0)\n",
    "    \n",
    "    return shap_array\n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "causal_shap_values = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    formatted_values = load_and_format_shap_values(file_path, feature_names)\n",
    "    causal_shap_values.append(formatted_values)\n",
    "\n",
    "seeds = [123]\n",
    "\n",
    "X = X[[\"xylose\", \"xanthosine\", \"uracil\", \"ribulose/xylulose\", \"valylglutamine\", \"tryptophylglycine\", \"succinate\", \"valine betaine\", \"ursodeoxycholate sulfate (1)\", \"tricarballylate\",\"succinimide\", \"thymine\", \"syringic acid\", \"serotonin\", \"ribitol\" ]]\n",
    "\n",
    "y = df_encoded['Group']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X),columns=X.columns,index=X.index)\n",
    "\n",
    "all_scores = {\n",
    "    'deletion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    },\n",
    "    'insertion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    }\n",
    "}\n",
    "\n",
    "idx = 0\n",
    "for i in seeds:\n",
    "    print(\"Training Random Forest model...\")\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 7],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, n_iter=50,\n",
    "            cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    model = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "    result = evaluate_global_shap_scores(model, X_test, y_test, pd.Series(np.abs(causal_shap_values[idx]).mean(axis=0), index=feature_names), causal=True)\n",
    "\n",
    "    for method in ['deletion', 'insertion']:\n",
    "        for metric in ['auroc', 'cross_entropy', 'brier']:\n",
    "            all_scores[method][metric].append(result[method][\"average_scores\"][metric])\n",
    "\n",
    "    import json\n",
    "\n",
    "    idx += 1\n",
    "\n",
    "\n",
    "final_results = {\n",
    "    'deletion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['deletion'].items()\n",
    "    },\n",
    "    'insertion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['insertion'].items()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(json.dumps(final_results, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords \n",
    "1. Shapley Flow\n",
    "2. Independent SHAP\n",
    "3. Kernel SHAP\n",
    "4. On Manifold SHAP\n",
    "5. ASV\n",
    "6. Causal SHAP\n",
    "7. The ground truth using Exact SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8020833333333333,\n",
      "                0.8397435897435898,\n",
      "                0.7131410256410257,\n",
      "                0.6145833333333333,\n",
      "                0.6185897435897436,\n",
      "                0.6698717948717949,\n",
      "                0.6081730769230769,\n",
      "                0.641025641025641,\n",
      "                0.5809294871794872,\n",
      "                0.6185897435897436,\n",
      "                0.6017628205128205,\n",
      "                0.5625,\n",
      "                0.5657051282051282,\n",
      "                0.49278846153846156,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5333619228350892,\n",
      "                0.5854290017917382,\n",
      "                0.7117184396839162,\n",
      "                0.7458745657755351,\n",
      "                0.7558989914783404,\n",
      "                0.7726885342236526,\n",
      "                0.8349087955431667,\n",
      "                0.817599807265667,\n",
      "                0.821387779310824,\n",
      "                0.8470874346587572,\n",
      "                0.8627058504741411,\n",
      "                0.8712524060971474,\n",
      "                0.8638035119597676,\n",
      "                0.8995743280976343,\n",
      "                0.9272027411818561\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17575241929729749,\n",
      "                0.1986929523104957,\n",
      "                0.2597070037610788,\n",
      "                0.27604349501841946,\n",
      "                0.28036038967648813,\n",
      "                0.2884387636561335,\n",
      "                0.3177134088503751,\n",
      "                0.3100027858499906,\n",
      "                0.3116496358859176,\n",
      "                0.32347073957162636,\n",
      "                0.33038564782264007,\n",
      "                0.33402314519077886,\n",
      "                0.33096646989988726,\n",
      "                0.3463612240726922,\n",
      "                0.3581441230715909\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6286324786324786,\n",
      "            \"cross_entropy\": 0.7900329406918155,\n",
      "            \"brier\": 0.29611414692902743,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8565705128205129,\n",
      "                0.8325320512820513,\n",
      "                0.8445512820512819,\n",
      "                0.8878205128205128,\n",
      "                0.8894230769230769,\n",
      "                0.8926282051282051,\n",
      "                0.8846153846153846,\n",
      "                0.8782051282051282,\n",
      "                0.8846153846153846,\n",
      "                0.8790064102564102,\n",
      "                0.8693910256410257,\n",
      "                0.8717948717948718,\n",
      "                0.8782051282051282,\n",
      "                0.8846153846153846,\n",
      "                0.8782051282051282\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5577995700528187,\n",
      "                0.5201346733885938,\n",
      "                0.4655374628351458,\n",
      "                0.4380237734852441,\n",
      "                0.4469987324467296,\n",
      "                0.44306461960637533,\n",
      "                0.43889639664236746,\n",
      "                0.4413966800638519,\n",
      "                0.4349291706557598,\n",
      "                0.4435350641405689,\n",
      "                0.4485116161938097,\n",
      "                0.4479421868334637,\n",
      "                0.4449253509023893,\n",
      "                0.428066117917529,\n",
      "                0.43130759728033224\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18281475287193621,\n",
      "                0.16834113484809304,\n",
      "                0.145363733060362,\n",
      "                0.13537964233817612,\n",
      "                0.14030164590946026,\n",
      "                0.13814634256382088,\n",
      "                0.1369469513204118,\n",
      "                0.13773027198378027,\n",
      "                0.13477548063551117,\n",
      "                0.13904810183125885,\n",
      "                0.14118484301751733,\n",
      "                0.1412712081256485,\n",
      "                0.14003001297997186,\n",
      "                0.1334331081439622,\n",
      "                0.13441740529050694\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8741452991452991,\n",
      "            \"cross_entropy\": 0.45540460082966533,\n",
      "            \"brier\": 0.14327897566136116,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7875,\n",
      "                0.7725000000000001,\n",
      "                0.7083333333333334,\n",
      "                0.6375,\n",
      "                0.6725,\n",
      "                0.6666666666666666,\n",
      "                0.54,\n",
      "                0.5850000000000001,\n",
      "                0.5783333333333334,\n",
      "                0.5858333333333332,\n",
      "                0.5570833333333334,\n",
      "                0.4475,\n",
      "                0.4504166666666667,\n",
      "                0.46916666666666673,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5893880935369175,\n",
      "                0.6176558398670412,\n",
      "                0.7076710805216456,\n",
      "                0.784759638926778,\n",
      "                0.8199100466259783,\n",
      "                0.8389216752560494,\n",
      "                0.9286573885797251,\n",
      "                0.8625779348618019,\n",
      "                0.8939732945679326,\n",
      "                0.8975144481881051,\n",
      "                0.9128735159094814,\n",
      "                0.9438404061101029,\n",
      "                0.9520129934761596,\n",
      "                0.9619538315570729,\n",
      "                0.9404186671352546\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.20014143968821002,\n",
      "                0.2133121563327899,\n",
      "                0.256208923039687,\n",
      "                0.2909840968525915,\n",
      "                0.30712628027987765,\n",
      "                0.3156494453326024,\n",
      "                0.3569612715182435,\n",
      "                0.3302770545611991,\n",
      "                0.3442630343753096,\n",
      "                0.3458184515411061,\n",
      "                0.3524938250597032,\n",
      "                0.3661318637705916,\n",
      "                0.36951949695807007,\n",
      "                0.3737091000733354,\n",
      "                0.3649649438114703\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.5972222222222221,\n",
      "            \"cross_entropy\": 0.8434752570080032,\n",
      "            \"brier\": 0.31917075887965246,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7708333333333334,\n",
      "                0.7933333333333333,\n",
      "                0.7704166666666665,\n",
      "                0.8325,\n",
      "                0.8125,\n",
      "                0.81,\n",
      "                0.8341666666666666,\n",
      "                0.8150000000000001,\n",
      "                0.8108333333333333,\n",
      "                0.8108333333333333,\n",
      "                0.8108333333333333,\n",
      "                0.8233333333333334,\n",
      "                0.8316666666666668,\n",
      "                0.8333333333333334,\n",
      "                0.8291666666666667\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.6613720387481131,\n",
      "                0.6627711878754254,\n",
      "                0.5714502079239782,\n",
      "                0.5022962775906499,\n",
      "                0.5148025511492268,\n",
      "                0.5007757405055746,\n",
      "                0.46982221679137404,\n",
      "                0.5046825103396795,\n",
      "                0.5075128233163185,\n",
      "                0.5071459957914193,\n",
      "                0.5034983927282529,\n",
      "                0.4960670431926233,\n",
      "                0.4918531367432289,\n",
      "                0.4871241976779984,\n",
      "                0.4891898601283233\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.22809981569093526,\n",
      "                0.22820859426101966,\n",
      "                0.19088783303745957,\n",
      "                0.164512661141683,\n",
      "                0.16800775438905266,\n",
      "                0.16194994874906474,\n",
      "                0.14979773533702664,\n",
      "                0.16326767370474068,\n",
      "                0.1646962467012852,\n",
      "                0.16360639327400986,\n",
      "                0.16369017735552202,\n",
      "                0.16179259075906077,\n",
      "                0.16020746528117583,\n",
      "                0.15805205753032267,\n",
      "                0.15935898123209713\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8125833333333335,\n",
      "            \"cross_entropy\": 0.5246909453668124,\n",
      "            \"brier\": 0.17240906189629707,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8387096774193548,\n",
      "                0.832708177044261,\n",
      "                0.8259564891222806,\n",
      "                0.7606901725431358,\n",
      "                0.7606901725431359,\n",
      "                0.7396849212303076,\n",
      "                0.6751687921980495,\n",
      "                0.5828957239309828,\n",
      "                0.5671417854463616,\n",
      "                0.5648912228057015,\n",
      "                0.6151537884471118,\n",
      "                0.5120030007501875,\n",
      "                0.5303825956489122,\n",
      "                0.6222805701425357,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5193068224943925,\n",
      "                0.5240599745562133,\n",
      "                0.5244811320258818,\n",
      "                0.6038883258676423,\n",
      "                0.6088825974239522,\n",
      "                0.6326031816543832,\n",
      "                0.7225015952523923,\n",
      "                0.774378708649886,\n",
      "                0.8014363553763459,\n",
      "                0.8144531160013843,\n",
      "                0.8114181043310499,\n",
      "                0.9084174172311995,\n",
      "                0.9184507189851845,\n",
      "                0.9268602038924735,\n",
      "                0.8937715432763311\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.16720830628118008,\n",
      "                0.16924180799641245,\n",
      "                0.17025486145577842,\n",
      "                0.20784383696927516,\n",
      "                0.21034698687941386,\n",
      "                0.22092306735423775,\n",
      "                0.26434412055215295,\n",
      "                0.2884480841469658,\n",
      "                0.30086124720926277,\n",
      "                0.30668864754757946,\n",
      "                0.30555906814196215,\n",
      "                0.3455091072997424,\n",
      "                0.349295647586681,\n",
      "                0.3524862497180961,\n",
      "                0.3406323110321205\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6618904726181545,\n",
      "            \"cross_entropy\": 0.7323273198012477,\n",
      "            \"brier\": 0.2666428900113907,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8945986496624156,\n",
      "                0.9249812453113279,\n",
      "                0.9242310577644411,\n",
      "                0.9122280570142536,\n",
      "                0.9047261815453863,\n",
      "                0.9077269317329333,\n",
      "                0.9182295573893473,\n",
      "                0.8942235558889722,\n",
      "                0.897224306076519,\n",
      "                0.905476369092273,\n",
      "                0.8897224306076519,\n",
      "                0.8964741185296324,\n",
      "                0.8964741185296324,\n",
      "                0.897224306076519,\n",
      "                0.8994748687171792\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5339335987660522,\n",
      "                0.503191506793987,\n",
      "                0.4970527625855122,\n",
      "                0.44586671949181594,\n",
      "                0.4414898955733365,\n",
      "                0.4089570759565767,\n",
      "                0.38271460631379256,\n",
      "                0.3864342002392052,\n",
      "                0.3896632329993499,\n",
      "                0.3895098927820571,\n",
      "                0.40661728017657317,\n",
      "                0.40560398943241993,\n",
      "                0.4067611848840516,\n",
      "                0.40288477563499814,\n",
      "                0.40118807518577815\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17395977258876588,\n",
      "                0.16418169590393328,\n",
      "                0.16392143796758013,\n",
      "                0.1389608188318918,\n",
      "                0.1371368313101777,\n",
      "                0.1262248612999938,\n",
      "                0.11498959260609118,\n",
      "                0.11602097537683442,\n",
      "                0.11710623144699898,\n",
      "                0.11685694547671749,\n",
      "                0.12191764026164768,\n",
      "                0.12157361278719718,\n",
      "                0.12209161831306989,\n",
      "                0.12052601630371493,\n",
      "                0.11986653926437998\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.9042010502625656,\n",
      "            \"cross_entropy\": 0.4267912531210338,\n",
      "            \"brier\": 0.1316889726492663,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8286445012787723,\n",
      "                0.805626598465473,\n",
      "                0.7877237851662404,\n",
      "                0.7971014492753624,\n",
      "                0.7834612105711849,\n",
      "                0.6385336743393009,\n",
      "                0.6368286445012787,\n",
      "                0.5345268542199488,\n",
      "                0.47314578005115093,\n",
      "                0.47058823529411764,\n",
      "                0.41687979539641945,\n",
      "                0.46675191815856787,\n",
      "                0.48508098891730606,\n",
      "                0.4177323103154305,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5247611733780392,\n",
      "                0.5461276235812134,\n",
      "                0.5679538770537451,\n",
      "                0.5625828432497123,\n",
      "                0.6186564425099202,\n",
      "                0.7460919453822819,\n",
      "                0.7322785264306098,\n",
      "                0.8055815756634814,\n",
      "                0.8310195288766946,\n",
      "                0.8326792107930114,\n",
      "                0.8498657995727185,\n",
      "                0.8711329850339488,\n",
      "                0.8896985357573236,\n",
      "                0.8752251492436385,\n",
      "                0.8697720218315294\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17191309223617363,\n",
      "                0.18164937848718152,\n",
      "                0.19122944200430128,\n",
      "                0.18888858787145657,\n",
      "                0.2140062987091098,\n",
      "                0.27435008510845854,\n",
      "                0.26817394461612076,\n",
      "                0.3035965952112115,\n",
      "                0.3161136724802682,\n",
      "                0.3168646859217512,\n",
      "                0.32482205621473437,\n",
      "                0.33486828613858943,\n",
      "                0.343590326481724,\n",
      "                0.3372812259975539,\n",
      "                0.3348469112139148\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6028417163967037,\n",
      "            \"cross_entropy\": 0.7415618158905245,\n",
      "            \"brier\": 0.27347963924616997,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8047740835464622,\n",
      "                0.8094629156010231,\n",
      "                0.8269394714407502,\n",
      "                0.8286445012787724,\n",
      "                0.8337595907928389,\n",
      "                0.8320545609548167,\n",
      "                0.8439897698209718,\n",
      "                0.8525149190110827,\n",
      "                0.8525149190110827,\n",
      "                0.8627450980392157,\n",
      "                0.8712702472293264,\n",
      "                0.8482523444160273,\n",
      "                0.8533674339300937,\n",
      "                0.855072463768116,\n",
      "                0.8533674339300937\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.6304875596901828,\n",
      "                0.5726721464587583,\n",
      "                0.5541054089286767,\n",
      "                0.5446356726712831,\n",
      "                0.5424625996058253,\n",
      "                0.4824953043152265,\n",
      "                0.4734645923642253,\n",
      "                0.4422034068841884,\n",
      "                0.43608586291924334,\n",
      "                0.4298823549499392,\n",
      "                0.42716516195644877,\n",
      "                0.4432763960927437,\n",
      "                0.45358953512208394,\n",
      "                0.45130270990607874,\n",
      "                0.45297774690534315\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.21120993032259455,\n",
      "                0.18659190174102622,\n",
      "                0.17950335031682949,\n",
      "                0.17672041228898647,\n",
      "                0.17401256373354693,\n",
      "                0.14820274883693133,\n",
      "                0.14508152714524378,\n",
      "                0.1356492255599117,\n",
      "                0.13397581658794583,\n",
      "                0.13218689315153653,\n",
      "                0.1311226632174912,\n",
      "                0.13606350263967296,\n",
      "                0.13969922820273195,\n",
      "                0.1391176880478164,\n",
      "                0.14064052329750873\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8419153168513781,\n",
      "            \"cross_entropy\": 0.4891204305846831,\n",
      "            \"brier\": 0.15398519833931829,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.77344336084021,\n",
      "                0.8124531132783195,\n",
      "                0.7516879219804952,\n",
      "                0.7434358589647412,\n",
      "                0.6339084771192798,\n",
      "                0.5697674418604651,\n",
      "                0.5836459114778695,\n",
      "                0.5656414103525882,\n",
      "                0.5150037509377345,\n",
      "                0.4553638409602401,\n",
      "                0.41072768192048015,\n",
      "                0.3930982745686422,\n",
      "                0.6140285071267817,\n",
      "                0.4531132783195799,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5584202674130104,\n",
      "                0.5682717806473163,\n",
      "                0.6383728441360038,\n",
      "                0.6726075538860187,\n",
      "                0.7382501310495396,\n",
      "                0.8083555665781142,\n",
      "                0.809865226540508,\n",
      "                0.816834065043128,\n",
      "                0.8531420017985573,\n",
      "                0.9089021997755932,\n",
      "                0.9280191310955136,\n",
      "                0.9493884091620327,\n",
      "                0.9073720733115722,\n",
      "                0.8929301656294587,\n",
      "                0.8770640441784052\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18761853207735799,\n",
      "                0.1904080207069314,\n",
      "                0.22368184158393084,\n",
      "                0.24062558241404672,\n",
      "                0.2696422668689097,\n",
      "                0.30185235940277017,\n",
      "                0.30259065412606484,\n",
      "                0.30583363363363364,\n",
      "                0.3214797601351352,\n",
      "                0.34533637950450446,\n",
      "                0.3527080570570571,\n",
      "                0.3605872852852853,\n",
      "                0.3456241775525525,\n",
      "                0.34024235885885884,\n",
      "                0.3339753430930932\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.5850212553138284,\n",
      "            \"cross_entropy\": 0.7951863640163181,\n",
      "            \"brier\": 0.29481375015334216,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7996999249812454,\n",
      "                0.8218304576144037,\n",
      "                0.8394598649662415,\n",
      "                0.838709677419355,\n",
      "                0.8604651162790699,\n",
      "                0.8454613653413353,\n",
      "                0.8372093023255813,\n",
      "                0.8267066766691673,\n",
      "                0.840960240060015,\n",
      "                0.8300825206301575,\n",
      "                0.8282070517629407,\n",
      "                0.8289572393098275,\n",
      "                0.8252063015753939,\n",
      "                0.8154538634658665,\n",
      "                0.8244561140285072\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5568416944948791,\n",
      "                0.5442047552251412,\n",
      "                0.47776169838230376,\n",
      "                0.47984045805752085,\n",
      "                0.45660477869686983,\n",
      "                0.4621389745448629,\n",
      "                0.4766297945078694,\n",
      "                0.4832814192871908,\n",
      "                0.47746912560043187,\n",
      "                0.4937059988487875,\n",
      "                0.496058042744185,\n",
      "                0.4955479092933553,\n",
      "                0.501331696683194,\n",
      "                0.5025047962107729,\n",
      "                0.49914526465592496\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18404619594594598,\n",
      "                0.17756453265765765,\n",
      "                0.15034626576576576,\n",
      "                0.1504253143424036,\n",
      "                0.14303556523296254,\n",
      "                0.1451331718548906,\n",
      "                0.15032873661671875,\n",
      "                0.15207793787154503,\n",
      "                0.15158763901912115,\n",
      "                0.15784162801066373,\n",
      "                0.15902254750413675,\n",
      "                0.1585164942084942,\n",
      "                0.1610550822608323,\n",
      "                0.16002635111578414,\n",
      "                0.15791030935718886\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8308577144286071,\n",
      "            \"cross_entropy\": 0.49353776048221926,\n",
      "            \"brier\": 0.1572611847842741,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 456, 789, 1010]\n",
    "\n",
    "X = X[[\"xylose\", \"xanthosine\", \"uracil\", \"ribulose/xylulose\", \"valylglutamine\", \"tryptophylglycine\", \"succinate\", \"valine betaine\", \"ursodeoxycholate sulfate (1)\", \"tricarballylate\",\"succinimide\", \"thymine\", \"syringic acid\", \"serotonin\", \"ribitol\" ]]\n",
    "\n",
    "y = df_encoded['Group']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X),columns=X.columns,index=X.index)\n",
    "\n",
    "all_scores = {\n",
    "    'deletion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    },\n",
    "    'insertion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    }\n",
    "}\n",
    "\n",
    "for i in seeds:\n",
    "    print(\"Training Random Forest model...\")\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 7],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, n_iter=50,\n",
    "            cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    model = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "\n",
    "    #########################\n",
    "\n",
    "    def predict_proba_class1(X):\n",
    "        return model.predict_proba(X)[:, 1]  \n",
    "\n",
    "    explainer = IndExplainer(predict_proba_class1, X_train, silent=True)\n",
    "\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "\n",
    "    mean_abs_shap_series = pd.Series(mean_abs_shap.flatten(), index=X_test.columns) \n",
    "    #########################\n",
    "    \n",
    "    result = evaluate_global_shap_scores(model, X_test, y_test, mean_abs_shap_series, causal=True)\n",
    "\n",
    "    for method in ['deletion', 'insertion']:\n",
    "        for metric in ['auroc', 'cross_entropy', 'brier']:\n",
    "            all_scores[method][metric].append(result[method][\"average_scores\"][metric])\n",
    "\n",
    "    import json\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.6151216290366774,\n",
      "            \"std\": 0.027375482840523428\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.7805167394815818,\n",
      "            \"std\": 0.04027216691388977\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.2900442370439166,\n",
      "            \"std\": 0.01860083481298497\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.8527405428042367,\n",
      "            \"std\": 0.03260365804331371\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.4779089980768828,\n",
      "            \"std\": 0.033698595728216825\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.1517246786661034,\n",
      "            \"std\": 0.01368477967407941\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "final_results = {\n",
    "    'deletion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['deletion'].items()\n",
    "    },\n",
    "    'insertion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['insertion'].items()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(json.dumps(final_results, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8020833333333333,\n",
      "                0.8397435897435898,\n",
      "                0.7131410256410257,\n",
      "                0.6145833333333333,\n",
      "                0.6594551282051282,\n",
      "                0.5817307692307693,\n",
      "                0.5889423076923077,\n",
      "                0.577724358974359,\n",
      "                0.5681089743589745,\n",
      "                0.5777243589743589,\n",
      "                0.624198717948718,\n",
      "                0.6330128205128205,\n",
      "                0.6410256410256411,\n",
      "                0.5496794871794872,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5333619228350892,\n",
      "                0.5854290017917382,\n",
      "                0.7117184396839162,\n",
      "                0.7458745657755351,\n",
      "                0.7609425205648278,\n",
      "                0.81629281154797,\n",
      "                0.8312398984400432,\n",
      "                0.8511110429516637,\n",
      "                0.8933019281633018,\n",
      "                0.8780998459981025,\n",
      "                0.8657641350109784,\n",
      "                0.8811974940453968,\n",
      "                0.9161860674641521,\n",
      "                0.9057119878394626,\n",
      "                0.9272027411818561\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17575241929729749,\n",
      "                0.1986929523104957,\n",
      "                0.2597070037610788,\n",
      "                0.27604349501841946,\n",
      "                0.28317193640107285,\n",
      "                0.3094726358791318,\n",
      "                0.3164453488727615,\n",
      "                0.3253059452913518,\n",
      "                0.3433949712750327,\n",
      "                0.3367545883237933,\n",
      "                0.33160906520520866,\n",
      "                0.3381256332774022,\n",
      "                0.35305033712142675,\n",
      "                0.34909087221399937,\n",
      "                0.3581441230715909\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6314102564102563,\n",
      "            \"cross_entropy\": 0.8068956268862688,\n",
      "            \"brier\": 0.3036507551546708,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8565705128205129,\n",
      "                0.8325320512820513,\n",
      "                0.8445512820512819,\n",
      "                0.8878205128205128,\n",
      "                0.8942307692307693,\n",
      "                0.8838141025641025,\n",
      "                0.8862179487179487,\n",
      "                0.8782051282051282,\n",
      "                0.8814102564102564,\n",
      "                0.877403846153846,\n",
      "                0.877403846153846,\n",
      "                0.8790064102564102,\n",
      "                0.8798076923076923,\n",
      "                0.8838141025641025,\n",
      "                0.8782051282051282\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5577995700528187,\n",
      "                0.5201346733885938,\n",
      "                0.4655374628351458,\n",
      "                0.4380237734852441,\n",
      "                0.43730879287510854,\n",
      "                0.4360449867580237,\n",
      "                0.44189194549626104,\n",
      "                0.4451958305447855,\n",
      "                0.4386177329599302,\n",
      "                0.44032337122927667,\n",
      "                0.43629862076617143,\n",
      "                0.4342793367923298,\n",
      "                0.4420019808957581,\n",
      "                0.4364323211908413,\n",
      "                0.43130759728033224\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18281475287193621,\n",
      "                0.16834113484809304,\n",
      "                0.145363733060362,\n",
      "                0.13537964233817612,\n",
      "                0.1343872099240829,\n",
      "                0.1345341998682114,\n",
      "                0.13688533663010144,\n",
      "                0.13822337699698292,\n",
      "                0.13550909934919772,\n",
      "                0.1353304599080069,\n",
      "                0.13421555528437148,\n",
      "                0.13373106966459333,\n",
      "                0.1372993291343565,\n",
      "                0.1351532954735166,\n",
      "                0.13441740529050694\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.874732905982906,\n",
      "            \"cross_entropy\": 0.4534131997700414,\n",
      "            \"brier\": 0.14143904004283303,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7875,\n",
      "                0.7458333333333332,\n",
      "                0.6716666666666666,\n",
      "                0.675,\n",
      "                0.5691666666666667,\n",
      "                0.5524999999999999,\n",
      "                0.4558333333333333,\n",
      "                0.4866666666666667,\n",
      "                0.4691666666666666,\n",
      "                0.49166666666666664,\n",
      "                0.5033333333333334,\n",
      "                0.47583333333333333,\n",
      "                0.5475,\n",
      "                0.6029166666666667,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5893880935369175,\n",
      "                0.6939687843745195,\n",
      "                0.739482983649083,\n",
      "                0.7667296841939735,\n",
      "                0.8712544852356086,\n",
      "                0.8798733125111229,\n",
      "                0.9110916682241855,\n",
      "                0.9186758706319762,\n",
      "                0.9316039269430203,\n",
      "                0.9363309592016718,\n",
      "                1.0063124068352836,\n",
      "                1.0346153137679555,\n",
      "                0.9121359840206228,\n",
      "                0.8969212247236866,\n",
      "                0.9404186671352546\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.20014143968821002,\n",
      "                0.25060080888344277,\n",
      "                0.27206466693271686,\n",
      "                0.2849038167509113,\n",
      "                0.33141265072432347,\n",
      "                0.3349961904861031,\n",
      "                0.349320717609804,\n",
      "                0.35223336606304056,\n",
      "                0.3572699182414392,\n",
      "                0.3591904245507134,\n",
      "                0.38723652898976557,\n",
      "                0.3976958840847826,\n",
      "                0.3522985231076693,\n",
      "                0.34589057140957685,\n",
      "                0.3649649438114703\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.5689722222222221,\n",
      "            \"cross_entropy\": 0.8685868909989921,\n",
      "            \"brier\": 0.3293480300889314,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7708333333333334,\n",
      "                0.7929166666666666,\n",
      "                0.8283333333333333,\n",
      "                0.8216666666666667,\n",
      "                0.8491666666666667,\n",
      "                0.855,\n",
      "                0.8541666666666666,\n",
      "                0.8533333333333334,\n",
      "                0.8616666666666667,\n",
      "                0.8533333333333333,\n",
      "                0.8441666666666666,\n",
      "                0.8466666666666667,\n",
      "                0.8308333333333333,\n",
      "                0.8291666666666667,\n",
      "                0.8291666666666667\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.6613720387481131,\n",
      "                0.5813672929279904,\n",
      "                0.5390738351746055,\n",
      "                0.5419344900707526,\n",
      "                0.47881915478840303,\n",
      "                0.4727521460481592,\n",
      "                0.46970585613591725,\n",
      "                0.46617739595823354,\n",
      "                0.4608750173250966,\n",
      "                0.4610126113659908,\n",
      "                0.47093760650181443,\n",
      "                0.47002089754970217,\n",
      "                0.49733548742144135,\n",
      "                0.4996235593909976,\n",
      "                0.4891898601283233\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.22809981569093526,\n",
      "                0.19605940381276157,\n",
      "                0.17778690431151167,\n",
      "                0.17884849264095265,\n",
      "                0.1558862551109809,\n",
      "                0.15351124764741664,\n",
      "                0.1520906346502931,\n",
      "                0.14982622061848694,\n",
      "                0.14837680564310968,\n",
      "                0.1480036628396874,\n",
      "                0.1509812624247849,\n",
      "                0.15122474485640175,\n",
      "                0.16156096150094154,\n",
      "                0.1631009832830725,\n",
      "                0.15935898123209713\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8346944444444445,\n",
      "            \"cross_entropy\": 0.504013149969036,\n",
      "            \"brier\": 0.16498109175089554,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8387096774193548,\n",
      "                0.7741935483870968,\n",
      "                0.7449362340585146,\n",
      "                0.7351837959489873,\n",
      "                0.735933983495874,\n",
      "                0.7284321080270068,\n",
      "                0.7231807951987997,\n",
      "                0.6556639159789948,\n",
      "                0.6556639159789948,\n",
      "                0.6234058514628658,\n",
      "                0.5843960990247562,\n",
      "                0.6020255063765941,\n",
      "                0.6920480120030008,\n",
      "                0.581020255063766,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5193068224943925,\n",
      "                0.5884276777641769,\n",
      "                0.6528984636814126,\n",
      "                0.6769923018390795,\n",
      "                0.6911745697742497,\n",
      "                0.695703166841507,\n",
      "                0.6989857419917485,\n",
      "                0.7485959290659667,\n",
      "                0.7562490405222203,\n",
      "                0.8273832987610231,\n",
      "                0.8658759414831441,\n",
      "                0.8717347481422624,\n",
      "                0.8812435436169391,\n",
      "                0.8617387738393916,\n",
      "                0.8937715432763311\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.16720830628118008,\n",
      "                0.20064877500497325,\n",
      "                0.23147481697693523,\n",
      "                0.24276897776608453,\n",
      "                0.24959079754281277,\n",
      "                0.25165201430618545,\n",
      "                0.25325513420366585,\n",
      "                0.2763005851672251,\n",
      "                0.27993386258127817,\n",
      "                0.3110796876499693,\n",
      "                0.3273353467674733,\n",
      "                0.3296812382295668,\n",
      "                0.3335017173309577,\n",
      "                0.3263939281262555,\n",
      "                0.3406323110321205\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6783195798949737,\n",
      "            \"cross_entropy\": 0.7486721042062564,\n",
      "            \"brier\": 0.2747638332644456,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8945986496624156,\n",
      "                0.8807201800450112,\n",
      "                0.9017254313578394,\n",
      "                0.9167291822955739,\n",
      "                0.90847711927982,\n",
      "                0.9069767441860466,\n",
      "                0.9099774943735934,\n",
      "                0.8927231807951987,\n",
      "                0.8972243060765192,\n",
      "                0.9009752438109527,\n",
      "                0.9017254313578394,\n",
      "                0.891972993248312,\n",
      "                0.8889722430607652,\n",
      "                0.8912228057014253,\n",
      "                0.8994748687171792\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5339335987660522,\n",
      "                0.4644702556151713,\n",
      "                0.41740777547848185,\n",
      "                0.38370294811830236,\n",
      "                0.3875108976141144,\n",
      "                0.38911292181094503,\n",
      "                0.3847639890286141,\n",
      "                0.3909603801330699,\n",
      "                0.3958801246442769,\n",
      "                0.39698862680441455,\n",
      "                0.4006144361616082,\n",
      "                0.4144497506025137,\n",
      "                0.41225214453236225,\n",
      "                0.4092374433330183,\n",
      "                0.40118807518577815\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17395977258876588,\n",
      "                0.14233368561447618,\n",
      "                0.12648882895646923,\n",
      "                0.11529523911652789,\n",
      "                0.11615970637542927,\n",
      "                0.11674902324000953,\n",
      "                0.11553623860675132,\n",
      "                0.11778630362659204,\n",
      "                0.11933122423266883,\n",
      "                0.1190254791478735,\n",
      "                0.12080716489676387,\n",
      "                0.12454089754848414,\n",
      "                0.12370237006857425,\n",
      "                0.12253728349745233,\n",
      "                0.11986653926437998\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8988997249312327,\n",
      "            \"cross_entropy\": 0.4121648911885816,\n",
      "            \"brier\": 0.12494131711874788,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8286445012787723,\n",
      "                0.7468030690537085,\n",
      "                0.7178175618073316,\n",
      "                0.6317135549872123,\n",
      "                0.7135549872122763,\n",
      "                0.6768968456947997,\n",
      "                0.6624040920716112,\n",
      "                0.6982097186700766,\n",
      "                0.5605285592497868,\n",
      "                0.5387894288150042,\n",
      "                0.48678601875532823,\n",
      "                0.49957374254049447,\n",
      "                0.4607843137254902,\n",
      "                0.43648763853367434,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5247611733780392,\n",
      "                0.5992980891784528,\n",
      "                0.6364483622529632,\n",
      "                0.7030805887135134,\n",
      "                0.715668995754935,\n",
      "                0.7504978793789844,\n",
      "                0.7510081525743754,\n",
      "                0.7590473267041544,\n",
      "                0.8610492646842218,\n",
      "                0.8698869915442957,\n",
      "                0.898067744616942,\n",
      "                0.8909999378610434,\n",
      "                0.9206560887715927,\n",
      "                0.9076342838507201,\n",
      "                0.8697720218315294\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.17191309223617363,\n",
      "                0.20559231482901733,\n",
      "                0.22279499813175022,\n",
      "                0.2545604943132168,\n",
      "                0.26095511313547015,\n",
      "                0.2777763204406657,\n",
      "                0.2778256410845587,\n",
      "                0.28157610151937973,\n",
      "                0.3299275809319805,\n",
      "                0.3338041440666112,\n",
      "                0.34649055004908447,\n",
      "                0.34350239570985713,\n",
      "                0.35668698977363994,\n",
      "                0.35130253098609654,\n",
      "                0.3348469112139148\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6105996021597043,\n",
      "            \"cross_entropy\": 0.7771917934063841,\n",
      "            \"brier\": 0.28997034522809445,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8047740835464622,\n",
      "                0.8405797101449275,\n",
      "                0.8350383631713556,\n",
      "                0.8644501278772379,\n",
      "                0.8525149190110827,\n",
      "                0.8491048593350383,\n",
      "                0.8559249786871269,\n",
      "                0.8533674339300938,\n",
      "                0.8499573742540495,\n",
      "                0.8550724637681161,\n",
      "                0.8550724637681159,\n",
      "                0.8567774936061381,\n",
      "                0.8473998294970162,\n",
      "                0.855924978687127,\n",
      "                0.8533674339300937\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.6304875596901828,\n",
      "                0.5231308843317846,\n",
      "                0.49239532464583374,\n",
      "                0.45061291867255465,\n",
      "                0.4488079879901134,\n",
      "                0.4377952509558597,\n",
      "                0.4328418086387747,\n",
      "                0.440467101555822,\n",
      "                0.4444247595254319,\n",
      "                0.44258720291592657,\n",
      "                0.4465317175562267,\n",
      "                0.4546256754904655,\n",
      "                0.46069593929516517,\n",
      "                0.4576390885722986,\n",
      "                0.45297774690534315\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.21120993032259455,\n",
      "                0.1662162563773505,\n",
      "                0.15263013176691798,\n",
      "                0.13865086965929263,\n",
      "                0.13820161325899794,\n",
      "                0.1343032965132808,\n",
      "                0.13305972480726605,\n",
      "                0.13575866176932855,\n",
      "                0.13582627594777436,\n",
      "                0.13511561326422913,\n",
      "                0.13686944444462473,\n",
      "                0.14026060803255688,\n",
      "                0.14380922857904643,\n",
      "                0.1424657863045856,\n",
      "                0.14064052329750873\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8486217675475988,\n",
      "            \"cross_entropy\": 0.4677347311161189,\n",
      "            \"brier\": 0.14566786428969034,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.77344336084021,\n",
      "                0.7531882970742686,\n",
      "                0.6946736684171043,\n",
      "                0.6856714178544637,\n",
      "                0.6740435108777195,\n",
      "                0.6489122280570143,\n",
      "                0.6594148537134285,\n",
      "                0.5656414103525882,\n",
      "                0.5150037509377345,\n",
      "                0.6297824456114028,\n",
      "                0.6065266316579144,\n",
      "                0.5611402850712678,\n",
      "                0.47674418604651164,\n",
      "                0.5112528132033008,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5584202674130104,\n",
      "                0.6152823978620233,\n",
      "                0.6579896115602043,\n",
      "                0.6642937181266289,\n",
      "                0.7118725548352302,\n",
      "                0.7509484075000866,\n",
      "                0.748053999148485,\n",
      "                0.816834065043128,\n",
      "                0.8531420017985573,\n",
      "                0.8142761901525477,\n",
      "                0.8249911770964635,\n",
      "                0.8143392159822175,\n",
      "                0.8735703801838499,\n",
      "                0.857969859547468,\n",
      "                0.8770640441784052\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18761853207735799,\n",
      "                0.21349258921102227,\n",
      "                0.23274374217265728,\n",
      "                0.235380370681268,\n",
      "                0.2585282642489428,\n",
      "                0.27702612541367894,\n",
      "                0.2757267580744009,\n",
      "                0.30583363363363364,\n",
      "                0.3214797601351352,\n",
      "                0.30571720007507514,\n",
      "                0.3101573502252252,\n",
      "                0.3060259530780781,\n",
      "                0.33219614864864866,\n",
      "                0.32596126801801806,\n",
      "                0.3339753430930932\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6170292573143286,\n",
      "            \"cross_entropy\": 0.7626031926952204,\n",
      "            \"brier\": 0.28145753591908235,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.7996999249812454,\n",
      "                0.8435858964741185,\n",
      "                0.8735933983495874,\n",
      "                0.8642160540135033,\n",
      "                0.873218304576144,\n",
      "                0.8394598649662416,\n",
      "                0.8293323330832708,\n",
      "                0.8267066766691673,\n",
      "                0.840960240060015,\n",
      "                0.8342085521380345,\n",
      "                0.8364591147786946,\n",
      "                0.8293323330832707,\n",
      "                0.8259564891222806,\n",
      "                0.8289572393098275,\n",
      "                0.8244561140285072\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.5568416944948791,\n",
      "                0.4803972268976447,\n",
      "                0.4527975866083388,\n",
      "                0.4595173641490266,\n",
      "                0.4617192025653125,\n",
      "                0.4657065262302917,\n",
      "                0.4777595750665153,\n",
      "                0.4832814192871908,\n",
      "                0.47746912560043187,\n",
      "                0.4870591121489736,\n",
      "                0.48602799564319465,\n",
      "                0.4897732885273448,\n",
      "                0.5007021723328844,\n",
      "                0.49850466599197213,\n",
      "                0.49914526465592496\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.18404619594594598,\n",
      "                0.1502662864114114,\n",
      "                0.14139421585041675,\n",
      "                0.14366550135020226,\n",
      "                0.14383770573060306,\n",
      "                0.1467720693620917,\n",
      "                0.15137168018784086,\n",
      "                0.15207793787154503,\n",
      "                0.15158763901912115,\n",
      "                0.15531925651161363,\n",
      "                0.15449668540479256,\n",
      "                0.1550220007450052,\n",
      "                0.159548823238417,\n",
      "                0.1580167910250812,\n",
      "                0.15791030935718886\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8380095023755938,\n",
      "            \"cross_entropy\": 0.4851134813466617,\n",
      "            \"brier\": 0.1536888732007518,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 456, 789, 1010]\n",
    "\n",
    "X = X[[\"xylose\", \"xanthosine\", \"uracil\", \"ribulose/xylulose\", \"valylglutamine\", \"tryptophylglycine\", \"succinate\", \"valine betaine\", \"ursodeoxycholate sulfate (1)\", \"tricarballylate\",\"succinimide\", \"thymine\", \"syringic acid\", \"serotonin\", \"ribitol\" ]]\n",
    "\n",
    "y = df_encoded['Group']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X),columns=X.columns,index=X.index)\n",
    "\n",
    "all_scores = {\n",
    "    'deletion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    },\n",
    "    'insertion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    }\n",
    "}\n",
    "\n",
    "for i in seeds:\n",
    "    print(\"Training Random Forest model...\")\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 7],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, n_iter=50,\n",
    "            cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    model = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "\n",
    "    #########################\n",
    "    def predict_proba_class1(X):\n",
    "        return model.predict_proba(X)[:, 1]  \n",
    "    \n",
    "    bg_mean = pd.DataFrame(X_train.mean()).T\n",
    "\n",
    "    explainer = OnManifoldExplainer(predict_proba_class1, pd.concat([bg_mean, X_test]), silent=True)\n",
    "\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "\n",
    "    mean_abs_shap_series = pd.Series(mean_abs_shap.flatten(), index=X_test.columns) \n",
    "    #########################\n",
    "    \n",
    "    result = evaluate_global_shap_scores(model, X_test, y_test, mean_abs_shap_series, causal=True)\n",
    "\n",
    "    for method in ['deletion', 'insertion']:\n",
    "        for metric in ['auroc', 'cross_entropy', 'brier']:\n",
    "            all_scores[method][metric].append(result[method][\"average_scores\"][metric])\n",
    "\n",
    "    import json\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.621266183600297,\n",
      "            \"std\": 0.035282795077840136\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.7927899216386244,\n",
      "            \"std\": 0.042532513465342384\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.29583809993104493,\n",
      "            \"std\": 0.01933550559422105\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.8589916690563552,\n",
      "            \"std\": 0.024407297119723653\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.46448789067808793,\n",
      "            \"std\": 0.031172257343868824\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.14614363728058372,\n",
      "            \"std\": 0.013294196112329402\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "final_results = {\n",
    "    'deletion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['deletion'].items()\n",
    "    },\n",
    "    'insertion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['insertion'].items()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(json.dumps(final_results, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manifold bg samples: 100%|██████████| 74/74 [19:59<00:00, 16.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.875801282051282,\n",
      "                0.8701923076923077,\n",
      "                0.6979166666666666,\n",
      "                0.688301282051282,\n",
      "                0.6834935897435898,\n",
      "                0.688301282051282,\n",
      "                0.6746794871794871,\n",
      "                0.7427884615384616,\n",
      "                0.6450320512820513,\n",
      "                0.6714743589743589,\n",
      "                0.6754807692307692,\n",
      "                0.5689102564102564,\n",
      "                0.5657051282051282,\n",
      "                0.561298076923077,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.43669113234623613,\n",
      "                0.47204025674087324,\n",
      "                0.6191839691330838,\n",
      "                0.6283403429292808,\n",
      "                0.633111626046965,\n",
      "                0.6365601677117544,\n",
      "                0.6455799058515825,\n",
      "                0.749397773598693,\n",
      "                0.788092377684378,\n",
      "                0.771898561332688,\n",
      "                0.7776509453410465,\n",
      "                0.838448453601495,\n",
      "                0.8638035119597676,\n",
      "                0.8895114950248152,\n",
      "                0.9272027411818561\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.13646746105293178,\n",
      "                0.14959968277776586,\n",
      "                0.21547561632790774,\n",
      "                0.2197939813877736,\n",
      "                0.22222391551421564,\n",
      "                0.22362711227830825,\n",
      "                0.22779083410962853,\n",
      "                0.27751723619827456,\n",
      "                0.29532111174063974,\n",
      "                0.2880341301447121,\n",
      "                0.29075889905777363,\n",
      "                0.3195535765465894,\n",
      "                0.33096646989988726,\n",
      "                0.3422827996885224,\n",
      "                0.3581441230715909\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6739583333333332,\n",
      "            \"cross_entropy\": 0.7118342173656343,\n",
      "            \"brier\": 0.25983712998643477,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.6947115384615384,\n",
      "                0.8509615384615385,\n",
      "                0.8693910256410257,\n",
      "                0.8733974358974359,\n",
      "                0.8749999999999999,\n",
      "                0.8870192307692307,\n",
      "                0.8958333333333333,\n",
      "                0.8677884615384616,\n",
      "                0.8950320512820512,\n",
      "                0.8942307692307692,\n",
      "                0.8934294871794872,\n",
      "                0.8814102564102564,\n",
      "                0.8782051282051282,\n",
      "                0.8766025641025641,\n",
      "                0.8782051282051282\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.942150054860188,\n",
      "                0.6957549346658604,\n",
      "                0.4809020996327366,\n",
      "                0.48018395302627154,\n",
      "                0.4771367474239001,\n",
      "                0.47517331832269827,\n",
      "                0.4831378297889369,\n",
      "                0.4635904582042966,\n",
      "                0.43802380979274036,\n",
      "                0.4412488405348328,\n",
      "                0.4411279604332359,\n",
      "                0.43505172375888984,\n",
      "                0.4449253509023893,\n",
      "                0.44638355008879305,\n",
      "                0.43130759728033224\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.3635532888116729,\n",
      "                0.2524498269564052,\n",
      "                0.14926202811510378,\n",
      "                0.1502334109834052,\n",
      "                0.14884427627966443,\n",
      "                0.1482860578175233,\n",
      "                0.15197953279340687,\n",
      "                0.1463750692328525,\n",
      "                0.13598569527306942,\n",
      "                0.13730319220102016,\n",
      "                0.13745065049268596,\n",
      "                0.13557912467211675,\n",
      "                0.14003001297997186,\n",
      "                0.1404396176015386,\n",
      "                0.13441740529050694\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8674145299145298,\n",
      "            \"cross_entropy\": 0.5050732152477402,\n",
      "            \"brier\": 0.16481261263339628,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manifold bg samples: 100%|██████████| 74/74 [29:51<00:00, 24.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8450000000000001,\n",
      "                0.8591666666666666,\n",
      "                0.85,\n",
      "                0.7733333333333334,\n",
      "                0.7816666666666666,\n",
      "                0.8191666666666667,\n",
      "                0.8141666666666667,\n",
      "                0.7766666666666666,\n",
      "                0.7141666666666666,\n",
      "                0.5975,\n",
      "                0.5766666666666667,\n",
      "                0.5825,\n",
      "                0.5433333333333334,\n",
      "                0.46916666666666673,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.46348152504083573,\n",
      "                0.5038479840310148,\n",
      "                0.5062277931708253,\n",
      "                0.6479800762185679,\n",
      "                0.6461582365066487,\n",
      "                0.6605130525709751,\n",
      "                0.6558149596220079,\n",
      "                0.7215240101652228,\n",
      "                0.8338952198662308,\n",
      "                0.8588743065203527,\n",
      "                0.9002853485098862,\n",
      "                0.9133620650225307,\n",
      "                0.9295370430088399,\n",
      "                0.9619538315570729,\n",
      "                0.9404186671352546\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.1492416549855909,\n",
      "                0.1629012125470369,\n",
      "                0.16396808634695653,\n",
      "                0.22870896331308266,\n",
      "                0.22800589091359624,\n",
      "                0.23479346262302797,\n",
      "                0.23267722338674188,\n",
      "                0.2637506573531085,\n",
      "                0.3170941584787061,\n",
      "                0.32889041403406627,\n",
      "                0.34736017437099864,\n",
      "                0.35277400771985,\n",
      "                0.3596306736743654,\n",
      "                0.3737091000733354,\n",
      "                0.3649649438114703\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.7001666666666666,\n",
      "            \"cross_entropy\": 0.7429249412630844,\n",
      "            \"brier\": 0.2738980415754622,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.4225,\n",
      "                0.6683333333333333,\n",
      "                0.6933333333333332,\n",
      "                0.7933333333333333,\n",
      "                0.7858333333333333,\n",
      "                0.7633333333333334,\n",
      "                0.765,\n",
      "                0.7999999999999999,\n",
      "                0.8375,\n",
      "                0.8358333333333333,\n",
      "                0.8291666666666666,\n",
      "                0.8283333333333334,\n",
      "                0.8291666666666667,\n",
      "                0.8333333333333334,\n",
      "                0.8291666666666667\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                1.0581095902435442,\n",
      "                0.8155651816667262,\n",
      "                0.7864138774161455,\n",
      "                0.6125405354599703,\n",
      "                0.6052227086521177,\n",
      "                0.6100096415014459,\n",
      "                0.6026908768968381,\n",
      "                0.5728570196942204,\n",
      "                0.5056292270356424,\n",
      "                0.49910605040674827,\n",
      "                0.4911264546784567,\n",
      "                0.4910995079965055,\n",
      "                0.48945596872821817,\n",
      "                0.4871241976779984,\n",
      "                0.4891898601283233\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.40742211097577297,\n",
      "                0.3042629082718849,\n",
      "                0.29136965849380037,\n",
      "                0.20518321362393857,\n",
      "                0.20329716471241757,\n",
      "                0.2049975804299983,\n",
      "                0.20199408884024922,\n",
      "                0.1884796428397139,\n",
      "                0.16445716549037767,\n",
      "                0.1611399650273408,\n",
      "                0.1583433396955948,\n",
      "                0.1582349781241334,\n",
      "                0.15834470371442683,\n",
      "                0.15805205753032267,\n",
      "                0.15935898123209713\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.7676111111111114,\n",
      "            \"cross_entropy\": 0.6077427132121935,\n",
      "            \"brier\": 0.20832917060013792,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manifold bg samples: 100%|██████████| 74/74 [18:22<00:00, 14.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.897224306076519,\n",
      "                0.9069767441860466,\n",
      "                0.9129782445611403,\n",
      "                0.7644411102775694,\n",
      "                0.7719429857464366,\n",
      "                0.7606901725431358,\n",
      "                0.7246811702925732,\n",
      "                0.6789197299324831,\n",
      "                0.5288822205551389,\n",
      "                0.595648912228057,\n",
      "                0.5896474118529632,\n",
      "                0.5956489122280569,\n",
      "                0.6136534133533382,\n",
      "                0.6305326331582897,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.40288477563499814,\n",
      "                0.4141219458374432,\n",
      "                0.41417679382889977,\n",
      "                0.5933931234171496,\n",
      "                0.5965041379073557,\n",
      "                0.6067059708882301,\n",
      "                0.6364460728984707,\n",
      "                0.6639473867078696,\n",
      "                0.7668308904176752,\n",
      "                0.7595326233337698,\n",
      "                0.7661579588673484,\n",
      "                0.7931773833041441,\n",
      "                0.7961082722322681,\n",
      "                0.8083139504923024,\n",
      "                0.8937715432763311\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.12052601630371493,\n",
      "                0.12638005970204846,\n",
      "                0.1261688185171659,\n",
      "                0.20261567217435367,\n",
      "                0.2041715868388219,\n",
      "                0.20888071696318192,\n",
      "                0.22239251938262125,\n",
      "                0.2355871452240931,\n",
      "                0.28541246047322827,\n",
      "                0.2821666521598129,\n",
      "                0.28513967633944526,\n",
      "                0.29772671319422095,\n",
      "                0.2990120178331499,\n",
      "                0.3045942154665294,\n",
      "                0.3406323110321205\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6981245311327833,\n",
      "            \"cross_entropy\": 0.660804855269617,\n",
      "            \"brier\": 0.2360937721069672,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.6222805701425357,\n",
      "                0.7783195798949738,\n",
      "                0.7726931732933234,\n",
      "                0.8747186796699175,\n",
      "                0.8732183045761441,\n",
      "                0.903225806451613,\n",
      "                0.8762190547636909,\n",
      "                0.891972993248312,\n",
      "                0.8927231807951987,\n",
      "                0.8852213053263316,\n",
      "                0.886721680420105,\n",
      "                0.8829707426856714,\n",
      "                0.883720930232558,\n",
      "                0.8927231807951987,\n",
      "                0.8994748687171792\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.9268602038924735,\n",
      "                0.6722592621508194,\n",
      "                0.6627812384475171,\n",
      "                0.47068699841368167,\n",
      "                0.46374881396530954,\n",
      "                0.44817851054452523,\n",
      "                0.4379761029353042,\n",
      "                0.4095714928809875,\n",
      "                0.38784409963441907,\n",
      "                0.4037766887847375,\n",
      "                0.40286235033043494,\n",
      "                0.40813820587861405,\n",
      "                0.40286852981275734,\n",
      "                0.404710652495034,\n",
      "                0.40118807518577815\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.3524862497180961,\n",
      "                0.2410195326348351,\n",
      "                0.23688326480876082,\n",
      "                0.14672182381251211,\n",
      "                0.14446998378135734,\n",
      "                0.14116945381584864,\n",
      "                0.1364777020643822,\n",
      "                0.12572792968095206,\n",
      "                0.11669117542714758,\n",
      "                0.12039163413195296,\n",
      "                0.12032826631552897,\n",
      "                0.12208580366798558,\n",
      "                0.11995953548951802,\n",
      "                0.12092991294254503,\n",
      "                0.11986653926437998\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8544136034008503,\n",
      "            \"cross_entropy\": 0.4868967483568261,\n",
      "            \"brier\": 0.15768058717038685,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manifold bg samples: 100%|██████████| 74/74 [19:45<00:00, 16.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8525149190110827,\n",
      "                0.8303495311167945,\n",
      "                0.7459505541346974,\n",
      "                0.7399829497016197,\n",
      "                0.7681159420289855,\n",
      "                0.7766410912190963,\n",
      "                0.7365728900255755,\n",
      "                0.6828644501278772,\n",
      "                0.6743393009377665,\n",
      "                0.5490196078431373,\n",
      "                0.5865302642796248,\n",
      "                0.6359761295822677,\n",
      "                0.7553282182438192,\n",
      "                0.7382779198635976,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.45477821996255413,\n",
      "                0.5042463544750885,\n",
      "                0.5896987601156359,\n",
      "                0.5924033874684482,\n",
      "                0.5890342622559555,\n",
      "                0.59308825392315,\n",
      "                0.6342709196729989,\n",
      "                0.7253942018209167,\n",
      "                0.7277977778043497,\n",
      "                0.8262667573358111,\n",
      "                0.7975802127245412,\n",
      "                0.7931938865122938,\n",
      "                0.8062117066674712,\n",
      "                0.8243694360956015,\n",
      "                0.8697720218315294\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.1412383750959336,\n",
      "                0.16033216985162363,\n",
      "                0.2009963113523454,\n",
      "                0.2023450475292095,\n",
      "                0.2009209188145646,\n",
      "                0.2028300182896611,\n",
      "                0.22171563391312893,\n",
      "                0.26528440368204864,\n",
      "                0.2662845031885867,\n",
      "                0.3142345353319731,\n",
      "                0.30095981613197753,\n",
      "                0.29895634447346103,\n",
      "                0.3053434527265409,\n",
      "                0.31395187072787833,\n",
      "                0.3348469112139148\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.7048309178743961,\n",
      "            \"cross_entropy\": 0.6885404105777563,\n",
      "            \"brier\": 0.24868268748818986,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.5225916453537937,\n",
      "                0.7736572890025575,\n",
      "                0.83461210571185,\n",
      "                0.8465473145780049,\n",
      "                0.8269394714407502,\n",
      "                0.8184143222506394,\n",
      "                0.8303495311167947,\n",
      "                0.8516624040920716,\n",
      "                0.8576300085251493,\n",
      "                0.8508098891730604,\n",
      "                0.8482523444160274,\n",
      "                0.8491048593350383,\n",
      "                0.8456947996589941,\n",
      "                0.8499573742540495,\n",
      "                0.8533674339300937\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.8841799118706527,\n",
      "                0.7297076996195972,\n",
      "                0.5331960460257005,\n",
      "                0.5233725597654217,\n",
      "                0.516922577900446,\n",
      "                0.5289421244975764,\n",
      "                0.5025567734218431,\n",
      "                0.4637054547772893,\n",
      "                0.4593433748441408,\n",
      "                0.44908861473566974,\n",
      "                0.4505468720982317,\n",
      "                0.4510364561880388,\n",
      "                0.464261747871166,\n",
      "                0.46217289056521105,\n",
      "                0.45297774690534315\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.34116762828507174,\n",
      "                0.26808549839807233,\n",
      "                0.17021357612734983,\n",
      "                0.16589229095114658,\n",
      "                0.16436926876390767,\n",
      "                0.17088887869763533,\n",
      "                0.1582787810416096,\n",
      "                0.14510519634514157,\n",
      "                0.14336227826892914,\n",
      "                0.13955688109660172,\n",
      "                0.13935427773914172,\n",
      "                0.14018326257629826,\n",
      "                0.14503531778247264,\n",
      "                0.14378011729697168,\n",
      "                0.14064052329750873\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8173060528559248,\n",
      "            \"cross_entropy\": 0.5248007234057552,\n",
      "            \"brier\": 0.1717275851111906,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manifold bg samples: 100%|██████████| 74/74 [10:42<00:00,  8.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8289572393098273,\n",
      "                0.7606901725431358,\n",
      "                0.7599399849962492,\n",
      "                0.7164291072768192,\n",
      "                0.7288072018004501,\n",
      "                0.7445611402850713,\n",
      "                0.7404351087771942,\n",
      "                0.7633158289572393,\n",
      "                0.7389347336834208,\n",
      "                0.5030007501875469,\n",
      "                0.694298574643661,\n",
      "                0.6627906976744187,\n",
      "                0.6616654163540885,\n",
      "                0.4531132783195799,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.49632592747636495,\n",
      "                0.5643987344168251,\n",
      "                0.571175102485457,\n",
      "                0.6285383888137552,\n",
      "                0.6428295941459625,\n",
      "                0.6407472220988919,\n",
      "                0.6513830533185926,\n",
      "                0.7522478118176555,\n",
      "                0.8016668328943528,\n",
      "                0.8438274579794854,\n",
      "                0.8083182013309688,\n",
      "                0.8274990139227111,\n",
      "                0.8449545579930909,\n",
      "                0.8929301656294587,\n",
      "                0.8770640441784052\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.15883698253355397,\n",
      "                0.19061004602561749,\n",
      "                0.19387493895936755,\n",
      "                0.21996225058987556,\n",
      "                0.22651660691303555,\n",
      "                0.225571003554575,\n",
      "                0.22987597983697985,\n",
      "                0.2788111471394864,\n",
      "                0.30146869738616167,\n",
      "                0.31924157207207204,\n",
      "                0.3045865364114114,\n",
      "                0.3129245454204204,\n",
      "                0.3205085634384384,\n",
      "                0.34024235885885884,\n",
      "                0.3339753430930932\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6837959489872467,\n",
      "            \"cross_entropy\": 0.7229270739001319,\n",
      "            \"brier\": 0.26380043814886317,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.650787696924231,\n",
      "                0.8255813953488371,\n",
      "                0.8034508627156789,\n",
      "                0.826331582895724,\n",
      "                0.8162040510127533,\n",
      "                0.8203300825206301,\n",
      "                0.8289572393098275,\n",
      "                0.832708177044261,\n",
      "                0.8019504876219055,\n",
      "                0.8128282070517628,\n",
      "                0.8109527381845462,\n",
      "                0.8132033008252063,\n",
      "                0.8064516129032258,\n",
      "                0.8154538634658665,\n",
      "                0.8244561140285072\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.8975694028631751,\n",
      "                0.5625422769429589,\n",
      "                0.576273073979609,\n",
      "                0.4928850498307244,\n",
      "                0.49328874017645585,\n",
      "                0.4983179281388435,\n",
      "                0.507256909935697,\n",
      "                0.5155062783222324,\n",
      "                0.520195014728994,\n",
      "                0.5014737265323196,\n",
      "                0.5081027920801997,\n",
      "                0.5063216913919825,\n",
      "                0.5068943943624133,\n",
      "                0.5025047962107729,\n",
      "                0.49914526465592496\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.3418443483483484,\n",
      "                0.18668762237237244,\n",
      "                0.19257530930930936,\n",
      "                0.1547648328277257,\n",
      "                0.15458249705062208,\n",
      "                0.15692175214500215,\n",
      "                0.16175562111601396,\n",
      "                0.16446497938499727,\n",
      "                0.16628032353718517,\n",
      "                0.15759343344556292,\n",
      "                0.1603903742664859,\n",
      "                0.16024237449630752,\n",
      "                0.16029521114673345,\n",
      "                0.16002635111578414,\n",
      "                0.15791030935718886\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8059764941235308,\n",
      "            \"cross_entropy\": 0.5392184893434868,\n",
      "            \"brier\": 0.17575568932797597,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 456, 789, 1010]\n",
    "\n",
    "X = X[[\"xylose\", \"xanthosine\", \"uracil\", \"ribulose/xylulose\", \"valylglutamine\", \"tryptophylglycine\", \"succinate\", \"valine betaine\", \"ursodeoxycholate sulfate (1)\", \"tricarballylate\",\"succinimide\", \"thymine\", \"syringic acid\", \"serotonin\", \"ribitol\" ]]\n",
    "\n",
    "y = df_encoded['Group']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X),columns=X.columns,index=X.index)\n",
    "\n",
    "all_scores = {\n",
    "    'deletion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    },\n",
    "    'insertion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    }\n",
    "}\n",
    "\n",
    "for i in seeds:\n",
    "    print(\"Training Random Forest model...\")\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 7],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, n_iter=50,\n",
    "            cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    model = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "\n",
    "    #########################\n",
    "    def predict_proba_class1(X):\n",
    "        return model.predict_proba(X)[:, 1]  \n",
    "    \n",
    "    bg_mean = pd.DataFrame(X_train.mean()).T\n",
    "\n",
    "    orderings = [\n",
    "        [12, 11, 14, 3,  # root causes (syringic acid, thymine, ribitol, ribulose/xylulose)\n",
    "        1, 2, 0,  # intermediates (xanthosine, uracil, xylose)\n",
    "        4, 8, 9, 10, 6,  # intermediates (valylglutamine, ursodeoxycholate sulfate (1), tricarballylate, succinimide, succinate)\n",
    "        7, 13, 5]  # terminal nodes (valine betaine, serotonin, tryptophylglycine)\n",
    "    ]\n",
    "\n",
    "    explainer = OnManifoldExplainer(predict_proba_class1, pd.concat([bg_mean, X_test]), orderings=orderings)\n",
    "\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "\n",
    "    mean_abs_shap_series = pd.Series(mean_abs_shap.flatten(), index=X_test.columns) \n",
    "    #########################\n",
    "    \n",
    "    result = evaluate_global_shap_scores(model, X_test, y_test, mean_abs_shap_series, causal=True)\n",
    "\n",
    "    for method in ['deletion', 'insertion']:\n",
    "        for metric in ['auroc', 'cross_entropy', 'brier']:\n",
    "            all_scores[method][metric].append(result[method][\"average_scores\"][metric])\n",
    "\n",
    "    import json\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.6921752795988854,\n",
      "            \"std\": 0.011502098538809511\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.7054062996752448,\n",
      "            \"std\": 0.02838905134021829\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.2564624138611834,\n",
      "            \"std\": 0.01299724688165758\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.8225443582811895,\n",
      "            \"std\": 0.0356330652569389\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.5327463779132003,\n",
      "            \"std\": 0.04146676843585114\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.1756611289686175,\n",
      "            \"std\": 0.017456648263696528\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "final_results = {\n",
    "    'deletion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['deletion'].items()\n",
    "    },\n",
    "    'insertion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['insertion'].items()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(json.dumps(final_results, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Graph\n",
    "ribulose_xylulose = Node('ribulose/xylulose')\n",
    "xylose = Node('xylose')\n",
    "syringic_acid = Node('syringic acid')\n",
    "xanthosine = Node('xanthosine')\n",
    "uracil = Node('uracil')\n",
    "thymine = Node('thymine')\n",
    "ribitol = Node('ribitol')\n",
    "valylglutamine = Node('valylglutamine')\n",
    "tryptophylglycine = Node('tryptophylglycine')\n",
    "ursodeoxycholate = Node('ursodeoxycholate sulfate (1)')\n",
    "tricarballylate = Node('tricarballylate')\n",
    "succinimide = Node('succinimide')\n",
    "succinate = Node('succinate')\n",
    "valine_betaine = Node('valine betaine')\n",
    "serotonin = Node('serotonin')\n",
    "prob_class = Node('Prob_Class_1', is_target_node=True)\n",
    "\n",
    "xylose = Node(\n",
    "    'xylose',\n",
    "    lambda ribulose_xylulose: 0.8674788 * ribulose_xylulose,\n",
    "    [ribulose_xylulose]\n",
    ")\n",
    "\n",
    "xanthosine = Node(\n",
    "    'xanthosine',\n",
    "    lambda syringic_acid: 0.1901521 * syringic_acid,\n",
    "    [syringic_acid]\n",
    ")\n",
    "\n",
    "uracil = Node(\n",
    "    'uracil',\n",
    "    lambda xanthosine, thymine, ribitol: (\n",
    "        0.2527678 * xanthosine + \n",
    "        0.8636415 * thymine + \n",
    "        0.4761028 * ribitol\n",
    "    ),\n",
    "    [xanthosine, thymine, ribitol]\n",
    ")\n",
    "\n",
    "tryptophylglycine = Node(\n",
    "    'tryptophylglycine',\n",
    "    lambda valylglutamine, ursodeoxycholate: (\n",
    "        0.5859569 * valylglutamine + \n",
    "        0.1857000 * ursodeoxycholate\n",
    "    ),\n",
    "    [valylglutamine, ursodeoxycholate]\n",
    ")\n",
    "\n",
    "succinimide = Node(\n",
    "    'succinimide',\n",
    "    lambda tricarballylate: -0.1968689 * tricarballylate,\n",
    "    [tricarballylate]\n",
    ")\n",
    "\n",
    "succinate = Node(\n",
    "    'succinate',\n",
    "    lambda tryptophylglycine, succinimide: (\n",
    "        0.1726190 * tryptophylglycine + \n",
    "        0.3095849 * succinimide\n",
    "    ),\n",
    "    [tryptophylglycine, succinimide]\n",
    ")\n",
    "\n",
    "ribulose_xylulose = Node(\n",
    "    'ribulose/xylulose',\n",
    "    lambda uracil, succinate: (\n",
    "        0.5130565 * uracil + \n",
    "        0.3220030 * succinate\n",
    "    ),\n",
    "    [uracil, succinate]\n",
    ")\n",
    "\n",
    "prob_class = Node(\n",
    "    'Prob_Class_1',\n",
    "    lambda xylose, valine_betaine, serotonin: (\n",
    "        -0.5316215 * xylose + \n",
    "        -0.2937117 * valine_betaine + \n",
    "        -0.3372437 * serotonin\n",
    "    ),\n",
    "    [xylose, valine_betaine, serotonin],\n",
    "    is_target_node=True\n",
    ")\n",
    "\n",
    "nodes = [\n",
    "    ribulose_xylulose, xylose, syringic_acid, xanthosine, \n",
    "    uracil, thymine, ribitol, valylglutamine, \n",
    "    tryptophylglycine, ursodeoxycholate, tricarballylate,\n",
    "    succinimide, succinate, valine_betaine, serotonin, prob_class\n",
    "]\n",
    "\n",
    "graph = Graph(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manifold bg samples: 100%|██████████| 74/74 [19:48<00:00, 16.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.875801282051282,\n",
      "                0.7876602564102564,\n",
      "                0.7932692307692308,\n",
      "                0.6915064102564102,\n",
      "                0.6834935897435898,\n",
      "                0.734775641025641,\n",
      "                0.7355769230769231,\n",
      "                0.6386217948717949,\n",
      "                0.6450320512820513,\n",
      "                0.6714743589743589,\n",
      "                0.5472756410256411,\n",
      "                0.5689102564102564,\n",
      "                0.5657051282051282,\n",
      "                0.561298076923077,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.43669113234623613,\n",
      "                0.5388048363387743,\n",
      "                0.5392280241430504,\n",
      "                0.6252884908318787,\n",
      "                0.633111626046965,\n",
      "                0.7335953581502903,\n",
      "                0.7384849454721409,\n",
      "                0.7770661627597445,\n",
      "                0.788092377684378,\n",
      "                0.771898561332688,\n",
      "                0.8436854461387147,\n",
      "                0.838448453601495,\n",
      "                0.8638035119597676,\n",
      "                0.8895114950248152,\n",
      "                0.9272027411818561\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.13646746105293178,\n",
      "                0.17830100315149947,\n",
      "                0.17840241519735942,\n",
      "                0.21850628071836634,\n",
      "                0.22222391551421564,\n",
      "                0.270375971763844,\n",
      "                0.27227231301088717,\n",
      "                0.29040913354180675,\n",
      "                0.29532111174063974,\n",
      "                0.2880341301447121,\n",
      "                0.32173521461038423,\n",
      "                0.3195535765465894,\n",
      "                0.33096646989988726,\n",
      "                0.3422827996885224,\n",
      "                0.3581441230715909\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6666933760683759,\n",
      "            \"cross_entropy\": 0.7296608775341864,\n",
      "            \"brier\": 0.26819972797688246,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.6947115384615384,\n",
      "                0.8950320512820512,\n",
      "                0.8806089743589743,\n",
      "                0.872596153846154,\n",
      "                0.8749999999999999,\n",
      "                0.8629807692307693,\n",
      "                0.8613782051282051,\n",
      "                0.8966346153846154,\n",
      "                0.8950320512820512,\n",
      "                0.8942307692307692,\n",
      "                0.8782051282051282,\n",
      "                0.8814102564102564,\n",
      "                0.8782051282051282,\n",
      "                0.8766025641025641,\n",
      "                0.8782051282051282\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.942150054860188,\n",
      "                0.563900724261094,\n",
      "                0.5542958055399924,\n",
      "                0.47969978461525553,\n",
      "                0.4771367474239001,\n",
      "                0.45488978126142315,\n",
      "                0.45793087152552736,\n",
      "                0.43326107531745484,\n",
      "                0.43802380979274036,\n",
      "                0.4412488405348328,\n",
      "                0.4384906937386859,\n",
      "                0.43505172375888984,\n",
      "                0.4449253509023893,\n",
      "                0.44638355008879305,\n",
      "                0.43130759728033224\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.3635532888116729,\n",
      "                0.1856036561852923,\n",
      "                0.18154393305087835,\n",
      "                0.14875905232738046,\n",
      "                0.14884427627966443,\n",
      "                0.14127373472686025,\n",
      "                0.14276168563523914,\n",
      "                0.13275202438950412,\n",
      "                0.13598569527306942,\n",
      "                0.13730319220102016,\n",
      "                0.13671497346073322,\n",
      "                0.13557912467211675,\n",
      "                0.14003001297997186,\n",
      "                0.1404396176015386,\n",
      "                0.13441740529050694\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8680555555555554,\n",
      "            \"cross_entropy\": 0.4959130940600999,\n",
      "            \"brier\": 0.16037077819236326,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manifold bg samples: 100%|██████████| 74/74 [28:43<00:00, 23.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8450000000000001,\n",
      "                0.8141666666666667,\n",
      "                0.7833333333333333,\n",
      "                0.79,\n",
      "                0.7816666666666666,\n",
      "                0.7858333333333333,\n",
      "                0.8141666666666667,\n",
      "                0.7966666666666666,\n",
      "                0.7141666666666666,\n",
      "                0.5975,\n",
      "                0.5791666666666667,\n",
      "                0.5866666666666666,\n",
      "                0.5829166666666666,\n",
      "                0.59375,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.46348152504083573,\n",
      "                0.5594626201426361,\n",
      "                0.6422735643032516,\n",
      "                0.6425548453825349,\n",
      "                0.6461582365066487,\n",
      "                0.6426693107298991,\n",
      "                0.6558149596220079,\n",
      "                0.7525305519805069,\n",
      "                0.8338952198662308,\n",
      "                0.8588743065203527,\n",
      "                0.8700189923232652,\n",
      "                0.8577995220266754,\n",
      "                0.8831062620975887,\n",
      "                0.9236067718009598,\n",
      "                0.9404186671352546\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.1492416549855909,\n",
      "                0.1864823689350708,\n",
      "                0.2258973445476315,\n",
      "                0.2261942355494394,\n",
      "                0.22800589091359624,\n",
      "                0.22654566741300156,\n",
      "                0.23267722338674188,\n",
      "                0.2785935490990221,\n",
      "                0.3170941584787061,\n",
      "                0.32889041403406627,\n",
      "                0.3335256423775696,\n",
      "                0.32818562487590314,\n",
      "                0.33975010104491654,\n",
      "                0.35780297111009546,\n",
      "                0.3649649438114703\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.7043333333333331,\n",
      "            \"cross_entropy\": 0.7448443570319099,\n",
      "            \"brier\": 0.2749234527041881,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.4225,\n",
      "                0.7425,\n",
      "                0.7675,\n",
      "                0.76,\n",
      "                0.7858333333333333,\n",
      "                0.7916666666666666,\n",
      "                0.765,\n",
      "                0.8191666666666667,\n",
      "                0.8375,\n",
      "                0.8358333333333333,\n",
      "                0.8325,\n",
      "                0.8300000000000001,\n",
      "                0.8275,\n",
      "                0.8308333333333333,\n",
      "                0.8291666666666667\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                1.0581095902435442,\n",
      "                0.7325103820791401,\n",
      "                0.6336655627352441,\n",
      "                0.6254110501644493,\n",
      "                0.6052227086521177,\n",
      "                0.5991331849190027,\n",
      "                0.6026908768968381,\n",
      "                0.5316666782480418,\n",
      "                0.5056292270356424,\n",
      "                0.49910605040674827,\n",
      "                0.49936536058256076,\n",
      "                0.5030838429584268,\n",
      "                0.5012814049582596,\n",
      "                0.49102784065628935,\n",
      "                0.4891898601283233\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.40742211097577297,\n",
      "                0.2509022970803229,\n",
      "                0.2117742365237242,\n",
      "                0.2099068782699713,\n",
      "                0.20329716471241757,\n",
      "                0.20093333619447598,\n",
      "                0.20199408884024922,\n",
      "                0.17590282160002685,\n",
      "                0.16445716549037767,\n",
      "                0.1611399650273408,\n",
      "                0.1612497215710637,\n",
      "                0.1633008853745132,\n",
      "                0.16295956956780958,\n",
      "                0.1591191947949442,\n",
      "                0.15935898123209713\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.7785,\n",
      "            \"cross_entropy\": 0.5918062413776418,\n",
      "            \"brier\": 0.19958122781700713,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manifold bg samples: 100%|██████████| 74/74 [19:46<00:00, 16.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.897224306076519,\n",
      "                0.8304576144036009,\n",
      "                0.7719429857464366,\n",
      "                0.77344336084021,\n",
      "                0.7719429857464366,\n",
      "                0.7441860465116279,\n",
      "                0.7111777944486122,\n",
      "                0.7471867966991748,\n",
      "                0.6729182295573893,\n",
      "                0.595648912228057,\n",
      "                0.5896474118529632,\n",
      "                0.6016504126031508,\n",
      "                0.5577644411102776,\n",
      "                0.5626406601650413,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.40288477563499814,\n",
      "                0.5259650674721693,\n",
      "                0.587662607299144,\n",
      "                0.5928428069160117,\n",
      "                0.5965041379073557,\n",
      "                0.6201038196823963,\n",
      "                0.6940660403657485,\n",
      "                0.6861717333666404,\n",
      "                0.7317392661288826,\n",
      "                0.7595326233337698,\n",
      "                0.7661579588673484,\n",
      "                0.7666894011953829,\n",
      "                0.8391446468202268,\n",
      "                0.8507441265848273,\n",
      "                0.8937715432763311\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.12052601630371493,\n",
      "                0.17005606902148862,\n",
      "                0.2000310262409235,\n",
      "                0.20258687982311638,\n",
      "                0.2041715868388219,\n",
      "                0.21487707289666366,\n",
      "                0.2507481598082458,\n",
      "                0.24709801087710798,\n",
      "                0.26891844618991867,\n",
      "                0.2821666521598129,\n",
      "                0.28513967633944526,\n",
      "                0.2852881158908696,\n",
      "                0.3172785108476887,\n",
      "                0.3223428025595217,\n",
      "                0.3406323110321205\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6885221305326331,\n",
      "            \"cross_entropy\": 0.6875987036567489,\n",
      "            \"brier\": 0.24745742245529734,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.6222805701425357,\n",
      "                0.8687171792948238,\n",
      "                0.8777194298574643,\n",
      "                0.8724681170292574,\n",
      "                0.8732183045761441,\n",
      "                0.8927231807951987,\n",
      "                0.9069767441860466,\n",
      "                0.9024756189047262,\n",
      "                0.8829707426856714,\n",
      "                0.8852213053263316,\n",
      "                0.886721680420105,\n",
      "                0.8837209302325582,\n",
      "                0.8957239309827457,\n",
      "                0.8957239309827456,\n",
      "                0.8994748687171792\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.9268602038924735,\n",
      "                0.5659833927304229,\n",
      "                0.4789439281995496,\n",
      "                0.4720073639113456,\n",
      "                0.46374881396530954,\n",
      "                0.43031135973610957,\n",
      "                0.3919251150819651,\n",
      "                0.4000237229752986,\n",
      "                0.40542211211378776,\n",
      "                0.4037766887847375,\n",
      "                0.40286235033043494,\n",
      "                0.3982638636636216,\n",
      "                0.39408404859511226,\n",
      "                0.3989797570020913,\n",
      "                0.40118807518577815\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.3524862497180961,\n",
      "                0.18776901948858687,\n",
      "                0.14807165879361645,\n",
      "                0.1461601158512945,\n",
      "                0.14446998378135734,\n",
      "                0.13143164343033845,\n",
      "                0.11813343909348381,\n",
      "                0.12024569987243837,\n",
      "                0.12129463646607917,\n",
      "                0.12039163413195296,\n",
      "                0.12032826631552897,\n",
      "                0.11849101433390234,\n",
      "                0.11694038427102484,\n",
      "                0.11867717145159401,\n",
      "                0.11986653926437998\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8697424356089022,\n",
      "            \"cross_entropy\": 0.46229205307786914,\n",
      "            \"brier\": 0.1456504970842449,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manifold bg samples: 100%|██████████| 74/74 [19:44<00:00, 16.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8525149190110827,\n",
      "                0.8167092924126172,\n",
      "                0.8448422847399829,\n",
      "                0.7698209718670077,\n",
      "                0.7681159420289855,\n",
      "                0.7672634271099744,\n",
      "                0.7715260017050298,\n",
      "                0.7433930093776641,\n",
      "                0.6743393009377665,\n",
      "                0.5490196078431373,\n",
      "                0.5677749360613811,\n",
      "                0.6359761295822677,\n",
      "                0.7553282182438192,\n",
      "                0.7382779198635976,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.45477821996255413,\n",
      "                0.5256099554425006,\n",
      "                0.5222032977165597,\n",
      "                0.5910661323167326,\n",
      "                0.5890342622559555,\n",
      "                0.589970107828804,\n",
      "                0.5917311316661136,\n",
      "                0.6324494998198492,\n",
      "                0.7277977778043497,\n",
      "                0.8262667573358111,\n",
      "                0.8217587523528829,\n",
      "                0.7931938865122938,\n",
      "                0.8062117066674712,\n",
      "                0.8243694360956015,\n",
      "                0.8697720218315294\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.1412383750959336,\n",
      "                0.17239494574144393,\n",
      "                0.17055408536923194,\n",
      "                0.20180219421713533,\n",
      "                0.2009209188145646,\n",
      "                0.20128165096391246,\n",
      "                0.202244828843674,\n",
      "                0.22086309502970544,\n",
      "                0.2662845031885867,\n",
      "                0.3142345353319731,\n",
      "                0.31224347218580323,\n",
      "                0.29895634447346103,\n",
      "                0.3053434527265409,\n",
      "                0.31395187072787833,\n",
      "                0.3348469112139148\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.7169934640522876,\n",
      "            \"cross_entropy\": 0.6777475297072671,\n",
      "            \"brier\": 0.24381074559491728,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.5225916453537937,\n",
      "                0.8226768968456948,\n",
      "                0.7877237851662404,\n",
      "                0.8192668371696505,\n",
      "                0.8269394714407502,\n",
      "                0.8320545609548167,\n",
      "                0.8226768968456948,\n",
      "                0.8329070758738278,\n",
      "                0.8576300085251493,\n",
      "                0.8508098891730604,\n",
      "                0.8508098891730606,\n",
      "                0.8491048593350383,\n",
      "                0.8456947996589941,\n",
      "                0.8499573742540495,\n",
      "                0.8533674339300937\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.8841799118706527,\n",
      "                0.643442574542808,\n",
      "                0.6261513760082309,\n",
      "                0.5242129172385113,\n",
      "                0.516922577900446,\n",
      "                0.5108174430060799,\n",
      "                0.5203417820353451,\n",
      "                0.495574611513594,\n",
      "                0.4593433748441408,\n",
      "                0.44908861473566974,\n",
      "                0.4538090653171603,\n",
      "                0.4510364561880388,\n",
      "                0.464261747871166,\n",
      "                0.46217289056521105,\n",
      "                0.45297774690534315\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.34116762828507174,\n",
      "                0.21767892007545953,\n",
      "                0.2101565797175451,\n",
      "                0.16711517726817157,\n",
      "                0.16436926876390767,\n",
      "                0.16260063586950751,\n",
      "                0.16786037694503358,\n",
      "                0.15586039742713897,\n",
      "                0.14336227826892914,\n",
      "                0.13955688109660172,\n",
      "                0.14143827453103525,\n",
      "                0.14018326257629826,\n",
      "                0.14503531778247264,\n",
      "                0.14378011729697168,\n",
      "                0.14064052329750873\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.814947428246661,\n",
      "            \"cross_entropy\": 0.52762220603616,\n",
      "            \"brier\": 0.17205370928011024,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manifold bg samples: 100%|██████████| 74/74 [10:39<00:00,  8.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deletion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.8289572393098273,\n",
      "                0.7606901725431358,\n",
      "                0.7599399849962492,\n",
      "                0.7164291072768192,\n",
      "                0.7288072018004501,\n",
      "                0.7445611402850713,\n",
      "                0.7404351087771942,\n",
      "                0.7633158289572393,\n",
      "                0.7389347336834208,\n",
      "                0.5030007501875469,\n",
      "                0.694298574643661,\n",
      "                0.6627906976744187,\n",
      "                0.6616654163540885,\n",
      "                0.4531132783195799,\n",
      "                0.5\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.49632592747636495,\n",
      "                0.5643987344168251,\n",
      "                0.571175102485457,\n",
      "                0.6285383888137552,\n",
      "                0.6428295941459625,\n",
      "                0.6407472220988919,\n",
      "                0.6513830533185926,\n",
      "                0.7522478118176555,\n",
      "                0.8016668328943528,\n",
      "                0.8438274579794854,\n",
      "                0.8083182013309688,\n",
      "                0.8274990139227111,\n",
      "                0.8449545579930909,\n",
      "                0.8929301656294587,\n",
      "                0.8770640441784052\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.15883698253355397,\n",
      "                0.19061004602561749,\n",
      "                0.19387493895936755,\n",
      "                0.21996225058987556,\n",
      "                0.22651660691303555,\n",
      "                0.225571003554575,\n",
      "                0.22987597983697985,\n",
      "                0.2788111471394864,\n",
      "                0.30146869738616167,\n",
      "                0.31924157207207204,\n",
      "                0.3045865364114114,\n",
      "                0.3129245454204204,\n",
      "                0.3205085634384384,\n",
      "                0.34024235885885884,\n",
      "                0.3339753430930932\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.6837959489872467,\n",
      "            \"cross_entropy\": 0.7229270739001319,\n",
      "            \"brier\": 0.26380043814886317,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"stepwise_metrics\": {\n",
      "            \"auroc\": [\n",
      "                0.650787696924231,\n",
      "                0.8255813953488371,\n",
      "                0.8034508627156789,\n",
      "                0.826331582895724,\n",
      "                0.8162040510127533,\n",
      "                0.8203300825206301,\n",
      "                0.8289572393098275,\n",
      "                0.832708177044261,\n",
      "                0.8019504876219055,\n",
      "                0.8128282070517628,\n",
      "                0.8109527381845462,\n",
      "                0.8132033008252063,\n",
      "                0.8064516129032258,\n",
      "                0.8154538634658665,\n",
      "                0.8244561140285072\n",
      "            ],\n",
      "            \"cross_entropy\": [\n",
      "                0.8975694028631751,\n",
      "                0.5625422769429589,\n",
      "                0.576273073979609,\n",
      "                0.4928850498307244,\n",
      "                0.49328874017645585,\n",
      "                0.4983179281388435,\n",
      "                0.507256909935697,\n",
      "                0.5155062783222324,\n",
      "                0.520195014728994,\n",
      "                0.5014737265323196,\n",
      "                0.5081027920801997,\n",
      "                0.5063216913919825,\n",
      "                0.5068943943624133,\n",
      "                0.5025047962107729,\n",
      "                0.49914526465592496\n",
      "            ],\n",
      "            \"brier\": [\n",
      "                0.3418443483483484,\n",
      "                0.18668762237237244,\n",
      "                0.19257530930930936,\n",
      "                0.1547648328277257,\n",
      "                0.15458249705062208,\n",
      "                0.15692175214500215,\n",
      "                0.16175562111601396,\n",
      "                0.16446497938499727,\n",
      "                0.16628032353718517,\n",
      "                0.15759343344556292,\n",
      "                0.1603903742664859,\n",
      "                0.16024237449630752,\n",
      "                0.16029521114673345,\n",
      "                0.16002635111578414,\n",
      "                0.15791030935718886\n",
      "            ],\n",
      "            \"rmse\": [],\n",
      "            \"mae\": [],\n",
      "            \"r_squared\": []\n",
      "        },\n",
      "        \"average_scores\": {\n",
      "            \"auroc\": 0.8059764941235308,\n",
      "            \"cross_entropy\": 0.5392184893434868,\n",
      "            \"brier\": 0.17575568932797597,\n",
      "            \"rmse\": NaN,\n",
      "            \"mae\": NaN,\n",
      "            \"r_squared\": NaN\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 456, 789, 1010]\n",
    "\n",
    "X = X[[\"xylose\", \"xanthosine\", \"uracil\", \"ribulose/xylulose\", \"valylglutamine\", \"tryptophylglycine\", \"succinate\", \"valine betaine\", \"ursodeoxycholate sulfate (1)\", \"tricarballylate\",\"succinimide\", \"thymine\", \"syringic acid\", \"serotonin\", \"ribitol\" ]]\n",
    "\n",
    "y = df_encoded['Group']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X),columns=X.columns,index=X.index)\n",
    "\n",
    "all_scores = {\n",
    "    'deletion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    },\n",
    "    'insertion': {\n",
    "        'auroc': [],\n",
    "        'cross_entropy': [],\n",
    "        'brier': []\n",
    "    }\n",
    "}\n",
    "\n",
    "for i in seeds:\n",
    "    print(\"Training Random Forest model...\")\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 7],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, n_iter=50,\n",
    "            cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    model = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "\n",
    "    #########################\n",
    "    def predict_proba_class1(X):\n",
    "        return model.predict_proba(X)[:, 1]  \n",
    "    \n",
    "    bg_mean = pd.DataFrame(X_train.mean()).T\n",
    "\n",
    "    graph_explainer = GraphExplainer(graph, bg_mean)\n",
    "\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "\n",
    "    mean_abs_shap_series = pd.Series(mean_abs_shap.flatten(), index=X_test.columns) \n",
    "    #########################\n",
    "    \n",
    "    result = evaluate_global_shap_scores(model, X_test, y_test, mean_abs_shap_series, causal=True)\n",
    "\n",
    "    for method in ['deletion', 'insertion']:\n",
    "        for metric in ['auroc', 'cross_entropy', 'brier']:\n",
    "            all_scores[method][metric].append(result[method][\"average_scores\"][metric])\n",
    "\n",
    "    import json\n",
    "\n",
    "    print(json.dumps(result, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "{\n",
      "    \"deletion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.6920676505947754,\n",
      "            \"std\": 0.017300801815510077\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.7125557083660489,\n",
      "            \"std\": 0.025601446262198797\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.2596383573760297,\n",
      "            \"std\": 0.012026159755735429\n",
      "        }\n",
      "    },\n",
      "    \"insertion\": {\n",
      "        \"auroc\": {\n",
      "            \"mean\": 0.8274443827069298,\n",
      "            \"std\": 0.035919324461945755\n",
      "        },\n",
      "        \"cross_entropy\": {\n",
      "            \"mean\": 0.5233704167790515,\n",
      "            \"std\": 0.043444613676933655\n",
      "        },\n",
      "        \"brier\": {\n",
      "            \"mean\": 0.17068238034034028,\n",
      "            \"std\": 0.017864415528248787\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "final_results = {\n",
    "    'deletion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['deletion'].items()\n",
    "    },\n",
    "    'insertion': {\n",
    "        metric: {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        }\n",
    "        for metric, scores in all_scores['insertion'].items()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(json.dumps(final_results, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
